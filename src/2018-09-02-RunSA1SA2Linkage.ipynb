{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/tf-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/paperspace/anaconda3/envs/tf-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import ggcnn.experiment as experiment\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def load_sa1_dataset():\n",
    "    keys_SA1 = []\n",
    "    features_SA1 = []\n",
    "    labels = []\n",
    "    keys_SA2 = []\n",
    "    features_SA2 = []\n",
    "    \n",
    "    # Load SA1 Node Features\n",
    "    with open('Data/2018-09-02-NSW-SA1Input-Normalised.csv', 'r') as file:\n",
    "        for i, line in enumerate(file):\n",
    "            if i == 0:  # Skip first line (header)\n",
    "                continue\n",
    "            s = line[:-1].split(',')  # Last value in line is \\n\n",
    "            keys_SA1.append(s[0])\n",
    "            features_SA1.extend([float(v) for v in s[1:-1]])  # Last column is the outcome y\n",
    "#             labels.append(np.floor(float(s[-1]) / 10).astype(int))\n",
    "            labels.append(float(s[-1]))\n",
    "    \n",
    "    \n",
    "    # Load SA2 Node Features\n",
    "    with open('Data/2018-08-28-NSW-SA2Input-Normalised.csv', 'r') as file:\n",
    "        for i, line in enumerate(file):\n",
    "            if i == 0:  # Skip first line (header)\n",
    "                continue\n",
    "            s = line[:-1].split(',')  # Last value in line is \\n\n",
    "            keys_SA2.append(s[0])\n",
    "            features_SA2.extend([float(v) for v in s[1:-1]])  # Last column is the outcome y\n",
    "\n",
    "    labels = np.array(labels)\n",
    "    features_SA1 = np.array(features_SA1).reshape((len(keys_SA1), -1))\n",
    "    features_SA2 = np.array(features_SA2).reshape((len(keys_SA2), -1))\n",
    "    \n",
    "    # Load SA1 Link Features\n",
    "    with open('Data/Geography/2018-09-01-NSW-Neighbouring_Suburbs_With_Bridges-Filtered.csv', 'r') as file:\n",
    "        adj_mat_SA1 = np.zeros((len(keys_SA1), len(keys_SA1)))\n",
    "        for i, line in enumerate(file):\n",
    "            if i == 0:  # Skip first line (header)\n",
    "                continue\n",
    "            s = line[:-1].split(',')\n",
    "            a = keys_SA1.index(s[0])\n",
    "            b = keys_SA1.index(s[1])\n",
    "            adj_mat_SA1[a, b] = 1\n",
    "            adj_mat_SA1[b, a] = 1\n",
    "    \n",
    "\n",
    "    # Load SA2 Link Features\n",
    "    with open('Data/Geography/2018-09-01-SA2Neighbouring_Suburbs_With_Bridges-Filtered.csv', 'r') as file:\n",
    "        adj_mat_SA2 = np.zeros((len(keys_SA2), len(keys_SA2)))\n",
    "        for i, line in enumerate(file):\n",
    "            if i == 0:  # Skip first line (header)\n",
    "                continue\n",
    "            s = line[:-1].split(',')\n",
    "            a = keys_SA2.index(s[0])\n",
    "            b = keys_SA2.index(s[1])\n",
    "            adj_mat_SA2[a, b] = 1\n",
    "            adj_mat_SA2[b, a] = 1\n",
    "    \n",
    "    \n",
    "    # Load SA1, SA2 Links\n",
    "    with open('Data/2018-09-02-SA1SA2Links.csv', 'r') as file:\n",
    "        adj_mat_SA1SA2 = np.zeros((len(keys_SA1), len(keys_SA2)))\n",
    "        for i, line in enumerate(file):\n",
    "            if i == 0:  # Skip first line (header)\n",
    "                continue\n",
    "            s = line[:-1].split(',')\n",
    "            a = keys_SA1.index(s[0])\n",
    "            b = keys_SA2.index(s[1])\n",
    "            adj_mat_SA1SA2[a, b] = 1\n",
    "    \n",
    "    adj_mat_SA2SA1 = np.transpose(adj_mat_SA1SA2)\n",
    "    \n",
    "    return (features_SA1, adj_mat_SA1, labels, features_SA2, adj_mat_SA2, adj_mat_SA1SA2, adj_mat_SA2SA1), (keys_SA1, keys_SA2)\n",
    "\n",
    "dataset, keys = load_sa1_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SA1Experiment():\n",
    "    def __init__(self, neurons, blocks, reverseLinkagePosition = \"Early\", linkagePosition = \"Late\",\n",
    "                    linkageActFun = True, linkageBatchNorm = True, linkageNeurons = None,\n",
    "                    auxilaryEmbedding1 = False, auxilaryEmbedding2 = False,\n",
    "                    auxilaryGraph = False, linkage_adjustment_components = None):\n",
    "        self.blocks = blocks\n",
    "        self.neurons = neurons\n",
    "        self.reverseLinkagePosition = reverseLinkagePosition\n",
    "        self.linkagePosition = linkagePosition\n",
    "        self.linkageActFun = linkageActFun\n",
    "        self.linkageBatchNorm = linkageBatchNorm\n",
    "        self.linkageNeurons = linkageNeurons\n",
    "        self.auxilaryEmbedding1 = auxilaryEmbedding1\n",
    "        self.auxilaryEmbedding2 = auxilaryEmbedding2\n",
    "        self.auxilaryGraph = auxilaryGraph\n",
    "        self.linkage_adjustment_components = linkage_adjustment_components\n",
    "    \n",
    "    def create_network(self, net, input):\n",
    "        net.create_network(input)\n",
    "\n",
    "        if self.linkage_adjustment_components is not None:\n",
    "            net.make_linkage_adjustment_layer()\n",
    "        \n",
    "        if self.reverseLinkagePosition == \"Early\" or self.reverseLinkagePosition == \"Both\":\n",
    "            net.make_reverse_auxilary_linkage_layer(self.linkageNeurons, with_act_func = self.linkageActFun, with_bn = self.linkageBatchNorm)\n",
    "        if self.linkagePosition == \"Early\" or self.linkagePosition == \"Both\":\n",
    "            net.make_auxilary_linkage_layer(self.linkageNeurons, with_act_func = self.linkageActFun, with_bn = self.linkageBatchNorm)\n",
    "        \n",
    "        net.make_embedding_layer(self.neurons)\n",
    "        net.make_dropout_layer()\n",
    "        \n",
    "        for _ in range(self.blocks):\n",
    "            net.make_graphcnn_layer(self.neurons)\n",
    "            net.make_dropout_layer()\n",
    "            net.make_embedding_layer(self.neurons)\n",
    "            net.make_dropout_layer()\n",
    "        \n",
    "        if self.auxilaryEmbedding1:\n",
    "            net.make_auxilary_embedding_layer(self.neurons)\n",
    "            net.make_dropout_layer(input_type = 'current_V_auxilary')\n",
    "        if self.reverseLinkagePosition == \"Late\" or self.reverseLinkagePosition == \"Both\":\n",
    "            net.make_reverse_auxilary_linkage_layer(self.linkageNeurons, with_act_func = self.linkageActFun, with_bn = self.linkageBatchNorm)\n",
    "        if self.auxilaryEmbedding2:\n",
    "            net.make_auxilary_embedding_layer(self.neurons)\n",
    "            net.make_dropout_layer(input_type = 'current_V_auxilary')\n",
    "        if self.auxilaryGraph:\n",
    "            net.make_auxilary_graphcnn_layer(self.neurons)\n",
    "            net.make_dropout_layer(input_type = 'current_V_auxilary')\n",
    "        if self.linkagePosition == \"Late\" or self.linkagePosition == \"Both\":\n",
    "            net.make_auxilary_linkage_layer(self.linkageNeurons, with_act_func = self.linkageActFun, with_bn = self.linkageBatchNorm)\n",
    "        \n",
    "        net.make_embedding_layer(self.neurons)\n",
    "        net.make_embedding_layer(1, name='final', with_bn=False, with_act_func = False)\n",
    "\n",
    "\n",
    "######\n",
    "\n",
    "def run(no_folds = 5, supervised = True, i = 0, l = 2, n = 128, expParameters = {}):\n",
    "    inst = KFold(n_splits = no_folds, shuffle=True, random_state=125)\n",
    "        \n",
    "    exp = experiment.GGCNNExperiment('2018-08-28-SA1SA2', '2018-08-28-SA1SA2', SA1Experiment(neurons = n, blocks = l, **expParameters))\n",
    "\n",
    "    exp.num_iterations = 5000\n",
    "    exp.optimizer = 'adam'\n",
    "    exp.loss_type = 'linear'\n",
    "\n",
    "    exp.debug = True  # Was True\n",
    "\n",
    "    exp.preprocess_data(dataset)\n",
    "\n",
    "    valid_idx = np.flatnonzero(dataset[2] >= 0)  # Missing data labelled with -1\n",
    "    if supervised:\n",
    "        train_idx, test_idx = list(inst.split( valid_idx ))[i]\n",
    "    else:\n",
    "        test_idx, train_idx = list(inst.split( valid_idx ))[i]  # Reversed to get more samples in the test set than the training set\n",
    "\n",
    "    n_components = expParameters.get('linkage_adjustment_components', None)\n",
    "    exp.create_data(train_idx, test_idx, n_components = n_components)\n",
    "    exp.build_network()\n",
    "    results = exp.run()\n",
    "    \n",
    "    # Node type of input nodes: 0 = training set; 1 = test set; -1 = neither\n",
    "    idx_split = np.empty((len(dataset[2]), 1))\n",
    "    idx_split.fill(-1)\n",
    "    idx_split[train_idx] = 0\n",
    "    idx_split[test_idx] = 1\n",
    "\n",
    "    return results, idx_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:43:29.856494 Creating training Tensorflow Tensors\n",
      "PCA variance ratio:  [0.17138445 0.12530963 0.08620866]\n",
      "2018-09-02 03:43:29.992220 Creating training network\n",
      "2018-09-02 03:43:30.903594 Creating loss function and summaries\n",
      "2018-09-02 03:43:31.089888 Training model \"2018-08-28-SA1SA2\"!\n",
      "2018-09-02 03:43:31.089997 Preparing training\n",
      "2018-09-02 03:43:33.855414 Starting threads\n",
      "2018-09-02 03:43:33.855581 Starting training. train_batch_size: 0 test_batch_size: 0\n",
      "2018-09-02 03:43:34.800175 Test Step 0 Finished\n",
      "2018-09-02 03:43:34.800299 Test Step 0 \"min loss\" =  4.0179608e+17\n",
      "2018-09-02 03:43:34.800353 Test Step 0 \"loss\" =  4.0179608e+17\n",
      "2018-09-02 03:43:37.791144 Training Step 0 Finished Timing (Training: 0.760064, Test: 0.23987) after 3.93478 seconds\n",
      "2018-09-02 03:43:37.791270 Training Step 0 \"min loss\" =  2716.7556\n",
      "2018-09-02 03:43:37.791340 Training Step 0 \"loss\" =  2716.7556\n",
      "2018-09-02 03:43:38.427577 Test Step 5 Finished\n",
      "2018-09-02 03:43:38.427694 Test Step 5 \"min loss\" =  2695.7793\n",
      "2018-09-02 03:43:38.427775 Test Step 5 \"loss\" =  2695.7793\n",
      "2018-09-02 03:43:38.562596 Training Step 5 Finished Timing (Training: 0.920242, Test: 0.0793795) after 0.771198 seconds\n",
      "2018-09-02 03:43:38.562886 Training Step 5 \"min loss\" =  2655.564\n",
      "2018-09-02 03:43:38.562952 Training Step 5 \"loss\" =  2655.564\n",
      "2018-09-02 03:43:39.208765 Test Step 10 Finished\n",
      "2018-09-02 03:43:39.209282 Test Step 10 \"min loss\" =  2640.367\n",
      "2018-09-02 03:43:39.209360 Test Step 10 \"loss\" =  2640.367\n",
      "2018-09-02 03:43:39.357729 Training Step 10 Finished Timing (Training: 0.922573, Test: 0.0765324) after 0.794709 seconds\n",
      "2018-09-02 03:43:39.358041 Training Step 10 \"min loss\" =  2597.3164\n",
      "2018-09-02 03:43:39.358112 Training Step 10 \"loss\" =  2597.3164\n",
      "2018-09-02 03:43:39.991924 Test Step 15 Finished\n",
      "2018-09-02 03:43:39.992030 Test Step 15 \"min loss\" =  2561.0774\n",
      "2018-09-02 03:43:39.992127 Test Step 15 \"loss\" =  2561.0774\n",
      "2018-09-02 03:43:40.137708 Training Step 15 Finished Timing (Training: 0.921243, Test: 0.0778396) after 0.779528 seconds\n",
      "2018-09-02 03:43:40.137784 Training Step 15 \"min loss\" =  2545.9785\n",
      "2018-09-02 03:43:40.137845 Training Step 15 \"loss\" =  2545.9785\n",
      "2018-09-02 03:43:40.774222 Test Step 20 Finished\n",
      "2018-09-02 03:43:40.774356 Test Step 20 \"min loss\" =  2486.842\n",
      "2018-09-02 03:43:40.775059 Test Step 20 \"loss\" =  2486.842\n",
      "2018-09-02 03:43:40.924964 Training Step 20 Finished Timing (Training: 0.922098, Test: 0.076757) after 0.787046 seconds\n",
      "2018-09-02 03:43:40.925085 Training Step 20 \"min loss\" =  2498.8184\n",
      "2018-09-02 03:43:40.925734 Training Step 20 \"loss\" =  2498.8184\n",
      "2018-09-02 03:43:41.573268 Test Step 25 Finished\n",
      "2018-09-02 03:43:41.573401 Test Step 25 \"min loss\" =  2417.7974\n",
      "2018-09-02 03:43:41.573992 Test Step 25 \"loss\" =  2417.7974\n",
      "2018-09-02 03:43:41.720023 Training Step 25 Finished Timing (Training: 0.921048, Test: 0.0776089) after 0.794186 seconds\n",
      "2018-09-02 03:43:41.720163 Training Step 25 \"min loss\" =  2454.5654\n",
      "2018-09-02 03:43:41.720238 Training Step 25 \"loss\" =  2454.5654\n",
      "2018-09-02 03:43:42.353680 Test Step 30 Finished\n",
      "2018-09-02 03:43:42.353780 Test Step 30 \"min loss\" =  2357.6292\n",
      "2018-09-02 03:43:42.354267 Test Step 30 \"loss\" =  2357.6292\n",
      "2018-09-02 03:43:42.494377 Training Step 30 Finished Timing (Training: 0.920098, Test: 0.0785729) after 0.774061 seconds\n",
      "2018-09-02 03:43:42.494459 Training Step 30 \"min loss\" =  2407.4097\n",
      "2018-09-02 03:43:42.494501 Training Step 30 \"loss\" =  2407.4097\n",
      "2018-09-02 03:43:43.132928 Test Step 35 Finished\n",
      "2018-09-02 03:43:43.133362 Test Step 35 \"min loss\" =  2325.2444\n",
      "2018-09-02 03:43:43.133436 Test Step 35 \"loss\" =  2325.2444\n",
      "2018-09-02 03:43:43.280018 Training Step 35 Finished Timing (Training: 0.919761, Test: 0.0789579) after 0.785463 seconds\n",
      "2018-09-02 03:43:43.280095 Training Step 35 \"min loss\" =  2362.9634\n",
      "2018-09-02 03:43:43.280136 Training Step 35 \"loss\" =  2362.9634\n",
      "2018-09-02 03:43:43.931031 Test Step 40 Finished\n",
      "2018-09-02 03:43:43.931141 Test Step 40 \"min loss\" =  2275.8074\n",
      "2018-09-02 03:43:43.931209 Test Step 40 \"loss\" =  2275.8074\n",
      "2018-09-02 03:43:44.076235 Training Step 40 Finished Timing (Training: 0.919665, Test: 0.0789905) after 0.796016 seconds\n",
      "2018-09-02 03:43:44.076305 Training Step 40 \"min loss\" =  2318.7937\n",
      "2018-09-02 03:43:44.076359 Training Step 40 \"loss\" =  2318.7937\n",
      "2018-09-02 03:43:44.703780 Test Step 45 Finished\n",
      "2018-09-02 03:43:44.703909 Test Step 45 \"min loss\" =  2225.5977\n",
      "2018-09-02 03:43:44.704421 Test Step 45 \"loss\" =  2225.5977\n",
      "2018-09-02 03:43:44.847697 Training Step 45 Finished Timing (Training: 0.920015, Test: 0.078603) after 0.771274 seconds\n",
      "2018-09-02 03:43:44.847797 Training Step 45 \"min loss\" =  2270.8462\n",
      "2018-09-02 03:43:44.847840 Training Step 45 \"loss\" =  2270.8462\n",
      "2018-09-02 03:43:45.498200 Test Step 50 Finished\n",
      "2018-09-02 03:43:45.498318 Test Step 50 \"min loss\" =  2170.8955\n",
      "2018-09-02 03:43:45.498398 Test Step 50 \"loss\" =  2170.8955\n",
      "2018-09-02 03:43:45.639482 Training Step 50 Finished Timing (Training: 0.920097, Test: 0.0785965) after 0.791588 seconds\n",
      "2018-09-02 03:43:45.639561 Training Step 50 \"min loss\" =  2227.2764\n",
      "2018-09-02 03:43:45.639631 Training Step 50 \"loss\" =  2227.2764\n",
      "2018-09-02 03:43:46.275648 Test Step 55 Finished\n",
      "2018-09-02 03:43:46.275763 Test Step 55 \"min loss\" =  2114.097\n",
      "2018-09-02 03:43:46.275826 Test Step 55 \"loss\" =  2114.097\n",
      "2018-09-02 03:43:46.411272 Training Step 55 Finished Timing (Training: 0.919617, Test: 0.0791305) after 0.771537 seconds\n",
      "2018-09-02 03:43:46.411345 Training Step 55 \"min loss\" =  2189.7688\n",
      "2018-09-02 03:43:46.411417 Training Step 55 \"loss\" =  2189.7688\n",
      "2018-09-02 03:43:47.033490 Test Step 60 Finished\n",
      "2018-09-02 03:43:47.033952 Test Step 60 \"min loss\" =  2079.2073\n",
      "2018-09-02 03:43:47.034015 Test Step 60 \"loss\" =  2079.2073\n",
      "2018-09-02 03:43:47.181814 Training Step 60 Finished Timing (Training: 0.919423, Test: 0.0793403) after 0.770338 seconds\n",
      "2018-09-02 03:43:47.181877 Training Step 60 \"min loss\" =  2144.2366\n",
      "2018-09-02 03:43:47.181916 Training Step 60 \"loss\" =  2144.2366\n",
      "2018-09-02 03:43:47.814381 Test Step 65 Finished\n",
      "2018-09-02 03:43:47.814477 Test Step 65 \"min loss\" =  2045.776\n",
      "2018-09-02 03:43:47.814519 Test Step 65 \"loss\" =  2045.776\n",
      "2018-09-02 03:43:47.959843 Training Step 65 Finished Timing (Training: 0.919338, Test: 0.0794784) after 0.777831 seconds\n",
      "2018-09-02 03:43:47.959905 Training Step 65 \"min loss\" =  2102.8923\n",
      "2018-09-02 03:43:47.959944 Training Step 65 \"loss\" =  2102.8923\n",
      "2018-09-02 03:43:48.605861 Test Step 70 Finished\n",
      "2018-09-02 03:43:48.605986 Test Step 70 \"min loss\" =  2011.9984\n",
      "2018-09-02 03:43:48.606048 Test Step 70 \"loss\" =  2011.9984\n",
      "2018-09-02 03:43:48.759248 Training Step 70 Finished Timing (Training: 0.919386, Test: 0.0794709) after 0.799201 seconds\n",
      "2018-09-02 03:43:48.759320 Training Step 70 \"min loss\" =  2062.4026\n",
      "2018-09-02 03:43:48.759881 Training Step 70 \"loss\" =  2062.4026\n",
      "2018-09-02 03:43:49.412592 Test Step 75 Finished\n",
      "2018-09-02 03:43:49.412697 Test Step 75 \"min loss\" =  1985.2675\n",
      "2018-09-02 03:43:49.412762 Test Step 75 \"loss\" =  1985.2675\n",
      "2018-09-02 03:43:49.561617 Training Step 75 Finished Timing (Training: 0.919387, Test: 0.0794661) after 0.801657 seconds\n",
      "2018-09-02 03:43:49.561720 Training Step 75 \"min loss\" =  2019.9869\n",
      "2018-09-02 03:43:49.562182 Training Step 75 \"loss\" =  2019.9869\n",
      "2018-09-02 03:43:50.203753 Test Step 80 Finished\n",
      "2018-09-02 03:43:50.203866 Test Step 80 \"min loss\" =  1955.7463\n",
      "2018-09-02 03:43:50.203932 Test Step 80 \"loss\" =  1955.7463\n",
      "2018-09-02 03:43:50.347515 Training Step 80 Finished Timing (Training: 0.919576, Test: 0.0792748) after 0.785262 seconds\n",
      "2018-09-02 03:43:50.347597 Training Step 80 \"min loss\" =  1978.7742\n",
      "2018-09-02 03:43:50.348073 Training Step 80 \"loss\" =  1978.7742\n",
      "2018-09-02 03:43:50.984268 Test Step 85 Finished\n",
      "2018-09-02 03:43:50.984375 Test Step 85 \"min loss\" =  1898.4648\n",
      "2018-09-02 03:43:50.984422 Test Step 85 \"loss\" =  1898.4648\n",
      "2018-09-02 03:43:51.130536 Training Step 85 Finished Timing (Training: 0.919097, Test: 0.0797552) after 0.782401 seconds\n",
      "2018-09-02 03:43:51.130602 Training Step 85 \"min loss\" =  1938.954\n",
      "2018-09-02 03:43:51.130660 Training Step 85 \"loss\" =  1938.954\n",
      "2018-09-02 03:43:51.768112 Test Step 90 Finished\n",
      "2018-09-02 03:43:51.768215 Test Step 90 \"min loss\" =  1865.818\n",
      "2018-09-02 03:43:51.768919 Test Step 90 \"loss\" =  1865.818\n",
      "2018-09-02 03:43:51.916204 Training Step 90 Finished Timing (Training: 0.919388, Test: 0.0794488) after 0.785467 seconds\n",
      "2018-09-02 03:43:51.916272 Training Step 90 \"min loss\" =  1898.8672\n",
      "2018-09-02 03:43:51.916329 Training Step 90 \"loss\" =  1898.8672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:43:52.550873 Test Step 95 Finished\n",
      "2018-09-02 03:43:52.550960 Test Step 95 \"min loss\" =  1836.6749\n",
      "2018-09-02 03:43:52.551745 Test Step 95 \"loss\" =  1836.6749\n",
      "2018-09-02 03:43:52.695588 Training Step 95 Finished Timing (Training: 0.919694, Test: 0.0790509) after 0.778068 seconds\n",
      "2018-09-02 03:43:52.695655 Training Step 95 \"min loss\" =  1855.4877\n",
      "2018-09-02 03:43:52.695695 Training Step 95 \"loss\" =  1855.4877\n",
      "2018-09-02 03:43:53.342520 Test Step 100 Finished\n",
      "2018-09-02 03:43:53.342599 Test Step 100 \"min loss\" =  1800.9597\n",
      "2018-09-02 03:43:53.342673 Test Step 100 \"loss\" =  1800.9597\n",
      "2018-09-02 03:43:53.494693 Training Step 100 Finished Timing (Training: 0.919859, Test: 0.0788193) after 0.798063 seconds\n",
      "2018-09-02 03:43:53.494755 Training Step 100 \"min loss\" =  1817.3055\n",
      "2018-09-02 03:43:53.494802 Training Step 100 \"loss\" =  1817.3055\n",
      "2018-09-02 03:43:54.134661 Test Step 105 Finished\n",
      "2018-09-02 03:43:54.134753 Test Step 105 \"min loss\" =  1745.6259\n",
      "2018-09-02 03:43:54.134839 Test Step 105 \"loss\" =  1745.6259\n",
      "2018-09-02 03:43:54.282529 Training Step 105 Finished Timing (Training: 0.925024, Test: 0.0746645) after 0.787503 seconds\n",
      "2018-09-02 03:43:54.282595 Training Step 105 \"min loss\" =  1775.8435\n",
      "2018-09-02 03:43:54.282634 Training Step 105 \"loss\" =  1775.8435\n",
      "2018-09-02 03:43:54.900191 Test Step 110 Finished\n",
      "2018-09-02 03:43:54.900284 Test Step 110 \"min loss\" =  1715.3085\n",
      "2018-09-02 03:43:54.900717 Test Step 110 \"loss\" =  1715.3085\n",
      "2018-09-02 03:43:55.044148 Training Step 110 Finished Timing (Training: 0.920638, Test: 0.0784609) after 0.761439 seconds\n",
      "2018-09-02 03:43:55.044219 Training Step 110 \"min loss\" =  1732.0612\n",
      "2018-09-02 03:43:55.044260 Training Step 110 \"loss\" =  1732.0612\n",
      "2018-09-02 03:43:55.686013 Test Step 115 Finished\n",
      "2018-09-02 03:43:55.686116 Test Step 115 \"min loss\" =  1696.0559\n",
      "2018-09-02 03:43:55.686755 Test Step 115 \"loss\" =  1696.0559\n",
      "2018-09-02 03:43:55.836465 Training Step 115 Finished Timing (Training: 0.920107, Test: 0.0788497) after 0.792094 seconds\n",
      "2018-09-02 03:43:55.836527 Training Step 115 \"min loss\" =  1692.2596\n",
      "2018-09-02 03:43:55.836589 Training Step 115 \"loss\" =  1692.2596\n",
      "2018-09-02 03:43:56.473983 Test Step 120 Finished\n",
      "2018-09-02 03:43:56.474111 Test Step 120 \"min loss\" =  1667.9989\n",
      "2018-09-02 03:43:56.474154 Test Step 120 \"loss\" =  1667.9989\n",
      "2018-09-02 03:43:56.620730 Training Step 120 Finished Timing (Training: 0.920105, Test: 0.0789632) after 0.784077 seconds\n",
      "2018-09-02 03:43:56.620795 Training Step 120 \"min loss\" =  1650.1041\n",
      "2018-09-02 03:43:56.620846 Training Step 120 \"loss\" =  1650.1041\n",
      "2018-09-02 03:43:57.246308 Test Step 125 Finished\n",
      "2018-09-02 03:43:57.246384 Test Step 125 \"min loss\" =  1611.7955\n",
      "2018-09-02 03:43:57.246457 Test Step 125 \"loss\" =  1611.7955\n",
      "2018-09-02 03:43:57.391182 Training Step 125 Finished Timing (Training: 0.920508, Test: 0.0784799) after 0.769645 seconds\n",
      "2018-09-02 03:43:57.391242 Training Step 125 \"min loss\" =  1606.747\n",
      "2018-09-02 03:43:57.391296 Training Step 125 \"loss\" =  1606.747\n",
      "2018-09-02 03:43:58.035921 Test Step 130 Finished\n",
      "2018-09-02 03:43:58.036000 Test Step 130 \"min loss\" =  1563.8516\n",
      "2018-09-02 03:43:58.036041 Test Step 130 \"loss\" =  1563.8516\n",
      "2018-09-02 03:43:58.173284 Training Step 130 Finished Timing (Training: 0.920844, Test: 0.0780629) after 0.781159 seconds\n",
      "2018-09-02 03:43:58.173363 Training Step 130 \"min loss\" =  1566.9568\n",
      "2018-09-02 03:43:58.173878 Training Step 130 \"loss\" =  1566.9568\n",
      "2018-09-02 03:43:58.812914 Test Step 135 Finished\n",
      "2018-09-02 03:43:58.812994 Test Step 135 \"min loss\" =  1519.749\n",
      "2018-09-02 03:43:58.813057 Test Step 135 \"loss\" =  1519.749\n",
      "2018-09-02 03:43:58.958566 Training Step 135 Finished Timing (Training: 0.921661, Test: 0.0772433) after 0.784622 seconds\n",
      "2018-09-02 03:43:58.958647 Training Step 135 \"min loss\" =  1525.1097\n",
      "2018-09-02 03:43:58.958689 Training Step 135 \"loss\" =  1525.1097\n",
      "2018-09-02 03:43:59.601770 Test Step 140 Finished\n",
      "2018-09-02 03:43:59.601869 Test Step 140 \"min loss\" =  1496.0358\n",
      "2018-09-02 03:43:59.602608 Test Step 140 \"loss\" =  1496.0358\n",
      "2018-09-02 03:43:59.745384 Training Step 140 Finished Timing (Training: 0.921688, Test: 0.0771783) after 0.786644 seconds\n",
      "2018-09-02 03:43:59.745694 Training Step 140 \"min loss\" =  1482.839\n",
      "2018-09-02 03:43:59.745760 Training Step 140 \"loss\" =  1482.839\n",
      "2018-09-02 03:44:00.398221 Test Step 145 Finished\n",
      "2018-09-02 03:44:00.398333 Test Step 145 \"min loss\" =  1450.5542\n",
      "2018-09-02 03:44:00.399005 Test Step 145 \"loss\" =  1450.5542\n",
      "2018-09-02 03:44:00.536143 Training Step 145 Finished Timing (Training: 0.921042, Test: 0.0777043) after 0.789894 seconds\n",
      "2018-09-02 03:44:00.536207 Training Step 145 \"min loss\" =  1440.1368\n",
      "2018-09-02 03:44:00.536249 Training Step 145 \"loss\" =  1440.1368\n",
      "2018-09-02 03:44:01.174293 Test Step 150 Finished\n",
      "2018-09-02 03:44:01.174447 Test Step 150 \"min loss\" =  1411.5728\n",
      "2018-09-02 03:44:01.174540 Test Step 150 \"loss\" =  1411.5728\n",
      "2018-09-02 03:44:01.327360 Training Step 150 Finished Timing (Training: 0.920874, Test: 0.0778274) after 0.79105 seconds\n",
      "2018-09-02 03:44:01.327476 Training Step 150 \"min loss\" =  1400.0807\n",
      "2018-09-02 03:44:01.327554 Training Step 150 \"loss\" =  1400.0807\n",
      "2018-09-02 03:44:01.966436 Test Step 155 Finished\n",
      "2018-09-02 03:44:01.967034 Test Step 155 \"min loss\" =  1371.741\n",
      "2018-09-02 03:44:01.967191 Test Step 155 \"loss\" =  1371.741\n",
      "2018-09-02 03:44:02.115962 Training Step 155 Finished Timing (Training: 0.921142, Test: 0.0775374) after 0.788346 seconds\n",
      "2018-09-02 03:44:02.116024 Training Step 155 \"min loss\" =  1358.5189\n",
      "2018-09-02 03:44:02.116074 Training Step 155 \"loss\" =  1358.5189\n",
      "2018-09-02 03:44:02.754547 Test Step 160 Finished\n",
      "2018-09-02 03:44:02.754657 Test Step 160 \"min loss\" =  1322.7253\n",
      "2018-09-02 03:44:02.755248 Test Step 160 \"loss\" =  1322.7253\n",
      "2018-09-02 03:44:02.891556 Training Step 160 Finished Timing (Training: 0.920998, Test: 0.0775987) after 0.774593 seconds\n",
      "2018-09-02 03:44:02.891618 Training Step 160 \"min loss\" =  1316.0634\n",
      "2018-09-02 03:44:02.891672 Training Step 160 \"loss\" =  1316.0634\n",
      "2018-09-02 03:44:03.529296 Test Step 165 Finished\n",
      "2018-09-02 03:44:03.529393 Test Step 165 \"min loss\" =  1303.4702\n",
      "2018-09-02 03:44:03.530022 Test Step 165 \"loss\" =  1303.4702\n",
      "2018-09-02 03:44:03.677810 Training Step 165 Finished Timing (Training: 0.921172, Test: 0.0774269) after 0.786075 seconds\n",
      "2018-09-02 03:44:03.677871 Training Step 165 \"min loss\" =  1278.2397\n",
      "2018-09-02 03:44:03.677925 Training Step 165 \"loss\" =  1278.2397\n",
      "2018-09-02 03:44:04.320572 Test Step 170 Finished\n",
      "2018-09-02 03:44:04.320697 Test Step 170 \"min loss\" =  1285.4275\n",
      "2018-09-02 03:44:04.320769 Test Step 170 \"loss\" =  1285.4275\n",
      "2018-09-02 03:44:04.462088 Training Step 170 Finished Timing (Training: 0.920985, Test: 0.077632) after 0.783661 seconds\n",
      "2018-09-02 03:44:04.462152 Training Step 170 \"min loss\" =  1235.093\n",
      "2018-09-02 03:44:04.462584 Training Step 170 \"loss\" =  1235.093\n",
      "2018-09-02 03:44:05.094846 Test Step 175 Finished\n",
      "2018-09-02 03:44:05.095259 Test Step 175 \"min loss\" =  1226.3995\n",
      "2018-09-02 03:44:05.095319 Test Step 175 \"loss\" =  1226.3995\n",
      "2018-09-02 03:44:05.239091 Training Step 175 Finished Timing (Training: 0.921092, Test: 0.0775214) after 0.776441 seconds\n",
      "2018-09-02 03:44:05.239157 Training Step 175 \"min loss\" =  1196.4554\n",
      "2018-09-02 03:44:05.239228 Training Step 175 \"loss\" =  1196.4554\n",
      "2018-09-02 03:44:05.869966 Test Step 180 Finished\n",
      "2018-09-02 03:44:05.870364 Test Step 180 \"min loss\" =  1187.9027\n",
      "2018-09-02 03:44:05.870428 Test Step 180 \"loss\" =  1187.9027\n",
      "2018-09-02 03:44:06.007998 Training Step 180 Finished Timing (Training: 0.921061, Test: 0.0775227) after 0.768013 seconds\n",
      "2018-09-02 03:44:06.008118 Training Step 180 \"min loss\" =  1155.1293\n",
      "2018-09-02 03:44:06.008176 Training Step 180 \"loss\" =  1155.1293\n",
      "2018-09-02 03:44:06.656433 Test Step 185 Finished\n",
      "2018-09-02 03:44:06.656549 Test Step 185 \"min loss\" =  1152.5414\n",
      "2018-09-02 03:44:06.656616 Test Step 185 \"loss\" =  1152.5414\n",
      "2018-09-02 03:44:06.805410 Training Step 185 Finished Timing (Training: 0.92092, Test: 0.0776578) after 0.796482 seconds\n",
      "2018-09-02 03:44:06.805483 Training Step 185 \"min loss\" =  1115.4631\n",
      "2018-09-02 03:44:06.805965 Training Step 185 \"loss\" =  1115.4631\n",
      "2018-09-02 03:44:07.439139 Test Step 190 Finished\n",
      "2018-09-02 03:44:07.439230 Test Step 190 \"min loss\" =  1100.828\n",
      "2018-09-02 03:44:07.439732 Test Step 190 \"loss\" =  1100.828\n",
      "2018-09-02 03:44:07.582764 Training Step 190 Finished Timing (Training: 0.920969, Test: 0.0775944) after 0.776734 seconds\n",
      "2018-09-02 03:44:07.582861 Training Step 190 \"min loss\" =  1075.7858\n",
      "2018-09-02 03:44:07.582925 Training Step 190 \"loss\" =  1075.7858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:44:08.215039 Test Step 195 Finished\n",
      "2018-09-02 03:44:08.215143 Test Step 195 \"min loss\" =  1040.426\n",
      "2018-09-02 03:44:08.215770 Test Step 195 \"loss\" =  1040.426\n",
      "2018-09-02 03:44:08.366231 Training Step 195 Finished Timing (Training: 0.920776, Test: 0.0777771) after 0.783235 seconds\n",
      "2018-09-02 03:44:08.366368 Training Step 195 \"min loss\" =  1034.5922\n",
      "2018-09-02 03:44:08.366424 Training Step 195 \"loss\" =  1034.5922\n",
      "2018-09-02 03:44:08.993591 Test Step 200 Finished\n",
      "2018-09-02 03:44:08.993931 Test Step 200 \"min loss\" =  1017.2856\n",
      "2018-09-02 03:44:08.993994 Test Step 200 \"loss\" =  1017.2856\n",
      "2018-09-02 03:44:09.135781 Training Step 200 Finished Timing (Training: 0.920593, Test: 0.0779833) after 0.769294 seconds\n",
      "2018-09-02 03:44:09.136060 Training Step 200 \"min loss\" =  998.33014\n",
      "2018-09-02 03:44:09.136366 Training Step 200 \"loss\" =  998.33014\n",
      "2018-09-02 03:44:09.766574 Test Step 205 Finished\n",
      "2018-09-02 03:44:09.766669 Test Step 205 \"min loss\" =  991.8444\n",
      "2018-09-02 03:44:09.767343 Test Step 205 \"loss\" =  991.8444\n",
      "2018-09-02 03:44:09.914819 Training Step 205 Finished Timing (Training: 0.92094, Test: 0.0779644) after 0.778389 seconds\n",
      "2018-09-02 03:44:09.914940 Training Step 205 \"min loss\" =  959.5428\n",
      "2018-09-02 03:44:09.915260 Training Step 205 \"loss\" =  959.5428\n",
      "2018-09-02 03:44:10.551887 Test Step 210 Finished\n",
      "2018-09-02 03:44:10.552407 Test Step 210 \"min loss\" =  931.47205\n",
      "2018-09-02 03:44:10.552586 Test Step 210 \"loss\" =  931.47205\n",
      "2018-09-02 03:44:10.697158 Training Step 210 Finished Timing (Training: 0.92169, Test: 0.076597) after 0.781805 seconds\n",
      "2018-09-02 03:44:10.697220 Training Step 210 \"min loss\" =  922.3275\n",
      "2018-09-02 03:44:10.697325 Training Step 210 \"loss\" =  922.3275\n",
      "2018-09-02 03:44:11.354724 Test Step 215 Finished\n",
      "2018-09-02 03:44:11.354830 Test Step 215 \"min loss\" =  917.7097\n",
      "2018-09-02 03:44:11.354888 Test Step 215 \"loss\" =  917.7097\n",
      "2018-09-02 03:44:11.501867 Training Step 215 Finished Timing (Training: 0.920799, Test: 0.0778714) after 0.804487 seconds\n",
      "2018-09-02 03:44:11.501933 Training Step 215 \"min loss\" =  885.6081\n",
      "2018-09-02 03:44:11.501990 Training Step 215 \"loss\" =  885.6081\n",
      "2018-09-02 03:44:12.149601 Test Step 220 Finished\n",
      "2018-09-02 03:44:12.150071 Test Step 220 \"min loss\" =  889.686\n",
      "2018-09-02 03:44:12.150226 Test Step 220 \"loss\" =  889.686\n",
      "2018-09-02 03:44:12.293650 Training Step 220 Finished Timing (Training: 0.92044, Test: 0.0780577) after 0.790974 seconds\n",
      "2018-09-02 03:44:12.294001 Training Step 220 \"min loss\" =  849.427\n",
      "2018-09-02 03:44:12.294069 Training Step 220 \"loss\" =  849.427\n",
      "2018-09-02 03:44:12.946920 Test Step 225 Finished\n",
      "2018-09-02 03:44:12.946995 Test Step 225 \"min loss\" =  841.8726\n",
      "2018-09-02 03:44:12.947695 Test Step 225 \"loss\" =  841.8726\n",
      "2018-09-02 03:44:13.094217 Training Step 225 Finished Timing (Training: 0.919774, Test: 0.078474) after 0.799598 seconds\n",
      "2018-09-02 03:44:13.094279 Training Step 225 \"min loss\" =  813.9587\n",
      "2018-09-02 03:44:13.094689 Training Step 225 \"loss\" =  813.9587\n",
      "2018-09-02 03:44:13.729007 Test Step 230 Finished\n",
      "2018-09-02 03:44:13.729467 Test Step 230 \"min loss\" =  794.08887\n",
      "2018-09-02 03:44:13.729542 Test Step 230 \"loss\" =  794.08887\n",
      "2018-09-02 03:44:13.869434 Training Step 230 Finished Timing (Training: 0.919427, Test: 0.0787394) after 0.774678 seconds\n",
      "2018-09-02 03:44:13.869503 Training Step 230 \"min loss\" =  778.68805\n",
      "2018-09-02 03:44:13.869558 Training Step 230 \"loss\" =  778.68805\n",
      "2018-09-02 03:44:14.508346 Test Step 235 Finished\n",
      "2018-09-02 03:44:14.508517 Test Step 235 \"min loss\" =  779.0549\n",
      "2018-09-02 03:44:14.509166 Test Step 235 \"loss\" =  779.0549\n",
      "2018-09-02 03:44:14.651630 Training Step 235 Finished Timing (Training: 0.919747, Test: 0.0784174) after 0.782012 seconds\n",
      "2018-09-02 03:44:14.651985 Training Step 235 \"min loss\" =  745.19403\n",
      "2018-09-02 03:44:14.652063 Training Step 235 \"loss\" =  745.19403\n",
      "2018-09-02 03:44:15.292479 Test Step 240 Finished\n",
      "2018-09-02 03:44:15.292621 Test Step 240 \"min loss\" =  764.7843\n",
      "2018-09-02 03:44:15.293304 Test Step 240 \"loss\" =  764.7843\n",
      "2018-09-02 03:44:15.442897 Training Step 240 Finished Timing (Training: 0.9204, Test: 0.0777692) after 0.790769 seconds\n",
      "2018-09-02 03:44:15.442960 Training Step 240 \"min loss\" =  713.20123\n",
      "2018-09-02 03:44:15.443397 Training Step 240 \"loss\" =  713.20123\n",
      "2018-09-02 03:44:16.069072 Test Step 245 Finished\n",
      "2018-09-02 03:44:16.069187 Test Step 245 \"min loss\" =  717.2193\n",
      "2018-09-02 03:44:16.069276 Test Step 245 \"loss\" =  717.2193\n",
      "2018-09-02 03:44:16.204142 Training Step 245 Finished Timing (Training: 0.92014, Test: 0.0779582) after 0.76068 seconds\n",
      "2018-09-02 03:44:16.204205 Training Step 245 \"min loss\" =  677.92694\n",
      "2018-09-02 03:44:16.204779 Training Step 245 \"loss\" =  677.92694\n",
      "2018-09-02 03:44:16.840389 Test Step 250 Finished\n",
      "2018-09-02 03:44:16.840488 Test Step 250 \"min loss\" =  688.62384\n",
      "2018-09-02 03:44:16.841141 Test Step 250 \"loss\" =  688.62384\n",
      "2018-09-02 03:44:16.984865 Training Step 250 Finished Timing (Training: 0.919801, Test: 0.0782877) after 0.780006 seconds\n",
      "2018-09-02 03:44:16.985007 Training Step 250 \"min loss\" =  647.9135\n",
      "2018-09-02 03:44:16.985065 Training Step 250 \"loss\" =  647.9135\n",
      "2018-09-02 03:44:17.610183 Test Step 255 Finished\n",
      "2018-09-02 03:44:17.610700 Test Step 255 \"min loss\" =  663.9314\n",
      "2018-09-02 03:44:17.610836 Test Step 255 \"loss\" =  663.9314\n",
      "2018-09-02 03:44:17.760477 Training Step 255 Finished Timing (Training: 0.919677, Test: 0.0783777) after 0.774671 seconds\n",
      "2018-09-02 03:44:17.760788 Training Step 255 \"min loss\" =  616.89246\n",
      "2018-09-02 03:44:17.760855 Training Step 255 \"loss\" =  616.89246\n",
      "2018-09-02 03:44:18.415675 Test Step 260 Finished\n",
      "2018-09-02 03:44:18.416154 Test Step 260 \"min loss\" =  619.69\n",
      "2018-09-02 03:44:18.416219 Test Step 260 \"loss\" =  619.69\n",
      "2018-09-02 03:44:18.558803 Training Step 260 Finished Timing (Training: 0.920375, Test: 0.077731) after 0.797885 seconds\n",
      "2018-09-02 03:44:18.558872 Training Step 260 \"min loss\" =  585.4913\n",
      "2018-09-02 03:44:18.558922 Training Step 260 \"loss\" =  585.4913\n",
      "2018-09-02 03:44:19.212205 Test Step 265 Finished\n",
      "2018-09-02 03:44:19.212581 Test Step 265 \"min loss\" =  613.40393\n",
      "2018-09-02 03:44:19.212809 Test Step 265 \"loss\" =  613.40393\n",
      "2018-09-02 03:44:19.358757 Training Step 265 Finished Timing (Training: 0.920757, Test: 0.0774025) after 0.799761 seconds\n",
      "2018-09-02 03:44:19.358822 Training Step 265 \"min loss\" =  556.0025\n",
      "2018-09-02 03:44:19.358860 Training Step 265 \"loss\" =  556.0025\n",
      "2018-09-02 03:44:19.998983 Test Step 270 Finished\n",
      "2018-09-02 03:44:19.999081 Test Step 270 \"min loss\" =  584.7974\n",
      "2018-09-02 03:44:19.999146 Test Step 270 \"loss\" =  584.7974\n",
      "2018-09-02 03:44:20.144550 Training Step 270 Finished Timing (Training: 0.920452, Test: 0.0777997) after 0.785609 seconds\n",
      "2018-09-02 03:44:20.144633 Training Step 270 \"min loss\" =  528.5836\n",
      "2018-09-02 03:44:20.144674 Training Step 270 \"loss\" =  528.5836\n",
      "2018-09-02 03:44:20.771241 Test Step 275 Finished\n",
      "2018-09-02 03:44:20.771705 Test Step 275 \"min loss\" =  542.44293\n",
      "2018-09-02 03:44:20.771768 Test Step 275 \"loss\" =  542.44293\n",
      "2018-09-02 03:44:20.914009 Training Step 275 Finished Timing (Training: 0.920724, Test: 0.0775724) after 0.769258 seconds\n",
      "2018-09-02 03:44:20.914071 Training Step 275 \"min loss\" =  500.4022\n",
      "2018-09-02 03:44:20.914123 Training Step 275 \"loss\" =  500.4022\n",
      "2018-09-02 03:44:21.562717 Test Step 280 Finished\n",
      "2018-09-02 03:44:21.563215 Test Step 280 \"min loss\" =  512.8163\n",
      "2018-09-02 03:44:21.563276 Test Step 280 \"loss\" =  512.8163\n",
      "2018-09-02 03:44:21.708364 Training Step 280 Finished Timing (Training: 0.92072, Test: 0.0775675) after 0.793535 seconds\n",
      "2018-09-02 03:44:21.708495 Training Step 280 \"min loss\" =  472.209\n",
      "2018-09-02 03:44:21.708545 Training Step 280 \"loss\" =  472.209\n",
      "2018-09-02 03:44:22.362741 Test Step 285 Finished\n",
      "2018-09-02 03:44:22.362863 Test Step 285 \"min loss\" =  478.2307\n",
      "2018-09-02 03:44:22.363479 Test Step 285 \"loss\" =  478.2307\n",
      "2018-09-02 03:44:22.515965 Training Step 285 Finished Timing (Training: 0.920681, Test: 0.0776283) after 0.807363 seconds\n",
      "2018-09-02 03:44:22.516030 Training Step 285 \"min loss\" =  448.40115\n",
      "2018-09-02 03:44:22.516069 Training Step 285 \"loss\" =  448.40115\n",
      "2018-09-02 03:44:23.164874 Test Step 290 Finished\n",
      "2018-09-02 03:44:23.165008 Test Step 290 \"min loss\" =  467.0803\n",
      "2018-09-02 03:44:23.165072 Test Step 290 \"loss\" =  467.0803\n",
      "2018-09-02 03:44:23.310244 Training Step 290 Finished Timing (Training: 0.920416, Test: 0.0779518) after 0.79406 seconds\n",
      "2018-09-02 03:44:23.310741 Training Step 290 \"min loss\" =  422.6191\n",
      "2018-09-02 03:44:23.310907 Training Step 290 \"loss\" =  422.6191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:44:23.966869 Test Step 295 Finished\n",
      "2018-09-02 03:44:23.967038 Test Step 295 \"min loss\" =  465.27988\n",
      "2018-09-02 03:44:23.967184 Test Step 295 \"loss\" =  465.27988\n",
      "2018-09-02 03:44:24.109337 Training Step 295 Finished Timing (Training: 0.920141, Test: 0.0781921) after 0.798278 seconds\n",
      "2018-09-02 03:44:24.109400 Training Step 295 \"min loss\" =  399.0815\n",
      "2018-09-02 03:44:24.109893 Training Step 295 \"loss\" =  399.0815\n",
      "2018-09-02 03:44:24.752132 Test Step 300 Finished\n",
      "2018-09-02 03:44:24.752606 Test Step 300 \"min loss\" =  441.42545\n",
      "2018-09-02 03:44:24.752669 Test Step 300 \"loss\" =  441.42545\n",
      "2018-09-02 03:44:24.892070 Training Step 300 Finished Timing (Training: 0.91994, Test: 0.0783958) after 0.782098 seconds\n",
      "2018-09-02 03:44:24.892135 Training Step 300 \"min loss\" =  376.82462\n",
      "2018-09-02 03:44:24.892205 Training Step 300 \"loss\" =  376.82462\n",
      "2018-09-02 03:44:25.519658 Test Step 305 Finished\n",
      "2018-09-02 03:44:25.519762 Test Step 305 \"min loss\" =  415.89703\n",
      "2018-09-02 03:44:25.520334 Test Step 305 \"loss\" =  415.89703\n",
      "2018-09-02 03:44:25.662415 Training Step 305 Finished Timing (Training: 0.926071, Test: 0.0729355) after 0.770158 seconds\n",
      "2018-09-02 03:44:25.662490 Training Step 305 \"min loss\" =  357.1446\n",
      "2018-09-02 03:44:25.662549 Training Step 305 \"loss\" =  357.1446\n",
      "2018-09-02 03:44:26.301156 Test Step 310 Finished\n",
      "2018-09-02 03:44:26.301270 Test Step 310 \"min loss\" =  398.22977\n",
      "2018-09-02 03:44:26.301358 Test Step 310 \"loss\" =  398.22977\n",
      "2018-09-02 03:44:26.447457 Training Step 310 Finished Timing (Training: 0.924757, Test: 0.0740115) after 0.784187 seconds\n",
      "2018-09-02 03:44:26.447520 Training Step 310 \"min loss\" =  332.6758\n",
      "2018-09-02 03:44:26.447567 Training Step 310 \"loss\" =  332.6758\n",
      "2018-09-02 03:44:27.076021 Test Step 315 Finished\n",
      "2018-09-02 03:44:27.076126 Test Step 315 \"min loss\" =  378.64993\n",
      "2018-09-02 03:44:27.076613 Test Step 315 \"loss\" =  378.64993\n",
      "2018-09-02 03:44:27.219349 Training Step 315 Finished Timing (Training: 0.922649, Test: 0.0758895) after 0.771084 seconds\n",
      "2018-09-02 03:44:27.219409 Training Step 315 \"min loss\" =  312.8312\n",
      "2018-09-02 03:44:27.219481 Training Step 315 \"loss\" =  312.8312\n",
      "2018-09-02 03:44:27.850479 Test Step 320 Finished\n",
      "2018-09-02 03:44:27.850581 Test Step 320 \"min loss\" =  364.7213\n",
      "2018-09-02 03:44:27.851127 Test Step 320 \"loss\" =  364.7213\n",
      "2018-09-02 03:44:27.993121 Training Step 320 Finished Timing (Training: 0.922046, Test: 0.0763538) after 0.773035 seconds\n",
      "2018-09-02 03:44:27.993199 Training Step 320 \"min loss\" =  292.1806\n",
      "2018-09-02 03:44:27.993664 Training Step 320 \"loss\" =  292.1806\n",
      "2018-09-02 03:44:28.640266 Test Step 325 Finished\n",
      "2018-09-02 03:44:28.640361 Test Step 325 \"min loss\" =  343.43356\n",
      "2018-09-02 03:44:28.640420 Test Step 325 \"loss\" =  343.43356\n",
      "2018-09-02 03:44:28.786375 Training Step 325 Finished Timing (Training: 0.92139, Test: 0.0769488) after 0.79264 seconds\n",
      "2018-09-02 03:44:28.786443 Training Step 325 \"min loss\" =  275.61783\n",
      "2018-09-02 03:44:28.786481 Training Step 325 \"loss\" =  275.61783\n",
      "2018-09-02 03:44:29.434948 Test Step 330 Finished\n",
      "2018-09-02 03:44:29.435056 Test Step 330 \"min loss\" =  328.86243\n",
      "2018-09-02 03:44:29.435625 Test Step 330 \"loss\" =  328.86243\n",
      "2018-09-02 03:44:29.583433 Training Step 330 Finished Timing (Training: 0.921287, Test: 0.0771326) after 0.796877 seconds\n",
      "2018-09-02 03:44:29.583496 Training Step 330 \"min loss\" =  255.55994\n",
      "2018-09-02 03:44:29.583536 Training Step 330 \"loss\" =  255.55994\n",
      "2018-09-02 03:44:30.221386 Test Step 335 Finished\n",
      "2018-09-02 03:44:30.221494 Test Step 335 \"min loss\" =  312.93005\n",
      "2018-09-02 03:44:30.221556 Test Step 335 \"loss\" =  312.93005\n",
      "2018-09-02 03:44:30.371343 Training Step 335 Finished Timing (Training: 0.922055, Test: 0.0765166) after 0.787749 seconds\n",
      "2018-09-02 03:44:30.371457 Training Step 335 \"min loss\" =  239.14055\n",
      "2018-09-02 03:44:30.371529 Training Step 335 \"loss\" =  239.14055\n",
      "2018-09-02 03:44:31.014906 Test Step 340 Finished\n",
      "2018-09-02 03:44:31.015039 Test Step 340 \"min loss\" =  288.89648\n",
      "2018-09-02 03:44:31.015100 Test Step 340 \"loss\" =  288.89648\n",
      "2018-09-02 03:44:31.154616 Training Step 340 Finished Timing (Training: 0.921619, Test: 0.0769195) after 0.78223 seconds\n",
      "2018-09-02 03:44:31.154693 Training Step 340 \"min loss\" =  221.65904\n",
      "2018-09-02 03:44:31.154768 Training Step 340 \"loss\" =  221.65904\n",
      "2018-09-02 03:44:31.795789 Test Step 345 Finished\n",
      "2018-09-02 03:44:31.795916 Test Step 345 \"min loss\" =  286.38608\n",
      "2018-09-02 03:44:31.796629 Test Step 345 \"loss\" =  286.38608\n",
      "2018-09-02 03:44:31.940977 Training Step 345 Finished Timing (Training: 0.921033, Test: 0.0774978) after 0.786165 seconds\n",
      "2018-09-02 03:44:31.941039 Training Step 345 \"min loss\" =  209.61021\n",
      "2018-09-02 03:44:31.941588 Training Step 345 \"loss\" =  209.61021\n",
      "2018-09-02 03:44:32.581285 Test Step 350 Finished\n",
      "2018-09-02 03:44:32.581391 Test Step 350 \"min loss\" =  277.91922\n",
      "2018-09-02 03:44:32.581944 Test Step 350 \"loss\" =  277.91922\n",
      "2018-09-02 03:44:32.729371 Training Step 350 Finished Timing (Training: 0.921577, Test: 0.0769192) after 0.78771 seconds\n",
      "2018-09-02 03:44:32.729453 Training Step 350 \"min loss\" =  193.83134\n",
      "2018-09-02 03:44:32.729502 Training Step 350 \"loss\" =  193.83134\n",
      "2018-09-02 03:44:33.378374 Test Step 355 Finished\n",
      "2018-09-02 03:44:33.378508 Test Step 355 \"min loss\" =  264.14832\n",
      "2018-09-02 03:44:33.379014 Test Step 355 \"loss\" =  264.14832\n",
      "2018-09-02 03:44:33.516502 Training Step 355 Finished Timing (Training: 0.921119, Test: 0.0773163) after 0.786148 seconds\n",
      "2018-09-02 03:44:33.516570 Training Step 355 \"min loss\" =  179.84746\n",
      "2018-09-02 03:44:33.516627 Training Step 355 \"loss\" =  179.84746\n",
      "2018-09-02 03:44:34.158669 Test Step 360 Finished\n",
      "2018-09-02 03:44:34.158756 Test Step 360 \"min loss\" =  254.16226\n",
      "2018-09-02 03:44:34.158811 Test Step 360 \"loss\" =  254.16226\n",
      "2018-09-02 03:44:34.301792 Training Step 360 Finished Timing (Training: 0.92136, Test: 0.0771623) after 0.785107 seconds\n",
      "2018-09-02 03:44:34.301852 Training Step 360 \"min loss\" =  166.87144\n",
      "2018-09-02 03:44:34.302203 Training Step 360 \"loss\" =  166.87144\n",
      "2018-09-02 03:44:34.947657 Test Step 365 Finished\n",
      "2018-09-02 03:44:34.948175 Test Step 365 \"min loss\" =  240.44167\n",
      "2018-09-02 03:44:34.948240 Test Step 365 \"loss\" =  240.44167\n",
      "2018-09-02 03:44:35.086974 Training Step 365 Finished Timing (Training: 0.921377, Test: 0.0771232) after 0.78446 seconds\n",
      "2018-09-02 03:44:35.087103 Training Step 365 \"min loss\" =  153.7696\n",
      "2018-09-02 03:44:35.087167 Training Step 365 \"loss\" =  153.7696\n",
      "2018-09-02 03:44:35.718344 Test Step 370 Finished\n",
      "2018-09-02 03:44:35.718811 Test Step 370 \"min loss\" =  230.19603\n",
      "2018-09-02 03:44:35.718872 Test Step 370 \"loss\" =  230.19603\n",
      "2018-09-02 03:44:35.867904 Training Step 370 Finished Timing (Training: 0.921273, Test: 0.0772522) after 0.780655 seconds\n",
      "2018-09-02 03:44:35.867972 Training Step 370 \"min loss\" =  144.30438\n",
      "2018-09-02 03:44:35.868033 Training Step 370 \"loss\" =  144.30438\n",
      "2018-09-02 03:44:36.516778 Test Step 375 Finished\n",
      "2018-09-02 03:44:36.517254 Test Step 375 \"min loss\" =  230.19603\n",
      "2018-09-02 03:44:36.517555 Test Step 375 \"loss\" =  234.89943\n",
      "2018-09-02 03:44:36.665601 Training Step 375 Finished Timing (Training: 0.921186, Test: 0.0773107) after 0.797045 seconds\n",
      "2018-09-02 03:44:36.665662 Training Step 375 \"min loss\" =  132.36316\n",
      "2018-09-02 03:44:36.665701 Training Step 375 \"loss\" =  132.36316\n",
      "2018-09-02 03:44:37.310953 Test Step 380 Finished\n",
      "2018-09-02 03:44:37.311044 Test Step 380 \"min loss\" =  214.53311\n",
      "2018-09-02 03:44:37.311100 Test Step 380 \"loss\" =  214.53311\n",
      "2018-09-02 03:44:37.456586 Training Step 380 Finished Timing (Training: 0.920836, Test: 0.0776684) after 0.790123 seconds\n",
      "2018-09-02 03:44:37.456656 Training Step 380 \"min loss\" =  124.00047\n",
      "2018-09-02 03:44:37.456730 Training Step 380 \"loss\" =  124.00047\n",
      "2018-09-02 03:44:38.094297 Test Step 385 Finished\n",
      "2018-09-02 03:44:38.094793 Test Step 385 \"min loss\" =  214.53311\n",
      "2018-09-02 03:44:38.094941 Test Step 385 \"loss\" =  221.19324\n",
      "2018-09-02 03:44:38.243669 Training Step 385 Finished Timing (Training: 0.920756, Test: 0.0777659) after 0.786879 seconds\n",
      "2018-09-02 03:44:38.243730 Training Step 385 \"min loss\" =  114.76412\n",
      "2018-09-02 03:44:38.243793 Training Step 385 \"loss\" =  114.76412\n",
      "2018-09-02 03:44:38.888757 Test Step 390 Finished\n",
      "2018-09-02 03:44:38.888857 Test Step 390 \"min loss\" =  201.40205\n",
      "2018-09-02 03:44:38.888915 Test Step 390 \"loss\" =  201.40205\n",
      "2018-09-02 03:44:39.033498 Training Step 390 Finished Timing (Training: 0.920702, Test: 0.0778708) after 0.789635 seconds\n",
      "2018-09-02 03:44:39.033561 Training Step 390 \"min loss\" =  106.635994\n",
      "2018-09-02 03:44:39.033622 Training Step 390 \"loss\" =  106.635994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:44:39.682167 Test Step 395 Finished\n",
      "2018-09-02 03:44:39.682607 Test Step 395 \"min loss\" =  182.2249\n",
      "2018-09-02 03:44:39.682669 Test Step 395 \"loss\" =  182.2249\n",
      "2018-09-02 03:44:39.828606 Training Step 395 Finished Timing (Training: 0.920619, Test: 0.0779792) after 0.794925 seconds\n",
      "2018-09-02 03:44:39.828675 Training Step 395 \"min loss\" =  97.5112\n",
      "2018-09-02 03:44:39.828734 Training Step 395 \"loss\" =  97.5112\n",
      "2018-09-02 03:44:40.474404 Test Step 400 Finished\n",
      "2018-09-02 03:44:40.474534 Test Step 400 \"min loss\" =  166.78708\n",
      "2018-09-02 03:44:40.474591 Test Step 400 \"loss\" =  166.78708\n",
      "2018-09-02 03:44:40.622538 Training Step 400 Finished Timing (Training: 0.920726, Test: 0.0779117) after 0.793741 seconds\n",
      "2018-09-02 03:44:40.622602 Training Step 400 \"min loss\" =  91.79095\n",
      "2018-09-02 03:44:40.622641 Training Step 400 \"loss\" =  91.79095\n",
      "2018-09-02 03:44:41.260361 Test Step 405 Finished\n",
      "2018-09-02 03:44:41.260837 Test Step 405 \"min loss\" =  155.83723\n",
      "2018-09-02 03:44:41.260899 Test Step 405 \"loss\" =  155.83723\n",
      "2018-09-02 03:44:41.406563 Training Step 405 Finished Timing (Training: 0.923158, Test: 0.0760461) after 0.783238 seconds\n",
      "2018-09-02 03:44:41.406627 Training Step 405 \"min loss\" =  84.00061\n",
      "2018-09-02 03:44:41.406682 Training Step 405 \"loss\" =  85.160576\n",
      "2018-09-02 03:44:42.055478 Test Step 410 Finished\n",
      "2018-09-02 03:44:42.055936 Test Step 410 \"min loss\" =  137.79163\n",
      "2018-09-02 03:44:42.055999 Test Step 410 \"loss\" =  137.79163\n",
      "2018-09-02 03:44:42.200456 Training Step 410 Finished Timing (Training: 0.922247, Test: 0.0768544) after 0.793703 seconds\n",
      "2018-09-02 03:44:42.200782 Training Step 410 \"min loss\" =  78.455795\n",
      "2018-09-02 03:44:42.200844 Training Step 410 \"loss\" =  78.455795\n",
      "2018-09-02 03:44:42.838569 Test Step 415 Finished\n",
      "2018-09-02 03:44:42.839107 Test Step 415 \"min loss\" =  119.66108\n",
      "2018-09-02 03:44:42.839321 Test Step 415 \"loss\" =  119.66108\n",
      "2018-09-02 03:44:42.985136 Training Step 415 Finished Timing (Training: 0.924449, Test: 0.074401) after 0.784229 seconds\n",
      "2018-09-02 03:44:42.985211 Training Step 415 \"min loss\" =  72.43893\n",
      "2018-09-02 03:44:42.985586 Training Step 415 \"loss\" =  72.43893\n",
      "2018-09-02 03:44:43.614901 Test Step 420 Finished\n",
      "2018-09-02 03:44:43.615000 Test Step 420 \"min loss\" =  111.332466\n",
      "2018-09-02 03:44:43.615677 Test Step 420 \"loss\" =  111.332466\n",
      "2018-09-02 03:44:43.765386 Training Step 420 Finished Timing (Training: 0.923156, Test: 0.0754924) after 0.779733 seconds\n",
      "2018-09-02 03:44:43.765451 Training Step 420 \"min loss\" =  66.65658\n",
      "2018-09-02 03:44:43.765519 Training Step 420 \"loss\" =  66.65658\n",
      "2018-09-02 03:44:44.403271 Test Step 425 Finished\n",
      "2018-09-02 03:44:44.403823 Test Step 425 \"min loss\" =  100.59067\n",
      "2018-09-02 03:44:44.403887 Test Step 425 \"loss\" =  100.59067\n",
      "2018-09-02 03:44:44.552755 Training Step 425 Finished Timing (Training: 0.922868, Test: 0.0755277) after 0.786516 seconds\n",
      "2018-09-02 03:44:44.553080 Training Step 425 \"min loss\" =  61.439426\n",
      "2018-09-02 03:44:44.553377 Training Step 425 \"loss\" =  61.439426\n",
      "2018-09-02 03:44:45.196655 Test Step 430 Finished\n",
      "2018-09-02 03:44:45.196750 Test Step 430 \"min loss\" =  100.59067\n",
      "2018-09-02 03:44:45.196802 Test Step 430 \"loss\" =  105.26891\n",
      "2018-09-02 03:44:45.335124 Training Step 430 Finished Timing (Training: 0.921975, Test: 0.0764925) after 0.78168 seconds\n",
      "2018-09-02 03:44:45.335195 Training Step 430 \"min loss\" =  56.59095\n",
      "2018-09-02 03:44:45.335286 Training Step 430 \"loss\" =  56.59095\n",
      "2018-09-02 03:44:45.976415 Test Step 435 Finished\n",
      "2018-09-02 03:44:45.976510 Test Step 435 \"min loss\" =  93.63479\n",
      "2018-09-02 03:44:45.976575 Test Step 435 \"loss\" =  93.63479\n",
      "2018-09-02 03:44:46.121893 Training Step 435 Finished Timing (Training: 0.921955, Test: 0.0765285) after 0.785939 seconds\n",
      "2018-09-02 03:44:46.121982 Training Step 435 \"min loss\" =  52.787666\n",
      "2018-09-02 03:44:46.122078 Training Step 435 \"loss\" =  52.787666\n",
      "2018-09-02 03:44:46.756516 Test Step 440 Finished\n",
      "2018-09-02 03:44:46.756616 Test Step 440 \"min loss\" =  86.171974\n",
      "2018-09-02 03:44:46.757222 Test Step 440 \"loss\" =  86.171974\n",
      "2018-09-02 03:44:46.902466 Training Step 440 Finished Timing (Training: 0.921613, Test: 0.0767359) after 0.779378 seconds\n",
      "2018-09-02 03:44:46.902762 Training Step 440 \"min loss\" =  48.348007\n",
      "2018-09-02 03:44:46.903011 Training Step 440 \"loss\" =  48.348007\n",
      "2018-09-02 03:44:47.551990 Test Step 445 Finished\n",
      "2018-09-02 03:44:47.552088 Test Step 445 \"min loss\" =  81.5927\n",
      "2018-09-02 03:44:47.552570 Test Step 445 \"loss\" =  81.5927\n",
      "2018-09-02 03:44:47.700032 Training Step 445 Finished Timing (Training: 0.921517, Test: 0.0768374) after 0.796956 seconds\n",
      "2018-09-02 03:44:47.700097 Training Step 445 \"min loss\" =  46.13578\n",
      "2018-09-02 03:44:47.700158 Training Step 445 \"loss\" =  46.13578\n",
      "2018-09-02 03:44:48.337369 Test Step 450 Finished\n",
      "2018-09-02 03:44:48.337463 Test Step 450 \"min loss\" =  74.33787\n",
      "2018-09-02 03:44:48.337511 Test Step 450 \"loss\" =  74.33787\n",
      "2018-09-02 03:44:48.477600 Training Step 450 Finished Timing (Training: 0.920945, Test: 0.0774292) after 0.776684 seconds\n",
      "2018-09-02 03:44:48.477668 Training Step 450 \"min loss\" =  42.663036\n",
      "2018-09-02 03:44:48.478117 Training Step 450 \"loss\" =  42.663036\n",
      "2018-09-02 03:44:49.111292 Test Step 455 Finished\n",
      "2018-09-02 03:44:49.111423 Test Step 455 \"min loss\" =  68.20715\n",
      "2018-09-02 03:44:49.111937 Test Step 455 \"loss\" =  68.20715\n",
      "2018-09-02 03:44:49.247968 Training Step 455 Finished Timing (Training: 0.92043, Test: 0.0779362) after 0.769784 seconds\n",
      "2018-09-02 03:44:49.248032 Training Step 455 \"min loss\" =  39.221764\n",
      "2018-09-02 03:44:49.248074 Training Step 455 \"loss\" =  39.221764\n",
      "2018-09-02 03:44:49.882449 Test Step 460 Finished\n",
      "2018-09-02 03:44:49.882569 Test Step 460 \"min loss\" =  61.501236\n",
      "2018-09-02 03:44:49.882619 Test Step 460 \"loss\" =  61.501236\n",
      "2018-09-02 03:44:50.030993 Training Step 460 Finished Timing (Training: 0.920628, Test: 0.0777536) after 0.782845 seconds\n",
      "2018-09-02 03:44:50.031059 Training Step 460 \"min loss\" =  37.210865\n",
      "2018-09-02 03:44:50.031099 Training Step 460 \"loss\" =  37.210865\n",
      "2018-09-02 03:44:50.676050 Test Step 465 Finished\n",
      "2018-09-02 03:44:50.676161 Test Step 465 \"min loss\" =  61.501236\n",
      "2018-09-02 03:44:50.676880 Test Step 465 \"loss\" =  63.0459\n",
      "2018-09-02 03:44:50.826480 Training Step 465 Finished Timing (Training: 0.920763, Test: 0.0776342) after 0.795326 seconds\n",
      "2018-09-02 03:44:50.826547 Training Step 465 \"min loss\" =  35.188023\n",
      "2018-09-02 03:44:50.826590 Training Step 465 \"loss\" =  35.188023\n",
      "2018-09-02 03:44:51.470762 Test Step 470 Finished\n",
      "2018-09-02 03:44:51.471215 Test Step 470 \"min loss\" =  58.887222\n",
      "2018-09-02 03:44:51.471476 Test Step 470 \"loss\" =  58.887222\n",
      "2018-09-02 03:44:51.608915 Training Step 470 Finished Timing (Training: 0.920704, Test: 0.0777159) after 0.782237 seconds\n",
      "2018-09-02 03:44:51.608992 Training Step 470 \"min loss\" =  33.091602\n",
      "2018-09-02 03:44:51.609051 Training Step 470 \"loss\" =  33.091602\n",
      "2018-09-02 03:44:52.249342 Test Step 475 Finished\n",
      "2018-09-02 03:44:52.249805 Test Step 475 \"min loss\" =  51.042164\n",
      "2018-09-02 03:44:52.249868 Test Step 475 \"loss\" =  51.042164\n",
      "2018-09-02 03:44:52.401706 Training Step 475 Finished Timing (Training: 0.920817, Test: 0.0776389) after 0.79258 seconds\n",
      "2018-09-02 03:44:52.401842 Training Step 475 \"min loss\" =  30.532349\n",
      "2018-09-02 03:44:52.402285 Training Step 475 \"loss\" =  30.532349\n",
      "2018-09-02 03:44:53.028159 Test Step 480 Finished\n",
      "2018-09-02 03:44:53.028243 Test Step 480 \"min loss\" =  51.042164\n",
      "2018-09-02 03:44:53.028680 Test Step 480 \"loss\" =  51.57487\n",
      "2018-09-02 03:44:53.170544 Training Step 480 Finished Timing (Training: 0.921076, Test: 0.077375) after 0.7682 seconds\n",
      "2018-09-02 03:44:53.170604 Training Step 480 \"min loss\" =  28.722643\n",
      "2018-09-02 03:44:53.170656 Training Step 480 \"loss\" =  29.31384\n",
      "2018-09-02 03:44:53.807404 Test Step 485 Finished\n",
      "2018-09-02 03:44:53.807709 Test Step 485 \"min loss\" =  47.186897\n",
      "2018-09-02 03:44:53.807982 Test Step 485 \"loss\" =  47.186897\n",
      "2018-09-02 03:44:53.955474 Training Step 485 Finished Timing (Training: 0.921361, Test: 0.0771192) after 0.784761 seconds\n",
      "2018-09-02 03:44:53.955556 Training Step 485 \"min loss\" =  26.348448\n",
      "2018-09-02 03:44:53.955635 Training Step 485 \"loss\" =  26.348448\n",
      "2018-09-02 03:44:54.572147 Test Step 490 Finished\n",
      "2018-09-02 03:44:54.572525 Test Step 490 \"min loss\" =  45.798225\n",
      "2018-09-02 03:44:54.572725 Test Step 490 \"loss\" =  45.798225\n",
      "2018-09-02 03:44:54.717530 Training Step 490 Finished Timing (Training: 0.921133, Test: 0.0773475) after 0.761823 seconds\n",
      "2018-09-02 03:44:54.717765 Training Step 490 \"min loss\" =  25.361656\n",
      "2018-09-02 03:44:54.717820 Training Step 490 \"loss\" =  25.606434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:44:55.342417 Test Step 495 Finished\n",
      "2018-09-02 03:44:55.342885 Test Step 495 \"min loss\" =  45.798225\n",
      "2018-09-02 03:44:55.343132 Test Step 495 \"loss\" =  47.569366\n",
      "2018-09-02 03:44:55.484900 Training Step 495 Finished Timing (Training: 0.921065, Test: 0.0774142) after 0.767017 seconds\n",
      "2018-09-02 03:44:55.485162 Training Step 495 \"min loss\" =  23.500774\n",
      "2018-09-02 03:44:55.485220 Training Step 495 \"loss\" =  24.568485\n",
      "2018-09-02 03:44:56.122485 Test Step 500 Finished\n",
      "2018-09-02 03:44:56.122786 Test Step 500 \"min loss\" =  45.798225\n",
      "2018-09-02 03:44:56.123060 Test Step 500 \"loss\" =  47.263336\n",
      "2018-09-02 03:44:56.266464 Training Step 500 Finished Timing (Training: 0.920606, Test: 0.0778583) after 0.781174 seconds\n",
      "2018-09-02 03:44:56.266853 Training Step 500 \"min loss\" =  22.381872\n",
      "2018-09-02 03:44:56.267380 Training Step 500 \"loss\" =  22.381872\n",
      "2018-09-02 03:44:56.918840 Test Step 505 Finished\n",
      "2018-09-02 03:44:56.919238 Test Step 505 \"min loss\" =  41.55907\n",
      "2018-09-02 03:44:56.919294 Test Step 505 \"loss\" =  41.55907\n",
      "2018-09-02 03:44:57.056522 Training Step 505 Finished Timing (Training: 0.919973, Test: 0.0788973) after 0.788685 seconds\n",
      "2018-09-02 03:44:57.056810 Training Step 505 \"min loss\" =  21.371557\n",
      "2018-09-02 03:44:57.056867 Training Step 505 \"loss\" =  21.371557\n",
      "2018-09-02 03:44:57.691816 Test Step 510 Finished\n",
      "2018-09-02 03:44:57.692199 Test Step 510 \"min loss\" =  37.92178\n",
      "2018-09-02 03:44:57.692254 Test Step 510 \"loss\" =  37.92178\n",
      "2018-09-02 03:44:57.840756 Training Step 510 Finished Timing (Training: 0.920819, Test: 0.077807) after 0.783832 seconds\n",
      "2018-09-02 03:44:57.840817 Training Step 510 \"min loss\" =  20.101862\n",
      "2018-09-02 03:44:57.840863 Training Step 510 \"loss\" =  20.101862\n",
      "2018-09-02 03:44:58.470278 Test Step 515 Finished\n",
      "2018-09-02 03:44:58.470368 Test Step 515 \"min loss\" =  36.43563\n",
      "2018-09-02 03:44:58.470425 Test Step 515 \"loss\" =  36.43563\n",
      "2018-09-02 03:44:58.613722 Training Step 515 Finished Timing (Training: 0.921016, Test: 0.0775561) after 0.772802 seconds\n",
      "2018-09-02 03:44:58.613796 Training Step 515 \"min loss\" =  19.666685\n",
      "2018-09-02 03:44:58.613849 Training Step 515 \"loss\" =  20.799715\n",
      "2018-09-02 03:44:59.247246 Test Step 520 Finished\n",
      "2018-09-02 03:44:59.247373 Test Step 520 \"min loss\" =  35.200172\n",
      "2018-09-02 03:44:59.247431 Test Step 520 \"loss\" =  35.200172\n",
      "2018-09-02 03:44:59.388883 Training Step 520 Finished Timing (Training: 0.920753, Test: 0.0778229) after 0.774974 seconds\n",
      "2018-09-02 03:44:59.388968 Training Step 520 \"min loss\" =  18.614668\n",
      "2018-09-02 03:44:59.389023 Training Step 520 \"loss\" =  18.614668\n",
      "2018-09-02 03:45:00.028671 Test Step 525 Finished\n",
      "2018-09-02 03:45:00.028816 Test Step 525 \"min loss\" =  32.385494\n",
      "2018-09-02 03:45:00.029597 Test Step 525 \"loss\" =  32.385494\n",
      "2018-09-02 03:45:00.173306 Training Step 525 Finished Timing (Training: 0.920824, Test: 0.0776197) after 0.784222 seconds\n",
      "2018-09-02 03:45:00.173399 Training Step 525 \"min loss\" =  18.129911\n",
      "2018-09-02 03:45:00.174016 Training Step 525 \"loss\" =  18.760887\n",
      "2018-09-02 03:45:00.811815 Test Step 530 Finished\n",
      "2018-09-02 03:45:00.811999 Test Step 530 \"min loss\" =  31.431028\n",
      "2018-09-02 03:45:00.812732 Test Step 530 \"loss\" =  31.431028\n",
      "2018-09-02 03:45:00.950182 Training Step 530 Finished Timing (Training: 0.920569, Test: 0.0775166) after 0.775709 seconds\n",
      "2018-09-02 03:45:00.950265 Training Step 530 \"min loss\" =  17.82061\n",
      "2018-09-02 03:45:00.950991 Training Step 530 \"loss\" =  17.82061\n",
      "2018-09-02 03:45:01.610182 Test Step 535 Finished\n",
      "2018-09-02 03:45:01.610672 Test Step 535 \"min loss\" =  31.431028\n",
      "2018-09-02 03:45:01.611250 Test Step 535 \"loss\" =  32.462246\n",
      "2018-09-02 03:45:01.750733 Training Step 535 Finished Timing (Training: 0.920232, Test: 0.0776398) after 0.799393 seconds\n",
      "2018-09-02 03:45:01.750872 Training Step 535 \"min loss\" =  16.284782\n",
      "2018-09-02 03:45:01.750988 Training Step 535 \"loss\" =  16.284782\n",
      "2018-09-02 03:45:02.392318 Test Step 540 Finished\n",
      "2018-09-02 03:45:02.392698 Test Step 540 \"min loss\" =  27.745401\n",
      "2018-09-02 03:45:02.393286 Test Step 540 \"loss\" =  27.745401\n",
      "2018-09-02 03:45:02.532846 Training Step 540 Finished Timing (Training: 0.919336, Test: 0.0784011) after 0.780722 seconds\n",
      "2018-09-02 03:45:02.533233 Training Step 540 \"min loss\" =  16.284782\n",
      "2018-09-02 03:45:02.533358 Training Step 540 \"loss\" =  17.326757\n",
      "2018-09-02 03:45:03.156701 Test Step 545 Finished\n",
      "2018-09-02 03:45:03.156829 Test Step 545 \"min loss\" =  27.601778\n",
      "2018-09-02 03:45:03.157540 Test Step 545 \"loss\" =  27.601778\n",
      "2018-09-02 03:45:03.304786 Training Step 545 Finished Timing (Training: 0.919505, Test: 0.0780887) after 0.770612 seconds\n",
      "2018-09-02 03:45:03.304867 Training Step 545 \"min loss\" =  16.018547\n",
      "2018-09-02 03:45:03.305492 Training Step 545 \"loss\" =  16.389349\n",
      "2018-09-02 03:45:03.940332 Test Step 550 Finished\n",
      "2018-09-02 03:45:03.940733 Test Step 550 \"min loss\" =  22.054867\n",
      "2018-09-02 03:45:03.941256 Test Step 550 \"loss\" =  22.054867\n",
      "2018-09-02 03:45:04.085482 Training Step 550 Finished Timing (Training: 0.919455, Test: 0.0780789) after 0.779417 seconds\n",
      "2018-09-02 03:45:04.085560 Training Step 550 \"min loss\" =  15.212516\n",
      "2018-09-02 03:45:04.086156 Training Step 550 \"loss\" =  15.651244\n",
      "2018-09-02 03:45:04.715012 Test Step 555 Finished\n",
      "2018-09-02 03:45:04.715444 Test Step 555 \"min loss\" =  21.864166\n",
      "2018-09-02 03:45:04.715743 Test Step 555 \"loss\" =  21.864166\n",
      "2018-09-02 03:45:04.865175 Training Step 555 Finished Timing (Training: 0.919334, Test: 0.0781384) after 0.778565 seconds\n",
      "2018-09-02 03:45:04.865276 Training Step 555 \"min loss\" =  14.451179\n",
      "2018-09-02 03:45:04.865858 Training Step 555 \"loss\" =  15.027607\n",
      "2018-09-02 03:45:05.519899 Test Step 560 Finished\n",
      "2018-09-02 03:45:05.520024 Test Step 560 \"min loss\" =  20.555134\n",
      "2018-09-02 03:45:05.520083 Test Step 560 \"loss\" =  20.555134\n",
      "2018-09-02 03:45:05.661658 Training Step 560 Finished Timing (Training: 0.919308, Test: 0.0782166) after 0.795234 seconds\n",
      "2018-09-02 03:45:05.661732 Training Step 560 \"min loss\" =  14.451179\n",
      "2018-09-02 03:45:05.662178 Training Step 560 \"loss\" =  14.545297\n",
      "2018-09-02 03:45:06.294840 Test Step 565 Finished\n",
      "2018-09-02 03:45:06.295362 Test Step 565 \"min loss\" =  19.855644\n",
      "2018-09-02 03:45:06.295428 Test Step 565 \"loss\" =  19.855644\n",
      "2018-09-02 03:45:06.442305 Training Step 565 Finished Timing (Training: 0.919386, Test: 0.0782041) after 0.780063 seconds\n",
      "2018-09-02 03:45:06.442368 Training Step 565 \"min loss\" =  14.243139\n",
      "2018-09-02 03:45:06.442428 Training Step 565 \"loss\" =  14.243139\n",
      "2018-09-02 03:45:07.085089 Test Step 570 Finished\n",
      "2018-09-02 03:45:07.085656 Test Step 570 \"min loss\" =  19.416134\n",
      "2018-09-02 03:45:07.085795 Test Step 570 \"loss\" =  19.416134\n",
      "2018-09-02 03:45:07.226888 Training Step 570 Finished Timing (Training: 0.919132, Test: 0.0785409) after 0.784403 seconds\n",
      "2018-09-02 03:45:07.226966 Training Step 570 \"min loss\" =  13.515637\n",
      "2018-09-02 03:45:07.227043 Training Step 570 \"loss\" =  13.515637\n",
      "2018-09-02 03:45:07.877798 Test Step 575 Finished\n",
      "2018-09-02 03:45:07.877880 Test Step 575 \"min loss\" =  19.416134\n",
      "2018-09-02 03:45:07.877934 Test Step 575 \"loss\" =  21.189692\n",
      "2018-09-02 03:45:08.020562 Training Step 575 Finished Timing (Training: 0.919172, Test: 0.0786186) after 0.793426 seconds\n",
      "2018-09-02 03:45:08.020636 Training Step 575 \"min loss\" =  13.112944\n",
      "2018-09-02 03:45:08.020692 Training Step 575 \"loss\" =  13.112944\n",
      "2018-09-02 03:45:08.654297 Test Step 580 Finished\n",
      "2018-09-02 03:45:08.654694 Test Step 580 \"min loss\" =  18.644968\n",
      "2018-09-02 03:45:08.654938 Test Step 580 \"loss\" =  18.644968\n",
      "2018-09-02 03:45:08.800142 Training Step 580 Finished Timing (Training: 0.919337, Test: 0.0785195) after 0.779392 seconds\n",
      "2018-09-02 03:45:08.800222 Training Step 580 \"min loss\" =  13.112944\n",
      "2018-09-02 03:45:08.800277 Training Step 580 \"loss\" =  14.080344\n",
      "2018-09-02 03:45:09.429772 Test Step 585 Finished\n",
      "2018-09-02 03:45:09.430059 Test Step 585 \"min loss\" =  15.553422\n",
      "2018-09-02 03:45:09.430328 Test Step 585 \"loss\" =  15.553422\n",
      "2018-09-02 03:45:09.573788 Training Step 585 Finished Timing (Training: 0.919491, Test: 0.0784084) after 0.773437 seconds\n",
      "2018-09-02 03:45:09.573865 Training Step 585 \"min loss\" =  13.112944\n",
      "2018-09-02 03:45:09.573919 Training Step 585 \"loss\" =  14.69108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:45:10.220321 Test Step 590 Finished\n",
      "2018-09-02 03:45:10.220419 Test Step 590 \"min loss\" =  15.084329\n",
      "2018-09-02 03:45:10.220473 Test Step 590 \"loss\" =  15.084329\n",
      "2018-09-02 03:45:10.364486 Training Step 590 Finished Timing (Training: 0.919559, Test: 0.0783916) after 0.789978 seconds\n",
      "2018-09-02 03:45:10.364556 Training Step 590 \"min loss\" =  12.535976\n",
      "2018-09-02 03:45:10.364608 Training Step 590 \"loss\" =  13.06788\n",
      "2018-09-02 03:45:11.012165 Test Step 595 Finished\n",
      "2018-09-02 03:45:11.012288 Test Step 595 \"min loss\" =  15.012782\n",
      "2018-09-02 03:45:11.012937 Test Step 595 \"loss\" =  15.012782\n",
      "2018-09-02 03:45:11.160641 Training Step 595 Finished Timing (Training: 0.919451, Test: 0.0785389) after 0.795959 seconds\n",
      "2018-09-02 03:45:11.160804 Training Step 595 \"min loss\" =  12.535976\n",
      "2018-09-02 03:45:11.160865 Training Step 595 \"loss\" =  13.287822\n",
      "2018-09-02 03:45:11.800960 Test Step 600 Finished\n",
      "2018-09-02 03:45:11.801427 Test Step 600 \"min loss\" =  15.012782\n",
      "2018-09-02 03:45:11.801629 Test Step 600 \"loss\" =  15.543476\n",
      "2018-09-02 03:45:11.951767 Training Step 600 Finished Timing (Training: 0.919348, Test: 0.0786181) after 0.790199 seconds\n",
      "2018-09-02 03:45:11.951823 Training Step 600 \"min loss\" =  12.342302\n",
      "2018-09-02 03:45:11.951878 Training Step 600 \"loss\" =  12.342302\n",
      "2018-09-02 03:45:12.592278 Test Step 605 Finished\n",
      "2018-09-02 03:45:12.592625 Test Step 605 \"min loss\" =  15.012782\n",
      "2018-09-02 03:45:12.592813 Test Step 605 \"loss\" =  15.250385\n",
      "2018-09-02 03:45:12.738829 Training Step 605 Finished Timing (Training: 0.924487, Test: 0.0747402) after 0.786374 seconds\n",
      "2018-09-02 03:45:12.738911 Training Step 605 \"min loss\" =  12.342302\n",
      "2018-09-02 03:45:12.738969 Training Step 605 \"loss\" =  12.778921\n",
      "2018-09-02 03:45:13.388275 Test Step 610 Finished\n",
      "2018-09-02 03:45:13.388371 Test Step 610 \"min loss\" =  14.987363\n",
      "2018-09-02 03:45:13.388432 Test Step 610 \"loss\" =  14.987363\n",
      "2018-09-02 03:45:13.530457 Training Step 610 Finished Timing (Training: 0.920968, Test: 0.0779654) after 0.791413 seconds\n",
      "2018-09-02 03:45:13.530525 Training Step 610 \"min loss\" =  11.92876\n",
      "2018-09-02 03:45:13.530577 Training Step 610 \"loss\" =  12.138565\n",
      "2018-09-02 03:45:14.173437 Test Step 615 Finished\n",
      "2018-09-02 03:45:14.173745 Test Step 615 \"min loss\" =  14.987363\n",
      "2018-09-02 03:45:14.174018 Test Step 615 \"loss\" =  15.720939\n",
      "2018-09-02 03:45:14.314687 Training Step 615 Finished Timing (Training: 0.920949, Test: 0.0778203) after 0.784053 seconds\n",
      "2018-09-02 03:45:14.314765 Training Step 615 \"min loss\" =  11.92876\n",
      "2018-09-02 03:45:14.315192 Training Step 615 \"loss\" =  12.82454\n",
      "2018-09-02 03:45:14.952821 Test Step 620 Finished\n",
      "2018-09-02 03:45:14.953246 Test Step 620 \"min loss\" =  12.858888\n",
      "2018-09-02 03:45:14.953455 Test Step 620 \"loss\" =  12.858888\n",
      "2018-09-02 03:45:15.096785 Training Step 620 Finished Timing (Training: 0.92021, Test: 0.0783823) after 0.781535 seconds\n",
      "2018-09-02 03:45:15.096848 Training Step 620 \"min loss\" =  11.611379\n",
      "2018-09-02 03:45:15.097204 Training Step 620 \"loss\" =  11.611379\n",
      "2018-09-02 03:45:15.743477 Test Step 625 Finished\n",
      "2018-09-02 03:45:15.743612 Test Step 625 \"min loss\" =  12.607917\n",
      "2018-09-02 03:45:15.744191 Test Step 625 \"loss\" =  12.607917\n",
      "2018-09-02 03:45:15.882993 Training Step 625 Finished Timing (Training: 0.919633, Test: 0.0788713) after 0.785729 seconds\n",
      "2018-09-02 03:45:15.883271 Training Step 625 \"min loss\" =  11.179002\n",
      "2018-09-02 03:45:15.883331 Training Step 625 \"loss\" =  11.363103\n",
      "2018-09-02 03:45:16.527573 Test Step 630 Finished\n",
      "2018-09-02 03:45:16.527701 Test Step 630 \"min loss\" =  12.289505\n",
      "2018-09-02 03:45:16.528278 Test Step 630 \"loss\" =  12.289505\n",
      "2018-09-02 03:45:16.666021 Training Step 630 Finished Timing (Training: 0.920295, Test: 0.078205) after 0.78262 seconds\n",
      "2018-09-02 03:45:16.666140 Training Step 630 \"min loss\" =  11.131419\n",
      "2018-09-02 03:45:16.666195 Training Step 630 \"loss\" =  11.131419\n",
      "2018-09-02 03:45:17.310374 Test Step 635 Finished\n",
      "2018-09-02 03:45:17.310481 Test Step 635 \"min loss\" =  12.289505\n",
      "2018-09-02 03:45:17.310570 Test Step 635 \"loss\" =  12.295478\n",
      "2018-09-02 03:45:17.453945 Training Step 635 Finished Timing (Training: 0.920103, Test: 0.0782077) after 0.786937 seconds\n",
      "2018-09-02 03:45:17.454022 Training Step 635 \"min loss\" =  11.131419\n",
      "2018-09-02 03:45:17.454097 Training Step 635 \"loss\" =  11.966551\n",
      "2018-09-02 03:45:18.082170 Test Step 640 Finished\n",
      "2018-09-02 03:45:18.082263 Test Step 640 \"min loss\" =  12.140547\n",
      "2018-09-02 03:45:18.082313 Test Step 640 \"loss\" =  12.140547\n",
      "2018-09-02 03:45:18.229740 Training Step 640 Finished Timing (Training: 0.920819, Test: 0.0775378) after 0.775002 seconds\n",
      "2018-09-02 03:45:18.229812 Training Step 640 \"min loss\" =  11.131419\n",
      "2018-09-02 03:45:18.229861 Training Step 640 \"loss\" =  11.778268\n",
      "2018-09-02 03:45:18.870693 Test Step 645 Finished\n",
      "2018-09-02 03:45:18.870781 Test Step 645 \"min loss\" =  11.430917\n",
      "2018-09-02 03:45:18.870840 Test Step 645 \"loss\" =  11.430917\n",
      "2018-09-02 03:45:19.018881 Training Step 645 Finished Timing (Training: 0.92073, Test: 0.0776224) after 0.788924 seconds\n",
      "2018-09-02 03:45:19.018952 Training Step 645 \"min loss\" =  10.964399\n",
      "2018-09-02 03:45:19.018992 Training Step 645 \"loss\" =  11.495592\n",
      "2018-09-02 03:45:19.661030 Test Step 650 Finished\n",
      "2018-09-02 03:45:19.661131 Test Step 650 \"min loss\" =  11.430917\n",
      "2018-09-02 03:45:19.661198 Test Step 650 \"loss\" =  11.604946\n",
      "2018-09-02 03:45:19.801454 Training Step 650 Finished Timing (Training: 0.921111, Test: 0.0773485) after 0.78238 seconds\n",
      "2018-09-02 03:45:19.801517 Training Step 650 \"min loss\" =  10.964399\n",
      "2018-09-02 03:45:19.801937 Training Step 650 \"loss\" =  11.285711\n",
      "2018-09-02 03:45:20.433137 Test Step 655 Finished\n",
      "2018-09-02 03:45:20.433243 Test Step 655 \"min loss\" =  11.325236\n",
      "2018-09-02 03:45:20.433926 Test Step 655 \"loss\" =  11.325236\n",
      "2018-09-02 03:45:20.581569 Training Step 655 Finished Timing (Training: 0.921167, Test: 0.0772652) after 0.779564 seconds\n",
      "2018-09-02 03:45:20.581636 Training Step 655 \"min loss\" =  10.929083\n",
      "2018-09-02 03:45:20.582129 Training Step 655 \"loss\" =  11.19123\n",
      "2018-09-02 03:45:21.228449 Test Step 660 Finished\n",
      "2018-09-02 03:45:21.228552 Test Step 660 \"min loss\" =  10.528344\n",
      "2018-09-02 03:45:21.228594 Test Step 660 \"loss\" =  10.528344\n",
      "2018-09-02 03:45:21.372039 Training Step 660 Finished Timing (Training: 0.921343, Test: 0.077025) after 0.789833 seconds\n",
      "2018-09-02 03:45:21.372176 Training Step 660 \"min loss\" =  10.752433\n",
      "2018-09-02 03:45:21.372225 Training Step 660 \"loss\" =  10.842571\n",
      "2018-09-02 03:45:22.011267 Test Step 665 Finished\n",
      "2018-09-02 03:45:22.011763 Test Step 665 \"min loss\" =  10.528344\n",
      "2018-09-02 03:45:22.011824 Test Step 665 \"loss\" =  11.023444\n",
      "2018-09-02 03:45:22.160583 Training Step 665 Finished Timing (Training: 0.921406, Test: 0.0769997) after 0.788293 seconds\n",
      "2018-09-02 03:45:22.160877 Training Step 665 \"min loss\" =  10.752433\n",
      "2018-09-02 03:45:22.160936 Training Step 665 \"loss\" =  11.371172\n",
      "2018-09-02 03:45:22.796701 Test Step 670 Finished\n",
      "2018-09-02 03:45:22.796815 Test Step 670 \"min loss\" =  10.528344\n",
      "2018-09-02 03:45:22.796873 Test Step 670 \"loss\" =  10.562744\n",
      "2018-09-02 03:45:22.933425 Training Step 670 Finished Timing (Training: 0.921216, Test: 0.0772397) after 0.77243 seconds\n",
      "2018-09-02 03:45:22.933488 Training Step 670 \"min loss\" =  10.752433\n",
      "2018-09-02 03:45:22.933854 Training Step 670 \"loss\" =  11.066905\n",
      "2018-09-02 03:45:23.549230 Test Step 675 Finished\n",
      "2018-09-02 03:45:23.549769 Test Step 675 \"min loss\" =  10.490219\n",
      "2018-09-02 03:45:23.549926 Test Step 675 \"loss\" =  10.490219\n",
      "2018-09-02 03:45:23.699935 Training Step 675 Finished Timing (Training: 0.921454, Test: 0.0769513) after 0.765598 seconds\n",
      "2018-09-02 03:45:23.700001 Training Step 675 \"min loss\" =  10.612412\n",
      "2018-09-02 03:45:23.700058 Training Step 675 \"loss\" =  10.829972\n",
      "2018-09-02 03:45:24.328480 Test Step 680 Finished\n",
      "2018-09-02 03:45:24.328574 Test Step 680 \"min loss\" =  10.253022\n",
      "2018-09-02 03:45:24.328626 Test Step 680 \"loss\" =  10.253022\n",
      "2018-09-02 03:45:24.483261 Training Step 680 Finished Timing (Training: 0.921534, Test: 0.0768744) after 0.783134 seconds\n",
      "2018-09-02 03:45:24.483430 Training Step 680 \"min loss\" =  10.612412\n",
      "2018-09-02 03:45:24.483485 Training Step 680 \"loss\" =  11.115188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:45:25.117685 Test Step 685 Finished\n",
      "2018-09-02 03:45:25.117778 Test Step 685 \"min loss\" =  9.933361\n",
      "2018-09-02 03:45:25.118276 Test Step 685 \"loss\" =  9.933361\n",
      "2018-09-02 03:45:25.261708 Training Step 685 Finished Timing (Training: 0.921583, Test: 0.0768221) after 0.778161 seconds\n",
      "2018-09-02 03:45:25.261782 Training Step 685 \"min loss\" =  10.003572\n",
      "2018-09-02 03:45:25.261846 Training Step 685 \"loss\" =  10.381117\n",
      "2018-09-02 03:45:25.915375 Test Step 690 Finished\n",
      "2018-09-02 03:45:25.915497 Test Step 690 \"min loss\" =  9.933361\n",
      "2018-09-02 03:45:25.915577 Test Step 690 \"loss\" =  10.278904\n",
      "2018-09-02 03:45:26.059317 Training Step 690 Finished Timing (Training: 0.921607, Test: 0.0768197) after 0.796933 seconds\n",
      "2018-09-02 03:45:26.059402 Training Step 690 \"min loss\" =  10.003572\n",
      "2018-09-02 03:45:26.059838 Training Step 690 \"loss\" =  11.13826\n",
      "2018-09-02 03:45:26.713879 Test Step 695 Finished\n",
      "2018-09-02 03:45:26.714009 Test Step 695 \"min loss\" =  9.933361\n",
      "2018-09-02 03:45:26.714097 Test Step 695 \"loss\" =  10.055789\n",
      "2018-09-02 03:45:26.867789 Training Step 695 Finished Timing (Training: 0.921891, Test: 0.0765613) after 0.807887 seconds\n",
      "2018-09-02 03:45:26.867878 Training Step 695 \"min loss\" =  10.003572\n",
      "2018-09-02 03:45:26.868391 Training Step 695 \"loss\" =  10.72971\n",
      "2018-09-02 03:45:27.509209 Test Step 700 Finished\n",
      "2018-09-02 03:45:27.509558 Test Step 700 \"min loss\" =  9.933361\n",
      "2018-09-02 03:45:27.509613 Test Step 700 \"loss\" =  10.068987\n",
      "2018-09-02 03:45:27.650375 Training Step 700 Finished Timing (Training: 0.921866, Test: 0.0765896) after 0.781924 seconds\n",
      "2018-09-02 03:45:27.650435 Training Step 700 \"min loss\" =  10.003572\n",
      "2018-09-02 03:45:27.650905 Training Step 700 \"loss\" =  10.590826\n",
      "2018-09-02 03:45:28.285088 Test Step 705 Finished\n",
      "2018-09-02 03:45:28.285581 Test Step 705 \"min loss\" =  9.933361\n",
      "2018-09-02 03:45:28.285837 Test Step 705 \"loss\" =  10.058281\n",
      "2018-09-02 03:45:28.429717 Training Step 705 Finished Timing (Training: 0.92139, Test: 0.0775479) after 0.778735 seconds\n",
      "2018-09-02 03:45:28.429783 Training Step 705 \"min loss\" =  10.003572\n",
      "2018-09-02 03:45:28.429836 Training Step 705 \"loss\" =  10.620948\n",
      "2018-09-02 03:45:29.065605 Test Step 710 Finished\n",
      "2018-09-02 03:45:29.065725 Test Step 710 \"min loss\" =  9.933361\n",
      "2018-09-02 03:45:29.065803 Test Step 710 \"loss\" =  10.29395\n",
      "2018-09-02 03:45:29.208685 Training Step 710 Finished Timing (Training: 0.920427, Test: 0.0787482) after 0.778786 seconds\n",
      "2018-09-02 03:45:29.208783 Training Step 710 \"min loss\" =  10.003572\n",
      "2018-09-02 03:45:29.208859 Training Step 710 \"loss\" =  10.302353\n",
      "2018-09-02 03:45:29.862866 Test Step 715 Finished\n",
      "2018-09-02 03:45:29.862965 Test Step 715 \"min loss\" =  9.889884\n",
      "2018-09-02 03:45:29.863023 Test Step 715 \"loss\" =  9.889884\n",
      "2018-09-02 03:45:30.009932 Training Step 715 Finished Timing (Training: 0.92004, Test: 0.0792065) after 0.801013 seconds\n",
      "2018-09-02 03:45:30.010023 Training Step 715 \"min loss\" =  10.003572\n",
      "2018-09-02 03:45:30.010077 Training Step 715 \"loss\" =  10.548343\n",
      "2018-09-02 03:45:30.655081 Test Step 720 Finished\n",
      "2018-09-02 03:45:30.655184 Test Step 720 \"min loss\" =  9.889884\n",
      "2018-09-02 03:45:30.655813 Test Step 720 \"loss\" =  10.106342\n",
      "2018-09-02 03:45:30.802419 Training Step 720 Finished Timing (Training: 0.91904, Test: 0.0800251) after 0.792283 seconds\n",
      "2018-09-02 03:45:30.802476 Training Step 720 \"min loss\" =  9.62144\n",
      "2018-09-02 03:45:30.802836 Training Step 720 \"loss\" =  10.449613\n",
      "2018-09-02 03:45:31.447140 Test Step 725 Finished\n",
      "2018-09-02 03:45:31.447608 Test Step 725 \"min loss\" =  9.676639\n",
      "2018-09-02 03:45:31.447670 Test Step 725 \"loss\" =  9.676639\n",
      "2018-09-02 03:45:31.586106 Training Step 725 Finished Timing (Training: 0.918965, Test: 0.079893) after 0.783212 seconds\n",
      "2018-09-02 03:45:31.586177 Training Step 725 \"min loss\" =  9.42879\n",
      "2018-09-02 03:45:31.586230 Training Step 725 \"loss\" =  9.42879\n",
      "2018-09-02 03:45:32.233602 Test Step 730 Finished\n",
      "2018-09-02 03:45:32.233752 Test Step 730 \"min loss\" =  9.431457\n",
      "2018-09-02 03:45:32.233820 Test Step 730 \"loss\" =  9.431457\n",
      "2018-09-02 03:45:32.379862 Training Step 730 Finished Timing (Training: 0.919353, Test: 0.0794675) after 0.793008 seconds\n",
      "2018-09-02 03:45:32.379926 Training Step 730 \"min loss\" =  9.42879\n",
      "2018-09-02 03:45:32.380737 Training Step 730 \"loss\" =  9.768979\n",
      "2018-09-02 03:45:32.996840 Test Step 735 Finished\n",
      "2018-09-02 03:45:32.996947 Test Step 735 \"min loss\" =  9.431457\n",
      "2018-09-02 03:45:32.997015 Test Step 735 \"loss\" =  9.640348\n",
      "2018-09-02 03:45:33.144652 Training Step 735 Finished Timing (Training: 0.918801, Test: 0.0799626) after 0.763835 seconds\n",
      "2018-09-02 03:45:33.145011 Training Step 735 \"min loss\" =  9.42879\n",
      "2018-09-02 03:45:33.145236 Training Step 735 \"loss\" =  9.683722\n",
      "2018-09-02 03:45:33.794089 Test Step 740 Finished\n",
      "2018-09-02 03:45:33.794481 Test Step 740 \"min loss\" =  9.431457\n",
      "2018-09-02 03:45:33.794542 Test Step 740 \"loss\" =  9.711069\n",
      "2018-09-02 03:45:33.936314 Training Step 740 Finished Timing (Training: 0.918974, Test: 0.0796985) after 0.790652 seconds\n",
      "2018-09-02 03:45:33.936383 Training Step 740 \"min loss\" =  9.419943\n",
      "2018-09-02 03:45:33.936443 Training Step 740 \"loss\" =  10.270854\n",
      "2018-09-02 03:45:34.581671 Test Step 745 Finished\n",
      "2018-09-02 03:45:34.581798 Test Step 745 \"min loss\" =  9.431457\n",
      "2018-09-02 03:45:34.581888 Test Step 745 \"loss\" =  9.5450325\n",
      "2018-09-02 03:45:34.728776 Training Step 745 Finished Timing (Training: 0.919002, Test: 0.0797466) after 0.792253 seconds\n",
      "2018-09-02 03:45:34.728860 Training Step 745 \"min loss\" =  9.322901\n",
      "2018-09-02 03:45:34.729280 Training Step 745 \"loss\" =  9.322901\n",
      "2018-09-02 03:45:35.367080 Test Step 750 Finished\n",
      "2018-09-02 03:45:35.367225 Test Step 750 \"min loss\" =  9.431457\n",
      "2018-09-02 03:45:35.367289 Test Step 750 \"loss\" =  9.528799\n",
      "2018-09-02 03:45:35.516003 Training Step 750 Finished Timing (Training: 0.919235, Test: 0.0795257) after 0.786642 seconds\n",
      "2018-09-02 03:45:35.516137 Training Step 750 \"min loss\" =  9.322901\n",
      "2018-09-02 03:45:35.516189 Training Step 750 \"loss\" =  9.582738\n",
      "2018-09-02 03:45:36.155261 Test Step 755 Finished\n",
      "2018-09-02 03:45:36.155808 Test Step 755 \"min loss\" =  9.253182\n",
      "2018-09-02 03:45:36.155978 Test Step 755 \"loss\" =  9.253182\n",
      "2018-09-02 03:45:36.304685 Training Step 755 Finished Timing (Training: 0.919695, Test: 0.078969) after 0.787758 seconds\n",
      "2018-09-02 03:45:36.304838 Training Step 755 \"min loss\" =  9.0736685\n",
      "2018-09-02 03:45:36.304903 Training Step 755 \"loss\" =  9.695146\n",
      "2018-09-02 03:45:36.936134 Test Step 760 Finished\n",
      "2018-09-02 03:45:36.936269 Test Step 760 \"min loss\" =  9.253182\n",
      "2018-09-02 03:45:36.936328 Test Step 760 \"loss\" =  9.336822\n",
      "2018-09-02 03:45:37.079511 Training Step 760 Finished Timing (Training: 0.919482, Test: 0.0791367) after 0.773673 seconds\n",
      "2018-09-02 03:45:37.079575 Training Step 760 \"min loss\" =  9.0736685\n",
      "2018-09-02 03:45:37.080084 Training Step 760 \"loss\" =  9.247471\n",
      "2018-09-02 03:45:37.716578 Test Step 765 Finished\n",
      "2018-09-02 03:45:37.716987 Test Step 765 \"min loss\" =  9.253182\n",
      "2018-09-02 03:45:37.717361 Test Step 765 \"loss\" =  9.507957\n",
      "2018-09-02 03:45:37.855729 Training Step 765 Finished Timing (Training: 0.919157, Test: 0.0793401) after 0.775075 seconds\n",
      "2018-09-02 03:45:37.855800 Training Step 765 \"min loss\" =  9.0736685\n",
      "2018-09-02 03:45:37.856262 Training Step 765 \"loss\" =  9.651081\n",
      "2018-09-02 03:45:38.514098 Test Step 770 Finished\n",
      "2018-09-02 03:45:38.514582 Test Step 770 \"min loss\" =  9.253182\n",
      "2018-09-02 03:45:38.514654 Test Step 770 \"loss\" =  9.67246\n",
      "2018-09-02 03:45:38.662537 Training Step 770 Finished Timing (Training: 0.919106, Test: 0.0793509) after 0.805814 seconds\n",
      "2018-09-02 03:45:38.662605 Training Step 770 \"min loss\" =  8.980175\n",
      "2018-09-02 03:45:38.662647 Training Step 770 \"loss\" =  9.806281\n",
      "2018-09-02 03:45:39.304322 Test Step 775 Finished\n",
      "2018-09-02 03:45:39.304441 Test Step 775 \"min loss\" =  9.253182\n",
      "2018-09-02 03:45:39.305029 Test Step 775 \"loss\" =  9.343869\n",
      "2018-09-02 03:45:39.451669 Training Step 775 Finished Timing (Training: 0.918944, Test: 0.0795341) after 0.788964 seconds\n",
      "2018-09-02 03:45:39.451741 Training Step 775 \"min loss\" =  8.980175\n",
      "2018-09-02 03:45:39.451802 Training Step 775 \"loss\" =  9.129623\n",
      "2018-09-02 03:45:40.094300 Test Step 780 Finished\n",
      "2018-09-02 03:45:40.094402 Test Step 780 \"min loss\" =  9.030276\n",
      "2018-09-02 03:45:40.094459 Test Step 780 \"loss\" =  9.030276\n",
      "2018-09-02 03:45:40.235834 Training Step 780 Finished Timing (Training: 0.918777, Test: 0.0797001) after 0.783967 seconds\n",
      "2018-09-02 03:45:40.235901 Training Step 780 \"min loss\" =  8.980011\n",
      "2018-09-02 03:45:40.235957 Training Step 780 \"loss\" =  10.140211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:45:40.882055 Test Step 785 Finished\n",
      "2018-09-02 03:45:40.882560 Test Step 785 \"min loss\" =  9.030276\n",
      "2018-09-02 03:45:40.882628 Test Step 785 \"loss\" =  9.469858\n",
      "2018-09-02 03:45:41.023432 Training Step 785 Finished Timing (Training: 0.918707, Test: 0.0797404) after 0.78665 seconds\n",
      "2018-09-02 03:45:41.023710 Training Step 785 \"min loss\" =  8.810556\n",
      "2018-09-02 03:45:41.023773 Training Step 785 \"loss\" =  9.074562\n",
      "2018-09-02 03:45:41.659198 Test Step 790 Finished\n",
      "2018-09-02 03:45:41.659684 Test Step 790 \"min loss\" =  9.030276\n",
      "2018-09-02 03:45:41.659749 Test Step 790 \"loss\" =  9.333095\n",
      "2018-09-02 03:45:41.800711 Training Step 790 Finished Timing (Training: 0.91873, Test: 0.0797288) after 0.776877 seconds\n",
      "2018-09-02 03:45:41.800773 Training Step 790 \"min loss\" =  8.810556\n",
      "2018-09-02 03:45:41.800812 Training Step 790 \"loss\" =  9.195736\n",
      "2018-09-02 03:45:42.434685 Test Step 795 Finished\n",
      "2018-09-02 03:45:42.435322 Test Step 795 \"min loss\" =  8.972392\n",
      "2018-09-02 03:45:42.435386 Test Step 795 \"loss\" =  8.972392\n",
      "2018-09-02 03:45:42.587478 Training Step 795 Finished Timing (Training: 0.918914, Test: 0.079515) after 0.786616 seconds\n",
      "2018-09-02 03:45:42.587540 Training Step 795 \"min loss\" =  8.671091\n",
      "2018-09-02 03:45:42.588011 Training Step 795 \"loss\" =  9.339793\n",
      "2018-09-02 03:45:43.232065 Test Step 800 Finished\n",
      "2018-09-02 03:45:43.232424 Test Step 800 \"min loss\" =  8.972392\n",
      "2018-09-02 03:45:43.232785 Test Step 800 \"loss\" =  9.137721\n",
      "2018-09-02 03:45:43.380218 Training Step 800 Finished Timing (Training: 0.91931, Test: 0.0791087) after 0.792143 seconds\n",
      "2018-09-02 03:45:43.380280 Training Step 800 \"min loss\" =  8.671091\n",
      "2018-09-02 03:45:43.380339 Training Step 800 \"loss\" =  9.179844\n",
      "2018-09-02 03:45:44.025196 Test Step 805 Finished\n",
      "2018-09-02 03:45:44.025572 Test Step 805 \"min loss\" =  8.972392\n",
      "2018-09-02 03:45:44.025632 Test Step 805 \"loss\" =  9.073181\n",
      "2018-09-02 03:45:44.168057 Training Step 805 Finished Timing (Training: 0.915856, Test: 0.0825147) after 0.786878 seconds\n",
      "2018-09-02 03:45:44.168145 Training Step 805 \"min loss\" =  8.671091\n",
      "2018-09-02 03:45:44.168224 Training Step 805 \"loss\" =  9.714192\n",
      "2018-09-02 03:45:44.824449 Test Step 810 Finished\n",
      "2018-09-02 03:45:44.824676 Test Step 810 \"min loss\" =  8.972392\n",
      "2018-09-02 03:45:44.824766 Test Step 810 \"loss\" =  9.125868\n",
      "2018-09-02 03:45:44.973819 Training Step 810 Finished Timing (Training: 0.918207, Test: 0.0796464) after 0.804832 seconds\n",
      "2018-09-02 03:45:44.973880 Training Step 810 \"min loss\" =  8.671091\n",
      "2018-09-02 03:45:44.974233 Training Step 810 \"loss\" =  9.00965\n",
      "2018-09-02 03:45:45.614726 Test Step 815 Finished\n",
      "2018-09-02 03:45:45.615263 Test Step 815 \"min loss\" =  8.912436\n",
      "2018-09-02 03:45:45.615361 Test Step 815 \"loss\" =  8.912436\n",
      "2018-09-02 03:45:45.761408 Training Step 815 Finished Timing (Training: 0.919333, Test: 0.0784056) after 0.787026 seconds\n",
      "2018-09-02 03:45:45.761490 Training Step 815 \"min loss\" =  8.671091\n",
      "2018-09-02 03:45:45.761599 Training Step 815 \"loss\" =  9.358874\n",
      "2018-09-02 03:45:46.427632 Test Step 820 Finished\n",
      "2018-09-02 03:45:46.427781 Test Step 820 \"min loss\" =  8.899271\n",
      "2018-09-02 03:45:46.428583 Test Step 820 \"loss\" =  8.899271\n",
      "2018-09-02 03:45:46.574847 Training Step 820 Finished Timing (Training: 0.918612, Test: 0.0788563) after 0.812196 seconds\n",
      "2018-09-02 03:45:46.574923 Training Step 820 \"min loss\" =  8.475145\n",
      "2018-09-02 03:45:46.575639 Training Step 820 \"loss\" =  8.895917\n",
      "2018-09-02 03:45:47.232507 Test Step 825 Finished\n",
      "2018-09-02 03:45:47.233001 Test Step 825 \"min loss\" =  8.885042\n",
      "2018-09-02 03:45:47.233537 Test Step 825 \"loss\" =  8.885042\n",
      "2018-09-02 03:45:47.383651 Training Step 825 Finished Timing (Training: 0.918162, Test: 0.0792186) after 0.807913 seconds\n",
      "2018-09-02 03:45:47.384027 Training Step 825 \"min loss\" =  8.475145\n",
      "2018-09-02 03:45:47.384478 Training Step 825 \"loss\" =  9.312168\n",
      "2018-09-02 03:45:48.021924 Test Step 830 Finished\n",
      "2018-09-02 03:45:48.022075 Test Step 830 \"min loss\" =  8.885042\n",
      "2018-09-02 03:45:48.022707 Test Step 830 \"loss\" =  8.888718\n",
      "2018-09-02 03:45:48.171921 Training Step 830 Finished Timing (Training: 0.919008, Test: 0.0783508) after 0.786986 seconds\n",
      "2018-09-02 03:45:48.172138 Training Step 830 \"min loss\" =  8.475145\n",
      "2018-09-02 03:45:48.172205 Training Step 830 \"loss\" =  9.029662\n",
      "2018-09-02 03:45:48.820786 Test Step 835 Finished\n",
      "2018-09-02 03:45:48.820901 Test Step 835 \"min loss\" =  8.885042\n",
      "2018-09-02 03:45:48.820965 Test Step 835 \"loss\" =  9.111409\n",
      "2018-09-02 03:45:48.965548 Training Step 835 Finished Timing (Training: 0.919762, Test: 0.0778597) after 0.793276 seconds\n",
      "2018-09-02 03:45:48.965612 Training Step 835 \"min loss\" =  8.475145\n",
      "2018-09-02 03:45:48.966099 Training Step 835 \"loss\" =  9.009505\n",
      "2018-09-02 03:45:49.610613 Test Step 840 Finished\n",
      "2018-09-02 03:45:49.610706 Test Step 840 \"min loss\" =  8.536247\n",
      "2018-09-02 03:45:49.610789 Test Step 840 \"loss\" =  8.536247\n",
      "2018-09-02 03:45:49.755303 Training Step 840 Finished Timing (Training: 0.919432, Test: 0.0783383) after 0.789093 seconds\n",
      "2018-09-02 03:45:49.755372 Training Step 840 \"min loss\" =  8.322262\n",
      "2018-09-02 03:45:49.755416 Training Step 840 \"loss\" =  8.595503\n",
      "2018-09-02 03:45:50.391734 Test Step 845 Finished\n",
      "2018-09-02 03:45:50.391850 Test Step 845 \"min loss\" =  8.512789\n",
      "2018-09-02 03:45:50.391904 Test Step 845 \"loss\" =  8.512789\n",
      "2018-09-02 03:45:50.535292 Training Step 845 Finished Timing (Training: 0.919196, Test: 0.0787533) after 0.779794 seconds\n",
      "2018-09-02 03:45:50.535551 Training Step 845 \"min loss\" =  8.322262\n",
      "2018-09-02 03:45:50.535628 Training Step 845 \"loss\" =  8.844949\n",
      "2018-09-02 03:45:51.163276 Test Step 850 Finished\n",
      "2018-09-02 03:45:51.163367 Test Step 850 \"min loss\" =  8.512789\n",
      "2018-09-02 03:45:51.164165 Test Step 850 \"loss\" =  9.227785\n",
      "2018-09-02 03:45:51.310085 Training Step 850 Finished Timing (Training: 0.919095, Test: 0.0788789) after 0.774389 seconds\n",
      "2018-09-02 03:45:51.310150 Training Step 850 \"min loss\" =  8.322262\n",
      "2018-09-02 03:45:51.310702 Training Step 850 \"loss\" =  8.967996\n",
      "2018-09-02 03:45:51.948611 Test Step 855 Finished\n",
      "2018-09-02 03:45:51.949163 Test Step 855 \"min loss\" =  8.512789\n",
      "2018-09-02 03:45:51.949614 Test Step 855 \"loss\" =  8.755508\n",
      "2018-09-02 03:45:52.097267 Training Step 855 Finished Timing (Training: 0.919433, Test: 0.0785193) after 0.786494 seconds\n",
      "2018-09-02 03:45:52.097372 Training Step 855 \"min loss\" =  8.322262\n",
      "2018-09-02 03:45:52.097757 Training Step 855 \"loss\" =  9.279662\n",
      "2018-09-02 03:45:52.727848 Test Step 860 Finished\n",
      "2018-09-02 03:45:52.728313 Test Step 860 \"min loss\" =  8.512789\n",
      "2018-09-02 03:45:52.728572 Test Step 860 \"loss\" =  8.786514\n",
      "2018-09-02 03:45:52.875218 Training Step 860 Finished Timing (Training: 0.919155, Test: 0.0787407) after 0.777017 seconds\n",
      "2018-09-02 03:45:52.875489 Training Step 860 \"min loss\" =  8.0961075\n",
      "2018-09-02 03:45:52.875854 Training Step 860 \"loss\" =  9.134815\n",
      "2018-09-02 03:45:53.514486 Test Step 865 Finished\n",
      "2018-09-02 03:45:53.514736 Test Step 865 \"min loss\" =  8.512789\n",
      "2018-09-02 03:45:53.515181 Test Step 865 \"loss\" =  8.517106\n",
      "2018-09-02 03:45:53.661948 Training Step 865 Finished Timing (Training: 0.919446, Test: 0.0784432) after 0.785785 seconds\n",
      "2018-09-02 03:45:53.662030 Training Step 865 \"min loss\" =  8.0961075\n",
      "2018-09-02 03:45:53.662582 Training Step 865 \"loss\" =  8.634092\n",
      "2018-09-02 03:45:54.298059 Test Step 870 Finished\n",
      "2018-09-02 03:45:54.298476 Test Step 870 \"min loss\" =  8.512789\n",
      "2018-09-02 03:45:54.298726 Test Step 870 \"loss\" =  8.855486\n",
      "2018-09-02 03:45:54.434234 Training Step 870 Finished Timing (Training: 0.919094, Test: 0.0787768) after 0.771377 seconds\n",
      "2018-09-02 03:45:54.434317 Training Step 870 \"min loss\" =  8.0961075\n",
      "2018-09-02 03:45:54.434884 Training Step 870 \"loss\" =  8.849017\n",
      "2018-09-02 03:45:55.099727 Test Step 875 Finished\n",
      "2018-09-02 03:45:55.099840 Test Step 875 \"min loss\" =  8.512789\n",
      "2018-09-02 03:45:55.100514 Test Step 875 \"loss\" =  8.759259\n",
      "2018-09-02 03:45:55.245650 Training Step 875 Finished Timing (Training: 0.91895, Test: 0.0789107) after 0.810448 seconds\n",
      "2018-09-02 03:45:55.245728 Training Step 875 \"min loss\" =  8.0961075\n",
      "2018-09-02 03:45:55.246263 Training Step 875 \"loss\" =  8.957639\n",
      "2018-09-02 03:45:55.888642 Test Step 880 Finished\n",
      "2018-09-02 03:45:55.888761 Test Step 880 \"min loss\" =  8.512789\n",
      "2018-09-02 03:45:55.889215 Test Step 880 \"loss\" =  8.888442\n",
      "2018-09-02 03:45:56.030967 Training Step 880 Finished Timing (Training: 0.918835, Test: 0.0790391) after 0.784494 seconds\n",
      "2018-09-02 03:45:56.031033 Training Step 880 \"min loss\" =  8.0961075\n",
      "2018-09-02 03:45:56.031076 Training Step 880 \"loss\" =  8.436504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:45:56.676589 Test Step 885 Finished\n",
      "2018-09-02 03:45:56.676726 Test Step 885 \"min loss\" =  8.512789\n",
      "2018-09-02 03:45:56.677238 Test Step 885 \"loss\" =  8.840404\n",
      "2018-09-02 03:45:56.821584 Training Step 885 Finished Timing (Training: 0.918966, Test: 0.0789595) after 0.790395 seconds\n",
      "2018-09-02 03:45:56.821649 Training Step 885 \"min loss\" =  7.846715\n",
      "2018-09-02 03:45:56.821706 Training Step 885 \"loss\" =  8.103902\n",
      "2018-09-02 03:45:57.462223 Test Step 890 Finished\n",
      "2018-09-02 03:45:57.462676 Test Step 890 \"min loss\" =  8.512789\n",
      "2018-09-02 03:45:57.462742 Test Step 890 \"loss\" =  9.481587\n",
      "2018-09-02 03:45:57.610369 Training Step 890 Finished Timing (Training: 0.919023, Test: 0.0789609) after 0.788588 seconds\n",
      "2018-09-02 03:45:57.610434 Training Step 890 \"min loss\" =  7.846715\n",
      "2018-09-02 03:45:57.610544 Training Step 890 \"loss\" =  8.503866\n",
      "2018-09-02 03:45:58.257520 Test Step 895 Finished\n",
      "2018-09-02 03:45:58.257663 Test Step 895 \"min loss\" =  8.512789\n",
      "2018-09-02 03:45:58.258169 Test Step 895 \"loss\" =  8.906787\n",
      "2018-09-02 03:45:58.399358 Training Step 895 Finished Timing (Training: 0.918902, Test: 0.0791231) after 0.788746 seconds\n",
      "2018-09-02 03:45:58.399442 Training Step 895 \"min loss\" =  7.846715\n",
      "2018-09-02 03:45:58.399512 Training Step 895 \"loss\" =  8.442305\n",
      "2018-09-02 03:45:59.032500 Test Step 900 Finished\n",
      "2018-09-02 03:45:59.032575 Test Step 900 \"min loss\" =  8.512789\n",
      "2018-09-02 03:45:59.032630 Test Step 900 \"loss\" =  8.740898\n",
      "2018-09-02 03:45:59.177486 Training Step 900 Finished Timing (Training: 0.918901, Test: 0.0791428) after 0.777109 seconds\n",
      "2018-09-02 03:45:59.177542 Training Step 900 \"min loss\" =  7.8266344\n",
      "2018-09-02 03:45:59.178018 Training Step 900 \"loss\" =  8.193925\n",
      "2018-09-02 03:45:59.819702 Test Step 905 Finished\n",
      "2018-09-02 03:45:59.819790 Test Step 905 \"min loss\" =  8.512789\n",
      "2018-09-02 03:45:59.819846 Test Step 905 \"loss\" =  8.763789\n",
      "2018-09-02 03:45:59.971790 Training Step 905 Finished Timing (Training: 0.919376, Test: 0.0803312) after 0.7937 seconds\n",
      "2018-09-02 03:45:59.971854 Training Step 905 \"min loss\" =  7.7981224\n",
      "2018-09-02 03:45:59.971908 Training Step 905 \"loss\" =  7.7981224\n",
      "2018-09-02 03:46:00.597722 Test Step 910 Finished\n",
      "2018-09-02 03:46:00.597854 Test Step 910 \"min loss\" =  8.445126\n",
      "2018-09-02 03:46:00.597938 Test Step 910 \"loss\" =  8.445126\n",
      "2018-09-02 03:46:00.750308 Training Step 910 Finished Timing (Training: 0.922364, Test: 0.0771516) after 0.778298 seconds\n",
      "2018-09-02 03:46:00.750382 Training Step 910 \"min loss\" =  7.7981224\n",
      "2018-09-02 03:46:00.750441 Training Step 910 \"loss\" =  8.794829\n",
      "2018-09-02 03:46:01.389431 Test Step 915 Finished\n",
      "2018-09-02 03:46:01.389572 Test Step 915 \"min loss\" =  8.445126\n",
      "2018-09-02 03:46:01.389635 Test Step 915 \"loss\" =  8.8516\n",
      "2018-09-02 03:46:01.536004 Training Step 915 Finished Timing (Training: 0.922572, Test: 0.0765325) after 0.785496 seconds\n",
      "2018-09-02 03:46:01.536111 Training Step 915 \"min loss\" =  7.5237026\n",
      "2018-09-02 03:46:01.536170 Training Step 915 \"loss\" =  8.484684\n",
      "2018-09-02 03:46:02.177456 Test Step 920 Finished\n",
      "2018-09-02 03:46:02.177587 Test Step 920 \"min loss\" =  8.445126\n",
      "2018-09-02 03:46:02.177666 Test Step 920 \"loss\" =  9.249358\n",
      "2018-09-02 03:46:02.327177 Training Step 920 Finished Timing (Training: 0.921701, Test: 0.0774572) after 0.790911 seconds\n",
      "2018-09-02 03:46:02.327241 Training Step 920 \"min loss\" =  7.5237026\n",
      "2018-09-02 03:46:02.327288 Training Step 920 \"loss\" =  8.731779\n",
      "2018-09-02 03:46:02.969029 Test Step 925 Finished\n",
      "2018-09-02 03:46:02.969165 Test Step 925 \"min loss\" =  8.445126\n",
      "2018-09-02 03:46:02.969246 Test Step 925 \"loss\" =  9.230726\n",
      "2018-09-02 03:46:03.113350 Training Step 925 Finished Timing (Training: 0.921649, Test: 0.0773423) after 0.786006 seconds\n",
      "2018-09-02 03:46:03.113412 Training Step 925 \"min loss\" =  7.5237026\n",
      "2018-09-02 03:46:03.113490 Training Step 925 \"loss\" =  8.151627\n",
      "2018-09-02 03:46:03.751377 Test Step 930 Finished\n",
      "2018-09-02 03:46:03.751484 Test Step 930 \"min loss\" =  8.369231\n",
      "2018-09-02 03:46:03.752127 Test Step 930 \"loss\" =  8.369231\n",
      "2018-09-02 03:46:03.900212 Training Step 930 Finished Timing (Training: 0.922036, Test: 0.0767251) after 0.785911 seconds\n",
      "2018-09-02 03:46:03.900272 Training Step 930 \"min loss\" =  7.5237026\n",
      "2018-09-02 03:46:03.900330 Training Step 930 \"loss\" =  8.144188\n",
      "2018-09-02 03:46:04.528240 Test Step 935 Finished\n",
      "2018-09-02 03:46:04.528729 Test Step 935 \"min loss\" =  8.369231\n",
      "2018-09-02 03:46:04.528790 Test Step 935 \"loss\" =  9.112957\n",
      "2018-09-02 03:46:04.676115 Training Step 935 Finished Timing (Training: 0.921708, Test: 0.0769713) after 0.77512 seconds\n",
      "2018-09-02 03:46:04.676189 Training Step 935 \"min loss\" =  7.5237026\n",
      "2018-09-02 03:46:04.676816 Training Step 935 \"loss\" =  8.631908\n",
      "2018-09-02 03:46:05.315953 Test Step 940 Finished\n",
      "2018-09-02 03:46:05.316392 Test Step 940 \"min loss\" =  8.369231\n",
      "2018-09-02 03:46:05.316453 Test Step 940 \"loss\" =  8.608618\n",
      "2018-09-02 03:46:05.457483 Training Step 940 Finished Timing (Training: 0.92158, Test: 0.077049) after 0.78059 seconds\n",
      "2018-09-02 03:46:05.457849 Training Step 940 \"min loss\" =  7.5237026\n",
      "2018-09-02 03:46:05.457922 Training Step 940 \"loss\" =  7.9552193\n",
      "2018-09-02 03:46:06.100701 Test Step 945 Finished\n",
      "2018-09-02 03:46:06.100812 Test Step 945 \"min loss\" =  8.369231\n",
      "2018-09-02 03:46:06.101093 Test Step 945 \"loss\" =  8.718187\n",
      "2018-09-02 03:46:06.247609 Training Step 945 Finished Timing (Training: 0.920954, Test: 0.0776877) after 0.789629 seconds\n",
      "2018-09-02 03:46:06.247672 Training Step 945 \"min loss\" =  7.5237026\n",
      "2018-09-02 03:46:06.247721 Training Step 945 \"loss\" =  7.98994\n",
      "2018-09-02 03:46:06.875632 Test Step 950 Finished\n",
      "2018-09-02 03:46:06.876083 Test Step 950 \"min loss\" =  8.369231\n",
      "2018-09-02 03:46:06.876457 Test Step 950 \"loss\" =  8.709666\n",
      "2018-09-02 03:46:07.018038 Training Step 950 Finished Timing (Training: 0.920597, Test: 0.0779573) after 0.769783 seconds\n",
      "2018-09-02 03:46:07.018135 Training Step 950 \"min loss\" =  7.5237026\n",
      "2018-09-02 03:46:07.018537 Training Step 950 \"loss\" =  8.212812\n",
      "2018-09-02 03:46:07.659933 Test Step 955 Finished\n",
      "2018-09-02 03:46:07.660403 Test Step 955 \"min loss\" =  8.139859\n",
      "2018-09-02 03:46:07.660891 Test Step 955 \"loss\" =  8.139859\n",
      "2018-09-02 03:46:07.799670 Training Step 955 Finished Timing (Training: 0.920334, Test: 0.0781178) after 0.781075 seconds\n",
      "2018-09-02 03:46:07.799745 Training Step 955 \"min loss\" =  7.5237026\n",
      "2018-09-02 03:46:07.800347 Training Step 955 \"loss\" =  7.9926324\n",
      "2018-09-02 03:46:08.441209 Test Step 960 Finished\n",
      "2018-09-02 03:46:08.441357 Test Step 960 \"min loss\" =  8.139859\n",
      "2018-09-02 03:46:08.441998 Test Step 960 \"loss\" =  8.631982\n",
      "2018-09-02 03:46:08.582148 Training Step 960 Finished Timing (Training: 0.920022, Test: 0.0782781) after 0.781342 seconds\n",
      "2018-09-02 03:46:08.582508 Training Step 960 \"min loss\" =  7.4742274\n",
      "2018-09-02 03:46:08.582848 Training Step 960 \"loss\" =  8.16108\n",
      "2018-09-02 03:46:09.220795 Test Step 965 Finished\n",
      "2018-09-02 03:46:09.221256 Test Step 965 \"min loss\" =  8.139859\n",
      "2018-09-02 03:46:09.221788 Test Step 965 \"loss\" =  8.285512\n",
      "2018-09-02 03:46:09.356249 Training Step 965 Finished Timing (Training: 0.919963, Test: 0.078219) after 0.772946 seconds\n",
      "2018-09-02 03:46:09.356334 Training Step 965 \"min loss\" =  7.4742274\n",
      "2018-09-02 03:46:09.357052 Training Step 965 \"loss\" =  7.8995457\n",
      "2018-09-02 03:46:10.002109 Test Step 970 Finished\n",
      "2018-09-02 03:46:10.002254 Test Step 970 \"min loss\" =  8.139859\n",
      "2018-09-02 03:46:10.002379 Test Step 970 \"loss\" =  8.4483595\n",
      "2018-09-02 03:46:10.145843 Training Step 970 Finished Timing (Training: 0.919892, Test: 0.0781901) after 0.788319 seconds\n",
      "2018-09-02 03:46:10.145923 Training Step 970 \"min loss\" =  7.4742274\n",
      "2018-09-02 03:46:10.146648 Training Step 970 \"loss\" =  8.028276\n",
      "2018-09-02 03:46:10.788734 Test Step 975 Finished\n",
      "2018-09-02 03:46:10.788874 Test Step 975 \"min loss\" =  8.139859\n",
      "2018-09-02 03:46:10.789630 Test Step 975 \"loss\" =  9.186738\n",
      "2018-09-02 03:46:10.935428 Training Step 975 Finished Timing (Training: 0.919915, Test: 0.0781119) after 0.788443 seconds\n",
      "2018-09-02 03:46:10.935508 Training Step 975 \"min loss\" =  7.4742274\n",
      "2018-09-02 03:46:10.936101 Training Step 975 \"loss\" =  7.8325667\n",
      "2018-09-02 03:46:11.581763 Test Step 980 Finished\n",
      "2018-09-02 03:46:11.581915 Test Step 980 \"min loss\" =  8.139859\n",
      "2018-09-02 03:46:11.582417 Test Step 980 \"loss\" =  8.636753\n",
      "2018-09-02 03:46:11.729041 Training Step 980 Finished Timing (Training: 0.919582, Test: 0.0784481) after 0.792829 seconds\n",
      "2018-09-02 03:46:11.729146 Training Step 980 \"min loss\" =  7.4742274\n",
      "2018-09-02 03:46:11.729203 Training Step 980 \"loss\" =  7.9995155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:46:12.361648 Test Step 985 Finished\n",
      "2018-09-02 03:46:12.361757 Test Step 985 \"min loss\" =  8.139859\n",
      "2018-09-02 03:46:12.362246 Test Step 985 \"loss\" =  8.322662\n",
      "2018-09-02 03:46:12.504117 Training Step 985 Finished Timing (Training: 0.9195, Test: 0.0785558) after 0.774841 seconds\n",
      "2018-09-02 03:46:12.504392 Training Step 985 \"min loss\" =  7.3532968\n",
      "2018-09-02 03:46:12.504448 Training Step 985 \"loss\" =  7.6216645\n",
      "2018-09-02 03:46:13.165626 Test Step 990 Finished\n",
      "2018-09-02 03:46:13.165727 Test Step 990 \"min loss\" =  8.139859\n",
      "2018-09-02 03:46:13.166206 Test Step 990 \"loss\" =  8.275541\n",
      "2018-09-02 03:46:13.314107 Training Step 990 Finished Timing (Training: 0.919896, Test: 0.078197) after 0.809602 seconds\n",
      "2018-09-02 03:46:13.314173 Training Step 990 \"min loss\" =  7.3532968\n",
      "2018-09-02 03:46:13.314224 Training Step 990 \"loss\" =  7.9409585\n",
      "2018-09-02 03:46:13.961896 Test Step 995 Finished\n",
      "2018-09-02 03:46:13.962361 Test Step 995 \"min loss\" =  8.139859\n",
      "2018-09-02 03:46:13.962575 Test Step 995 \"loss\" =  8.4844265\n",
      "2018-09-02 03:46:14.105487 Training Step 995 Finished Timing (Training: 0.919906, Test: 0.0782251) after 0.791209 seconds\n",
      "2018-09-02 03:46:14.105549 Training Step 995 \"min loss\" =  7.3532968\n",
      "2018-09-02 03:46:14.105598 Training Step 995 \"loss\" =  8.0206785\n",
      "2018-09-02 03:46:14.747951 Test Step 1000 Finished\n",
      "2018-09-02 03:46:14.748029 Test Step 1000 \"min loss\" =  7.992064\n",
      "2018-09-02 03:46:14.748082 Test Step 1000 \"loss\" =  7.992064\n",
      "2018-09-02 03:46:14.890703 Training Step 1000 Finished Timing (Training: 0.920007, Test: 0.0781921) after 0.785043 seconds\n",
      "2018-09-02 03:46:14.890775 Training Step 1000 \"min loss\" =  7.3532968\n",
      "2018-09-02 03:46:14.890832 Training Step 1000 \"loss\" =  8.048445\n",
      "2018-09-02 03:46:15.527855 Test Step 1005 Finished\n",
      "2018-09-02 03:46:15.528384 Test Step 1005 \"min loss\" =  7.992064\n",
      "2018-09-02 03:46:15.528604 Test Step 1005 \"loss\" =  8.283886\n",
      "2018-09-02 03:46:15.680228 Training Step 1005 Finished Timing (Training: 0.924366, Test: 0.0745654) after 0.789328 seconds\n",
      "2018-09-02 03:46:15.680318 Training Step 1005 \"min loss\" =  7.3444805\n",
      "2018-09-02 03:46:15.680357 Training Step 1005 \"loss\" =  7.77716\n",
      "2018-09-02 03:46:16.321294 Test Step 1010 Finished\n",
      "2018-09-02 03:46:16.321416 Test Step 1010 \"min loss\" =  7.992064\n",
      "2018-09-02 03:46:16.322092 Test Step 1010 \"loss\" =  8.292563\n",
      "2018-09-02 03:46:16.463689 Training Step 1010 Finished Timing (Training: 0.921671, Test: 0.0769869) after 0.783251 seconds\n",
      "2018-09-02 03:46:16.463765 Training Step 1010 \"min loss\" =  7.3444805\n",
      "2018-09-02 03:46:16.463809 Training Step 1010 \"loss\" =  7.7943077\n",
      "2018-09-02 03:46:17.120354 Test Step 1015 Finished\n",
      "2018-09-02 03:46:17.120452 Test Step 1015 \"min loss\" =  7.992064\n",
      "2018-09-02 03:46:17.120511 Test Step 1015 \"loss\" =  8.673324\n",
      "2018-09-02 03:46:17.264861 Training Step 1015 Finished Timing (Training: 0.92126, Test: 0.0769335) after 0.800171 seconds\n",
      "2018-09-02 03:46:17.264925 Training Step 1015 \"min loss\" =  7.3444805\n",
      "2018-09-02 03:46:17.265552 Training Step 1015 \"loss\" =  8.040303\n",
      "2018-09-02 03:46:17.886795 Test Step 1020 Finished\n",
      "2018-09-02 03:46:17.886880 Test Step 1020 \"min loss\" =  7.992064\n",
      "2018-09-02 03:46:17.886944 Test Step 1020 \"loss\" =  8.05491\n",
      "2018-09-02 03:46:18.027250 Training Step 1020 Finished Timing (Training: 0.922317, Test: 0.0759508) after 0.761537 seconds\n",
      "2018-09-02 03:46:18.027363 Training Step 1020 \"min loss\" =  7.3444805\n",
      "2018-09-02 03:46:18.027743 Training Step 1020 \"loss\" =  8.849126\n",
      "2018-09-02 03:46:18.667917 Test Step 1025 Finished\n",
      "2018-09-02 03:46:18.668026 Test Step 1025 \"min loss\" =  7.992064\n",
      "2018-09-02 03:46:18.668510 Test Step 1025 \"loss\" =  8.60672\n",
      "2018-09-02 03:46:18.810565 Training Step 1025 Finished Timing (Training: 0.921738, Test: 0.0765513) after 0.782731 seconds\n",
      "2018-09-02 03:46:18.810816 Training Step 1025 \"min loss\" =  7.1859913\n",
      "2018-09-02 03:46:18.810880 Training Step 1025 \"loss\" =  7.951624\n",
      "2018-09-02 03:46:19.437741 Test Step 1030 Finished\n",
      "2018-09-02 03:46:19.437839 Test Step 1030 \"min loss\" =  7.992064\n",
      "2018-09-02 03:46:19.437907 Test Step 1030 \"loss\" =  8.732007\n",
      "2018-09-02 03:46:19.586110 Training Step 1030 Finished Timing (Training: 0.922147, Test: 0.0762848) after 0.775162 seconds\n",
      "2018-09-02 03:46:19.586191 Training Step 1030 \"min loss\" =  7.1859913\n",
      "2018-09-02 03:46:19.586254 Training Step 1030 \"loss\" =  7.41992\n",
      "2018-09-02 03:46:20.236342 Test Step 1035 Finished\n",
      "2018-09-02 03:46:20.236438 Test Step 1035 \"min loss\" =  7.992064\n",
      "2018-09-02 03:46:20.236509 Test Step 1035 \"loss\" =  8.307883\n",
      "2018-09-02 03:46:20.384674 Training Step 1035 Finished Timing (Training: 0.92161, Test: 0.0769632) after 0.798334 seconds\n",
      "2018-09-02 03:46:20.384746 Training Step 1035 \"min loss\" =  7.1859913\n",
      "2018-09-02 03:46:20.384810 Training Step 1035 \"loss\" =  7.228332\n",
      "2018-09-02 03:46:21.024932 Test Step 1040 Finished\n",
      "2018-09-02 03:46:21.025039 Test Step 1040 \"min loss\" =  7.992064\n",
      "2018-09-02 03:46:21.025102 Test Step 1040 \"loss\" =  8.695718\n",
      "2018-09-02 03:46:21.170633 Training Step 1040 Finished Timing (Training: 0.921244, Test: 0.0774307) after 0.785757 seconds\n",
      "2018-09-02 03:46:21.170700 Training Step 1040 \"min loss\" =  7.1859913\n",
      "2018-09-02 03:46:21.170767 Training Step 1040 \"loss\" =  7.8883724\n",
      "2018-09-02 03:46:21.807034 Test Step 1045 Finished\n",
      "2018-09-02 03:46:21.807160 Test Step 1045 \"min loss\" =  7.992064\n",
      "2018-09-02 03:46:21.807707 Test Step 1045 \"loss\" =  8.051379\n",
      "2018-09-02 03:46:21.955390 Training Step 1045 Finished Timing (Training: 0.921136, Test: 0.0774252) after 0.783683 seconds\n",
      "2018-09-02 03:46:21.955506 Training Step 1045 \"min loss\" =  7.1859913\n",
      "2018-09-02 03:46:21.955604 Training Step 1045 \"loss\" =  7.561238\n",
      "2018-09-02 03:46:22.604989 Test Step 1050 Finished\n",
      "2018-09-02 03:46:22.605096 Test Step 1050 \"min loss\" =  7.992064\n",
      "2018-09-02 03:46:22.605945 Test Step 1050 \"loss\" =  8.164865\n",
      "2018-09-02 03:46:22.747491 Training Step 1050 Finished Timing (Training: 0.920623, Test: 0.0779094) after 0.791819 seconds\n",
      "2018-09-02 03:46:22.747577 Training Step 1050 \"min loss\" =  7.1859913\n",
      "2018-09-02 03:46:22.748025 Training Step 1050 \"loss\" =  8.044771\n",
      "2018-09-02 03:46:23.381298 Test Step 1055 Finished\n",
      "2018-09-02 03:46:23.381389 Test Step 1055 \"min loss\" =  7.992064\n",
      "2018-09-02 03:46:23.381466 Test Step 1055 \"loss\" =  8.294406\n",
      "2018-09-02 03:46:23.525611 Training Step 1055 Finished Timing (Training: 0.920709, Test: 0.0778547) after 0.777514 seconds\n",
      "2018-09-02 03:46:23.525691 Training Step 1055 \"min loss\" =  7.067051\n",
      "2018-09-02 03:46:23.525754 Training Step 1055 \"loss\" =  7.8353114\n",
      "2018-09-02 03:46:24.166927 Test Step 1060 Finished\n",
      "2018-09-02 03:46:24.167369 Test Step 1060 \"min loss\" =  7.992064\n",
      "2018-09-02 03:46:24.167434 Test Step 1060 \"loss\" =  8.227753\n",
      "2018-09-02 03:46:24.316287 Training Step 1060 Finished Timing (Training: 0.920447, Test: 0.0781518) after 0.790467 seconds\n",
      "2018-09-02 03:46:24.316356 Training Step 1060 \"min loss\" =  7.0476584\n",
      "2018-09-02 03:46:24.316420 Training Step 1060 \"loss\" =  7.5388846\n",
      "2018-09-02 03:46:24.958433 Test Step 1065 Finished\n",
      "2018-09-02 03:46:24.958524 Test Step 1065 \"min loss\" =  7.992064\n",
      "2018-09-02 03:46:24.958587 Test Step 1065 \"loss\" =  8.051021\n",
      "2018-09-02 03:46:25.103885 Training Step 1065 Finished Timing (Training: 0.920184, Test: 0.078476) after 0.787382 seconds\n",
      "2018-09-02 03:46:25.103956 Training Step 1065 \"min loss\" =  7.0476584\n",
      "2018-09-02 03:46:25.104048 Training Step 1065 \"loss\" =  7.383246\n",
      "2018-09-02 03:46:25.741480 Test Step 1070 Finished\n",
      "2018-09-02 03:46:25.741576 Test Step 1070 \"min loss\" =  7.992064\n",
      "2018-09-02 03:46:25.741680 Test Step 1070 \"loss\" =  8.03634\n",
      "2018-09-02 03:46:25.885517 Training Step 1070 Finished Timing (Training: 0.920146, Test: 0.0785627) after 0.781404 seconds\n",
      "2018-09-02 03:46:25.885585 Training Step 1070 \"min loss\" =  7.0476584\n",
      "2018-09-02 03:46:25.885638 Training Step 1070 \"loss\" =  7.2743754\n",
      "2018-09-02 03:46:26.521441 Test Step 1075 Finished\n",
      "2018-09-02 03:46:26.521540 Test Step 1075 \"min loss\" =  7.9379196\n",
      "2018-09-02 03:46:26.521616 Test Step 1075 \"loss\" =  7.9379196\n",
      "2018-09-02 03:46:26.671581 Training Step 1075 Finished Timing (Training: 0.919961, Test: 0.0787739) after 0.785617 seconds\n",
      "2018-09-02 03:46:26.671650 Training Step 1075 \"min loss\" =  7.0476584\n",
      "2018-09-02 03:46:26.672370 Training Step 1075 \"loss\" =  7.50223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:46:27.317926 Test Step 1080 Finished\n",
      "2018-09-02 03:46:27.318035 Test Step 1080 \"min loss\" =  7.9379196\n",
      "2018-09-02 03:46:27.318551 Test Step 1080 \"loss\" =  8.096303\n",
      "2018-09-02 03:46:27.459631 Training Step 1080 Finished Timing (Training: 0.919558, Test: 0.0791138) after 0.786987 seconds\n",
      "2018-09-02 03:46:27.459705 Training Step 1080 \"min loss\" =  7.0476584\n",
      "2018-09-02 03:46:27.460225 Training Step 1080 \"loss\" =  7.0915666\n",
      "2018-09-02 03:46:28.110656 Test Step 1085 Finished\n",
      "2018-09-02 03:46:28.110739 Test Step 1085 \"min loss\" =  7.9379196\n",
      "2018-09-02 03:46:28.111238 Test Step 1085 \"loss\" =  8.280115\n",
      "2018-09-02 03:46:28.263009 Training Step 1085 Finished Timing (Training: 0.919578, Test: 0.0790741) after 0.802715 seconds\n",
      "2018-09-02 03:46:28.263079 Training Step 1085 \"min loss\" =  7.0476584\n",
      "2018-09-02 03:46:28.263702 Training Step 1085 \"loss\" =  7.11669\n",
      "2018-09-02 03:46:28.897994 Test Step 1090 Finished\n",
      "2018-09-02 03:46:28.898084 Test Step 1090 \"min loss\" =  7.9379196\n",
      "2018-09-02 03:46:28.898611 Test Step 1090 \"loss\" =  8.113793\n",
      "2018-09-02 03:46:29.037724 Training Step 1090 Finished Timing (Training: 0.919461, Test: 0.0791503) after 0.773793 seconds\n",
      "2018-09-02 03:46:29.037793 Training Step 1090 \"min loss\" =  7.0476584\n",
      "2018-09-02 03:46:29.037875 Training Step 1090 \"loss\" =  8.040833\n",
      "2018-09-02 03:46:29.689925 Test Step 1095 Finished\n",
      "2018-09-02 03:46:29.690014 Test Step 1095 \"min loss\" =  7.9379196\n",
      "2018-09-02 03:46:29.690082 Test Step 1095 \"loss\" =  8.277025\n",
      "2018-09-02 03:46:29.835979 Training Step 1095 Finished Timing (Training: 0.919254, Test: 0.0793526) after 0.79732 seconds\n",
      "2018-09-02 03:46:29.836057 Training Step 1095 \"min loss\" =  7.021185\n",
      "2018-09-02 03:46:29.836152 Training Step 1095 \"loss\" =  7.44605\n",
      "2018-09-02 03:46:30.473922 Test Step 1100 Finished\n",
      "2018-09-02 03:46:30.474056 Test Step 1100 \"min loss\" =  7.9379196\n",
      "2018-09-02 03:46:30.474148 Test Step 1100 \"loss\" =  8.181042\n",
      "2018-09-02 03:46:30.619035 Training Step 1100 Finished Timing (Training: 0.919401, Test: 0.0792392) after 0.782813 seconds\n",
      "2018-09-02 03:46:30.619147 Training Step 1100 \"min loss\" =  7.021185\n",
      "2018-09-02 03:46:30.619222 Training Step 1100 \"loss\" =  7.1330214\n",
      "2018-09-02 03:46:31.245694 Test Step 1105 Finished\n",
      "2018-09-02 03:46:31.245808 Test Step 1105 \"min loss\" =  7.9379196\n",
      "2018-09-02 03:46:31.245872 Test Step 1105 \"loss\" =  8.13587\n",
      "2018-09-02 03:46:31.393564 Training Step 1105 Finished Timing (Training: 0.919488, Test: 0.0801695) after 0.774281 seconds\n",
      "2018-09-02 03:46:31.393632 Training Step 1105 \"min loss\" =  7.021185\n",
      "2018-09-02 03:46:31.394372 Training Step 1105 \"loss\" =  7.315557\n",
      "2018-09-02 03:46:32.038604 Test Step 1110 Finished\n",
      "2018-09-02 03:46:32.038709 Test Step 1110 \"min loss\" =  7.9379196\n",
      "2018-09-02 03:46:32.039396 Test Step 1110 \"loss\" =  8.241585\n",
      "2018-09-02 03:46:32.188098 Training Step 1110 Finished Timing (Training: 0.919505, Test: 0.0791794) after 0.793629 seconds\n",
      "2018-09-02 03:46:32.188168 Training Step 1110 \"min loss\" =  6.865333\n",
      "2018-09-02 03:46:32.188709 Training Step 1110 \"loss\" =  7.1540923\n",
      "2018-09-02 03:46:32.808454 Test Step 1115 Finished\n",
      "2018-09-02 03:46:32.808559 Test Step 1115 \"min loss\" =  7.908741\n",
      "2018-09-02 03:46:32.809022 Test Step 1115 \"loss\" =  7.908741\n",
      "2018-09-02 03:46:32.960763 Training Step 1115 Finished Timing (Training: 0.918466, Test: 0.0800815) after 0.771981 seconds\n",
      "2018-09-02 03:46:32.960841 Training Step 1115 \"min loss\" =  6.694016\n",
      "2018-09-02 03:46:32.960896 Training Step 1115 \"loss\" =  6.694016\n",
      "2018-09-02 03:46:33.599089 Test Step 1120 Finished\n",
      "2018-09-02 03:46:33.599189 Test Step 1120 \"min loss\" =  7.8812532\n",
      "2018-09-02 03:46:33.599670 Test Step 1120 \"loss\" =  7.8812532\n",
      "2018-09-02 03:46:33.739623 Training Step 1120 Finished Timing (Training: 0.918505, Test: 0.0801314) after 0.778666 seconds\n",
      "2018-09-02 03:46:33.739715 Training Step 1120 \"min loss\" =  6.694016\n",
      "2018-09-02 03:46:33.739771 Training Step 1120 \"loss\" =  7.284474\n",
      "2018-09-02 03:46:34.390924 Test Step 1125 Finished\n",
      "2018-09-02 03:46:34.391032 Test Step 1125 \"min loss\" =  7.808438\n",
      "2018-09-02 03:46:34.391705 Test Step 1125 \"loss\" =  7.808438\n",
      "2018-09-02 03:46:34.540471 Training Step 1125 Finished Timing (Training: 0.918467, Test: 0.0801017) after 0.800639 seconds\n",
      "2018-09-02 03:46:34.540552 Training Step 1125 \"min loss\" =  6.694016\n",
      "2018-09-02 03:46:34.540606 Training Step 1125 \"loss\" =  6.989932\n",
      "2018-09-02 03:46:35.184608 Test Step 1130 Finished\n",
      "2018-09-02 03:46:35.184721 Test Step 1130 \"min loss\" =  7.808438\n",
      "2018-09-02 03:46:35.185221 Test Step 1130 \"loss\" =  8.102717\n",
      "2018-09-02 03:46:35.337149 Training Step 1130 Finished Timing (Training: 0.919127, Test: 0.079489) after 0.796483 seconds\n",
      "2018-09-02 03:46:35.337213 Training Step 1130 \"min loss\" =  6.694016\n",
      "2018-09-02 03:46:35.337658 Training Step 1130 \"loss\" =  6.713184\n",
      "2018-09-02 03:46:35.972095 Test Step 1135 Finished\n",
      "2018-09-02 03:46:35.972220 Test Step 1135 \"min loss\" =  7.808438\n",
      "2018-09-02 03:46:35.972263 Test Step 1135 \"loss\" =  8.148083\n",
      "2018-09-02 03:46:36.120672 Training Step 1135 Finished Timing (Training: 0.919714, Test: 0.0789499) after 0.78295 seconds\n",
      "2018-09-02 03:46:36.120733 Training Step 1135 \"min loss\" =  6.694016\n",
      "2018-09-02 03:46:36.120770 Training Step 1135 \"loss\" =  7.089043\n",
      "2018-09-02 03:46:36.765400 Test Step 1140 Finished\n",
      "2018-09-02 03:46:36.765509 Test Step 1140 \"min loss\" =  7.808438\n",
      "2018-09-02 03:46:36.765551 Test Step 1140 \"loss\" =  8.242658\n",
      "2018-09-02 03:46:36.908213 Training Step 1140 Finished Timing (Training: 0.920053, Test: 0.0787204) after 0.787399 seconds\n",
      "2018-09-02 03:46:36.908280 Training Step 1140 \"min loss\" =  6.694016\n",
      "2018-09-02 03:46:36.908318 Training Step 1140 \"loss\" =  6.83182\n",
      "2018-09-02 03:46:37.562308 Test Step 1145 Finished\n",
      "2018-09-02 03:46:37.562409 Test Step 1145 \"min loss\" =  7.808438\n",
      "2018-09-02 03:46:37.562452 Test Step 1145 \"loss\" =  8.169339\n",
      "2018-09-02 03:46:37.704786 Training Step 1145 Finished Timing (Training: 0.920096, Test: 0.0787629) after 0.796425 seconds\n",
      "2018-09-02 03:46:37.704846 Training Step 1145 \"min loss\" =  6.694016\n",
      "2018-09-02 03:46:37.704885 Training Step 1145 \"loss\" =  7.0417204\n",
      "2018-09-02 03:46:38.354964 Test Step 1150 Finished\n",
      "2018-09-02 03:46:38.355040 Test Step 1150 \"min loss\" =  7.808438\n",
      "2018-09-02 03:46:38.355080 Test Step 1150 \"loss\" =  8.138744\n",
      "2018-09-02 03:46:38.504885 Training Step 1150 Finished Timing (Training: 0.920705, Test: 0.0782296) after 0.799958 seconds\n",
      "2018-09-02 03:46:38.504940 Training Step 1150 \"min loss\" =  6.694016\n",
      "2018-09-02 03:46:38.504977 Training Step 1150 \"loss\" =  6.934176\n",
      "2018-09-02 03:46:39.165122 Test Step 1155 Finished\n",
      "2018-09-02 03:46:39.165560 Test Step 1155 \"min loss\" =  7.800105\n",
      "2018-09-02 03:46:39.165852 Test Step 1155 \"loss\" =  7.800105\n",
      "2018-09-02 03:46:39.315085 Training Step 1155 Finished Timing (Training: 0.920747, Test: 0.0781509) after 0.810057 seconds\n",
      "2018-09-02 03:46:39.315388 Training Step 1155 \"min loss\" =  6.694016\n",
      "2018-09-02 03:46:39.315677 Training Step 1155 \"loss\" =  7.3289595\n",
      "2018-09-02 03:46:39.949302 Test Step 1160 Finished\n",
      "2018-09-02 03:46:39.949715 Test Step 1160 \"min loss\" =  7.800105\n",
      "2018-09-02 03:46:39.950003 Test Step 1160 \"loss\" =  8.293171\n",
      "2018-09-02 03:46:40.088500 Training Step 1160 Finished Timing (Training: 0.920734, Test: 0.0780517) after 0.772534 seconds\n",
      "2018-09-02 03:46:40.088773 Training Step 1160 \"min loss\" =  6.694016\n",
      "2018-09-02 03:46:40.089058 Training Step 1160 \"loss\" =  7.248444\n",
      "2018-09-02 03:46:40.731441 Test Step 1165 Finished\n",
      "2018-09-02 03:46:40.731832 Test Step 1165 \"min loss\" =  7.719307\n",
      "2018-09-02 03:46:40.732122 Test Step 1165 \"loss\" =  7.719307\n",
      "2018-09-02 03:46:40.882248 Training Step 1165 Finished Timing (Training: 0.920652, Test: 0.0780428) after 0.792868 seconds\n",
      "2018-09-02 03:46:40.882581 Training Step 1165 \"min loss\" =  6.505491\n",
      "2018-09-02 03:46:40.882868 Training Step 1165 \"loss\" =  6.505491\n",
      "2018-09-02 03:46:41.509525 Test Step 1170 Finished\n",
      "2018-09-02 03:46:41.509916 Test Step 1170 \"min loss\" =  7.719307\n",
      "2018-09-02 03:46:41.510241 Test Step 1170 \"loss\" =  7.897031\n",
      "2018-09-02 03:46:41.655862 Training Step 1170 Finished Timing (Training: 0.920776, Test: 0.0778318) after 0.7727 seconds\n",
      "2018-09-02 03:46:41.655952 Training Step 1170 \"min loss\" =  6.505491\n",
      "2018-09-02 03:46:41.655993 Training Step 1170 \"loss\" =  7.193126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:46:42.287720 Test Step 1175 Finished\n",
      "2018-09-02 03:46:42.287872 Test Step 1175 \"min loss\" =  7.719307\n",
      "2018-09-02 03:46:42.287953 Test Step 1175 \"loss\" =  8.121631\n",
      "2018-09-02 03:46:42.430921 Training Step 1175 Finished Timing (Training: 0.920815, Test: 0.0778429) after 0.774879 seconds\n",
      "2018-09-02 03:46:42.430995 Training Step 1175 \"min loss\" =  6.505491\n",
      "2018-09-02 03:46:42.431032 Training Step 1175 \"loss\" =  6.8702564\n",
      "2018-09-02 03:46:43.068159 Test Step 1180 Finished\n",
      "2018-09-02 03:46:43.068258 Test Step 1180 \"min loss\" =  7.719307\n",
      "2018-09-02 03:46:43.068301 Test Step 1180 \"loss\" =  7.8636165\n",
      "2018-09-02 03:46:43.213995 Training Step 1180 Finished Timing (Training: 0.920837, Test: 0.0778731) after 0.782919 seconds\n",
      "2018-09-02 03:46:43.214052 Training Step 1180 \"min loss\" =  6.505491\n",
      "2018-09-02 03:46:43.214090 Training Step 1180 \"loss\" =  6.611815\n",
      "2018-09-02 03:46:43.858531 Test Step 1185 Finished\n",
      "2018-09-02 03:46:43.858902 Test Step 1185 \"min loss\" =  7.719307\n",
      "2018-09-02 03:46:43.859039 Test Step 1185 \"loss\" =  7.793467\n",
      "2018-09-02 03:46:44.004630 Training Step 1185 Finished Timing (Training: 0.920553, Test: 0.0781798) after 0.790483 seconds\n",
      "2018-09-02 03:46:44.004894 Training Step 1185 \"min loss\" =  6.505491\n",
      "2018-09-02 03:46:44.005071 Training Step 1185 \"loss\" =  6.8437963\n",
      "2018-09-02 03:46:44.643376 Test Step 1190 Finished\n",
      "2018-09-02 03:46:44.643712 Test Step 1190 \"min loss\" =  7.719307\n",
      "2018-09-02 03:46:44.644006 Test Step 1190 \"loss\" =  7.7304115\n",
      "2018-09-02 03:46:44.788305 Training Step 1190 Finished Timing (Training: 0.920627, Test: 0.0780744) after 0.783189 seconds\n",
      "2018-09-02 03:46:44.788584 Training Step 1190 \"min loss\" =  6.505491\n",
      "2018-09-02 03:46:44.788868 Training Step 1190 \"loss\" =  6.8561773\n",
      "2018-09-02 03:46:45.420098 Test Step 1195 Finished\n",
      "2018-09-02 03:46:45.420601 Test Step 1195 \"min loss\" =  7.719307\n",
      "2018-09-02 03:46:45.420890 Test Step 1195 \"loss\" =  7.8644733\n",
      "2018-09-02 03:46:45.561430 Training Step 1195 Finished Timing (Training: 0.92037, Test: 0.0782683) after 0.772272 seconds\n",
      "2018-09-02 03:46:45.561744 Training Step 1195 \"min loss\" =  6.505491\n",
      "2018-09-02 03:46:45.562033 Training Step 1195 \"loss\" =  6.7639885\n",
      "2018-09-02 03:46:46.202742 Test Step 1200 Finished\n",
      "2018-09-02 03:46:46.203127 Test Step 1200 \"min loss\" =  7.719307\n",
      "2018-09-02 03:46:46.203415 Test Step 1200 \"loss\" =  7.805199\n",
      "2018-09-02 03:46:46.354345 Training Step 1200 Finished Timing (Training: 0.920217, Test: 0.0783685) after 0.79202 seconds\n",
      "2018-09-02 03:46:46.354611 Training Step 1200 \"min loss\" =  6.505491\n",
      "2018-09-02 03:46:46.354897 Training Step 1200 \"loss\" =  6.7760034\n",
      "2018-09-02 03:46:46.986472 Test Step 1205 Finished\n",
      "2018-09-02 03:46:46.986896 Test Step 1205 \"min loss\" =  7.719307\n",
      "2018-09-02 03:46:46.987188 Test Step 1205 \"loss\" =  7.75647\n",
      "2018-09-02 03:46:47.131334 Training Step 1205 Finished Timing (Training: 0.92323, Test: 0.0754429) after 0.776148 seconds\n",
      "2018-09-02 03:46:47.131585 Training Step 1205 \"min loss\" =  6.429778\n",
      "2018-09-02 03:46:47.131871 Training Step 1205 \"loss\" =  6.823352\n",
      "2018-09-02 03:46:47.775033 Test Step 1210 Finished\n",
      "2018-09-02 03:46:47.775465 Test Step 1210 \"min loss\" =  7.5306892\n",
      "2018-09-02 03:46:47.775755 Test Step 1210 \"loss\" =  7.5306892\n",
      "2018-09-02 03:46:47.925108 Training Step 1210 Finished Timing (Training: 0.91883, Test: 0.079317) after 0.792929 seconds\n",
      "2018-09-02 03:46:47.925416 Training Step 1210 \"min loss\" =  6.429778\n",
      "2018-09-02 03:46:47.925734 Training Step 1210 \"loss\" =  6.7249317\n",
      "2018-09-02 03:46:48.560839 Test Step 1215 Finished\n",
      "2018-09-02 03:46:48.561184 Test Step 1215 \"min loss\" =  7.5306892\n",
      "2018-09-02 03:46:48.561499 Test Step 1215 \"loss\" =  7.856193\n",
      "2018-09-02 03:46:48.706968 Training Step 1215 Finished Timing (Training: 0.918114, Test: 0.0798383) after 0.780945 seconds\n",
      "2018-09-02 03:46:48.707219 Training Step 1215 \"min loss\" =  6.3768544\n",
      "2018-09-02 03:46:48.707509 Training Step 1215 \"loss\" =  6.3768544\n",
      "2018-09-02 03:46:49.345196 Test Step 1220 Finished\n",
      "2018-09-02 03:46:49.345576 Test Step 1220 \"min loss\" =  7.5306892\n",
      "2018-09-02 03:46:49.345858 Test Step 1220 \"loss\" =  7.879485\n",
      "2018-09-02 03:46:49.489448 Training Step 1220 Finished Timing (Training: 0.918107, Test: 0.0797841) after 0.78165 seconds\n",
      "2018-09-02 03:46:49.489503 Training Step 1220 \"min loss\" =  6.3768544\n",
      "2018-09-02 03:46:49.489541 Training Step 1220 \"loss\" =  6.670847\n",
      "2018-09-02 03:46:50.135773 Test Step 1225 Finished\n",
      "2018-09-02 03:46:50.135857 Test Step 1225 \"min loss\" =  7.5306892\n",
      "2018-09-02 03:46:50.135901 Test Step 1225 \"loss\" =  8.214356\n",
      "2018-09-02 03:46:50.280124 Training Step 1225 Finished Timing (Training: 0.917727, Test: 0.080496) after 0.79054 seconds\n",
      "2018-09-02 03:46:50.280183 Training Step 1225 \"min loss\" =  6.3768544\n",
      "2018-09-02 03:46:50.280222 Training Step 1225 \"loss\" =  6.922342\n",
      "2018-09-02 03:46:50.905572 Test Step 1230 Finished\n",
      "2018-09-02 03:46:50.905736 Test Step 1230 \"min loss\" =  7.5306892\n",
      "2018-09-02 03:46:50.905780 Test Step 1230 \"loss\" =  7.650538\n",
      "2018-09-02 03:46:51.059610 Training Step 1230 Finished Timing (Training: 0.918922, Test: 0.0795013) after 0.779328 seconds\n",
      "2018-09-02 03:46:51.059669 Training Step 1230 \"min loss\" =  6.3768544\n",
      "2018-09-02 03:46:51.059720 Training Step 1230 \"loss\" =  7.2145534\n",
      "2018-09-02 03:46:51.702153 Test Step 1235 Finished\n",
      "2018-09-02 03:46:51.702598 Test Step 1235 \"min loss\" =  7.5306892\n",
      "2018-09-02 03:46:51.702888 Test Step 1235 \"loss\" =  7.6425867\n",
      "2018-09-02 03:46:51.851243 Training Step 1235 Finished Timing (Training: 0.919155, Test: 0.0792752) after 0.791479 seconds\n",
      "2018-09-02 03:46:51.851300 Training Step 1235 \"min loss\" =  6.3768544\n",
      "2018-09-02 03:46:51.851340 Training Step 1235 \"loss\" =  6.8428264\n",
      "2018-09-02 03:46:52.476875 Test Step 1240 Finished\n",
      "2018-09-02 03:46:52.477010 Test Step 1240 \"min loss\" =  7.5306892\n",
      "2018-09-02 03:46:52.477072 Test Step 1240 \"loss\" =  7.675242\n",
      "2018-09-02 03:46:52.627573 Training Step 1240 Finished Timing (Training: 0.919287, Test: 0.0792699) after 0.776185 seconds\n",
      "2018-09-02 03:46:52.627630 Training Step 1240 \"min loss\" =  6.2797537\n",
      "2018-09-02 03:46:52.627667 Training Step 1240 \"loss\" =  6.2797537\n",
      "2018-09-02 03:46:53.272699 Test Step 1245 Finished\n",
      "2018-09-02 03:46:53.272778 Test Step 1245 \"min loss\" =  7.5306892\n",
      "2018-09-02 03:46:53.272822 Test Step 1245 \"loss\" =  7.6856246\n",
      "2018-09-02 03:46:53.420680 Training Step 1245 Finished Timing (Training: 0.919795, Test: 0.0788766) after 0.792972 seconds\n",
      "2018-09-02 03:46:53.420740 Training Step 1245 \"min loss\" =  6.2797537\n",
      "2018-09-02 03:46:53.420778 Training Step 1245 \"loss\" =  6.6625643\n",
      "2018-09-02 03:46:54.062826 Test Step 1250 Finished\n",
      "2018-09-02 03:46:54.062913 Test Step 1250 \"min loss\" =  7.5306892\n",
      "2018-09-02 03:46:54.062955 Test Step 1250 \"loss\" =  7.9189653\n",
      "2018-09-02 03:46:54.200887 Training Step 1250 Finished Timing (Training: 0.919686, Test: 0.0790751) after 0.780063 seconds\n",
      "2018-09-02 03:46:54.200950 Training Step 1250 \"min loss\" =  6.21769\n",
      "2018-09-02 03:46:54.200989 Training Step 1250 \"loss\" =  6.9612436\n",
      "2018-09-02 03:46:54.848553 Test Step 1255 Finished\n",
      "2018-09-02 03:46:54.848987 Test Step 1255 \"min loss\" =  7.5204597\n",
      "2018-09-02 03:46:54.849290 Test Step 1255 \"loss\" =  7.5204597\n",
      "2018-09-02 03:46:54.990458 Training Step 1255 Finished Timing (Training: 0.920029, Test: 0.0787066) after 0.789424 seconds\n",
      "2018-09-02 03:46:54.990733 Training Step 1255 \"min loss\" =  6.21769\n",
      "2018-09-02 03:46:54.991018 Training Step 1255 \"loss\" =  6.639604\n",
      "2018-09-02 03:46:55.637874 Test Step 1260 Finished\n",
      "2018-09-02 03:46:55.638279 Test Step 1260 \"min loss\" =  7.5204597\n",
      "2018-09-02 03:46:55.638567 Test Step 1260 \"loss\" =  7.5594554\n",
      "2018-09-02 03:46:55.787397 Training Step 1260 Finished Timing (Training: 0.920533, Test: 0.0781113) after 0.796094 seconds\n",
      "2018-09-02 03:46:55.787677 Training Step 1260 \"min loss\" =  6.21769\n",
      "2018-09-02 03:46:55.787961 Training Step 1260 \"loss\" =  6.600572\n",
      "2018-09-02 03:46:56.437975 Test Step 1265 Finished\n",
      "2018-09-02 03:46:56.438381 Test Step 1265 \"min loss\" =  7.5204597\n",
      "2018-09-02 03:46:56.438696 Test Step 1265 \"loss\" =  7.7251806\n",
      "2018-09-02 03:46:56.581974 Training Step 1265 Finished Timing (Training: 0.920102, Test: 0.0784633) after 0.793718 seconds\n",
      "2018-09-02 03:46:56.582324 Training Step 1265 \"min loss\" =  6.21769\n",
      "2018-09-02 03:46:56.582613 Training Step 1265 \"loss\" =  6.5275493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:46:57.230224 Test Step 1270 Finished\n",
      "2018-09-02 03:46:57.230677 Test Step 1270 \"min loss\" =  7.3972964\n",
      "2018-09-02 03:46:57.230967 Test Step 1270 \"loss\" =  7.3972964\n",
      "2018-09-02 03:46:57.377555 Training Step 1270 Finished Timing (Training: 0.920406, Test: 0.0780818) after 0.794652 seconds\n",
      "2018-09-02 03:46:57.377808 Training Step 1270 \"min loss\" =  6.21769\n",
      "2018-09-02 03:46:57.378092 Training Step 1270 \"loss\" =  6.6459384\n",
      "2018-09-02 03:46:57.996047 Test Step 1275 Finished\n",
      "2018-09-02 03:46:57.996479 Test Step 1275 \"min loss\" =  7.3972964\n",
      "2018-09-02 03:46:57.996768 Test Step 1275 \"loss\" =  7.713557\n",
      "2018-09-02 03:46:58.137581 Training Step 1275 Finished Timing (Training: 0.919846, Test: 0.0785815) after 0.759203 seconds\n",
      "2018-09-02 03:46:58.137837 Training Step 1275 \"min loss\" =  6.21769\n",
      "2018-09-02 03:46:58.138125 Training Step 1275 \"loss\" =  6.5187674\n",
      "2018-09-02 03:46:58.788078 Test Step 1280 Finished\n",
      "2018-09-02 03:46:58.788149 Test Step 1280 \"min loss\" =  7.3972964\n",
      "2018-09-02 03:46:58.788188 Test Step 1280 \"loss\" =  7.6756196\n",
      "2018-09-02 03:46:58.935018 Training Step 1280 Finished Timing (Training: 0.920011, Test: 0.0784362) after 0.796604 seconds\n",
      "2018-09-02 03:46:58.935077 Training Step 1280 \"min loss\" =  6.21769\n",
      "2018-09-02 03:46:58.935114 Training Step 1280 \"loss\" =  6.5155344\n",
      "2018-09-02 03:46:59.582023 Test Step 1285 Finished\n",
      "2018-09-02 03:46:59.582105 Test Step 1285 \"min loss\" =  7.3972964\n",
      "2018-09-02 03:46:59.582148 Test Step 1285 \"loss\" =  7.4803214\n",
      "2018-09-02 03:46:59.726912 Training Step 1285 Finished Timing (Training: 0.920028, Test: 0.0784864) after 0.791746 seconds\n",
      "2018-09-02 03:46:59.727051 Training Step 1285 \"min loss\" =  5.792836\n",
      "2018-09-02 03:46:59.727087 Training Step 1285 \"loss\" =  5.792836\n",
      "2018-09-02 03:47:00.356755 Test Step 1290 Finished\n",
      "2018-09-02 03:47:00.356879 Test Step 1290 \"min loss\" =  7.3972964\n",
      "2018-09-02 03:47:00.356923 Test Step 1290 \"loss\" =  7.883302\n",
      "2018-09-02 03:47:00.504669 Training Step 1290 Finished Timing (Training: 0.920027, Test: 0.0785353) after 0.777539 seconds\n",
      "2018-09-02 03:47:00.504722 Training Step 1290 \"min loss\" =  5.792836\n",
      "2018-09-02 03:47:00.504758 Training Step 1290 \"loss\" =  6.2480865\n",
      "2018-09-02 03:47:01.134072 Test Step 1295 Finished\n",
      "2018-09-02 03:47:01.134173 Test Step 1295 \"min loss\" =  7.3972964\n",
      "2018-09-02 03:47:01.134215 Test Step 1295 \"loss\" =  7.600468\n",
      "2018-09-02 03:47:01.274965 Training Step 1295 Finished Timing (Training: 0.920217, Test: 0.0783958) after 0.770163 seconds\n",
      "2018-09-02 03:47:01.275020 Training Step 1295 \"min loss\" =  5.792836\n",
      "2018-09-02 03:47:01.275057 Training Step 1295 \"loss\" =  6.4326587\n",
      "2018-09-02 03:47:01.916360 Test Step 1300 Finished\n",
      "2018-09-02 03:47:01.916462 Test Step 1300 \"min loss\" =  7.3972964\n",
      "2018-09-02 03:47:01.916505 Test Step 1300 \"loss\" =  7.7536907\n",
      "2018-09-02 03:47:02.067717 Training Step 1300 Finished Timing (Training: 0.920332, Test: 0.0783283) after 0.792607 seconds\n",
      "2018-09-02 03:47:02.067842 Training Step 1300 \"min loss\" =  5.792836\n",
      "2018-09-02 03:47:02.067886 Training Step 1300 \"loss\" =  6.2440634\n",
      "2018-09-02 03:47:02.715342 Test Step 1305 Finished\n",
      "2018-09-02 03:47:02.715476 Test Step 1305 \"min loss\" =  7.3972964\n",
      "2018-09-02 03:47:02.715519 Test Step 1305 \"loss\" =  7.5613394\n",
      "2018-09-02 03:47:02.859701 Training Step 1305 Finished Timing (Training: 0.92973, Test: 0.0699447) after 0.791767 seconds\n",
      "2018-09-02 03:47:02.859766 Training Step 1305 \"min loss\" =  5.792836\n",
      "2018-09-02 03:47:02.859805 Training Step 1305 \"loss\" =  5.953266\n",
      "2018-09-02 03:47:03.494245 Test Step 1310 Finished\n",
      "2018-09-02 03:47:03.494334 Test Step 1310 \"min loss\" =  7.3972964\n",
      "2018-09-02 03:47:03.494393 Test Step 1310 \"loss\" =  7.6506176\n",
      "2018-09-02 03:47:03.637450 Training Step 1310 Finished Timing (Training: 0.923953, Test: 0.0756494) after 0.777601 seconds\n",
      "2018-09-02 03:47:03.637507 Training Step 1310 \"min loss\" =  5.792836\n",
      "2018-09-02 03:47:03.637561 Training Step 1310 \"loss\" =  6.250325\n",
      "2018-09-02 03:47:04.289930 Test Step 1315 Finished\n",
      "2018-09-02 03:47:04.290092 Test Step 1315 \"min loss\" =  7.3972964\n",
      "2018-09-02 03:47:04.290150 Test Step 1315 \"loss\" =  7.527141\n",
      "2018-09-02 03:47:04.436399 Training Step 1315 Finished Timing (Training: 0.922328, Test: 0.077225) after 0.798795 seconds\n",
      "2018-09-02 03:47:04.436460 Training Step 1315 \"min loss\" =  5.792836\n",
      "2018-09-02 03:47:04.436498 Training Step 1315 \"loss\" =  6.408921\n",
      "2018-09-02 03:47:05.061530 Test Step 1320 Finished\n",
      "2018-09-02 03:47:05.061967 Test Step 1320 \"min loss\" =  7.3972964\n",
      "2018-09-02 03:47:05.062259 Test Step 1320 \"loss\" =  7.4291654\n",
      "2018-09-02 03:47:05.213682 Training Step 1320 Finished Timing (Training: 0.922227, Test: 0.0770579) after 0.77714 seconds\n",
      "2018-09-02 03:47:05.213950 Training Step 1320 \"min loss\" =  5.792836\n",
      "2018-09-02 03:47:05.214234 Training Step 1320 \"loss\" =  6.205619\n",
      "2018-09-02 03:47:05.855138 Test Step 1325 Finished\n",
      "2018-09-02 03:47:05.855541 Test Step 1325 \"min loss\" =  7.3972964\n",
      "2018-09-02 03:47:05.855830 Test Step 1325 \"loss\" =  7.513436\n",
      "2018-09-02 03:47:06.006288 Training Step 1325 Finished Timing (Training: 0.921704, Test: 0.0772544) after 0.791771 seconds\n",
      "2018-09-02 03:47:06.006567 Training Step 1325 \"min loss\" =  5.792836\n",
      "2018-09-02 03:47:06.006854 Training Step 1325 \"loss\" =  6.4136133\n",
      "2018-09-02 03:47:06.638822 Test Step 1330 Finished\n",
      "2018-09-02 03:47:06.639270 Test Step 1330 \"min loss\" =  7.3972964\n",
      "2018-09-02 03:47:06.639558 Test Step 1330 \"loss\" =  7.579686\n",
      "2018-09-02 03:47:06.790350 Training Step 1330 Finished Timing (Training: 0.920288, Test: 0.0784388) after 0.783202 seconds\n",
      "2018-09-02 03:47:06.790745 Training Step 1330 \"min loss\" =  5.792836\n",
      "2018-09-02 03:47:06.791031 Training Step 1330 \"loss\" =  6.429151\n",
      "2018-09-02 03:47:07.435051 Test Step 1335 Finished\n",
      "2018-09-02 03:47:07.435166 Test Step 1335 \"min loss\" =  7.3972964\n",
      "2018-09-02 03:47:07.435212 Test Step 1335 \"loss\" =  7.7814245\n",
      "2018-09-02 03:47:07.582435 Training Step 1335 Finished Timing (Training: 0.920574, Test: 0.0781148) after 0.791114 seconds\n",
      "2018-09-02 03:47:07.582499 Training Step 1335 \"min loss\" =  5.792836\n",
      "2018-09-02 03:47:07.582536 Training Step 1335 \"loss\" =  6.274442\n",
      "2018-09-02 03:47:08.220881 Test Step 1340 Finished\n",
      "2018-09-02 03:47:08.220995 Test Step 1340 \"min loss\" =  7.3972964\n",
      "2018-09-02 03:47:08.221038 Test Step 1340 \"loss\" =  7.864824\n",
      "2018-09-02 03:47:08.368824 Training Step 1340 Finished Timing (Training: 0.920066, Test: 0.078723) after 0.786212 seconds\n",
      "2018-09-02 03:47:08.368882 Training Step 1340 \"min loss\" =  5.792836\n",
      "2018-09-02 03:47:08.368919 Training Step 1340 \"loss\" =  6.041503\n",
      "2018-09-02 03:47:08.999385 Test Step 1345 Finished\n",
      "2018-09-02 03:47:08.999466 Test Step 1345 \"min loss\" =  7.3972964\n",
      "2018-09-02 03:47:08.999524 Test Step 1345 \"loss\" =  7.7890263\n",
      "2018-09-02 03:47:09.152834 Training Step 1345 Finished Timing (Training: 0.920254, Test: 0.0786205) after 0.78387 seconds\n",
      "2018-09-02 03:47:09.152896 Training Step 1345 \"min loss\" =  5.792836\n",
      "2018-09-02 03:47:09.152938 Training Step 1345 \"loss\" =  6.4797544\n",
      "2018-09-02 03:47:09.790679 Test Step 1350 Finished\n",
      "2018-09-02 03:47:09.790757 Test Step 1350 \"min loss\" =  7.3972964\n",
      "2018-09-02 03:47:09.790797 Test Step 1350 \"loss\" =  8.113232\n",
      "2018-09-02 03:47:09.935829 Training Step 1350 Finished Timing (Training: 0.920441, Test: 0.0785032) after 0.782845 seconds\n",
      "2018-09-02 03:47:09.935884 Training Step 1350 \"min loss\" =  5.792836\n",
      "2018-09-02 03:47:09.935920 Training Step 1350 \"loss\" =  6.658422\n",
      "2018-09-02 03:47:10.590674 Test Step 1355 Finished\n",
      "2018-09-02 03:47:10.590771 Test Step 1355 \"min loss\" =  7.3972964\n",
      "2018-09-02 03:47:10.590813 Test Step 1355 \"loss\" =  7.5280757\n",
      "2018-09-02 03:47:10.736155 Training Step 1355 Finished Timing (Training: 0.920093, Test: 0.0789093) after 0.80018 seconds\n",
      "2018-09-02 03:47:10.736415 Training Step 1355 \"min loss\" =  5.792836\n",
      "2018-09-02 03:47:10.736455 Training Step 1355 \"loss\" =  6.454734\n",
      "2018-09-02 03:47:11.394881 Test Step 1360 Finished\n",
      "2018-09-02 03:47:11.395020 Test Step 1360 \"min loss\" =  7.3972964\n",
      "2018-09-02 03:47:11.395064 Test Step 1360 \"loss\" =  7.667892\n",
      "2018-09-02 03:47:11.545327 Training Step 1360 Finished Timing (Training: 0.919954, Test: 0.0790682) after 0.808818 seconds\n",
      "2018-09-02 03:47:11.545453 Training Step 1360 \"min loss\" =  5.792836\n",
      "2018-09-02 03:47:11.545548 Training Step 1360 \"loss\" =  6.1076145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:47:12.210471 Test Step 1365 Finished\n",
      "2018-09-02 03:47:12.210591 Test Step 1365 \"min loss\" =  7.369645\n",
      "2018-09-02 03:47:12.210637 Test Step 1365 \"loss\" =  7.369645\n",
      "2018-09-02 03:47:12.358732 Training Step 1365 Finished Timing (Training: 0.920006, Test: 0.079038) after 0.813141 seconds\n",
      "2018-09-02 03:47:12.358796 Training Step 1365 \"min loss\" =  5.7911725\n",
      "2018-09-02 03:47:12.358838 Training Step 1365 \"loss\" =  6.535032\n",
      "2018-09-02 03:47:13.017141 Test Step 1370 Finished\n",
      "2018-09-02 03:47:13.017250 Test Step 1370 \"min loss\" =  7.369645\n",
      "2018-09-02 03:47:13.017333 Test Step 1370 \"loss\" =  7.441389\n",
      "2018-09-02 03:47:13.165470 Training Step 1370 Finished Timing (Training: 0.920389, Test: 0.078686) after 0.806575 seconds\n",
      "2018-09-02 03:47:13.165591 Training Step 1370 \"min loss\" =  5.7911725\n",
      "2018-09-02 03:47:13.165635 Training Step 1370 \"loss\" =  6.0940065\n",
      "2018-09-02 03:47:13.829034 Test Step 1375 Finished\n",
      "2018-09-02 03:47:13.829128 Test Step 1375 \"min loss\" =  7.369645\n",
      "2018-09-02 03:47:13.829173 Test Step 1375 \"loss\" =  7.4648204\n",
      "2018-09-02 03:47:13.984692 Training Step 1375 Finished Timing (Training: 0.92077, Test: 0.0783319) after 0.819011 seconds\n",
      "2018-09-02 03:47:13.984752 Training Step 1375 \"min loss\" =  5.7911725\n",
      "2018-09-02 03:47:13.984792 Training Step 1375 \"loss\" =  6.1836333\n",
      "2018-09-02 03:47:14.643944 Test Step 1380 Finished\n",
      "2018-09-02 03:47:14.644039 Test Step 1380 \"min loss\" =  7.354335\n",
      "2018-09-02 03:47:14.644083 Test Step 1380 \"loss\" =  7.354335\n",
      "2018-09-02 03:47:14.794272 Training Step 1380 Finished Timing (Training: 0.920673, Test: 0.0784576) after 0.809432 seconds\n",
      "2018-09-02 03:47:14.794345 Training Step 1380 \"min loss\" =  5.7911725\n",
      "2018-09-02 03:47:14.794387 Training Step 1380 \"loss\" =  5.9537625\n",
      "2018-09-02 03:47:15.449143 Test Step 1385 Finished\n",
      "2018-09-02 03:47:15.449225 Test Step 1385 \"min loss\" =  7.354335\n",
      "2018-09-02 03:47:15.449271 Test Step 1385 \"loss\" =  7.5459948\n",
      "2018-09-02 03:47:15.592585 Training Step 1385 Finished Timing (Training: 0.920713, Test: 0.0784362) after 0.798142 seconds\n",
      "2018-09-02 03:47:15.592702 Training Step 1385 \"min loss\" =  5.7774153\n",
      "2018-09-02 03:47:15.592743 Training Step 1385 \"loss\" =  5.8487387\n",
      "2018-09-02 03:47:16.260152 Test Step 1390 Finished\n",
      "2018-09-02 03:47:16.260255 Test Step 1390 \"min loss\" =  7.354335\n",
      "2018-09-02 03:47:16.260320 Test Step 1390 \"loss\" =  8.23348\n",
      "2018-09-02 03:47:16.411025 Training Step 1390 Finished Timing (Training: 0.920642, Test: 0.0785224) after 0.818236 seconds\n",
      "2018-09-02 03:47:16.411084 Training Step 1390 \"min loss\" =  5.7774153\n",
      "2018-09-02 03:47:16.411125 Training Step 1390 \"loss\" =  6.2926855\n",
      "2018-09-02 03:47:17.075550 Test Step 1395 Finished\n",
      "2018-09-02 03:47:17.075656 Test Step 1395 \"min loss\" =  7.354335\n",
      "2018-09-02 03:47:17.075701 Test Step 1395 \"loss\" =  7.673366\n",
      "2018-09-02 03:47:17.225887 Training Step 1395 Finished Timing (Training: 0.920635, Test: 0.0785495) after 0.814715 seconds\n",
      "2018-09-02 03:47:17.225945 Training Step 1395 \"min loss\" =  5.7774153\n",
      "2018-09-02 03:47:17.225986 Training Step 1395 \"loss\" =  6.291978\n",
      "2018-09-02 03:47:17.866953 Test Step 1400 Finished\n",
      "2018-09-02 03:47:17.867034 Test Step 1400 \"min loss\" =  7.354335\n",
      "2018-09-02 03:47:17.867079 Test Step 1400 \"loss\" =  7.6751337\n",
      "2018-09-02 03:47:18.017519 Training Step 1400 Finished Timing (Training: 0.920625, Test: 0.0785781) after 0.791477 seconds\n",
      "2018-09-02 03:47:18.017629 Training Step 1400 \"min loss\" =  5.7774153\n",
      "2018-09-02 03:47:18.017675 Training Step 1400 \"loss\" =  6.3790784\n",
      "2018-09-02 03:47:18.678422 Test Step 1405 Finished\n",
      "2018-09-02 03:47:18.678497 Test Step 1405 \"min loss\" =  7.354335\n",
      "2018-09-02 03:47:18.678543 Test Step 1405 \"loss\" =  8.206985\n",
      "2018-09-02 03:47:18.826376 Training Step 1405 Finished Timing (Training: 0.917376, Test: 0.0823642) after 0.808654 seconds\n",
      "2018-09-02 03:47:18.826434 Training Step 1405 \"min loss\" =  5.7774153\n",
      "2018-09-02 03:47:18.826475 Training Step 1405 \"loss\" =  6.072931\n",
      "2018-09-02 03:47:19.496126 Test Step 1410 Finished\n",
      "2018-09-02 03:47:19.496200 Test Step 1410 \"min loss\" =  7.354335\n",
      "2018-09-02 03:47:19.496248 Test Step 1410 \"loss\" =  7.9127274\n",
      "2018-09-02 03:47:19.647905 Training Step 1410 Finished Timing (Training: 0.918978, Test: 0.0806886) after 0.821374 seconds\n",
      "2018-09-02 03:47:19.648033 Training Step 1410 \"min loss\" =  5.6019444\n",
      "2018-09-02 03:47:19.648075 Training Step 1410 \"loss\" =  6.030734\n",
      "2018-09-02 03:47:20.295348 Test Step 1415 Finished\n",
      "2018-09-02 03:47:20.295430 Test Step 1415 \"min loss\" =  7.354335\n",
      "2018-09-02 03:47:20.295474 Test Step 1415 \"loss\" =  8.374373\n",
      "2018-09-02 03:47:20.441821 Training Step 1415 Finished Timing (Training: 0.919144, Test: 0.0804569) after 0.793685 seconds\n",
      "2018-09-02 03:47:20.441990 Training Step 1415 \"min loss\" =  5.6019444\n",
      "2018-09-02 03:47:20.442054 Training Step 1415 \"loss\" =  6.0941777\n",
      "2018-09-02 03:47:21.115809 Test Step 1420 Finished\n",
      "2018-09-02 03:47:21.115915 Test Step 1420 \"min loss\" =  7.354335\n",
      "2018-09-02 03:47:21.115961 Test Step 1420 \"loss\" =  7.7979665\n",
      "2018-09-02 03:47:21.264944 Training Step 1420 Finished Timing (Training: 0.918621, Test: 0.0809162) after 0.822832 seconds\n",
      "2018-09-02 03:47:21.265098 Training Step 1420 \"min loss\" =  5.6019444\n",
      "2018-09-02 03:47:21.265141 Training Step 1420 \"loss\" =  6.1050563\n",
      "2018-09-02 03:47:21.925201 Test Step 1425 Finished\n",
      "2018-09-02 03:47:21.925325 Test Step 1425 \"min loss\" =  7.354335\n",
      "2018-09-02 03:47:21.925372 Test Step 1425 \"loss\" =  7.39885\n",
      "2018-09-02 03:47:22.077590 Training Step 1425 Finished Timing (Training: 0.919469, Test: 0.0800365) after 0.812404 seconds\n",
      "2018-09-02 03:47:22.077645 Training Step 1425 \"min loss\" =  5.6019444\n",
      "2018-09-02 03:47:22.077681 Training Step 1425 \"loss\" =  5.855818\n",
      "2018-09-02 03:47:22.728429 Test Step 1430 Finished\n",
      "2018-09-02 03:47:22.728525 Test Step 1430 \"min loss\" =  7.354335\n",
      "2018-09-02 03:47:22.728567 Test Step 1430 \"loss\" =  8.457582\n",
      "2018-09-02 03:47:22.872853 Training Step 1430 Finished Timing (Training: 0.919534, Test: 0.0799823) after 0.795131 seconds\n",
      "2018-09-02 03:47:22.872915 Training Step 1430 \"min loss\" =  5.6019444\n",
      "2018-09-02 03:47:22.872954 Training Step 1430 \"loss\" =  6.472997\n",
      "2018-09-02 03:47:23.525703 Test Step 1435 Finished\n",
      "2018-09-02 03:47:23.525822 Test Step 1435 \"min loss\" =  7.354335\n",
      "2018-09-02 03:47:23.525882 Test Step 1435 \"loss\" =  7.862513\n",
      "2018-09-02 03:47:23.674902 Training Step 1435 Finished Timing (Training: 0.919858, Test: 0.0796542) after 0.801905 seconds\n",
      "2018-09-02 03:47:23.674958 Training Step 1435 \"min loss\" =  5.6019444\n",
      "2018-09-02 03:47:23.674994 Training Step 1435 \"loss\" =  5.871168\n",
      "2018-09-02 03:47:24.327871 Test Step 1440 Finished\n",
      "2018-09-02 03:47:24.328026 Test Step 1440 \"min loss\" =  7.354335\n",
      "2018-09-02 03:47:24.328068 Test Step 1440 \"loss\" =  7.716634\n",
      "2018-09-02 03:47:24.478114 Training Step 1440 Finished Timing (Training: 0.919746, Test: 0.0797633) after 0.803075 seconds\n",
      "2018-09-02 03:47:24.478174 Training Step 1440 \"min loss\" =  5.6019444\n",
      "2018-09-02 03:47:24.478213 Training Step 1440 \"loss\" =  5.884975\n",
      "2018-09-02 03:47:25.137616 Test Step 1445 Finished\n",
      "2018-09-02 03:47:25.137951 Test Step 1445 \"min loss\" =  7.347228\n",
      "2018-09-02 03:47:25.137995 Test Step 1445 \"loss\" =  7.347228\n",
      "2018-09-02 03:47:25.289894 Training Step 1445 Finished Timing (Training: 0.920011, Test: 0.0794723) after 0.811635 seconds\n",
      "2018-09-02 03:47:25.289966 Training Step 1445 \"min loss\" =  5.6019444\n",
      "2018-09-02 03:47:25.290003 Training Step 1445 \"loss\" =  6.015897\n",
      "2018-09-02 03:47:25.951535 Test Step 1450 Finished\n",
      "2018-09-02 03:47:25.951667 Test Step 1450 \"min loss\" =  7.347228\n",
      "2018-09-02 03:47:25.951730 Test Step 1450 \"loss\" =  7.478921\n",
      "2018-09-02 03:47:26.098428 Training Step 1450 Finished Timing (Training: 0.919891, Test: 0.079589) after 0.808381 seconds\n",
      "2018-09-02 03:47:26.098486 Training Step 1450 \"min loss\" =  5.47215\n",
      "2018-09-02 03:47:26.098523 Training Step 1450 \"loss\" =  6.1935844\n",
      "2018-09-02 03:47:26.746875 Test Step 1455 Finished\n",
      "2018-09-02 03:47:26.746975 Test Step 1455 \"min loss\" =  7.347228\n",
      "2018-09-02 03:47:26.747018 Test Step 1455 \"loss\" =  7.6000514\n",
      "2018-09-02 03:47:26.888015 Training Step 1455 Finished Timing (Training: 0.919462, Test: 0.0800216) after 0.789448 seconds\n",
      "2018-09-02 03:47:26.888071 Training Step 1455 \"min loss\" =  5.47215\n",
      "2018-09-02 03:47:26.888106 Training Step 1455 \"loss\" =  5.690813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:47:27.546604 Test Step 1460 Finished\n",
      "2018-09-02 03:47:27.546772 Test Step 1460 \"min loss\" =  7.347228\n",
      "2018-09-02 03:47:27.546832 Test Step 1460 \"loss\" =  7.5437956\n",
      "2018-09-02 03:47:27.697924 Training Step 1460 Finished Timing (Training: 0.919543, Test: 0.0799399) after 0.809775 seconds\n",
      "2018-09-02 03:47:27.697985 Training Step 1460 \"min loss\" =  5.47215\n",
      "2018-09-02 03:47:27.698021 Training Step 1460 \"loss\" =  5.7176633\n",
      "2018-09-02 03:47:28.352414 Test Step 1465 Finished\n",
      "2018-09-02 03:47:28.352845 Test Step 1465 \"min loss\" =  7.347228\n",
      "2018-09-02 03:47:28.353135 Test Step 1465 \"loss\" =  8.044652\n",
      "2018-09-02 03:47:28.506023 Training Step 1465 Finished Timing (Training: 0.919679, Test: 0.0797295) after 0.80796 seconds\n",
      "2018-09-02 03:47:28.506273 Training Step 1465 \"min loss\" =  5.47215\n",
      "2018-09-02 03:47:28.506558 Training Step 1465 \"loss\" =  5.9730825\n",
      "2018-09-02 03:47:29.149512 Test Step 1470 Finished\n",
      "2018-09-02 03:47:29.149972 Test Step 1470 \"min loss\" =  7.342845\n",
      "2018-09-02 03:47:29.150265 Test Step 1470 \"loss\" =  7.342845\n",
      "2018-09-02 03:47:29.296351 Training Step 1470 Finished Timing (Training: 0.919629, Test: 0.0796542) after 0.789508 seconds\n",
      "2018-09-02 03:47:29.296622 Training Step 1470 \"min loss\" =  5.3904\n",
      "2018-09-02 03:47:29.296936 Training Step 1470 \"loss\" =  6.0445924\n",
      "2018-09-02 03:47:29.960989 Test Step 1475 Finished\n",
      "2018-09-02 03:47:29.961374 Test Step 1475 \"min loss\" =  7.342845\n",
      "2018-09-02 03:47:29.961662 Test Step 1475 \"loss\" =  7.6327558\n",
      "2018-09-02 03:47:30.113266 Training Step 1475 Finished Timing (Training: 0.92006, Test: 0.0791184) after 0.816044 seconds\n",
      "2018-09-02 03:47:30.113553 Training Step 1475 \"min loss\" =  5.3904\n",
      "2018-09-02 03:47:30.113880 Training Step 1475 \"loss\" =  5.683518\n",
      "2018-09-02 03:47:30.765808 Test Step 1480 Finished\n",
      "2018-09-02 03:47:30.766226 Test Step 1480 \"min loss\" =  7.342845\n",
      "2018-09-02 03:47:30.766512 Test Step 1480 \"loss\" =  7.5119767\n",
      "2018-09-02 03:47:30.920354 Training Step 1480 Finished Timing (Training: 0.920041, Test: 0.079039) after 0.806177 seconds\n",
      "2018-09-02 03:47:30.920607 Training Step 1480 \"min loss\" =  5.3904\n",
      "2018-09-02 03:47:30.920894 Training Step 1480 \"loss\" =  5.7140675\n",
      "2018-09-02 03:47:31.576520 Test Step 1485 Finished\n",
      "2018-09-02 03:47:31.576610 Test Step 1485 \"min loss\" =  7.342845\n",
      "2018-09-02 03:47:31.576651 Test Step 1485 \"loss\" =  7.564887\n",
      "2018-09-02 03:47:31.732264 Training Step 1485 Finished Timing (Training: 0.919827, Test: 0.0792319) after 0.811069 seconds\n",
      "2018-09-02 03:47:31.732375 Training Step 1485 \"min loss\" =  5.3904\n",
      "2018-09-02 03:47:31.732416 Training Step 1485 \"loss\" =  5.828051\n",
      "2018-09-02 03:47:32.392962 Test Step 1490 Finished\n",
      "2018-09-02 03:47:32.393062 Test Step 1490 \"min loss\" =  7.342845\n",
      "2018-09-02 03:47:32.393103 Test Step 1490 \"loss\" =  7.545396\n",
      "2018-09-02 03:47:32.545456 Training Step 1490 Finished Timing (Training: 0.91974, Test: 0.0793436) after 0.812997 seconds\n",
      "2018-09-02 03:47:32.545529 Training Step 1490 \"min loss\" =  5.3904\n",
      "2018-09-02 03:47:32.545576 Training Step 1490 \"loss\" =  5.8319993\n",
      "2018-09-02 03:47:33.199889 Test Step 1495 Finished\n",
      "2018-09-02 03:47:33.199980 Test Step 1495 \"min loss\" =  7.342845\n",
      "2018-09-02 03:47:33.200023 Test Step 1495 \"loss\" =  7.6102934\n",
      "2018-09-02 03:47:33.351919 Training Step 1495 Finished Timing (Training: 0.919929, Test: 0.0791763) after 0.806258 seconds\n",
      "2018-09-02 03:47:33.352052 Training Step 1495 \"min loss\" =  5.3904\n",
      "2018-09-02 03:47:33.352140 Training Step 1495 \"loss\" =  5.7965803\n",
      "2018-09-02 03:47:34.010258 Test Step 1500 Finished\n",
      "2018-09-02 03:47:34.010345 Test Step 1500 \"min loss\" =  7.342845\n",
      "2018-09-02 03:47:34.010385 Test Step 1500 \"loss\" =  7.785084\n",
      "2018-09-02 03:47:34.161677 Training Step 1500 Finished Timing (Training: 0.920016, Test: 0.0791053) after 0.809495 seconds\n",
      "2018-09-02 03:47:34.161733 Training Step 1500 \"min loss\" =  5.3904\n",
      "2018-09-02 03:47:34.161770 Training Step 1500 \"loss\" =  6.0385785\n",
      "2018-09-02 03:47:34.814658 Test Step 1505 Finished\n",
      "2018-09-02 03:47:34.814747 Test Step 1505 \"min loss\" =  7.342845\n",
      "2018-09-02 03:47:34.814787 Test Step 1505 \"loss\" =  7.9781456\n",
      "2018-09-02 03:47:34.966210 Training Step 1505 Finished Timing (Training: 0.927288, Test: 0.0724712) after 0.804398 seconds\n",
      "2018-09-02 03:47:34.966266 Training Step 1505 \"min loss\" =  5.3904\n",
      "2018-09-02 03:47:34.966301 Training Step 1505 \"loss\" =  5.7071543\n",
      "2018-09-02 03:47:35.615933 Test Step 1510 Finished\n",
      "2018-09-02 03:47:35.616063 Test Step 1510 \"min loss\" =  7.342845\n",
      "2018-09-02 03:47:35.616108 Test Step 1510 \"loss\" =  7.6938143\n",
      "2018-09-02 03:47:35.767276 Training Step 1510 Finished Timing (Training: 0.924086, Test: 0.0755529) after 0.800928 seconds\n",
      "2018-09-02 03:47:35.767359 Training Step 1510 \"min loss\" =  5.3904\n",
      "2018-09-02 03:47:35.767399 Training Step 1510 \"loss\" =  5.8350306\n",
      "2018-09-02 03:47:36.428519 Test Step 1515 Finished\n",
      "2018-09-02 03:47:36.428628 Test Step 1515 \"min loss\" =  7.342845\n",
      "2018-09-02 03:47:36.428670 Test Step 1515 \"loss\" =  7.7171965\n",
      "2018-09-02 03:47:36.581057 Training Step 1515 Finished Timing (Training: 0.922644, Test: 0.0769513) after 0.813614 seconds\n",
      "2018-09-02 03:47:36.581115 Training Step 1515 \"min loss\" =  5.3904\n",
      "2018-09-02 03:47:36.581152 Training Step 1515 \"loss\" =  5.7251143\n",
      "2018-09-02 03:47:37.233381 Test Step 1520 Finished\n",
      "2018-09-02 03:47:37.233492 Test Step 1520 \"min loss\" =  7.342845\n",
      "2018-09-02 03:47:37.233535 Test Step 1520 \"loss\" =  7.4720206\n",
      "2018-09-02 03:47:37.388884 Training Step 1520 Finished Timing (Training: 0.923328, Test: 0.0762531) after 0.807689 seconds\n",
      "2018-09-02 03:47:37.388941 Training Step 1520 \"min loss\" =  5.3904\n",
      "2018-09-02 03:47:37.388978 Training Step 1520 \"loss\" =  6.0105596\n",
      "2018-09-02 03:47:38.041454 Test Step 1525 Finished\n",
      "2018-09-02 03:47:38.041548 Test Step 1525 \"min loss\" =  7.342845\n",
      "2018-09-02 03:47:38.041591 Test Step 1525 \"loss\" =  7.4119387\n",
      "2018-09-02 03:47:38.189150 Training Step 1525 Finished Timing (Training: 0.922896, Test: 0.0766842) after 0.800127 seconds\n",
      "2018-09-02 03:47:38.189222 Training Step 1525 \"min loss\" =  5.3781095\n",
      "2018-09-02 03:47:38.189262 Training Step 1525 \"loss\" =  5.3781095\n",
      "2018-09-02 03:47:38.843870 Test Step 1530 Finished\n",
      "2018-09-02 03:47:38.843966 Test Step 1530 \"min loss\" =  7.342845\n",
      "2018-09-02 03:47:38.844008 Test Step 1530 \"loss\" =  7.593319\n",
      "2018-09-02 03:47:38.992166 Training Step 1530 Finished Timing (Training: 0.923101, Test: 0.0764687) after 0.802837 seconds\n",
      "2018-09-02 03:47:38.992228 Training Step 1530 \"min loss\" =  5.3781095\n",
      "2018-09-02 03:47:38.992270 Training Step 1530 \"loss\" =  5.476411\n",
      "2018-09-02 03:47:39.653355 Test Step 1535 Finished\n",
      "2018-09-02 03:47:39.653431 Test Step 1535 \"min loss\" =  7.342845\n",
      "2018-09-02 03:47:39.653468 Test Step 1535 \"loss\" =  7.4099393\n",
      "2018-09-02 03:47:39.802580 Training Step 1535 Finished Timing (Training: 0.922428, Test: 0.0771469) after 0.810266 seconds\n",
      "2018-09-02 03:47:39.802640 Training Step 1535 \"min loss\" =  5.3781095\n",
      "2018-09-02 03:47:39.802681 Training Step 1535 \"loss\" =  5.9053845\n",
      "2018-09-02 03:47:40.465785 Test Step 1540 Finished\n",
      "2018-09-02 03:47:40.465855 Test Step 1540 \"min loss\" =  7.342845\n",
      "2018-09-02 03:47:40.465893 Test Step 1540 \"loss\" =  7.7017083\n",
      "2018-09-02 03:47:40.616200 Training Step 1540 Finished Timing (Training: 0.922156, Test: 0.0774228) after 0.813474 seconds\n",
      "2018-09-02 03:47:40.616257 Training Step 1540 \"min loss\" =  5.3781095\n",
      "2018-09-02 03:47:40.616293 Training Step 1540 \"loss\" =  5.677466\n",
      "2018-09-02 03:47:41.282075 Test Step 1545 Finished\n",
      "2018-09-02 03:47:41.282581 Test Step 1545 \"min loss\" =  7.342845\n",
      "2018-09-02 03:47:41.282903 Test Step 1545 \"loss\" =  7.362819\n",
      "2018-09-02 03:47:41.435031 Training Step 1545 Finished Timing (Training: 0.922309, Test: 0.0771344) after 0.818691 seconds\n",
      "2018-09-02 03:47:41.435354 Training Step 1545 \"min loss\" =  5.3781095\n",
      "2018-09-02 03:47:41.435655 Training Step 1545 \"loss\" =  5.969946\n",
      "2018-09-02 03:47:42.076631 Test Step 1550 Finished\n",
      "2018-09-02 03:47:42.077106 Test Step 1550 \"min loss\" =  7.342845\n",
      "2018-09-02 03:47:42.077446 Test Step 1550 \"loss\" =  7.7843556\n",
      "2018-09-02 03:47:42.227467 Training Step 1550 Finished Timing (Training: 0.921649, Test: 0.0775903) after 0.791509 seconds\n",
      "2018-09-02 03:47:42.227721 Training Step 1550 \"min loss\" =  5.3781095\n",
      "2018-09-02 03:47:42.228006 Training Step 1550 \"loss\" =  5.7493725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:47:42.880725 Test Step 1555 Finished\n",
      "2018-09-02 03:47:42.881111 Test Step 1555 \"min loss\" =  7.342845\n",
      "2018-09-02 03:47:42.881457 Test Step 1555 \"loss\" =  7.4110465\n",
      "2018-09-02 03:47:43.031970 Training Step 1555 Finished Timing (Training: 0.921299, Test: 0.0777969) after 0.803679 seconds\n",
      "2018-09-02 03:47:43.032227 Training Step 1555 \"min loss\" =  5.358497\n",
      "2018-09-02 03:47:43.032517 Training Step 1555 \"loss\" =  5.5401306\n",
      "2018-09-02 03:47:43.693456 Test Step 1560 Finished\n",
      "2018-09-02 03:47:43.693930 Test Step 1560 \"min loss\" =  7.342845\n",
      "2018-09-02 03:47:43.694217 Test Step 1560 \"loss\" =  7.4223266\n",
      "2018-09-02 03:47:43.843944 Training Step 1560 Finished Timing (Training: 0.920811, Test: 0.0781626) after 0.811141 seconds\n",
      "2018-09-02 03:47:43.844233 Training Step 1560 \"min loss\" =  5.358497\n",
      "2018-09-02 03:47:43.844521 Training Step 1560 \"loss\" =  5.5404034\n",
      "2018-09-02 03:47:44.491297 Test Step 1565 Finished\n",
      "2018-09-02 03:47:44.491730 Test Step 1565 \"min loss\" =  7.2648935\n",
      "2018-09-02 03:47:44.492022 Test Step 1565 \"loss\" =  7.2648935\n",
      "2018-09-02 03:47:44.645537 Training Step 1565 Finished Timing (Training: 0.920907, Test: 0.0779639) after 0.800727 seconds\n",
      "2018-09-02 03:47:44.645813 Training Step 1565 \"min loss\" =  5.358497\n",
      "2018-09-02 03:47:44.646099 Training Step 1565 \"loss\" =  5.6600146\n",
      "2018-09-02 03:47:45.309573 Test Step 1570 Finished\n",
      "2018-09-02 03:47:45.309681 Test Step 1570 \"min loss\" =  7.216817\n",
      "2018-09-02 03:47:45.309725 Test Step 1570 \"loss\" =  7.216817\n",
      "2018-09-02 03:47:45.463876 Training Step 1570 Finished Timing (Training: 0.920981, Test: 0.077875) after 0.817486 seconds\n",
      "2018-09-02 03:47:45.463951 Training Step 1570 \"min loss\" =  5.358497\n",
      "2018-09-02 03:47:45.463990 Training Step 1570 \"loss\" =  5.6893835\n",
      "2018-09-02 03:47:46.109225 Test Step 1575 Finished\n",
      "2018-09-02 03:47:46.109324 Test Step 1575 \"min loss\" =  7.1486673\n",
      "2018-09-02 03:47:46.109368 Test Step 1575 \"loss\" =  7.1486673\n",
      "2018-09-02 03:47:46.261214 Training Step 1575 Finished Timing (Training: 0.920809, Test: 0.0780892) after 0.797182 seconds\n",
      "2018-09-02 03:47:46.261268 Training Step 1575 \"min loss\" =  5.358497\n",
      "2018-09-02 03:47:46.261324 Training Step 1575 \"loss\" =  5.6845684\n",
      "2018-09-02 03:47:46.903467 Test Step 1580 Finished\n",
      "2018-09-02 03:47:46.903578 Test Step 1580 \"min loss\" =  7.1486673\n",
      "2018-09-02 03:47:46.903623 Test Step 1580 \"loss\" =  7.1532154\n",
      "2018-09-02 03:47:47.059430 Training Step 1580 Finished Timing (Training: 0.920824, Test: 0.0781115) after 0.798061 seconds\n",
      "2018-09-02 03:47:47.059493 Training Step 1580 \"min loss\" =  5.358497\n",
      "2018-09-02 03:47:47.059532 Training Step 1580 \"loss\" =  5.9777236\n",
      "2018-09-02 03:47:47.714810 Test Step 1585 Finished\n",
      "2018-09-02 03:47:47.714902 Test Step 1585 \"min loss\" =  7.124336\n",
      "2018-09-02 03:47:47.714947 Test Step 1585 \"loss\" =  7.124336\n",
      "2018-09-02 03:47:47.866469 Training Step 1585 Finished Timing (Training: 0.920634, Test: 0.0783369) after 0.806891 seconds\n",
      "2018-09-02 03:47:47.866529 Training Step 1585 \"min loss\" =  5.358497\n",
      "2018-09-02 03:47:47.866568 Training Step 1585 \"loss\" =  5.6278567\n",
      "2018-09-02 03:47:48.526798 Test Step 1590 Finished\n",
      "2018-09-02 03:47:48.527214 Test Step 1590 \"min loss\" =  7.124336\n",
      "2018-09-02 03:47:48.527533 Test Step 1590 \"loss\" =  7.4522095\n",
      "2018-09-02 03:47:48.677247 Training Step 1590 Finished Timing (Training: 0.920673, Test: 0.0782843) after 0.810602 seconds\n",
      "2018-09-02 03:47:48.677601 Training Step 1590 \"min loss\" =  5.358497\n",
      "2018-09-02 03:47:48.677888 Training Step 1590 \"loss\" =  6.0265527\n",
      "2018-09-02 03:47:49.336553 Test Step 1595 Finished\n",
      "2018-09-02 03:47:49.336959 Test Step 1595 \"min loss\" =  7.124336\n",
      "2018-09-02 03:47:49.337245 Test Step 1595 \"loss\" =  7.451062\n",
      "2018-09-02 03:47:49.488163 Training Step 1595 Finished Timing (Training: 0.920467, Test: 0.0784168) after 0.809985 seconds\n",
      "2018-09-02 03:47:49.488415 Training Step 1595 \"min loss\" =  5.358497\n",
      "2018-09-02 03:47:49.488699 Training Step 1595 \"loss\" =  5.3610306\n",
      "2018-09-02 03:47:50.144911 Test Step 1600 Finished\n",
      "2018-09-02 03:47:50.145355 Test Step 1600 \"min loss\" =  7.124336\n",
      "2018-09-02 03:47:50.145692 Test Step 1600 \"loss\" =  7.977759\n",
      "2018-09-02 03:47:50.293656 Training Step 1600 Finished Timing (Training: 0.920389, Test: 0.0784314) after 0.804671 seconds\n",
      "2018-09-02 03:47:50.293932 Training Step 1600 \"min loss\" =  5.358497\n",
      "2018-09-02 03:47:50.294216 Training Step 1600 \"loss\" =  5.7497215\n",
      "2018-09-02 03:47:50.940032 Test Step 1605 Finished\n",
      "2018-09-02 03:47:50.940455 Test Step 1605 \"min loss\" =  7.124336\n",
      "2018-09-02 03:47:50.940759 Test Step 1605 \"loss\" =  7.4130917\n",
      "2018-09-02 03:47:51.086864 Training Step 1605 Finished Timing (Training: 0.919318, Test: 0.0793565) after 0.792365 seconds\n",
      "2018-09-02 03:47:51.087140 Training Step 1605 \"min loss\" =  5.291268\n",
      "2018-09-02 03:47:51.087455 Training Step 1605 \"loss\" =  5.466494\n",
      "2018-09-02 03:47:51.737800 Test Step 1610 Finished\n",
      "2018-09-02 03:47:51.738212 Test Step 1610 \"min loss\" =  7.124336\n",
      "2018-09-02 03:47:51.738515 Test Step 1610 \"loss\" =  7.406125\n",
      "2018-09-02 03:47:51.889415 Training Step 1610 Finished Timing (Training: 0.919186, Test: 0.0789431) after 0.801656 seconds\n",
      "2018-09-02 03:47:51.889731 Training Step 1610 \"min loss\" =  5.291268\n",
      "2018-09-02 03:47:51.890016 Training Step 1610 \"loss\" =  5.356107\n",
      "2018-09-02 03:47:52.548234 Test Step 1615 Finished\n",
      "2018-09-02 03:47:52.548703 Test Step 1615 \"min loss\" =  7.124336\n",
      "2018-09-02 03:47:52.548992 Test Step 1615 \"loss\" =  7.5896773\n",
      "2018-09-02 03:47:52.700798 Training Step 1615 Finished Timing (Training: 0.918045, Test: 0.0798996) after 0.810497 seconds\n",
      "2018-09-02 03:47:52.701057 Training Step 1615 \"min loss\" =  5.291268\n",
      "2018-09-02 03:47:52.701370 Training Step 1615 \"loss\" =  5.7802296\n",
      "2018-09-02 03:47:53.363053 Test Step 1620 Finished\n",
      "2018-09-02 03:47:53.363413 Test Step 1620 \"min loss\" =  7.124336\n",
      "2018-09-02 03:47:53.363697 Test Step 1620 \"loss\" =  7.2454147\n",
      "2018-09-02 03:47:53.514502 Training Step 1620 Finished Timing (Training: 0.919037, Test: 0.0788635) after 0.812843 seconds\n",
      "2018-09-02 03:47:53.514750 Training Step 1620 \"min loss\" =  5.291268\n",
      "2018-09-02 03:47:53.515037 Training Step 1620 \"loss\" =  5.8362856\n",
      "2018-09-02 03:47:54.169751 Test Step 1625 Finished\n",
      "2018-09-02 03:47:54.170132 Test Step 1625 \"min loss\" =  7.124336\n",
      "2018-09-02 03:47:54.170419 Test Step 1625 \"loss\" =  7.340817\n",
      "2018-09-02 03:47:54.322931 Training Step 1625 Finished Timing (Training: 0.918409, Test: 0.0794591) after 0.807606 seconds\n",
      "2018-09-02 03:47:54.323178 Training Step 1625 \"min loss\" =  5.2478437\n",
      "2018-09-02 03:47:54.323461 Training Step 1625 \"loss\" =  5.415038\n",
      "2018-09-02 03:47:54.981228 Test Step 1630 Finished\n",
      "2018-09-02 03:47:54.981363 Test Step 1630 \"min loss\" =  7.124336\n",
      "2018-09-02 03:47:54.981411 Test Step 1630 \"loss\" =  7.665779\n",
      "2018-09-02 03:47:55.127717 Training Step 1630 Finished Timing (Training: 0.918551, Test: 0.0794492) after 0.803963 seconds\n",
      "2018-09-02 03:47:55.127845 Training Step 1630 \"min loss\" =  5.2478437\n",
      "2018-09-02 03:47:55.127886 Training Step 1630 \"loss\" =  5.396276\n",
      "2018-09-02 03:47:55.770043 Test Step 1635 Finished\n",
      "2018-09-02 03:47:55.770143 Test Step 1635 \"min loss\" =  7.124336\n",
      "2018-09-02 03:47:55.770187 Test Step 1635 \"loss\" =  7.9273624\n",
      "2018-09-02 03:47:55.924682 Training Step 1635 Finished Timing (Training: 0.919019, Test: 0.0791856) after 0.796749 seconds\n",
      "2018-09-02 03:47:55.924755 Training Step 1635 \"min loss\" =  5.2478437\n",
      "2018-09-02 03:47:55.924797 Training Step 1635 \"loss\" =  5.4752183\n",
      "2018-09-02 03:47:56.576255 Test Step 1640 Finished\n",
      "2018-09-02 03:47:56.576355 Test Step 1640 \"min loss\" =  7.124336\n",
      "2018-09-02 03:47:56.576402 Test Step 1640 \"loss\" =  7.4958916\n",
      "2018-09-02 03:47:56.724410 Training Step 1640 Finished Timing (Training: 0.920044, Test: 0.0783215) after 0.799566 seconds\n",
      "2018-09-02 03:47:56.724472 Training Step 1640 \"min loss\" =  5.2478437\n",
      "2018-09-02 03:47:56.724513 Training Step 1640 \"loss\" =  5.617965\n",
      "2018-09-02 03:47:57.379433 Test Step 1645 Finished\n",
      "2018-09-02 03:47:57.379537 Test Step 1645 \"min loss\" =  7.124336\n",
      "2018-09-02 03:47:57.379582 Test Step 1645 \"loss\" =  7.2775974\n",
      "2018-09-02 03:47:57.529079 Training Step 1645 Finished Timing (Training: 0.92038, Test: 0.0781127) after 0.804518 seconds\n",
      "2018-09-02 03:47:57.529142 Training Step 1645 \"min loss\" =  5.2478437\n",
      "2018-09-02 03:47:57.529183 Training Step 1645 \"loss\" =  5.371395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:47:58.177773 Test Step 1650 Finished\n",
      "2018-09-02 03:47:58.177838 Test Step 1650 \"min loss\" =  7.124336\n",
      "2018-09-02 03:47:58.177879 Test Step 1650 \"loss\" =  7.5825415\n",
      "2018-09-02 03:47:58.324376 Training Step 1650 Finished Timing (Training: 0.920312, Test: 0.0782894) after 0.795149 seconds\n",
      "2018-09-02 03:47:58.324435 Training Step 1650 \"min loss\" =  5.187078\n",
      "2018-09-02 03:47:58.324476 Training Step 1650 \"loss\" =  5.2744613\n",
      "2018-09-02 03:47:58.978301 Test Step 1655 Finished\n",
      "2018-09-02 03:47:58.978406 Test Step 1655 \"min loss\" =  7.124336\n",
      "2018-09-02 03:47:58.978452 Test Step 1655 \"loss\" =  7.532448\n",
      "2018-09-02 03:47:59.122256 Training Step 1655 Finished Timing (Training: 0.920117, Test: 0.078568) after 0.797734 seconds\n",
      "2018-09-02 03:47:59.122316 Training Step 1655 \"min loss\" =  5.187078\n",
      "2018-09-02 03:47:59.122356 Training Step 1655 \"loss\" =  5.5990634\n",
      "2018-09-02 03:47:59.780560 Test Step 1660 Finished\n",
      "2018-09-02 03:47:59.780646 Test Step 1660 \"min loss\" =  7.124336\n",
      "2018-09-02 03:47:59.780690 Test Step 1660 \"loss\" =  7.5811934\n",
      "2018-09-02 03:47:59.929227 Training Step 1660 Finished Timing (Training: 0.920281, Test: 0.0784778) after 0.806815 seconds\n",
      "2018-09-02 03:47:59.929405 Training Step 1660 \"min loss\" =  5.167043\n",
      "2018-09-02 03:47:59.929471 Training Step 1660 \"loss\" =  5.2187486\n",
      "2018-09-02 03:48:00.589416 Test Step 1665 Finished\n",
      "2018-09-02 03:48:00.589523 Test Step 1665 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:00.589568 Test Step 1665 \"loss\" =  7.440361\n",
      "2018-09-02 03:48:00.742977 Training Step 1665 Finished Timing (Training: 0.920386, Test: 0.0784181) after 0.813447 seconds\n",
      "2018-09-02 03:48:00.743103 Training Step 1665 \"min loss\" =  5.066071\n",
      "2018-09-02 03:48:00.743144 Training Step 1665 \"loss\" =  5.3187637\n",
      "2018-09-02 03:48:01.396181 Test Step 1670 Finished\n",
      "2018-09-02 03:48:01.396288 Test Step 1670 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:01.396333 Test Step 1670 \"loss\" =  7.7258983\n",
      "2018-09-02 03:48:01.543102 Training Step 1670 Finished Timing (Training: 0.920728, Test: 0.0781208) after 0.799911 seconds\n",
      "2018-09-02 03:48:01.543159 Training Step 1670 \"min loss\" =  5.066071\n",
      "2018-09-02 03:48:01.543200 Training Step 1670 \"loss\" =  5.27801\n",
      "2018-09-02 03:48:02.212859 Test Step 1675 Finished\n",
      "2018-09-02 03:48:02.212966 Test Step 1675 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:02.213011 Test Step 1675 \"loss\" =  7.9908977\n",
      "2018-09-02 03:48:02.366385 Training Step 1675 Finished Timing (Training: 0.920894, Test: 0.0780015) after 0.823125 seconds\n",
      "2018-09-02 03:48:02.366505 Training Step 1675 \"min loss\" =  5.066071\n",
      "2018-09-02 03:48:02.366551 Training Step 1675 \"loss\" =  5.4733624\n",
      "2018-09-02 03:48:03.022519 Test Step 1680 Finished\n",
      "2018-09-02 03:48:03.022631 Test Step 1680 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:03.022676 Test Step 1680 \"loss\" =  7.862472\n",
      "2018-09-02 03:48:03.169359 Training Step 1680 Finished Timing (Training: 0.920965, Test: 0.0779636) after 0.802758 seconds\n",
      "2018-09-02 03:48:03.169411 Training Step 1680 \"min loss\" =  5.066071\n",
      "2018-09-02 03:48:03.169447 Training Step 1680 \"loss\" =  5.135248\n",
      "2018-09-02 03:48:03.833611 Test Step 1685 Finished\n",
      "2018-09-02 03:48:03.833699 Test Step 1685 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:03.833756 Test Step 1685 \"loss\" =  7.5298643\n",
      "2018-09-02 03:48:03.985580 Training Step 1685 Finished Timing (Training: 0.920934, Test: 0.0780314) after 0.816089 seconds\n",
      "2018-09-02 03:48:03.985648 Training Step 1685 \"min loss\" =  4.910748\n",
      "2018-09-02 03:48:03.985687 Training Step 1685 \"loss\" =  4.910748\n",
      "2018-09-02 03:48:04.662398 Test Step 1690 Finished\n",
      "2018-09-02 03:48:04.662482 Test Step 1690 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:04.662525 Test Step 1690 \"loss\" =  7.35789\n",
      "2018-09-02 03:48:04.808301 Training Step 1690 Finished Timing (Training: 0.920668, Test: 0.0783321) after 0.822568 seconds\n",
      "2018-09-02 03:48:04.808366 Training Step 1690 \"min loss\" =  4.910748\n",
      "2018-09-02 03:48:04.808407 Training Step 1690 \"loss\" =  5.727689\n",
      "2018-09-02 03:48:05.488259 Test Step 1695 Finished\n",
      "2018-09-02 03:48:05.488337 Test Step 1695 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:05.488380 Test Step 1695 \"loss\" =  7.5694757\n",
      "2018-09-02 03:48:05.639283 Training Step 1695 Finished Timing (Training: 0.920592, Test: 0.078441) after 0.83083 seconds\n",
      "2018-09-02 03:48:05.639337 Training Step 1695 \"min loss\" =  4.910748\n",
      "2018-09-02 03:48:05.639372 Training Step 1695 \"loss\" =  5.4358063\n",
      "2018-09-02 03:48:06.312665 Test Step 1700 Finished\n",
      "2018-09-02 03:48:06.312769 Test Step 1700 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:06.312818 Test Step 1700 \"loss\" =  7.5321145\n",
      "2018-09-02 03:48:06.465753 Training Step 1700 Finished Timing (Training: 0.920509, Test: 0.0785504) after 0.826338 seconds\n",
      "2018-09-02 03:48:06.465819 Training Step 1700 \"min loss\" =  4.910748\n",
      "2018-09-02 03:48:06.465860 Training Step 1700 \"loss\" =  5.4220862\n",
      "2018-09-02 03:48:07.137743 Test Step 1705 Finished\n",
      "2018-09-02 03:48:07.137844 Test Step 1705 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:07.137890 Test Step 1705 \"loss\" =  7.465854\n",
      "2018-09-02 03:48:07.292297 Training Step 1705 Finished Timing (Training: 0.920279, Test: 0.0794519) after 0.826389 seconds\n",
      "2018-09-02 03:48:07.292362 Training Step 1705 \"min loss\" =  4.910748\n",
      "2018-09-02 03:48:07.292405 Training Step 1705 \"loss\" =  5.594268\n",
      "2018-09-02 03:48:07.966193 Test Step 1710 Finished\n",
      "2018-09-02 03:48:07.966309 Test Step 1710 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:07.966356 Test Step 1710 \"loss\" =  7.1872096\n",
      "2018-09-02 03:48:08.119666 Training Step 1710 Finished Timing (Training: 0.921137, Test: 0.0784855) after 0.827202 seconds\n",
      "2018-09-02 03:48:08.119779 Training Step 1710 \"min loss\" =  4.910748\n",
      "2018-09-02 03:48:08.119819 Training Step 1710 \"loss\" =  5.1139116\n",
      "2018-09-02 03:48:08.781585 Test Step 1715 Finished\n",
      "2018-09-02 03:48:08.781676 Test Step 1715 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:08.781724 Test Step 1715 \"loss\" =  7.176968\n",
      "2018-09-02 03:48:08.930145 Training Step 1715 Finished Timing (Training: 0.922107, Test: 0.0774623) after 0.810281 seconds\n",
      "2018-09-02 03:48:08.930204 Training Step 1715 \"min loss\" =  4.910748\n",
      "2018-09-02 03:48:08.930245 Training Step 1715 \"loss\" =  5.4573526\n",
      "2018-09-02 03:48:09.594556 Test Step 1720 Finished\n",
      "2018-09-02 03:48:09.594658 Test Step 1720 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:09.594702 Test Step 1720 \"loss\" =  7.6751704\n",
      "2018-09-02 03:48:09.745090 Training Step 1720 Finished Timing (Training: 0.92267, Test: 0.0768928) after 0.814798 seconds\n",
      "2018-09-02 03:48:09.745145 Training Step 1720 \"min loss\" =  4.910748\n",
      "2018-09-02 03:48:09.745185 Training Step 1720 \"loss\" =  5.413367\n",
      "2018-09-02 03:48:10.421519 Test Step 1725 Finished\n",
      "2018-09-02 03:48:10.421606 Test Step 1725 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:10.421649 Test Step 1725 \"loss\" =  7.4308553\n",
      "2018-09-02 03:48:10.574776 Training Step 1725 Finished Timing (Training: 0.920097, Test: 0.0794694) after 0.829537 seconds\n",
      "2018-09-02 03:48:10.574891 Training Step 1725 \"min loss\" =  4.910748\n",
      "2018-09-02 03:48:10.574931 Training Step 1725 \"loss\" =  5.5429106\n",
      "2018-09-02 03:48:11.241693 Test Step 1730 Finished\n",
      "2018-09-02 03:48:11.241796 Test Step 1730 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:11.241843 Test Step 1730 \"loss\" =  7.291669\n",
      "2018-09-02 03:48:11.386171 Training Step 1730 Finished Timing (Training: 0.920012, Test: 0.0795333) after 0.811183 seconds\n",
      "2018-09-02 03:48:11.386301 Training Step 1730 \"min loss\" =  4.910748\n",
      "2018-09-02 03:48:11.386360 Training Step 1730 \"loss\" =  5.106958\n",
      "2018-09-02 03:48:12.061173 Test Step 1735 Finished\n",
      "2018-09-02 03:48:12.061316 Test Step 1735 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:12.061382 Test Step 1735 \"loss\" =  7.364632\n",
      "2018-09-02 03:48:12.215180 Training Step 1735 Finished Timing (Training: 0.919993, Test: 0.0795248) after 0.828773 seconds\n",
      "2018-09-02 03:48:12.215242 Training Step 1735 \"min loss\" =  4.910748\n",
      "2018-09-02 03:48:12.215285 Training Step 1735 \"loss\" =  5.2620525\n",
      "2018-09-02 03:48:12.881571 Test Step 1740 Finished\n",
      "2018-09-02 03:48:12.881657 Test Step 1740 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:12.881717 Test Step 1740 \"loss\" =  7.742437\n",
      "2018-09-02 03:48:13.032173 Training Step 1740 Finished Timing (Training: 0.920408, Test: 0.0791135) after 0.81684 seconds\n",
      "2018-09-02 03:48:13.032234 Training Step 1740 \"min loss\" =  4.903375\n",
      "2018-09-02 03:48:13.032278 Training Step 1740 \"loss\" =  4.9590726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:48:13.705502 Test Step 1745 Finished\n",
      "2018-09-02 03:48:13.705584 Test Step 1745 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:13.705628 Test Step 1745 \"loss\" =  7.357837\n",
      "2018-09-02 03:48:13.853676 Training Step 1745 Finished Timing (Training: 0.92016, Test: 0.0793648) after 0.821352 seconds\n",
      "2018-09-02 03:48:13.853736 Training Step 1745 \"min loss\" =  4.903375\n",
      "2018-09-02 03:48:13.853778 Training Step 1745 \"loss\" =  5.2857165\n",
      "2018-09-02 03:48:14.519482 Test Step 1750 Finished\n",
      "2018-09-02 03:48:14.519596 Test Step 1750 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:14.519640 Test Step 1750 \"loss\" =  7.337637\n",
      "2018-09-02 03:48:14.664435 Training Step 1750 Finished Timing (Training: 0.9201, Test: 0.0794232) after 0.810608 seconds\n",
      "2018-09-02 03:48:14.664491 Training Step 1750 \"min loss\" =  4.903375\n",
      "2018-09-02 03:48:14.664527 Training Step 1750 \"loss\" =  5.2127695\n",
      "2018-09-02 03:48:15.328276 Test Step 1755 Finished\n",
      "2018-09-02 03:48:15.328383 Test Step 1755 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:15.328431 Test Step 1755 \"loss\" =  7.3611255\n",
      "2018-09-02 03:48:15.479471 Training Step 1755 Finished Timing (Training: 0.920314, Test: 0.0792093) after 0.814902 seconds\n",
      "2018-09-02 03:48:15.479548 Training Step 1755 \"min loss\" =  4.903375\n",
      "2018-09-02 03:48:15.479589 Training Step 1755 \"loss\" =  5.124577\n",
      "2018-09-02 03:48:16.147922 Test Step 1760 Finished\n",
      "2018-09-02 03:48:16.148030 Test Step 1760 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:16.148073 Test Step 1760 \"loss\" =  7.3993063\n",
      "2018-09-02 03:48:16.302753 Training Step 1760 Finished Timing (Training: 0.920192, Test: 0.0793307) after 0.823111 seconds\n",
      "2018-09-02 03:48:16.302861 Training Step 1760 \"min loss\" =  4.903375\n",
      "2018-09-02 03:48:16.302957 Training Step 1760 \"loss\" =  5.1180553\n",
      "2018-09-02 03:48:16.977863 Test Step 1765 Finished\n",
      "2018-09-02 03:48:16.977989 Test Step 1765 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:16.978034 Test Step 1765 \"loss\" =  7.4459295\n",
      "2018-09-02 03:48:17.126966 Training Step 1765 Finished Timing (Training: 0.920082, Test: 0.0794265) after 0.823924 seconds\n",
      "2018-09-02 03:48:17.127027 Training Step 1765 \"min loss\" =  4.903375\n",
      "2018-09-02 03:48:17.127069 Training Step 1765 \"loss\" =  5.356625\n",
      "2018-09-02 03:48:17.801800 Test Step 1770 Finished\n",
      "2018-09-02 03:48:17.801895 Test Step 1770 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:17.801944 Test Step 1770 \"loss\" =  7.4445257\n",
      "2018-09-02 03:48:17.953435 Training Step 1770 Finished Timing (Training: 0.919979, Test: 0.0795275) after 0.826319 seconds\n",
      "2018-09-02 03:48:17.953511 Training Step 1770 \"min loss\" =  4.903375\n",
      "2018-09-02 03:48:17.953553 Training Step 1770 \"loss\" =  5.345976\n",
      "2018-09-02 03:48:18.621079 Test Step 1775 Finished\n",
      "2018-09-02 03:48:18.621179 Test Step 1775 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:18.621229 Test Step 1775 \"loss\" =  7.578396\n",
      "2018-09-02 03:48:18.766916 Training Step 1775 Finished Timing (Training: 0.920223, Test: 0.079279) after 0.813315 seconds\n",
      "2018-09-02 03:48:18.766975 Training Step 1775 \"min loss\" =  4.903375\n",
      "2018-09-02 03:48:18.767016 Training Step 1775 \"loss\" =  5.083186\n",
      "2018-09-02 03:48:19.431230 Test Step 1780 Finished\n",
      "2018-09-02 03:48:19.431335 Test Step 1780 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:19.431379 Test Step 1780 \"loss\" =  7.458627\n",
      "2018-09-02 03:48:19.583456 Training Step 1780 Finished Timing (Training: 0.920683, Test: 0.0788216) after 0.816394 seconds\n",
      "2018-09-02 03:48:19.583514 Training Step 1780 \"min loss\" =  4.751721\n",
      "2018-09-02 03:48:19.583554 Training Step 1780 \"loss\" =  5.7107263\n",
      "2018-09-02 03:48:20.260788 Test Step 1785 Finished\n",
      "2018-09-02 03:48:20.260893 Test Step 1785 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:20.260937 Test Step 1785 \"loss\" =  7.4376993\n",
      "2018-09-02 03:48:20.414123 Training Step 1785 Finished Timing (Training: 0.920459, Test: 0.0790486) after 0.830521 seconds\n",
      "2018-09-02 03:48:20.414182 Training Step 1785 \"min loss\" =  4.751721\n",
      "2018-09-02 03:48:20.414223 Training Step 1785 \"loss\" =  5.0948787\n",
      "2018-09-02 03:48:21.077577 Test Step 1790 Finished\n",
      "2018-09-02 03:48:21.077687 Test Step 1790 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:21.077747 Test Step 1790 \"loss\" =  7.4959908\n",
      "2018-09-02 03:48:21.234831 Training Step 1790 Finished Timing (Training: 0.920724, Test: 0.0787845) after 0.820557 seconds\n",
      "2018-09-02 03:48:21.235160 Training Step 1790 \"min loss\" =  4.751721\n",
      "2018-09-02 03:48:21.235513 Training Step 1790 \"loss\" =  5.0945153\n",
      "2018-09-02 03:48:21.901670 Test Step 1795 Finished\n",
      "2018-09-02 03:48:21.902177 Test Step 1795 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:21.902520 Test Step 1795 \"loss\" =  7.407874\n",
      "2018-09-02 03:48:22.055924 Training Step 1795 Finished Timing (Training: 0.920523, Test: 0.0788685) after 0.82006 seconds\n",
      "2018-09-02 03:48:22.056218 Training Step 1795 \"min loss\" =  4.751721\n",
      "2018-09-02 03:48:22.056538 Training Step 1795 \"loss\" =  5.113826\n",
      "2018-09-02 03:48:22.733854 Test Step 1800 Finished\n",
      "2018-09-02 03:48:22.733951 Test Step 1800 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:22.733997 Test Step 1800 \"loss\" =  7.6492352\n",
      "2018-09-02 03:48:22.888285 Training Step 1800 Finished Timing (Training: 0.920463, Test: 0.0788879) after 0.831432 seconds\n",
      "2018-09-02 03:48:22.888342 Training Step 1800 \"min loss\" =  4.751721\n",
      "2018-09-02 03:48:22.888378 Training Step 1800 \"loss\" =  5.222884\n",
      "2018-09-02 03:48:23.558167 Test Step 1805 Finished\n",
      "2018-09-02 03:48:23.558276 Test Step 1805 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:23.558317 Test Step 1805 \"loss\" =  7.7374077\n",
      "2018-09-02 03:48:23.710241 Training Step 1805 Finished Timing (Training: 0.922151, Test: 0.0775824) after 0.821821 seconds\n",
      "2018-09-02 03:48:23.710303 Training Step 1805 \"min loss\" =  4.751721\n",
      "2018-09-02 03:48:23.710339 Training Step 1805 \"loss\" =  5.285631\n",
      "2018-09-02 03:48:24.381615 Test Step 1810 Finished\n",
      "2018-09-02 03:48:24.381689 Test Step 1810 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:24.381727 Test Step 1810 \"loss\" =  8.149399\n",
      "2018-09-02 03:48:24.532756 Training Step 1810 Finished Timing (Training: 0.921608, Test: 0.0780673) after 0.822376 seconds\n",
      "2018-09-02 03:48:24.532812 Training Step 1810 \"min loss\" =  4.751721\n",
      "2018-09-02 03:48:24.532850 Training Step 1810 \"loss\" =  5.1029844\n",
      "2018-09-02 03:48:25.207557 Test Step 1815 Finished\n",
      "2018-09-02 03:48:25.207640 Test Step 1815 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:25.207680 Test Step 1815 \"loss\" =  7.3799\n",
      "2018-09-02 03:48:25.360994 Training Step 1815 Finished Timing (Training: 0.921206, Test: 0.0784475) after 0.828099 seconds\n",
      "2018-09-02 03:48:25.361054 Training Step 1815 \"min loss\" =  4.751721\n",
      "2018-09-02 03:48:25.361090 Training Step 1815 \"loss\" =  5.0226917\n",
      "2018-09-02 03:48:26.021095 Test Step 1820 Finished\n",
      "2018-09-02 03:48:26.021519 Test Step 1820 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:26.021773 Test Step 1820 \"loss\" =  7.7516327\n",
      "2018-09-02 03:48:26.173882 Training Step 1820 Finished Timing (Training: 0.921188, Test: 0.0782806) after 0.81275 seconds\n",
      "2018-09-02 03:48:26.174099 Training Step 1820 \"min loss\" =  4.751721\n",
      "2018-09-02 03:48:26.174138 Training Step 1820 \"loss\" =  5.595964\n",
      "2018-09-02 03:48:26.843238 Test Step 1825 Finished\n",
      "2018-09-02 03:48:26.843608 Test Step 1825 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:26.843896 Test Step 1825 \"loss\" =  7.4277287\n",
      "2018-09-02 03:48:26.988226 Training Step 1825 Finished Timing (Training: 0.919539, Test: 0.079725) after 0.814043 seconds\n",
      "2018-09-02 03:48:26.988546 Training Step 1825 \"min loss\" =  4.740283\n",
      "2018-09-02 03:48:26.988831 Training Step 1825 \"loss\" =  5.121856\n",
      "2018-09-02 03:48:27.657638 Test Step 1830 Finished\n",
      "2018-09-02 03:48:27.658144 Test Step 1830 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:27.658430 Test Step 1830 \"loss\" =  7.301337\n",
      "2018-09-02 03:48:27.810468 Training Step 1830 Finished Timing (Training: 0.919225, Test: 0.0797563) after 0.821353 seconds\n",
      "2018-09-02 03:48:27.810717 Training Step 1830 \"min loss\" =  4.624073\n",
      "2018-09-02 03:48:27.811004 Training Step 1830 \"loss\" =  5.3131404\n",
      "2018-09-02 03:48:28.474116 Test Step 1835 Finished\n",
      "2018-09-02 03:48:28.474462 Test Step 1835 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:28.474748 Test Step 1835 \"loss\" =  7.8247075\n",
      "2018-09-02 03:48:28.626267 Training Step 1835 Finished Timing (Training: 0.919867, Test: 0.0789506) after 0.814976 seconds\n",
      "2018-09-02 03:48:28.626515 Training Step 1835 \"min loss\" =  4.624073\n",
      "2018-09-02 03:48:28.626799 Training Step 1835 \"loss\" =  4.927976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:48:29.282661 Test Step 1840 Finished\n",
      "2018-09-02 03:48:29.283013 Test Step 1840 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:29.283301 Test Step 1840 \"loss\" =  7.1967173\n",
      "2018-09-02 03:48:29.434593 Training Step 1840 Finished Timing (Training: 0.919799, Test: 0.0788956) after 0.807504 seconds\n",
      "2018-09-02 03:48:29.434950 Training Step 1840 \"min loss\" =  4.624073\n",
      "2018-09-02 03:48:29.435240 Training Step 1840 \"loss\" =  4.879271\n",
      "2018-09-02 03:48:30.089690 Test Step 1845 Finished\n",
      "2018-09-02 03:48:30.090182 Test Step 1845 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:30.090471 Test Step 1845 \"loss\" =  7.3844337\n",
      "2018-09-02 03:48:30.241726 Training Step 1845 Finished Timing (Training: 0.919742, Test: 0.0788174) after 0.806202 seconds\n",
      "2018-09-02 03:48:30.241977 Training Step 1845 \"min loss\" =  4.624073\n",
      "2018-09-02 03:48:30.242263 Training Step 1845 \"loss\" =  5.1275992\n",
      "2018-09-02 03:48:30.904376 Test Step 1850 Finished\n",
      "2018-09-02 03:48:30.904819 Test Step 1850 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:30.905108 Test Step 1850 \"loss\" =  7.3000526\n",
      "2018-09-02 03:48:31.057698 Training Step 1850 Finished Timing (Training: 0.919535, Test: 0.0789343) after 0.81514 seconds\n",
      "2018-09-02 03:48:31.058010 Training Step 1850 \"min loss\" =  4.624073\n",
      "2018-09-02 03:48:31.058312 Training Step 1850 \"loss\" =  4.9910975\n",
      "2018-09-02 03:48:31.709165 Test Step 1855 Finished\n",
      "2018-09-02 03:48:31.709612 Test Step 1855 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:31.709899 Test Step 1855 \"loss\" =  7.3677893\n",
      "2018-09-02 03:48:31.863444 Training Step 1855 Finished Timing (Training: 0.919572, Test: 0.0788177) after 0.804846 seconds\n",
      "2018-09-02 03:48:31.863731 Training Step 1855 \"min loss\" =  4.624073\n",
      "2018-09-02 03:48:31.864015 Training Step 1855 \"loss\" =  5.1941853\n",
      "2018-09-02 03:48:32.517711 Test Step 1860 Finished\n",
      "2018-09-02 03:48:32.518129 Test Step 1860 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:32.518416 Test Step 1860 \"loss\" =  7.2806015\n",
      "2018-09-02 03:48:32.666830 Training Step 1860 Finished Timing (Training: 0.91979, Test: 0.0785373) after 0.80253 seconds\n",
      "2018-09-02 03:48:32.667080 Training Step 1860 \"min loss\" =  4.624073\n",
      "2018-09-02 03:48:32.667364 Training Step 1860 \"loss\" =  5.073948\n",
      "2018-09-02 03:48:33.323321 Test Step 1865 Finished\n",
      "2018-09-02 03:48:33.323675 Test Step 1865 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:33.323961 Test Step 1865 \"loss\" =  7.3201156\n",
      "2018-09-02 03:48:33.475912 Training Step 1865 Finished Timing (Training: 0.920328, Test: 0.0779605) after 0.808261 seconds\n",
      "2018-09-02 03:48:33.476205 Training Step 1865 \"min loss\" =  4.624073\n",
      "2018-09-02 03:48:33.476493 Training Step 1865 \"loss\" =  5.437145\n",
      "2018-09-02 03:48:34.130610 Test Step 1870 Finished\n",
      "2018-09-02 03:48:34.130994 Test Step 1870 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:34.131284 Test Step 1870 \"loss\" =  7.1667194\n",
      "2018-09-02 03:48:34.284971 Training Step 1870 Finished Timing (Training: 0.920777, Test: 0.0774696) after 0.80818 seconds\n",
      "2018-09-02 03:48:34.285390 Training Step 1870 \"min loss\" =  4.624073\n",
      "2018-09-02 03:48:34.285676 Training Step 1870 \"loss\" =  5.130269\n",
      "2018-09-02 03:48:34.941198 Test Step 1875 Finished\n",
      "2018-09-02 03:48:34.941669 Test Step 1875 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:34.941971 Test Step 1875 \"loss\" =  7.1696467\n",
      "2018-09-02 03:48:35.090197 Training Step 1875 Finished Timing (Training: 0.920641, Test: 0.077549) after 0.804235 seconds\n",
      "2018-09-02 03:48:35.090462 Training Step 1875 \"min loss\" =  4.624073\n",
      "2018-09-02 03:48:35.090755 Training Step 1875 \"loss\" =  5.1664386\n",
      "2018-09-02 03:48:35.751882 Test Step 1880 Finished\n",
      "2018-09-02 03:48:35.752276 Test Step 1880 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:35.752570 Test Step 1880 \"loss\" =  7.2551804\n",
      "2018-09-02 03:48:35.908224 Training Step 1880 Finished Timing (Training: 0.92101, Test: 0.0771524) after 0.817162 seconds\n",
      "2018-09-02 03:48:35.908547 Training Step 1880 \"min loss\" =  4.624073\n",
      "2018-09-02 03:48:35.908832 Training Step 1880 \"loss\" =  4.9747043\n",
      "2018-09-02 03:48:36.573827 Test Step 1885 Finished\n",
      "2018-09-02 03:48:36.574225 Test Step 1885 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:36.574514 Test Step 1885 \"loss\" =  7.358597\n",
      "2018-09-02 03:48:36.719522 Training Step 1885 Finished Timing (Training: 0.92088, Test: 0.0772523) after 0.810405 seconds\n",
      "2018-09-02 03:48:36.719778 Training Step 1885 \"min loss\" =  4.624073\n",
      "2018-09-02 03:48:36.720064 Training Step 1885 \"loss\" =  5.389411\n",
      "2018-09-02 03:48:37.387646 Test Step 1890 Finished\n",
      "2018-09-02 03:48:37.388092 Test Step 1890 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:37.388381 Test Step 1890 \"loss\" =  7.2129674\n",
      "2018-09-02 03:48:37.540810 Training Step 1890 Finished Timing (Training: 0.920877, Test: 0.0772309) after 0.820458 seconds\n",
      "2018-09-02 03:48:37.541081 Training Step 1890 \"min loss\" =  4.624073\n",
      "2018-09-02 03:48:37.541390 Training Step 1890 \"loss\" =  4.978322\n",
      "2018-09-02 03:48:38.196178 Test Step 1895 Finished\n",
      "2018-09-02 03:48:38.196619 Test Step 1895 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:38.196910 Test Step 1895 \"loss\" =  7.1965632\n",
      "2018-09-02 03:48:38.348291 Training Step 1895 Finished Timing (Training: 0.920867, Test: 0.0772156) after 0.806617 seconds\n",
      "2018-09-02 03:48:38.348591 Training Step 1895 \"min loss\" =  4.624073\n",
      "2018-09-02 03:48:38.348892 Training Step 1895 \"loss\" =  4.9363756\n",
      "2018-09-02 03:48:38.992229 Test Step 1900 Finished\n",
      "2018-09-02 03:48:38.992647 Test Step 1900 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:38.992934 Test Step 1900 \"loss\" =  7.3478622\n",
      "2018-09-02 03:48:39.143184 Training Step 1900 Finished Timing (Training: 0.920657, Test: 0.0774025) after 0.793996 seconds\n",
      "2018-09-02 03:48:39.143527 Training Step 1900 \"min loss\" =  4.624073\n",
      "2018-09-02 03:48:39.143811 Training Step 1900 \"loss\" =  5.044538\n",
      "2018-09-02 03:48:39.788202 Test Step 1905 Finished\n",
      "2018-09-02 03:48:39.788670 Test Step 1905 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:39.788959 Test Step 1905 \"loss\" =  7.2788815\n",
      "2018-09-02 03:48:39.936134 Training Step 1905 Finished Timing (Training: 0.918333, Test: 0.0803144) after 0.792037 seconds\n",
      "2018-09-02 03:48:39.936382 Training Step 1905 \"min loss\" =  4.5849\n",
      "2018-09-02 03:48:39.936666 Training Step 1905 \"loss\" =  5.05232\n",
      "2018-09-02 03:48:40.585636 Test Step 1910 Finished\n",
      "2018-09-02 03:48:40.586025 Test Step 1910 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:40.586310 Test Step 1910 \"loss\" =  7.3915315\n",
      "2018-09-02 03:48:40.739953 Training Step 1910 Finished Timing (Training: 0.917715, Test: 0.0804634) after 0.802995 seconds\n",
      "2018-09-02 03:48:40.740233 Training Step 1910 \"min loss\" =  4.5849\n",
      "2018-09-02 03:48:40.740521 Training Step 1910 \"loss\" =  4.9000344\n",
      "2018-09-02 03:48:41.403532 Test Step 1915 Finished\n",
      "2018-09-02 03:48:41.403975 Test Step 1915 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:41.404272 Test Step 1915 \"loss\" =  7.22457\n",
      "2018-09-02 03:48:41.551175 Training Step 1915 Finished Timing (Training: 0.918957, Test: 0.0790297) after 0.810364 seconds\n",
      "2018-09-02 03:48:41.551454 Training Step 1915 \"min loss\" =  4.5849\n",
      "2018-09-02 03:48:41.551741 Training Step 1915 \"loss\" =  5.1176763\n",
      "2018-09-02 03:48:42.209125 Test Step 1920 Finished\n",
      "2018-09-02 03:48:42.209599 Test Step 1920 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:42.209890 Test Step 1920 \"loss\" =  7.279854\n",
      "2018-09-02 03:48:42.356341 Training Step 1920 Finished Timing (Training: 0.919345, Test: 0.078544) after 0.804314 seconds\n",
      "2018-09-02 03:48:42.356619 Training Step 1920 \"min loss\" =  4.5849\n",
      "2018-09-02 03:48:42.356933 Training Step 1920 \"loss\" =  4.922149\n",
      "2018-09-02 03:48:43.006699 Test Step 1925 Finished\n",
      "2018-09-02 03:48:43.006806 Test Step 1925 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:43.006849 Test Step 1925 \"loss\" =  7.96261\n",
      "2018-09-02 03:48:43.155505 Training Step 1925 Finished Timing (Training: 0.919238, Test: 0.0787964) after 0.798279 seconds\n",
      "2018-09-02 03:48:43.155562 Training Step 1925 \"min loss\" =  4.5849\n",
      "2018-09-02 03:48:43.155598 Training Step 1925 \"loss\" =  5.2379317\n",
      "2018-09-02 03:48:43.815891 Test Step 1930 Finished\n",
      "2018-09-02 03:48:43.815974 Test Step 1930 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:43.816015 Test Step 1930 \"loss\" =  7.6936316\n",
      "2018-09-02 03:48:43.965947 Training Step 1930 Finished Timing (Training: 0.920273, Test: 0.0780238) after 0.810307 seconds\n",
      "2018-09-02 03:48:43.966001 Training Step 1930 \"min loss\" =  4.5849\n",
      "2018-09-02 03:48:43.966037 Training Step 1930 \"loss\" =  4.6930943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:48:44.627873 Test Step 1935 Finished\n",
      "2018-09-02 03:48:44.627950 Test Step 1935 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:44.627991 Test Step 1935 \"loss\" =  7.4573135\n",
      "2018-09-02 03:48:44.778408 Training Step 1935 Finished Timing (Training: 0.920561, Test: 0.0779226) after 0.812319 seconds\n",
      "2018-09-02 03:48:44.778520 Training Step 1935 \"min loss\" =  4.5849\n",
      "2018-09-02 03:48:44.778564 Training Step 1935 \"loss\" =  4.91656\n",
      "2018-09-02 03:48:45.434684 Test Step 1940 Finished\n",
      "2018-09-02 03:48:45.434784 Test Step 1940 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:45.434828 Test Step 1940 \"loss\" =  7.6131907\n",
      "2018-09-02 03:48:45.583419 Training Step 1940 Finished Timing (Training: 0.920564, Test: 0.0780439) after 0.804811 seconds\n",
      "2018-09-02 03:48:45.583473 Training Step 1940 \"min loss\" =  4.5849\n",
      "2018-09-02 03:48:45.583509 Training Step 1940 \"loss\" =  4.9879174\n",
      "2018-09-02 03:48:46.236514 Test Step 1945 Finished\n",
      "2018-09-02 03:48:46.236620 Test Step 1945 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:46.236663 Test Step 1945 \"loss\" =  7.5479183\n",
      "2018-09-02 03:48:46.380193 Training Step 1945 Finished Timing (Training: 0.920562, Test: 0.0781505) after 0.79664 seconds\n",
      "2018-09-02 03:48:46.380247 Training Step 1945 \"min loss\" =  4.510655\n",
      "2018-09-02 03:48:46.380283 Training Step 1945 \"loss\" =  5.4479904\n",
      "2018-09-02 03:48:47.036051 Test Step 1950 Finished\n",
      "2018-09-02 03:48:47.036167 Test Step 1950 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:47.036211 Test Step 1950 \"loss\" =  7.766358\n",
      "2018-09-02 03:48:47.187036 Training Step 1950 Finished Timing (Training: 0.9211, Test: 0.0776956) after 0.806709 seconds\n",
      "2018-09-02 03:48:47.187107 Training Step 1950 \"min loss\" =  4.510655\n",
      "2018-09-02 03:48:47.187143 Training Step 1950 \"loss\" =  5.053891\n",
      "2018-09-02 03:48:47.838966 Test Step 1955 Finished\n",
      "2018-09-02 03:48:47.839418 Test Step 1955 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:47.839705 Test Step 1955 \"loss\" =  7.245718\n",
      "2018-09-02 03:48:47.979497 Training Step 1955 Finished Timing (Training: 0.920891, Test: 0.0778758) after 0.792303 seconds\n",
      "2018-09-02 03:48:47.979870 Training Step 1955 \"min loss\" =  4.404591\n",
      "2018-09-02 03:48:47.980169 Training Step 1955 \"loss\" =  4.404591\n",
      "2018-09-02 03:48:48.635259 Test Step 1960 Finished\n",
      "2018-09-02 03:48:48.635638 Test Step 1960 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:48.635926 Test Step 1960 \"loss\" =  7.289832\n",
      "2018-09-02 03:48:48.778802 Training Step 1960 Finished Timing (Training: 0.92086, Test: 0.0778063) after 0.798328 seconds\n",
      "2018-09-02 03:48:48.779125 Training Step 1960 \"min loss\" =  4.404591\n",
      "2018-09-02 03:48:48.779411 Training Step 1960 \"loss\" =  4.8332634\n",
      "2018-09-02 03:48:49.439521 Test Step 1965 Finished\n",
      "2018-09-02 03:48:49.439917 Test Step 1965 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:49.440237 Test Step 1965 \"loss\" =  7.2119474\n",
      "2018-09-02 03:48:49.590812 Training Step 1965 Finished Timing (Training: 0.920488, Test: 0.0780942) after 0.811116 seconds\n",
      "2018-09-02 03:48:49.591064 Training Step 1965 \"min loss\" =  4.404591\n",
      "2018-09-02 03:48:49.591349 Training Step 1965 \"loss\" =  4.960131\n",
      "2018-09-02 03:48:50.259660 Test Step 1970 Finished\n",
      "2018-09-02 03:48:50.260216 Test Step 1970 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:50.260514 Test Step 1970 \"loss\" =  7.4597354\n",
      "2018-09-02 03:48:50.414191 Training Step 1970 Finished Timing (Training: 0.920252, Test: 0.0782554) after 0.822546 seconds\n",
      "2018-09-02 03:48:50.414517 Training Step 1970 \"min loss\" =  4.404591\n",
      "2018-09-02 03:48:50.414804 Training Step 1970 \"loss\" =  5.109115\n",
      "2018-09-02 03:48:51.068330 Test Step 1975 Finished\n",
      "2018-09-02 03:48:51.068814 Test Step 1975 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:51.069104 Test Step 1975 \"loss\" =  7.4614263\n",
      "2018-09-02 03:48:51.213580 Training Step 1975 Finished Timing (Training: 0.920253, Test: 0.078185) after 0.798487 seconds\n",
      "2018-09-02 03:48:51.213841 Training Step 1975 \"min loss\" =  4.404591\n",
      "2018-09-02 03:48:51.214136 Training Step 1975 \"loss\" =  5.0069313\n",
      "2018-09-02 03:48:51.880216 Test Step 1980 Finished\n",
      "2018-09-02 03:48:51.880651 Test Step 1980 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:51.880941 Test Step 1980 \"loss\" =  7.329766\n",
      "2018-09-02 03:48:52.032163 Training Step 1980 Finished Timing (Training: 0.920165, Test: 0.0782255) after 0.817732 seconds\n",
      "2018-09-02 03:48:52.032505 Training Step 1980 \"min loss\" =  4.404591\n",
      "2018-09-02 03:48:52.032797 Training Step 1980 \"loss\" =  4.9762735\n",
      "2018-09-02 03:48:52.684258 Test Step 1985 Finished\n",
      "2018-09-02 03:48:52.684709 Test Step 1985 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:52.684996 Test Step 1985 \"loss\" =  7.352443\n",
      "2018-09-02 03:48:52.834489 Training Step 1985 Finished Timing (Training: 0.920233, Test: 0.0781067) after 0.801393 seconds\n",
      "2018-09-02 03:48:52.834875 Training Step 1985 \"min loss\" =  4.404591\n",
      "2018-09-02 03:48:52.835161 Training Step 1985 \"loss\" =  4.79971\n",
      "2018-09-02 03:48:53.481740 Test Step 1990 Finished\n",
      "2018-09-02 03:48:53.482150 Test Step 1990 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:53.482482 Test Step 1990 \"loss\" =  7.171073\n",
      "2018-09-02 03:48:53.633932 Training Step 1990 Finished Timing (Training: 0.920443, Test: 0.0778464) after 0.798483 seconds\n",
      "2018-09-02 03:48:53.634199 Training Step 1990 \"min loss\" =  4.404591\n",
      "2018-09-02 03:48:53.634497 Training Step 1990 \"loss\" =  5.0775805\n",
      "2018-09-02 03:48:54.306503 Test Step 1995 Finished\n",
      "2018-09-02 03:48:54.306911 Test Step 1995 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:54.307200 Test Step 1995 \"loss\" =  7.535991\n",
      "2018-09-02 03:48:54.457598 Training Step 1995 Finished Timing (Training: 0.920521, Test: 0.0777372) after 0.822779 seconds\n",
      "2018-09-02 03:48:54.457853 Training Step 1995 \"min loss\" =  4.3553014\n",
      "2018-09-02 03:48:54.458139 Training Step 1995 \"loss\" =  4.3553014\n",
      "2018-09-02 03:48:55.111564 Test Step 2000 Finished\n",
      "2018-09-02 03:48:55.112006 Test Step 2000 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:55.112296 Test Step 2000 \"loss\" =  7.3883204\n",
      "2018-09-02 03:48:55.264665 Training Step 2000 Finished Timing (Training: 0.920386, Test: 0.0778418) after 0.806228 seconds\n",
      "2018-09-02 03:48:55.265034 Training Step 2000 \"min loss\" =  4.3553014\n",
      "2018-09-02 03:48:55.265344 Training Step 2000 \"loss\" =  4.5814786\n",
      "2018-09-02 03:48:55.915731 Test Step 2005 Finished\n",
      "2018-09-02 03:48:55.916047 Test Step 2005 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:55.916334 Test Step 2005 \"loss\" =  7.1826386\n",
      "2018-09-02 03:48:56.067366 Training Step 2005 Finished Timing (Training: 0.922085, Test: 0.0767831) after 0.801728 seconds\n",
      "2018-09-02 03:48:56.067676 Training Step 2005 \"min loss\" =  4.3553014\n",
      "2018-09-02 03:48:56.067961 Training Step 2005 \"loss\" =  5.5550113\n",
      "2018-09-02 03:48:56.721217 Test Step 2010 Finished\n",
      "2018-09-02 03:48:56.721575 Test Step 2010 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:56.721863 Test Step 2010 \"loss\" =  7.3636866\n",
      "2018-09-02 03:48:56.874670 Training Step 2010 Finished Timing (Training: 0.922887, Test: 0.0754044) after 0.806424 seconds\n",
      "2018-09-02 03:48:56.874919 Training Step 2010 \"min loss\" =  4.3553014\n",
      "2018-09-02 03:48:56.875204 Training Step 2010 \"loss\" =  4.792996\n",
      "2018-09-02 03:48:57.533490 Test Step 2015 Finished\n",
      "2018-09-02 03:48:57.533952 Test Step 2015 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:57.534250 Test Step 2015 \"loss\" =  7.3861995\n",
      "2018-09-02 03:48:57.687439 Training Step 2015 Finished Timing (Training: 0.921655, Test: 0.0764292) after 0.811948 seconds\n",
      "2018-09-02 03:48:57.687690 Training Step 2015 \"min loss\" =  4.3553014\n",
      "2018-09-02 03:48:57.687976 Training Step 2015 \"loss\" =  5.0677834\n",
      "2018-09-02 03:48:58.353193 Test Step 2020 Finished\n",
      "2018-09-02 03:48:58.353581 Test Step 2020 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:58.353869 Test Step 2020 \"loss\" =  7.187235\n",
      "2018-09-02 03:48:58.509393 Training Step 2020 Finished Timing (Training: 0.921703, Test: 0.07631) after 0.821132 seconds\n",
      "2018-09-02 03:48:58.509643 Training Step 2020 \"min loss\" =  4.3553014\n",
      "2018-09-02 03:48:58.509928 Training Step 2020 \"loss\" =  4.7856607\n",
      "2018-09-02 03:48:59.145948 Test Step 2025 Finished\n",
      "2018-09-02 03:48:59.146397 Test Step 2025 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:59.146684 Test Step 2025 \"loss\" =  7.800799\n",
      "2018-09-02 03:48:59.302163 Training Step 2025 Finished Timing (Training: 0.920507, Test: 0.0774287) after 0.791931 seconds\n",
      "2018-09-02 03:48:59.302428 Training Step 2025 \"min loss\" =  4.3553014\n",
      "2018-09-02 03:48:59.302717 Training Step 2025 \"loss\" =  4.6483145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:48:59.962276 Test Step 2030 Finished\n",
      "2018-09-02 03:48:59.962771 Test Step 2030 \"min loss\" =  7.124336\n",
      "2018-09-02 03:48:59.963091 Test Step 2030 \"loss\" =  7.574427\n",
      "2018-09-02 03:49:00.114409 Training Step 2030 Finished Timing (Training: 0.919638, Test: 0.0782305) after 0.811401 seconds\n",
      "2018-09-02 03:49:00.114746 Training Step 2030 \"min loss\" =  4.3553014\n",
      "2018-09-02 03:49:00.115031 Training Step 2030 \"loss\" =  4.898402\n",
      "2018-09-02 03:49:00.783431 Test Step 2035 Finished\n",
      "2018-09-02 03:49:00.783878 Test Step 2035 \"min loss\" =  7.124336\n",
      "2018-09-02 03:49:00.784168 Test Step 2035 \"loss\" =  7.5669527\n",
      "2018-09-02 03:49:00.933547 Training Step 2035 Finished Timing (Training: 0.919369, Test: 0.0784611) after 0.818233 seconds\n",
      "2018-09-02 03:49:00.933796 Training Step 2035 \"min loss\" =  4.3553014\n",
      "2018-09-02 03:49:00.934079 Training Step 2035 \"loss\" =  4.7032895\n",
      "2018-09-02 03:49:01.598845 Test Step 2040 Finished\n",
      "2018-09-02 03:49:01.599182 Test Step 2040 \"min loss\" =  7.124336\n",
      "2018-09-02 03:49:01.599468 Test Step 2040 \"loss\" =  7.1353354\n",
      "2018-09-02 03:49:01.751595 Training Step 2040 Finished Timing (Training: 0.919513, Test: 0.0783212) after 0.817233 seconds\n",
      "2018-09-02 03:49:01.751849 Training Step 2040 \"min loss\" =  4.3553014\n",
      "2018-09-02 03:49:01.752135 Training Step 2040 \"loss\" =  4.722493\n",
      "2018-09-02 03:49:02.394115 Test Step 2045 Finished\n",
      "2018-09-02 03:49:02.394563 Test Step 2045 \"min loss\" =  7.124336\n",
      "2018-09-02 03:49:02.394855 Test Step 2045 \"loss\" =  7.251006\n",
      "2018-09-02 03:49:02.546180 Training Step 2045 Finished Timing (Training: 0.919686, Test: 0.0781243) after 0.793739 seconds\n",
      "2018-09-02 03:49:02.546560 Training Step 2045 \"min loss\" =  4.3553014\n",
      "2018-09-02 03:49:02.546847 Training Step 2045 \"loss\" =  4.876472\n",
      "2018-09-02 03:49:03.205186 Test Step 2050 Finished\n",
      "2018-09-02 03:49:03.205723 Test Step 2050 \"min loss\" =  7.124336\n",
      "2018-09-02 03:49:03.206015 Test Step 2050 \"loss\" =  7.20037\n",
      "2018-09-02 03:49:03.359546 Training Step 2050 Finished Timing (Training: 0.920071, Test: 0.0776929) after 0.812408 seconds\n",
      "2018-09-02 03:49:03.359816 Training Step 2050 \"min loss\" =  4.3553014\n",
      "2018-09-02 03:49:03.360120 Training Step 2050 \"loss\" =  4.7727566\n",
      "2018-09-02 03:49:04.024851 Test Step 2055 Finished\n",
      "2018-09-02 03:49:04.025194 Test Step 2055 \"min loss\" =  7.124336\n",
      "2018-09-02 03:49:04.025510 Test Step 2055 \"loss\" =  7.182951\n",
      "2018-09-02 03:49:04.170581 Training Step 2055 Finished Timing (Training: 0.919593, Test: 0.0781671) after 0.810168 seconds\n",
      "2018-09-02 03:49:04.170865 Training Step 2055 \"min loss\" =  4.3553014\n",
      "2018-09-02 03:49:04.171147 Training Step 2055 \"loss\" =  5.025009\n",
      "2018-09-02 03:49:04.840196 Test Step 2060 Finished\n",
      "2018-09-02 03:49:04.840641 Test Step 2060 \"min loss\" =  7.1077833\n",
      "2018-09-02 03:49:04.840945 Test Step 2060 \"loss\" =  7.1077833\n",
      "2018-09-02 03:49:04.985139 Training Step 2060 Finished Timing (Training: 0.919132, Test: 0.0786188) after 0.813705 seconds\n",
      "2018-09-02 03:49:04.985448 Training Step 2060 \"min loss\" =  4.3553014\n",
      "2018-09-02 03:49:04.985739 Training Step 2060 \"loss\" =  4.540106\n",
      "2018-09-02 03:49:05.652407 Test Step 2065 Finished\n",
      "2018-09-02 03:49:05.652871 Test Step 2065 \"min loss\" =  7.1077833\n",
      "2018-09-02 03:49:05.653163 Test Step 2065 \"loss\" =  7.26876\n",
      "2018-09-02 03:49:05.800618 Training Step 2065 Finished Timing (Training: 0.918994, Test: 0.078742) after 0.814591 seconds\n",
      "2018-09-02 03:49:05.800880 Training Step 2065 \"min loss\" =  4.3553014\n",
      "2018-09-02 03:49:05.801203 Training Step 2065 \"loss\" =  4.8113303\n",
      "2018-09-02 03:49:06.462137 Test Step 2070 Finished\n",
      "2018-09-02 03:49:06.462604 Test Step 2070 \"min loss\" =  7.1077833\n",
      "2018-09-02 03:49:06.462902 Test Step 2070 \"loss\" =  7.4070354\n",
      "2018-09-02 03:49:06.610554 Training Step 2070 Finished Timing (Training: 0.919108, Test: 0.0786125) after 0.80902 seconds\n",
      "2018-09-02 03:49:06.610806 Training Step 2070 \"min loss\" =  4.3553014\n",
      "2018-09-02 03:49:06.611091 Training Step 2070 \"loss\" =  4.560468\n",
      "2018-09-02 03:49:07.284222 Test Step 2075 Finished\n",
      "2018-09-02 03:49:07.284697 Test Step 2075 \"min loss\" =  7.1077833\n",
      "2018-09-02 03:49:07.285012 Test Step 2075 \"loss\" =  7.5520883\n",
      "2018-09-02 03:49:07.438157 Training Step 2075 Finished Timing (Training: 0.919143, Test: 0.0785682) after 0.82677 seconds\n",
      "2018-09-02 03:49:07.438510 Training Step 2075 \"min loss\" =  4.3553014\n",
      "2018-09-02 03:49:07.438854 Training Step 2075 \"loss\" =  4.8030615\n",
      "2018-09-02 03:49:08.103118 Test Step 2080 Finished\n",
      "2018-09-02 03:49:08.103553 Test Step 2080 \"min loss\" =  7.1077833\n",
      "2018-09-02 03:49:08.103840 Test Step 2080 \"loss\" =  7.330147\n",
      "2018-09-02 03:49:08.261573 Training Step 2080 Finished Timing (Training: 0.919157, Test: 0.0785416) after 0.822415 seconds\n",
      "2018-09-02 03:49:08.261980 Training Step 2080 \"min loss\" =  4.3553014\n",
      "2018-09-02 03:49:08.262268 Training Step 2080 \"loss\" =  4.8552027\n",
      "2018-09-02 03:49:08.937079 Test Step 2085 Finished\n",
      "2018-09-02 03:49:08.937488 Test Step 2085 \"min loss\" =  7.1077833\n",
      "2018-09-02 03:49:08.937775 Test Step 2085 \"loss\" =  7.658295\n",
      "2018-09-02 03:49:09.091927 Training Step 2085 Finished Timing (Training: 0.918981, Test: 0.0787111) after 0.829366 seconds\n",
      "2018-09-02 03:49:09.092213 Training Step 2085 \"min loss\" =  4.3553014\n",
      "2018-09-02 03:49:09.092501 Training Step 2085 \"loss\" =  4.688447\n",
      "2018-09-02 03:49:09.755701 Test Step 2090 Finished\n",
      "2018-09-02 03:49:09.756125 Test Step 2090 \"min loss\" =  7.1077833\n",
      "2018-09-02 03:49:09.756428 Test Step 2090 \"loss\" =  7.360951\n",
      "2018-09-02 03:49:09.903969 Training Step 2090 Finished Timing (Training: 0.918847, Test: 0.0788426) after 0.811177 seconds\n",
      "2018-09-02 03:49:09.904264 Training Step 2090 \"min loss\" =  4.2683353\n",
      "2018-09-02 03:49:09.904550 Training Step 2090 \"loss\" =  4.670164\n",
      "2018-09-02 03:49:10.566094 Test Step 2095 Finished\n",
      "2018-09-02 03:49:10.566552 Test Step 2095 \"min loss\" =  7.1077833\n",
      "2018-09-02 03:49:10.566846 Test Step 2095 \"loss\" =  7.204533\n",
      "2018-09-02 03:49:10.716526 Training Step 2095 Finished Timing (Training: 0.918687, Test: 0.0789979) after 0.811681 seconds\n",
      "2018-09-02 03:49:10.716960 Training Step 2095 \"min loss\" =  4.2683353\n",
      "2018-09-02 03:49:10.717484 Training Step 2095 \"loss\" =  4.6256695\n",
      "2018-09-02 03:49:11.384616 Test Step 2100 Finished\n",
      "2018-09-02 03:49:11.385070 Test Step 2100 \"min loss\" =  7.1077833\n",
      "2018-09-02 03:49:11.385387 Test Step 2100 \"loss\" =  7.423808\n",
      "2018-09-02 03:49:11.538678 Training Step 2100 Finished Timing (Training: 0.918586, Test: 0.0790165) after 0.820708 seconds\n",
      "2018-09-02 03:49:11.538930 Training Step 2100 \"min loss\" =  4.2683353\n",
      "2018-09-02 03:49:11.539215 Training Step 2100 \"loss\" =  4.551536\n",
      "2018-09-02 03:49:12.198916 Test Step 2105 Finished\n",
      "2018-09-02 03:49:12.199401 Test Step 2105 \"min loss\" =  7.1077833\n",
      "2018-09-02 03:49:12.199695 Test Step 2105 \"loss\" =  7.3934917\n",
      "2018-09-02 03:49:12.349166 Training Step 2105 Finished Timing (Training: 0.918933, Test: 0.0797147) after 0.809663 seconds\n",
      "2018-09-02 03:49:12.349446 Training Step 2105 \"min loss\" =  4.2683353\n",
      "2018-09-02 03:49:12.349731 Training Step 2105 \"loss\" =  4.6518145\n",
      "2018-09-02 03:49:13.022020 Test Step 2110 Finished\n",
      "2018-09-02 03:49:13.022427 Test Step 2110 \"min loss\" =  7.1077833\n",
      "2018-09-02 03:49:13.022714 Test Step 2110 \"loss\" =  7.7734947\n",
      "2018-09-02 03:49:13.177960 Training Step 2110 Finished Timing (Training: 0.918916, Test: 0.0792845) after 0.827935 seconds\n",
      "2018-09-02 03:49:13.178248 Training Step 2110 \"min loss\" =  4.2683353\n",
      "2018-09-02 03:49:13.178535 Training Step 2110 \"loss\" =  4.7889104\n",
      "2018-09-02 03:49:13.835872 Test Step 2115 Finished\n",
      "2018-09-02 03:49:13.836275 Test Step 2115 \"min loss\" =  7.1077833\n",
      "2018-09-02 03:49:13.836562 Test Step 2115 \"loss\" =  7.1899266\n",
      "2018-09-02 03:49:13.990552 Training Step 2115 Finished Timing (Training: 0.919424, Test: 0.0786101) after 0.81173 seconds\n",
      "2018-09-02 03:49:13.990830 Training Step 2115 \"min loss\" =  4.2683353\n",
      "2018-09-02 03:49:13.991111 Training Step 2115 \"loss\" =  4.699385\n",
      "2018-09-02 03:49:14.652314 Test Step 2120 Finished\n",
      "2018-09-02 03:49:14.652739 Test Step 2120 \"min loss\" =  7.1077833\n",
      "2018-09-02 03:49:14.653020 Test Step 2120 \"loss\" =  7.4442296\n",
      "2018-09-02 03:49:14.806464 Training Step 2120 Finished Timing (Training: 0.920102, Test: 0.0778428) after 0.815046 seconds\n",
      "2018-09-02 03:49:14.806735 Training Step 2120 \"min loss\" =  4.2683353\n",
      "2018-09-02 03:49:14.807021 Training Step 2120 \"loss\" =  4.7116613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:49:15.472878 Test Step 2125 Finished\n",
      "2018-09-02 03:49:15.473342 Test Step 2125 \"min loss\" =  7.1077833\n",
      "2018-09-02 03:49:15.473634 Test Step 2125 \"loss\" =  7.709696\n",
      "2018-09-02 03:49:15.622573 Training Step 2125 Finished Timing (Training: 0.919729, Test: 0.0781571) after 0.815265 seconds\n",
      "2018-09-02 03:49:15.622826 Training Step 2125 \"min loss\" =  4.2683353\n",
      "2018-09-02 03:49:15.623130 Training Step 2125 \"loss\" =  4.7273383\n",
      "2018-09-02 03:49:16.278724 Test Step 2130 Finished\n",
      "2018-09-02 03:49:16.279194 Test Step 2130 \"min loss\" =  7.1077833\n",
      "2018-09-02 03:49:16.279486 Test Step 2130 \"loss\" =  7.1867504\n",
      "2018-09-02 03:49:16.437386 Training Step 2130 Finished Timing (Training: 0.919437, Test: 0.0784019) after 0.813936 seconds\n",
      "2018-09-02 03:49:16.437688 Training Step 2130 \"min loss\" =  4.2683353\n",
      "2018-09-02 03:49:16.437991 Training Step 2130 \"loss\" =  4.4563594\n",
      "2018-09-02 03:49:17.092632 Test Step 2135 Finished\n",
      "2018-09-02 03:49:17.093061 Test Step 2135 \"min loss\" =  7.1077833\n",
      "2018-09-02 03:49:17.093396 Test Step 2135 \"loss\" =  7.671968\n",
      "2018-09-02 03:49:17.245548 Training Step 2135 Finished Timing (Training: 0.919465, Test: 0.0783335) after 0.807269 seconds\n",
      "2018-09-02 03:49:17.245800 Training Step 2135 \"min loss\" =  4.2683353\n",
      "2018-09-02 03:49:17.246086 Training Step 2135 \"loss\" =  4.670946\n",
      "2018-09-02 03:49:17.901932 Test Step 2140 Finished\n",
      "2018-09-02 03:49:17.902359 Test Step 2140 \"min loss\" =  7.1077833\n",
      "2018-09-02 03:49:17.902651 Test Step 2140 \"loss\" =  7.344544\n",
      "2018-09-02 03:49:18.051661 Training Step 2140 Finished Timing (Training: 0.920132, Test: 0.0776543) after 0.80528 seconds\n",
      "2018-09-02 03:49:18.051939 Training Step 2140 \"min loss\" =  4.2683353\n",
      "2018-09-02 03:49:18.052226 Training Step 2140 \"loss\" =  4.4170933\n",
      "2018-09-02 03:49:18.712796 Test Step 2145 Finished\n",
      "2018-09-02 03:49:18.713171 Test Step 2145 \"min loss\" =  7.1077833\n",
      "2018-09-02 03:49:18.713481 Test Step 2145 \"loss\" =  7.2982287\n",
      "2018-09-02 03:49:18.867504 Training Step 2145 Finished Timing (Training: 0.920629, Test: 0.0771494) after 0.814984 seconds\n",
      "2018-09-02 03:49:18.867759 Training Step 2145 \"min loss\" =  4.2164354\n",
      "2018-09-02 03:49:18.868046 Training Step 2145 \"loss\" =  4.791215\n",
      "2018-09-02 03:49:19.536438 Test Step 2150 Finished\n",
      "2018-09-02 03:49:19.536837 Test Step 2150 \"min loss\" =  7.1077833\n",
      "2018-09-02 03:49:19.537125 Test Step 2150 \"loss\" =  7.193775\n",
      "2018-09-02 03:49:19.687222 Training Step 2150 Finished Timing (Training: 0.920389, Test: 0.0773845) after 0.818888 seconds\n",
      "2018-09-02 03:49:19.687476 Training Step 2150 \"min loss\" =  4.2164354\n",
      "2018-09-02 03:49:19.687764 Training Step 2150 \"loss\" =  4.647601\n",
      "2018-09-02 03:49:20.344551 Test Step 2155 Finished\n",
      "2018-09-02 03:49:20.345001 Test Step 2155 \"min loss\" =  7.1077833\n",
      "2018-09-02 03:49:20.345307 Test Step 2155 \"loss\" =  7.537343\n",
      "2018-09-02 03:49:20.494979 Training Step 2155 Finished Timing (Training: 0.919946, Test: 0.0778139) after 0.80692 seconds\n",
      "2018-09-02 03:49:20.495313 Training Step 2155 \"min loss\" =  4.2164354\n",
      "2018-09-02 03:49:20.495599 Training Step 2155 \"loss\" =  4.5882015\n",
      "2018-09-02 03:49:21.155758 Test Step 2160 Finished\n",
      "2018-09-02 03:49:21.156199 Test Step 2160 \"min loss\" =  7.1077833\n",
      "2018-09-02 03:49:21.156492 Test Step 2160 \"loss\" =  7.2117877\n",
      "2018-09-02 03:49:21.300465 Training Step 2160 Finished Timing (Training: 0.919671, Test: 0.0780733) after 0.804582 seconds\n",
      "2018-09-02 03:49:21.300741 Training Step 2160 \"min loss\" =  4.2164354\n",
      "2018-09-02 03:49:21.301028 Training Step 2160 \"loss\" =  4.4022317\n",
      "2018-09-02 03:49:21.965191 Test Step 2165 Finished\n",
      "2018-09-02 03:49:21.965683 Test Step 2165 \"min loss\" =  7.1077833\n",
      "2018-09-02 03:49:21.966002 Test Step 2165 \"loss\" =  7.1436715\n",
      "2018-09-02 03:49:22.117956 Training Step 2165 Finished Timing (Training: 0.919606, Test: 0.0781205) after 0.816591 seconds\n",
      "2018-09-02 03:49:22.118364 Training Step 2165 \"min loss\" =  4.2164354\n",
      "2018-09-02 03:49:22.118664 Training Step 2165 \"loss\" =  4.2673903\n",
      "2018-09-02 03:49:22.787073 Test Step 2170 Finished\n",
      "2018-09-02 03:49:22.787520 Test Step 2170 \"min loss\" =  7.1077833\n",
      "2018-09-02 03:49:22.787813 Test Step 2170 \"loss\" =  7.138216\n",
      "2018-09-02 03:49:22.932044 Training Step 2170 Finished Timing (Training: 0.919107, Test: 0.0785984) after 0.813091 seconds\n",
      "2018-09-02 03:49:22.932321 Training Step 2170 \"min loss\" =  4.2164354\n",
      "2018-09-02 03:49:22.932610 Training Step 2170 \"loss\" =  4.7848773\n",
      "2018-09-02 03:49:23.612093 Test Step 2175 Finished\n",
      "2018-09-02 03:49:23.612538 Test Step 2175 \"min loss\" =  7.1077833\n",
      "2018-09-02 03:49:23.612852 Test Step 2175 \"loss\" =  7.267731\n",
      "2018-09-02 03:49:23.764629 Training Step 2175 Finished Timing (Training: 0.919106, Test: 0.0785934) after 0.831705 seconds\n",
      "2018-09-02 03:49:23.764925 Training Step 2175 \"min loss\" =  4.2164354\n",
      "2018-09-02 03:49:23.765209 Training Step 2175 \"loss\" =  4.658238\n",
      "2018-09-02 03:49:24.430743 Test Step 2180 Finished\n",
      "2018-09-02 03:49:24.431117 Test Step 2180 \"min loss\" =  7.1077833\n",
      "2018-09-02 03:49:24.431403 Test Step 2180 \"loss\" =  7.117501\n",
      "2018-09-02 03:49:24.586237 Training Step 2180 Finished Timing (Training: 0.918948, Test: 0.078753) after 0.820713 seconds\n",
      "2018-09-02 03:49:24.586512 Training Step 2180 \"min loss\" =  4.2164354\n",
      "2018-09-02 03:49:24.586792 Training Step 2180 \"loss\" =  4.563493\n",
      "2018-09-02 03:49:25.257298 Test Step 2185 Finished\n",
      "2018-09-02 03:49:25.257396 Test Step 2185 \"min loss\" =  7.053979\n",
      "2018-09-02 03:49:25.257441 Test Step 2185 \"loss\" =  7.053979\n",
      "2018-09-02 03:49:25.407166 Training Step 2185 Finished Timing (Training: 0.919221, Test: 0.0785365) after 0.820089 seconds\n",
      "2018-09-02 03:49:25.407231 Training Step 2185 \"min loss\" =  4.2164354\n",
      "2018-09-02 03:49:25.407270 Training Step 2185 \"loss\" =  4.5096354\n",
      "2018-09-02 03:49:26.088719 Test Step 2190 Finished\n",
      "2018-09-02 03:49:26.088820 Test Step 2190 \"min loss\" =  7.053979\n",
      "2018-09-02 03:49:26.088880 Test Step 2190 \"loss\" =  7.145342\n",
      "2018-09-02 03:49:26.239452 Training Step 2190 Finished Timing (Training: 0.919021, Test: 0.0788363) after 0.832139 seconds\n",
      "2018-09-02 03:49:26.239510 Training Step 2190 \"min loss\" =  4.2164354\n",
      "2018-09-02 03:49:26.239548 Training Step 2190 \"loss\" =  4.8292623\n",
      "2018-09-02 03:49:26.906721 Test Step 2195 Finished\n",
      "2018-09-02 03:49:26.906862 Test Step 2195 \"min loss\" =  7.053979\n",
      "2018-09-02 03:49:26.906904 Test Step 2195 \"loss\" =  7.082808\n",
      "2018-09-02 03:49:27.060262 Training Step 2195 Finished Timing (Training: 0.918876, Test: 0.0790688) after 0.820659 seconds\n",
      "2018-09-02 03:49:27.060393 Training Step 2195 \"min loss\" =  4.2164354\n",
      "2018-09-02 03:49:27.060438 Training Step 2195 \"loss\" =  4.5341377\n",
      "2018-09-02 03:49:27.731350 Test Step 2200 Finished\n",
      "2018-09-02 03:49:27.731450 Test Step 2200 \"min loss\" =  7.053979\n",
      "2018-09-02 03:49:27.731493 Test Step 2200 \"loss\" =  7.1448374\n",
      "2018-09-02 03:49:27.883142 Training Step 2200 Finished Timing (Training: 0.918802, Test: 0.0792174) after 0.822657 seconds\n",
      "2018-09-02 03:49:27.883199 Training Step 2200 \"min loss\" =  4.0697813\n",
      "2018-09-02 03:49:27.883235 Training Step 2200 \"loss\" =  4.0697813\n",
      "2018-09-02 03:49:28.538368 Test Step 2205 Finished\n",
      "2018-09-02 03:49:28.538781 Test Step 2205 \"min loss\" =  7.0441103\n",
      "2018-09-02 03:49:28.539070 Test Step 2205 \"loss\" =  7.0441103\n",
      "2018-09-02 03:49:28.683014 Training Step 2205 Finished Timing (Training: 0.91698, Test: 0.0817585) after 0.799737 seconds\n",
      "2018-09-02 03:49:28.683280 Training Step 2205 \"min loss\" =  4.0697813\n",
      "2018-09-02 03:49:28.683567 Training Step 2205 \"loss\" =  4.681257\n",
      "2018-09-02 03:49:29.343811 Test Step 2210 Finished\n",
      "2018-09-02 03:49:29.344232 Test Step 2210 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:29.344520 Test Step 2210 \"loss\" =  7.008738\n",
      "2018-09-02 03:49:29.496910 Training Step 2210 Finished Timing (Training: 0.917567, Test: 0.0806575) after 0.813057 seconds\n",
      "2018-09-02 03:49:29.497173 Training Step 2210 \"min loss\" =  4.0697813\n",
      "2018-09-02 03:49:29.497482 Training Step 2210 \"loss\" =  4.1638412\n",
      "2018-09-02 03:49:30.167886 Test Step 2215 Finished\n",
      "2018-09-02 03:49:30.168259 Test Step 2215 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:30.168547 Test Step 2215 \"loss\" =  7.3896832\n",
      "2018-09-02 03:49:30.321669 Training Step 2215 Finished Timing (Training: 0.918144, Test: 0.0799302) after 0.823895 seconds\n",
      "2018-09-02 03:49:30.322010 Training Step 2215 \"min loss\" =  4.0697813\n",
      "2018-09-02 03:49:30.322301 Training Step 2215 \"loss\" =  4.5045567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:49:30.991739 Test Step 2220 Finished\n",
      "2018-09-02 03:49:30.992178 Test Step 2220 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:30.992472 Test Step 2220 \"loss\" =  7.0636706\n",
      "2018-09-02 03:49:31.146630 Training Step 2220 Finished Timing (Training: 0.918559, Test: 0.0793847) after 0.824039 seconds\n",
      "2018-09-02 03:49:31.146897 Training Step 2220 \"min loss\" =  4.0697813\n",
      "2018-09-02 03:49:31.147187 Training Step 2220 \"loss\" =  4.267647\n",
      "2018-09-02 03:49:31.794188 Test Step 2225 Finished\n",
      "2018-09-02 03:49:31.794650 Test Step 2225 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:31.794933 Test Step 2225 \"loss\" =  7.309818\n",
      "2018-09-02 03:49:31.949569 Training Step 2225 Finished Timing (Training: 0.918438, Test: 0.0794293) after 0.802093 seconds\n",
      "2018-09-02 03:49:31.949864 Training Step 2225 \"min loss\" =  4.0697813\n",
      "2018-09-02 03:49:31.950163 Training Step 2225 \"loss\" =  4.382016\n",
      "2018-09-02 03:49:32.617220 Test Step 2230 Finished\n",
      "2018-09-02 03:49:32.617707 Test Step 2230 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:32.617990 Test Step 2230 \"loss\" =  7.279893\n",
      "2018-09-02 03:49:32.767543 Training Step 2230 Finished Timing (Training: 0.918609, Test: 0.0792039) after 0.81705 seconds\n",
      "2018-09-02 03:49:32.767814 Training Step 2230 \"min loss\" =  4.0697813\n",
      "2018-09-02 03:49:32.768105 Training Step 2230 \"loss\" =  4.566305\n",
      "2018-09-02 03:49:33.432039 Test Step 2235 Finished\n",
      "2018-09-02 03:49:33.432471 Test Step 2235 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:33.432758 Test Step 2235 \"loss\" =  7.562676\n",
      "2018-09-02 03:49:33.582560 Training Step 2235 Finished Timing (Training: 0.917687, Test: 0.080102) after 0.814162 seconds\n",
      "2018-09-02 03:49:33.582831 Training Step 2235 \"min loss\" =  4.0697813\n",
      "2018-09-02 03:49:33.583121 Training Step 2235 \"loss\" =  4.4835033\n",
      "2018-09-02 03:49:34.233835 Test Step 2240 Finished\n",
      "2018-09-02 03:49:34.234349 Test Step 2240 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:34.234640 Test Step 2240 \"loss\" =  7.430555\n",
      "2018-09-02 03:49:34.388235 Training Step 2240 Finished Timing (Training: 0.917306, Test: 0.0804551) after 0.804829 seconds\n",
      "2018-09-02 03:49:34.388489 Training Step 2240 \"min loss\" =  4.0697813\n",
      "2018-09-02 03:49:34.388777 Training Step 2240 \"loss\" =  4.647199\n",
      "2018-09-02 03:49:35.056049 Test Step 2245 Finished\n",
      "2018-09-02 03:49:35.056473 Test Step 2245 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:35.056762 Test Step 2245 \"loss\" =  7.619848\n",
      "2018-09-02 03:49:35.209841 Training Step 2245 Finished Timing (Training: 0.918007, Test: 0.0797441) after 0.820738 seconds\n",
      "2018-09-02 03:49:35.210102 Training Step 2245 \"min loss\" =  4.0697813\n",
      "2018-09-02 03:49:35.210413 Training Step 2245 \"loss\" =  4.6203136\n",
      "2018-09-02 03:49:35.879904 Test Step 2250 Finished\n",
      "2018-09-02 03:49:35.880326 Test Step 2250 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:35.880616 Test Step 2250 \"loss\" =  7.251086\n",
      "2018-09-02 03:49:36.034027 Training Step 2250 Finished Timing (Training: 0.918077, Test: 0.0796704) after 0.823323 seconds\n",
      "2018-09-02 03:49:36.034318 Training Step 2250 \"min loss\" =  4.0697813\n",
      "2018-09-02 03:49:36.034604 Training Step 2250 \"loss\" =  4.4223237\n",
      "2018-09-02 03:49:36.691651 Test Step 2255 Finished\n",
      "2018-09-02 03:49:36.692071 Test Step 2255 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:36.692366 Test Step 2255 \"loss\" =  7.340091\n",
      "2018-09-02 03:49:36.845320 Training Step 2255 Finished Timing (Training: 0.918249, Test: 0.0794911) after 0.810432 seconds\n",
      "2018-09-02 03:49:36.845587 Training Step 2255 \"min loss\" =  4.0697813\n",
      "2018-09-02 03:49:36.845874 Training Step 2255 \"loss\" =  4.2877483\n",
      "2018-09-02 03:49:37.514903 Test Step 2260 Finished\n",
      "2018-09-02 03:49:37.515350 Test Step 2260 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:37.515638 Test Step 2260 \"loss\" =  7.78435\n",
      "2018-09-02 03:49:37.661358 Training Step 2260 Finished Timing (Training: 0.918457, Test: 0.0792755) after 0.815179 seconds\n",
      "2018-09-02 03:49:37.661685 Training Step 2260 \"min loss\" =  4.0697813\n",
      "2018-09-02 03:49:37.661970 Training Step 2260 \"loss\" =  4.3616924\n",
      "2018-09-02 03:49:38.325155 Test Step 2265 Finished\n",
      "2018-09-02 03:49:38.325577 Test Step 2265 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:38.325866 Test Step 2265 \"loss\" =  7.452785\n",
      "2018-09-02 03:49:38.478458 Training Step 2265 Finished Timing (Training: 0.919028, Test: 0.0786979) after 0.816205 seconds\n",
      "2018-09-02 03:49:38.478712 Training Step 2265 \"min loss\" =  4.0697813\n",
      "2018-09-02 03:49:38.478998 Training Step 2265 \"loss\" =  4.4651337\n",
      "2018-09-02 03:49:39.139365 Test Step 2270 Finished\n",
      "2018-09-02 03:49:39.139789 Test Step 2270 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:39.140077 Test Step 2270 \"loss\" =  7.2171865\n",
      "2018-09-02 03:49:39.286602 Training Step 2270 Finished Timing (Training: 0.918913, Test: 0.0788125) after 0.80732 seconds\n",
      "2018-09-02 03:49:39.286852 Training Step 2270 \"min loss\" =  4.0697813\n",
      "2018-09-02 03:49:39.287171 Training Step 2270 \"loss\" =  4.2901073\n",
      "2018-09-02 03:49:39.950077 Test Step 2275 Finished\n",
      "2018-09-02 03:49:39.950462 Test Step 2275 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:39.950751 Test Step 2275 \"loss\" =  7.691352\n",
      "2018-09-02 03:49:40.106748 Training Step 2275 Finished Timing (Training: 0.919042, Test: 0.0786827) after 0.819268 seconds\n",
      "2018-09-02 03:49:40.107005 Training Step 2275 \"min loss\" =  4.0527625\n",
      "2018-09-02 03:49:40.107291 Training Step 2275 \"loss\" =  4.312665\n",
      "2018-09-02 03:49:40.778010 Test Step 2280 Finished\n",
      "2018-09-02 03:49:40.778509 Test Step 2280 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:40.778801 Test Step 2280 \"loss\" =  7.4802103\n",
      "2018-09-02 03:49:40.924551 Training Step 2280 Finished Timing (Training: 0.918932, Test: 0.0787863) after 0.816971 seconds\n",
      "2018-09-02 03:49:40.924839 Training Step 2280 \"min loss\" =  4.0527625\n",
      "2018-09-02 03:49:40.925157 Training Step 2280 \"loss\" =  4.4790945\n",
      "2018-09-02 03:49:41.591914 Test Step 2285 Finished\n",
      "2018-09-02 03:49:41.592363 Test Step 2285 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:41.592680 Test Step 2285 \"loss\" =  7.36984\n",
      "2018-09-02 03:49:41.740262 Training Step 2285 Finished Timing (Training: 0.918801, Test: 0.0789038) after 0.814758 seconds\n",
      "2018-09-02 03:49:41.740553 Training Step 2285 \"min loss\" =  4.0527625\n",
      "2018-09-02 03:49:41.740867 Training Step 2285 \"loss\" =  4.3392806\n",
      "2018-09-02 03:49:42.413227 Test Step 2290 Finished\n",
      "2018-09-02 03:49:42.413710 Test Step 2290 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:42.414029 Test Step 2290 \"loss\" =  7.440867\n",
      "2018-09-02 03:49:42.557135 Training Step 2290 Finished Timing (Training: 0.918659, Test: 0.0790321) after 0.815951 seconds\n",
      "2018-09-02 03:49:42.557470 Training Step 2290 \"min loss\" =  4.0527625\n",
      "2018-09-02 03:49:42.557787 Training Step 2290 \"loss\" =  4.3066125\n",
      "2018-09-02 03:49:43.218035 Test Step 2295 Finished\n",
      "2018-09-02 03:49:43.218475 Test Step 2295 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:43.218788 Test Step 2295 \"loss\" =  7.5934715\n",
      "2018-09-02 03:49:43.360144 Training Step 2295 Finished Timing (Training: 0.918676, Test: 0.0790015) after 0.802044 seconds\n",
      "2018-09-02 03:49:43.360423 Training Step 2295 \"min loss\" =  4.0527625\n",
      "2018-09-02 03:49:43.360738 Training Step 2295 \"loss\" =  4.211071\n",
      "2018-09-02 03:49:44.023341 Test Step 2300 Finished\n",
      "2018-09-02 03:49:44.023727 Test Step 2300 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:44.024041 Test Step 2300 \"loss\" =  7.6412945\n",
      "2018-09-02 03:49:44.176352 Training Step 2300 Finished Timing (Training: 0.918709, Test: 0.0789612) after 0.815298 seconds\n",
      "2018-09-02 03:49:44.176649 Training Step 2300 \"min loss\" =  4.0527625\n",
      "2018-09-02 03:49:44.176978 Training Step 2300 \"loss\" =  4.8379226\n",
      "2018-09-02 03:49:44.834344 Test Step 2305 Finished\n",
      "2018-09-02 03:49:44.834769 Test Step 2305 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:44.835083 Test Step 2305 \"loss\" =  7.2367177\n",
      "2018-09-02 03:49:44.983531 Training Step 2305 Finished Timing (Training: 0.919935, Test: 0.0787345) after 0.806201 seconds\n",
      "2018-09-02 03:49:44.983804 Training Step 2305 \"min loss\" =  4.0527625\n",
      "2018-09-02 03:49:44.984122 Training Step 2305 \"loss\" =  4.0998635\n",
      "2018-09-02 03:49:45.651433 Test Step 2310 Finished\n",
      "2018-09-02 03:49:45.651864 Test Step 2310 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:45.652204 Test Step 2310 \"loss\" =  7.2991343\n",
      "2018-09-02 03:49:45.802811 Training Step 2310 Finished Timing (Training: 0.91795, Test: 0.0801381) after 0.81837 seconds\n",
      "2018-09-02 03:49:45.803237 Training Step 2310 \"min loss\" =  4.0527625\n",
      "2018-09-02 03:49:45.803774 Training Step 2310 \"loss\" =  4.137578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:49:46.475124 Test Step 2315 Finished\n",
      "2018-09-02 03:49:46.475577 Test Step 2315 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:46.475911 Test Step 2315 \"loss\" =  7.247359\n",
      "2018-09-02 03:49:46.627291 Training Step 2315 Finished Timing (Training: 0.917179, Test: 0.0804631) after 0.822967 seconds\n",
      "2018-09-02 03:49:46.627575 Training Step 2315 \"min loss\" =  4.0527625\n",
      "2018-09-02 03:49:46.627890 Training Step 2315 \"loss\" =  4.3031926\n",
      "2018-09-02 03:49:47.291192 Test Step 2320 Finished\n",
      "2018-09-02 03:49:47.291645 Test Step 2320 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:47.291963 Test Step 2320 \"loss\" =  7.2089205\n",
      "2018-09-02 03:49:47.443558 Training Step 2320 Finished Timing (Training: 0.918255, Test: 0.0793508) after 0.815351 seconds\n",
      "2018-09-02 03:49:47.443837 Training Step 2320 \"min loss\" =  4.0527625\n",
      "2018-09-02 03:49:47.444180 Training Step 2320 \"loss\" =  4.743185\n",
      "2018-09-02 03:49:48.103019 Test Step 2325 Finished\n",
      "2018-09-02 03:49:48.103439 Test Step 2325 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:48.103758 Test Step 2325 \"loss\" =  7.2532573\n",
      "2018-09-02 03:49:48.251785 Training Step 2325 Finished Timing (Training: 0.91889, Test: 0.0786889) after 0.807268 seconds\n",
      "2018-09-02 03:49:48.252069 Training Step 2325 \"min loss\" =  4.0527625\n",
      "2018-09-02 03:49:48.252391 Training Step 2325 \"loss\" =  4.436195\n",
      "2018-09-02 03:49:48.922327 Test Step 2330 Finished\n",
      "2018-09-02 03:49:48.922718 Test Step 2330 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:48.923035 Test Step 2330 \"loss\" =  7.3113737\n",
      "2018-09-02 03:49:49.065551 Training Step 2330 Finished Timing (Training: 0.918017, Test: 0.0795501) after 0.812785 seconds\n",
      "2018-09-02 03:49:49.065822 Training Step 2330 \"min loss\" =  4.0527625\n",
      "2018-09-02 03:49:49.066140 Training Step 2330 \"loss\" =  4.6295323\n",
      "2018-09-02 03:49:49.730724 Test Step 2335 Finished\n",
      "2018-09-02 03:49:49.731150 Test Step 2335 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:49.731483 Test Step 2335 \"loss\" =  7.368042\n",
      "2018-09-02 03:49:49.881127 Training Step 2335 Finished Timing (Training: 0.918633, Test: 0.0789279) after 0.814658 seconds\n",
      "2018-09-02 03:49:49.881441 Training Step 2335 \"min loss\" =  4.0527625\n",
      "2018-09-02 03:49:49.881779 Training Step 2335 \"loss\" =  4.069254\n",
      "2018-09-02 03:49:50.546558 Test Step 2340 Finished\n",
      "2018-09-02 03:49:50.547015 Test Step 2340 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:50.547333 Test Step 2340 \"loss\" =  7.904122\n",
      "2018-09-02 03:49:50.699852 Training Step 2340 Finished Timing (Training: 0.918417, Test: 0.0791317) after 0.817758 seconds\n",
      "2018-09-02 03:49:50.700150 Training Step 2340 \"min loss\" =  4.0527625\n",
      "2018-09-02 03:49:50.700468 Training Step 2340 \"loss\" =  4.352839\n",
      "2018-09-02 03:49:51.359956 Test Step 2345 Finished\n",
      "2018-09-02 03:49:51.360474 Test Step 2345 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:51.360758 Test Step 2345 \"loss\" =  7.4724975\n",
      "2018-09-02 03:49:51.515002 Training Step 2345 Finished Timing (Training: 0.918502, Test: 0.0790382) after 0.814207 seconds\n",
      "2018-09-02 03:49:51.515297 Training Step 2345 \"min loss\" =  4.0527625\n",
      "2018-09-02 03:49:51.515583 Training Step 2345 \"loss\" =  4.7164993\n",
      "2018-09-02 03:49:52.185331 Test Step 2350 Finished\n",
      "2018-09-02 03:49:52.185828 Test Step 2350 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:52.186115 Test Step 2350 \"loss\" =  7.140965\n",
      "2018-09-02 03:49:52.333860 Training Step 2350 Finished Timing (Training: 0.918424, Test: 0.079119) after 0.817985 seconds\n",
      "2018-09-02 03:49:52.334206 Training Step 2350 \"min loss\" =  4.0527625\n",
      "2018-09-02 03:49:52.334501 Training Step 2350 \"loss\" =  4.224628\n",
      "2018-09-02 03:49:52.972734 Test Step 2355 Finished\n",
      "2018-09-02 03:49:52.973160 Test Step 2355 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:52.973502 Test Step 2355 \"loss\" =  7.1357875\n",
      "2018-09-02 03:49:53.123219 Training Step 2355 Finished Timing (Training: 0.918676, Test: 0.0788543) after 0.788427 seconds\n",
      "2018-09-02 03:49:53.123492 Training Step 2355 \"min loss\" =  4.0527625\n",
      "2018-09-02 03:49:53.123805 Training Step 2355 \"loss\" =  4.225595\n",
      "2018-09-02 03:49:53.798923 Test Step 2360 Finished\n",
      "2018-09-02 03:49:53.799360 Test Step 2360 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:53.799652 Test Step 2360 \"loss\" =  7.256984\n",
      "2018-09-02 03:49:53.952837 Training Step 2360 Finished Timing (Training: 0.918783, Test: 0.0787575) after 0.828715 seconds\n",
      "2018-09-02 03:49:53.953135 Training Step 2360 \"min loss\" =  4.0527625\n",
      "2018-09-02 03:49:53.953503 Training Step 2360 \"loss\" =  4.1005316\n",
      "2018-09-02 03:49:54.602308 Test Step 2365 Finished\n",
      "2018-09-02 03:49:54.602726 Test Step 2365 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:54.603017 Test Step 2365 \"loss\" =  7.4856653\n",
      "2018-09-02 03:49:54.755444 Training Step 2365 Finished Timing (Training: 0.919024, Test: 0.0785155) after 0.801648 seconds\n",
      "2018-09-02 03:49:54.755695 Training Step 2365 \"min loss\" =  4.007417\n",
      "2018-09-02 03:49:54.755992 Training Step 2365 \"loss\" =  4.4143453\n",
      "2018-09-02 03:49:55.410585 Test Step 2370 Finished\n",
      "2018-09-02 03:49:55.411001 Test Step 2370 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:55.411293 Test Step 2370 \"loss\" =  7.37872\n",
      "2018-09-02 03:49:55.563056 Training Step 2370 Finished Timing (Training: 0.919082, Test: 0.0784675) after 0.806763 seconds\n",
      "2018-09-02 03:49:55.563370 Training Step 2370 \"min loss\" =  4.007417\n",
      "2018-09-02 03:49:55.563666 Training Step 2370 \"loss\" =  4.1140213\n",
      "2018-09-02 03:49:56.218789 Test Step 2375 Finished\n",
      "2018-09-02 03:49:56.219339 Test Step 2375 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:56.219656 Test Step 2375 \"loss\" =  7.558928\n",
      "2018-09-02 03:49:56.369048 Training Step 2375 Finished Timing (Training: 0.919061, Test: 0.0784758) after 0.805089 seconds\n",
      "2018-09-02 03:49:56.369376 Training Step 2375 \"min loss\" =  4.007417\n",
      "2018-09-02 03:49:56.369718 Training Step 2375 \"loss\" =  4.3045835\n",
      "2018-09-02 03:49:57.047804 Test Step 2380 Finished\n",
      "2018-09-02 03:49:57.048236 Test Step 2380 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:57.048581 Test Step 2380 \"loss\" =  7.1830006\n",
      "2018-09-02 03:49:57.199618 Training Step 2380 Finished Timing (Training: 0.919082, Test: 0.0784469) after 0.829535 seconds\n",
      "2018-09-02 03:49:57.199936 Training Step 2380 \"min loss\" =  4.007417\n",
      "2018-09-02 03:49:57.200248 Training Step 2380 \"loss\" =  4.327389\n",
      "2018-09-02 03:49:57.864201 Test Step 2385 Finished\n",
      "2018-09-02 03:49:57.864627 Test Step 2385 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:57.864943 Test Step 2385 \"loss\" =  7.591766\n",
      "2018-09-02 03:49:58.014761 Training Step 2385 Finished Timing (Training: 0.919066, Test: 0.078463) after 0.814202 seconds\n",
      "2018-09-02 03:49:58.015035 Training Step 2385 \"min loss\" =  4.007417\n",
      "2018-09-02 03:49:58.015419 Training Step 2385 \"loss\" =  4.31539\n",
      "2018-09-02 03:49:58.676494 Test Step 2390 Finished\n",
      "2018-09-02 03:49:58.676909 Test Step 2390 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:58.677229 Test Step 2390 \"loss\" =  7.476143\n",
      "2018-09-02 03:49:58.829965 Training Step 2390 Finished Timing (Training: 0.919087, Test: 0.0784334) after 0.814221 seconds\n",
      "2018-09-02 03:49:58.830246 Training Step 2390 \"min loss\" =  4.007417\n",
      "2018-09-02 03:49:58.830561 Training Step 2390 \"loss\" =  4.3375287\n",
      "2018-09-02 03:49:59.509936 Test Step 2395 Finished\n",
      "2018-09-02 03:49:59.510308 Test Step 2395 \"min loss\" =  7.008738\n",
      "2018-09-02 03:49:59.510620 Test Step 2395 \"loss\" =  7.4990873\n",
      "2018-09-02 03:49:59.656125 Training Step 2395 Finished Timing (Training: 0.918805, Test: 0.0787225) after 0.825245 seconds\n",
      "2018-09-02 03:49:59.656193 Training Step 2395 \"min loss\" =  4.007417\n",
      "2018-09-02 03:49:59.656236 Training Step 2395 \"loss\" =  4.0317564\n",
      "2018-09-02 03:50:00.329809 Test Step 2400 Finished\n",
      "2018-09-02 03:50:00.329910 Test Step 2400 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:00.329974 Test Step 2400 \"loss\" =  7.4114647\n",
      "2018-09-02 03:50:00.483280 Training Step 2400 Finished Timing (Training: 0.91876, Test: 0.0788684) after 0.826984 seconds\n",
      "2018-09-02 03:50:00.483410 Training Step 2400 \"min loss\" =  4.007417\n",
      "2018-09-02 03:50:00.483455 Training Step 2400 \"loss\" =  4.265933\n",
      "2018-09-02 03:50:01.144782 Test Step 2405 Finished\n",
      "2018-09-02 03:50:01.144878 Test Step 2405 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:01.144922 Test Step 2405 \"loss\" =  7.5055404\n",
      "2018-09-02 03:50:01.296515 Training Step 2405 Finished Timing (Training: 0.919596, Test: 0.0801404) after 0.81301 seconds\n",
      "2018-09-02 03:50:01.296581 Training Step 2405 \"min loss\" =  3.925944\n",
      "2018-09-02 03:50:01.296622 Training Step 2405 \"loss\" =  3.925944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:50:01.959049 Test Step 2410 Finished\n",
      "2018-09-02 03:50:01.959548 Test Step 2410 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:01.959658 Test Step 2410 \"loss\" =  7.4029603\n",
      "2018-09-02 03:50:02.112112 Training Step 2410 Finished Timing (Training: 0.91922, Test: 0.0801261) after 0.815443 seconds\n",
      "2018-09-02 03:50:02.112465 Training Step 2410 \"min loss\" =  3.925944\n",
      "2018-09-02 03:50:02.112621 Training Step 2410 \"loss\" =  4.3580756\n",
      "2018-09-02 03:50:02.783766 Test Step 2415 Finished\n",
      "2018-09-02 03:50:02.784226 Test Step 2415 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:02.784574 Test Step 2415 \"loss\" =  7.4176016\n",
      "2018-09-02 03:50:02.936003 Training Step 2415 Finished Timing (Training: 0.918577, Test: 0.0802856) after 0.823332 seconds\n",
      "2018-09-02 03:50:02.936277 Training Step 2415 \"min loss\" =  3.925944\n",
      "2018-09-02 03:50:02.936591 Training Step 2415 \"loss\" =  4.4121604\n",
      "2018-09-02 03:50:03.606548 Test Step 2420 Finished\n",
      "2018-09-02 03:50:03.606966 Test Step 2420 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:03.607284 Test Step 2420 \"loss\" =  7.522936\n",
      "2018-09-02 03:50:03.758408 Training Step 2420 Finished Timing (Training: 0.918595, Test: 0.0799473) after 0.821499 seconds\n",
      "2018-09-02 03:50:03.758688 Training Step 2420 \"min loss\" =  3.925944\n",
      "2018-09-02 03:50:03.759021 Training Step 2420 \"loss\" =  4.2953362\n",
      "2018-09-02 03:50:04.425873 Test Step 2425 Finished\n",
      "2018-09-02 03:50:04.426260 Test Step 2425 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:04.426578 Test Step 2425 \"loss\" =  7.862912\n",
      "2018-09-02 03:50:04.577403 Training Step 2425 Finished Timing (Training: 0.919595, Test: 0.0787557) after 0.818064 seconds\n",
      "2018-09-02 03:50:04.577675 Training Step 2425 \"min loss\" =  3.9179375\n",
      "2018-09-02 03:50:04.577993 Training Step 2425 \"loss\" =  4.2787495\n",
      "2018-09-02 03:50:05.248807 Test Step 2430 Finished\n",
      "2018-09-02 03:50:05.249398 Test Step 2430 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:05.249723 Test Step 2430 \"loss\" =  7.6967187\n",
      "2018-09-02 03:50:05.401015 Training Step 2430 Finished Timing (Training: 0.919933, Test: 0.0782527) after 0.822704 seconds\n",
      "2018-09-02 03:50:05.401081 Training Step 2430 \"min loss\" =  3.9179375\n",
      "2018-09-02 03:50:05.401124 Training Step 2430 \"loss\" =  4.915235\n",
      "2018-09-02 03:50:06.052972 Test Step 2435 Finished\n",
      "2018-09-02 03:50:06.053066 Test Step 2435 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:06.053130 Test Step 2435 \"loss\" =  7.6751533\n",
      "2018-09-02 03:50:06.202019 Training Step 2435 Finished Timing (Training: 0.919598, Test: 0.0786236) after 0.800843 seconds\n",
      "2018-09-02 03:50:06.202114 Training Step 2435 \"min loss\" =  3.9179375\n",
      "2018-09-02 03:50:06.202534 Training Step 2435 \"loss\" =  4.200208\n",
      "2018-09-02 03:50:06.866169 Test Step 2440 Finished\n",
      "2018-09-02 03:50:06.866755 Test Step 2440 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:06.866919 Test Step 2440 \"loss\" =  8.354006\n",
      "2018-09-02 03:50:07.016702 Training Step 2440 Finished Timing (Training: 0.919521, Test: 0.0786275) after 0.814096 seconds\n",
      "2018-09-02 03:50:07.016762 Training Step 2440 \"min loss\" =  3.9179375\n",
      "2018-09-02 03:50:07.017265 Training Step 2440 \"loss\" =  4.0912485\n",
      "2018-09-02 03:50:07.683543 Test Step 2445 Finished\n",
      "2018-09-02 03:50:07.683650 Test Step 2445 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:07.684250 Test Step 2445 \"loss\" =  7.580804\n",
      "2018-09-02 03:50:07.835797 Training Step 2445 Finished Timing (Training: 0.919022, Test: 0.0790973) after 0.818166 seconds\n",
      "2018-09-02 03:50:07.835860 Training Step 2445 \"min loss\" =  3.857263\n",
      "2018-09-02 03:50:07.836416 Training Step 2445 \"loss\" =  3.857263\n",
      "2018-09-02 03:50:08.498229 Test Step 2450 Finished\n",
      "2018-09-02 03:50:08.498668 Test Step 2450 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:08.498727 Test Step 2450 \"loss\" =  7.3067966\n",
      "2018-09-02 03:50:08.652383 Training Step 2450 Finished Timing (Training: 0.919279, Test: 0.0788336) after 0.815577 seconds\n",
      "2018-09-02 03:50:08.652454 Training Step 2450 \"min loss\" =  3.857263\n",
      "2018-09-02 03:50:08.652820 Training Step 2450 \"loss\" =  4.0025935\n",
      "2018-09-02 03:50:09.312163 Test Step 2455 Finished\n",
      "2018-09-02 03:50:09.312258 Test Step 2455 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:09.312316 Test Step 2455 \"loss\" =  7.466867\n",
      "2018-09-02 03:50:09.464600 Training Step 2455 Finished Timing (Training: 0.919161, Test: 0.079025) after 0.81157 seconds\n",
      "2018-09-02 03:50:09.464861 Training Step 2455 \"min loss\" =  3.857263\n",
      "2018-09-02 03:50:09.464919 Training Step 2455 \"loss\" =  4.125063\n",
      "2018-09-02 03:50:10.131415 Test Step 2460 Finished\n",
      "2018-09-02 03:50:10.131517 Test Step 2460 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:10.131984 Test Step 2460 \"loss\" =  7.1465693\n",
      "2018-09-02 03:50:10.282779 Training Step 2460 Finished Timing (Training: 0.919281, Test: 0.0789141) after 0.817801 seconds\n",
      "2018-09-02 03:50:10.282846 Training Step 2460 \"min loss\" =  3.857263\n",
      "2018-09-02 03:50:10.282920 Training Step 2460 \"loss\" =  4.0202737\n",
      "2018-09-02 03:50:10.939308 Test Step 2465 Finished\n",
      "2018-09-02 03:50:10.939423 Test Step 2465 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:10.939482 Test Step 2465 \"loss\" =  7.3688474\n",
      "2018-09-02 03:50:11.085251 Training Step 2465 Finished Timing (Training: 0.919802, Test: 0.0784265) after 0.801644 seconds\n",
      "2018-09-02 03:50:11.085333 Training Step 2465 \"min loss\" =  3.857263\n",
      "2018-09-02 03:50:11.085710 Training Step 2465 \"loss\" =  3.9523177\n",
      "2018-09-02 03:50:11.743038 Test Step 2470 Finished\n",
      "2018-09-02 03:50:11.743486 Test Step 2470 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:11.743685 Test Step 2470 \"loss\" =  7.304297\n",
      "2018-09-02 03:50:11.893591 Training Step 2470 Finished Timing (Training: 0.919343, Test: 0.0788552) after 0.807552 seconds\n",
      "2018-09-02 03:50:11.893674 Training Step 2470 \"min loss\" =  3.857263\n",
      "2018-09-02 03:50:11.893732 Training Step 2470 \"loss\" =  4.293271\n",
      "2018-09-02 03:50:12.551665 Test Step 2475 Finished\n",
      "2018-09-02 03:50:12.551769 Test Step 2475 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:12.552260 Test Step 2475 \"loss\" =  7.4320602\n",
      "2018-09-02 03:50:12.702022 Training Step 2475 Finished Timing (Training: 0.919493, Test: 0.0786755) after 0.807667 seconds\n",
      "2018-09-02 03:50:12.702134 Training Step 2475 \"min loss\" =  3.857263\n",
      "2018-09-02 03:50:12.702685 Training Step 2475 \"loss\" =  4.347329\n",
      "2018-09-02 03:50:13.382908 Test Step 2480 Finished\n",
      "2018-09-02 03:50:13.383014 Test Step 2480 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:13.383086 Test Step 2480 \"loss\" =  7.5908623\n",
      "2018-09-02 03:50:13.536500 Training Step 2480 Finished Timing (Training: 0.919502, Test: 0.0787075) after 0.833749 seconds\n",
      "2018-09-02 03:50:13.536566 Training Step 2480 \"min loss\" =  3.7347872\n",
      "2018-09-02 03:50:13.536916 Training Step 2480 \"loss\" =  3.7347872\n",
      "2018-09-02 03:50:14.200161 Test Step 2485 Finished\n",
      "2018-09-02 03:50:14.200606 Test Step 2485 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:14.200663 Test Step 2485 \"loss\" =  7.562191\n",
      "2018-09-02 03:50:14.349235 Training Step 2485 Finished Timing (Training: 0.919716, Test: 0.0785004) after 0.812261 seconds\n",
      "2018-09-02 03:50:14.349352 Training Step 2485 \"min loss\" =  3.7347872\n",
      "2018-09-02 03:50:14.349407 Training Step 2485 \"loss\" =  4.0158916\n",
      "2018-09-02 03:50:15.003298 Test Step 2490 Finished\n",
      "2018-09-02 03:50:15.003373 Test Step 2490 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:15.003443 Test Step 2490 \"loss\" =  7.638564\n",
      "2018-09-02 03:50:15.155464 Training Step 2490 Finished Timing (Training: 0.91942, Test: 0.0788608) after 0.805987 seconds\n",
      "2018-09-02 03:50:15.155534 Training Step 2490 \"min loss\" =  3.7347872\n",
      "2018-09-02 03:50:15.155587 Training Step 2490 \"loss\" =  4.469779\n",
      "2018-09-02 03:50:15.824829 Test Step 2495 Finished\n",
      "2018-09-02 03:50:15.824946 Test Step 2495 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:15.825022 Test Step 2495 \"loss\" =  7.7015276\n",
      "2018-09-02 03:50:15.970060 Training Step 2495 Finished Timing (Training: 0.919495, Test: 0.0788066) after 0.814415 seconds\n",
      "2018-09-02 03:50:15.970340 Training Step 2495 \"min loss\" =  3.7347872\n",
      "2018-09-02 03:50:15.970397 Training Step 2495 \"loss\" =  3.9401598\n",
      "2018-09-02 03:50:16.628825 Test Step 2500 Finished\n",
      "2018-09-02 03:50:16.628950 Test Step 2500 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:16.629009 Test Step 2500 \"loss\" =  7.5911818\n",
      "2018-09-02 03:50:16.784927 Training Step 2500 Finished Timing (Training: 0.919617, Test: 0.078729) after 0.814474 seconds\n",
      "2018-09-02 03:50:16.785176 Training Step 2500 \"min loss\" =  3.7347872\n",
      "2018-09-02 03:50:16.785382 Training Step 2500 \"loss\" =  4.379464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:50:17.449588 Test Step 2505 Finished\n",
      "2018-09-02 03:50:17.449700 Test Step 2505 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:17.449762 Test Step 2505 \"loss\" =  7.608275\n",
      "2018-09-02 03:50:17.600853 Training Step 2505 Finished Timing (Training: 0.919217, Test: 0.0795256) after 0.815413 seconds\n",
      "2018-09-02 03:50:17.600936 Training Step 2505 \"min loss\" =  3.7347872\n",
      "2018-09-02 03:50:17.600990 Training Step 2505 \"loss\" =  4.139918\n",
      "2018-09-02 03:50:18.259652 Test Step 2510 Finished\n",
      "2018-09-02 03:50:18.259752 Test Step 2510 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:18.260223 Test Step 2510 \"loss\" =  7.652548\n",
      "2018-09-02 03:50:18.416256 Training Step 2510 Finished Timing (Training: 0.920102, Test: 0.0785023) after 0.815189 seconds\n",
      "2018-09-02 03:50:18.416326 Training Step 2510 \"min loss\" =  3.7347872\n",
      "2018-09-02 03:50:18.416379 Training Step 2510 \"loss\" =  4.1637034\n",
      "2018-09-02 03:50:19.088906 Test Step 2515 Finished\n",
      "2018-09-02 03:50:19.089014 Test Step 2515 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:19.089580 Test Step 2515 \"loss\" =  8.409595\n",
      "2018-09-02 03:50:19.239378 Training Step 2515 Finished Timing (Training: 0.92031, Test: 0.078378) after 0.82294 seconds\n",
      "2018-09-02 03:50:19.239450 Training Step 2515 \"min loss\" =  3.7347872\n",
      "2018-09-02 03:50:19.239782 Training Step 2515 \"loss\" =  4.331146\n",
      "2018-09-02 03:50:19.891479 Test Step 2520 Finished\n",
      "2018-09-02 03:50:19.891601 Test Step 2520 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:19.892216 Test Step 2520 \"loss\" =  7.5087934\n",
      "2018-09-02 03:50:20.047335 Training Step 2520 Finished Timing (Training: 0.921301, Test: 0.0772762) after 0.807492 seconds\n",
      "2018-09-02 03:50:20.047404 Training Step 2520 \"min loss\" =  3.7347872\n",
      "2018-09-02 03:50:20.047763 Training Step 2520 \"loss\" =  3.7987843\n",
      "2018-09-02 03:50:20.708357 Test Step 2525 Finished\n",
      "2018-09-02 03:50:20.708462 Test Step 2525 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:20.709112 Test Step 2525 \"loss\" =  7.818087\n",
      "2018-09-02 03:50:20.859585 Training Step 2525 Finished Timing (Training: 0.921335, Test: 0.0771991) after 0.811763 seconds\n",
      "2018-09-02 03:50:20.859654 Training Step 2525 \"min loss\" =  3.7347872\n",
      "2018-09-02 03:50:20.859706 Training Step 2525 \"loss\" =  4.430173\n",
      "2018-09-02 03:50:21.526191 Test Step 2530 Finished\n",
      "2018-09-02 03:50:21.526313 Test Step 2530 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:21.526962 Test Step 2530 \"loss\" =  7.301364\n",
      "2018-09-02 03:50:21.677703 Training Step 2530 Finished Timing (Training: 0.920797, Test: 0.0777371) after 0.817939 seconds\n",
      "2018-09-02 03:50:21.678039 Training Step 2530 \"min loss\" =  3.7347872\n",
      "2018-09-02 03:50:21.678323 Training Step 2530 \"loss\" =  4.2725396\n",
      "2018-09-02 03:50:22.342341 Test Step 2535 Finished\n",
      "2018-09-02 03:50:22.342830 Test Step 2535 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:22.342894 Test Step 2535 \"loss\" =  7.729196\n",
      "2018-09-02 03:50:22.490386 Training Step 2535 Finished Timing (Training: 0.920364, Test: 0.0780725) after 0.811999 seconds\n",
      "2018-09-02 03:50:22.490459 Training Step 2535 \"min loss\" =  3.7347872\n",
      "2018-09-02 03:50:22.490514 Training Step 2535 \"loss\" =  3.791768\n",
      "2018-09-02 03:50:23.155740 Test Step 2540 Finished\n",
      "2018-09-02 03:50:23.155861 Test Step 2540 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:23.156387 Test Step 2540 \"loss\" =  7.348246\n",
      "2018-09-02 03:50:23.305248 Training Step 2540 Finished Timing (Training: 0.919932, Test: 0.0784761) after 0.814134 seconds\n",
      "2018-09-02 03:50:23.305356 Training Step 2540 \"min loss\" =  3.7347872\n",
      "2018-09-02 03:50:23.305413 Training Step 2540 \"loss\" =  3.9189992\n",
      "2018-09-02 03:50:23.967843 Test Step 2545 Finished\n",
      "2018-09-02 03:50:23.967959 Test Step 2545 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:23.968433 Test Step 2545 \"loss\" =  7.2934685\n",
      "2018-09-02 03:50:24.112461 Training Step 2545 Finished Timing (Training: 0.920014, Test: 0.078447) after 0.806988 seconds\n",
      "2018-09-02 03:50:24.112712 Training Step 2545 \"min loss\" =  3.7347872\n",
      "2018-09-02 03:50:24.112767 Training Step 2545 \"loss\" =  3.8655248\n",
      "2018-09-02 03:50:24.790133 Test Step 2550 Finished\n",
      "2018-09-02 03:50:24.790515 Test Step 2550 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:24.790573 Test Step 2550 \"loss\" =  7.7375655\n",
      "2018-09-02 03:50:24.937191 Training Step 2550 Finished Timing (Training: 0.919949, Test: 0.0785205) after 0.824368 seconds\n",
      "2018-09-02 03:50:24.937441 Training Step 2550 \"min loss\" =  3.7347872\n",
      "2018-09-02 03:50:24.937493 Training Step 2550 \"loss\" =  4.323182\n",
      "2018-09-02 03:50:25.583751 Test Step 2555 Finished\n",
      "2018-09-02 03:50:25.583879 Test Step 2555 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:25.584750 Test Step 2555 \"loss\" =  7.3412914\n",
      "2018-09-02 03:50:25.736397 Training Step 2555 Finished Timing (Training: 0.919348, Test: 0.0790523) after 0.798847 seconds\n",
      "2018-09-02 03:50:25.736856 Training Step 2555 \"min loss\" =  3.711591\n",
      "2018-09-02 03:50:25.737089 Training Step 2555 \"loss\" =  4.29495\n",
      "2018-09-02 03:50:26.400770 Test Step 2560 Finished\n",
      "2018-09-02 03:50:26.400876 Test Step 2560 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:26.400933 Test Step 2560 \"loss\" =  7.2548532\n",
      "2018-09-02 03:50:26.555511 Training Step 2560 Finished Timing (Training: 0.919393, Test: 0.0790397) after 0.818352 seconds\n",
      "2018-09-02 03:50:26.555588 Training Step 2560 \"min loss\" =  3.5662894\n",
      "2018-09-02 03:50:26.555629 Training Step 2560 \"loss\" =  3.5662894\n",
      "2018-09-02 03:50:27.216899 Test Step 2565 Finished\n",
      "2018-09-02 03:50:27.217411 Test Step 2565 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:27.217478 Test Step 2565 \"loss\" =  7.4131994\n",
      "2018-09-02 03:50:27.372261 Training Step 2565 Finished Timing (Training: 0.91981, Test: 0.0786634) after 0.816571 seconds\n",
      "2018-09-02 03:50:27.372677 Training Step 2565 \"min loss\" =  3.5662894\n",
      "2018-09-02 03:50:27.372743 Training Step 2565 \"loss\" =  3.848058\n",
      "2018-09-02 03:50:28.040275 Test Step 2570 Finished\n",
      "2018-09-02 03:50:28.040753 Test Step 2570 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:28.040820 Test Step 2570 \"loss\" =  7.2368445\n",
      "2018-09-02 03:50:28.182241 Training Step 2570 Finished Timing (Training: 0.919449, Test: 0.0790277) after 0.809431 seconds\n",
      "2018-09-02 03:50:28.182318 Training Step 2570 \"min loss\" =  3.5662894\n",
      "2018-09-02 03:50:28.182381 Training Step 2570 \"loss\" =  4.266564\n",
      "2018-09-02 03:50:28.844561 Test Step 2575 Finished\n",
      "2018-09-02 03:50:28.845099 Test Step 2575 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:28.845390 Test Step 2575 \"loss\" =  7.456986\n",
      "2018-09-02 03:50:28.997718 Training Step 2575 Finished Timing (Training: 0.91935, Test: 0.0791249) after 0.815237 seconds\n",
      "2018-09-02 03:50:28.997791 Training Step 2575 \"min loss\" =  3.5662894\n",
      "2018-09-02 03:50:28.997865 Training Step 2575 \"loss\" =  4.0932508\n",
      "2018-09-02 03:50:29.665594 Test Step 2580 Finished\n",
      "2018-09-02 03:50:29.665713 Test Step 2580 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:29.666344 Test Step 2580 \"loss\" =  7.7432575\n",
      "2018-09-02 03:50:29.818458 Training Step 2580 Finished Timing (Training: 0.919363, Test: 0.0791241) after 0.820504 seconds\n",
      "2018-09-02 03:50:29.818527 Training Step 2580 \"min loss\" =  3.5662894\n",
      "2018-09-02 03:50:29.818578 Training Step 2580 \"loss\" =  3.7683656\n",
      "2018-09-02 03:50:30.479005 Test Step 2585 Finished\n",
      "2018-09-02 03:50:30.479132 Test Step 2585 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:30.479191 Test Step 2585 \"loss\" =  7.412491\n",
      "2018-09-02 03:50:30.633843 Training Step 2585 Finished Timing (Training: 0.919271, Test: 0.0792709) after 0.815207 seconds\n",
      "2018-09-02 03:50:30.633903 Training Step 2585 \"min loss\" =  3.5662894\n",
      "2018-09-02 03:50:30.634289 Training Step 2585 \"loss\" =  4.130802\n",
      "2018-09-02 03:50:31.292392 Test Step 2590 Finished\n",
      "2018-09-02 03:50:31.292529 Test Step 2590 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:31.293272 Test Step 2590 \"loss\" =  7.7513027\n",
      "2018-09-02 03:50:31.446382 Training Step 2590 Finished Timing (Training: 0.919396, Test: 0.0791001) after 0.811822 seconds\n",
      "2018-09-02 03:50:31.446442 Training Step 2590 \"min loss\" =  3.5662894\n",
      "2018-09-02 03:50:31.446490 Training Step 2590 \"loss\" =  3.9550228\n",
      "2018-09-02 03:50:32.100139 Test Step 2595 Finished\n",
      "2018-09-02 03:50:32.100256 Test Step 2595 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:32.100328 Test Step 2595 \"loss\" =  8.099752\n",
      "2018-09-02 03:50:32.255751 Training Step 2595 Finished Timing (Training: 0.919363, Test: 0.0791044) after 0.808645 seconds\n",
      "2018-09-02 03:50:32.256081 Training Step 2595 \"min loss\" =  3.5662894\n",
      "2018-09-02 03:50:32.256139 Training Step 2595 \"loss\" =  4.0076923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:50:32.922129 Test Step 2600 Finished\n",
      "2018-09-02 03:50:32.922589 Test Step 2600 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:32.922781 Test Step 2600 \"loss\" =  7.499942\n",
      "2018-09-02 03:50:33.076928 Training Step 2600 Finished Timing (Training: 0.919141, Test: 0.0792953) after 0.820392 seconds\n",
      "2018-09-02 03:50:33.077133 Training Step 2600 \"min loss\" =  3.5662894\n",
      "2018-09-02 03:50:33.077185 Training Step 2600 \"loss\" =  3.8988664\n",
      "2018-09-02 03:50:33.750423 Test Step 2605 Finished\n",
      "2018-09-02 03:50:33.750536 Test Step 2605 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:33.751009 Test Step 2605 \"loss\" =  7.463138\n",
      "2018-09-02 03:50:33.901852 Training Step 2605 Finished Timing (Training: 0.916696, Test: 0.0822016) after 0.824095 seconds\n",
      "2018-09-02 03:50:33.901939 Training Step 2605 \"min loss\" =  3.5662894\n",
      "2018-09-02 03:50:33.902340 Training Step 2605 \"loss\" =  4.252719\n",
      "2018-09-02 03:50:34.561125 Test Step 2610 Finished\n",
      "2018-09-02 03:50:34.561243 Test Step 2610 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:34.561886 Test Step 2610 \"loss\" =  7.8998947\n",
      "2018-09-02 03:50:34.714682 Training Step 2610 Finished Timing (Training: 0.918975, Test: 0.0796135) after 0.812277 seconds\n",
      "2018-09-02 03:50:34.714744 Training Step 2610 \"min loss\" =  3.5662894\n",
      "2018-09-02 03:50:34.715167 Training Step 2610 \"loss\" =  3.716351\n",
      "2018-09-02 03:50:35.371072 Test Step 2615 Finished\n",
      "2018-09-02 03:50:35.371497 Test Step 2615 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:35.371561 Test Step 2615 \"loss\" =  7.2406964\n",
      "2018-09-02 03:50:35.518506 Training Step 2615 Finished Timing (Training: 0.919309, Test: 0.0790726) after 0.80328 seconds\n",
      "2018-09-02 03:50:35.518751 Training Step 2615 \"min loss\" =  3.5662894\n",
      "2018-09-02 03:50:35.518941 Training Step 2615 \"loss\" =  3.8921537\n",
      "2018-09-02 03:50:36.173650 Test Step 2620 Finished\n",
      "2018-09-02 03:50:36.173753 Test Step 2620 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:36.173809 Test Step 2620 \"loss\" =  7.8737555\n",
      "2018-09-02 03:50:36.320586 Training Step 2620 Finished Timing (Training: 0.921118, Test: 0.0774379) after 0.801586 seconds\n",
      "2018-09-02 03:50:36.320665 Training Step 2620 \"min loss\" =  3.5662894\n",
      "2018-09-02 03:50:36.320715 Training Step 2620 \"loss\" =  3.8990495\n",
      "2018-09-02 03:50:36.965983 Test Step 2625 Finished\n",
      "2018-09-02 03:50:36.966100 Test Step 2625 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:36.966582 Test Step 2625 \"loss\" =  8.087419\n",
      "2018-09-02 03:50:37.119205 Training Step 2625 Finished Timing (Training: 0.920319, Test: 0.078306) after 0.798431 seconds\n",
      "2018-09-02 03:50:37.119270 Training Step 2625 \"min loss\" =  3.5662894\n",
      "2018-09-02 03:50:37.119320 Training Step 2625 \"loss\" =  3.8639617\n",
      "2018-09-02 03:50:37.787821 Test Step 2630 Finished\n",
      "2018-09-02 03:50:37.787940 Test Step 2630 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:37.788509 Test Step 2630 \"loss\" =  7.907119\n",
      "2018-09-02 03:50:37.940619 Training Step 2630 Finished Timing (Training: 0.920205, Test: 0.0784573) after 0.821243 seconds\n",
      "2018-09-02 03:50:37.940685 Training Step 2630 \"min loss\" =  3.5662894\n",
      "2018-09-02 03:50:37.940726 Training Step 2630 \"loss\" =  3.780509\n",
      "2018-09-02 03:50:38.606613 Test Step 2635 Finished\n",
      "2018-09-02 03:50:38.607032 Test Step 2635 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:38.607249 Test Step 2635 \"loss\" =  7.382798\n",
      "2018-09-02 03:50:38.755645 Training Step 2635 Finished Timing (Training: 0.919738, Test: 0.0789559) after 0.814833 seconds\n",
      "2018-09-02 03:50:38.755805 Training Step 2635 \"min loss\" =  3.5662894\n",
      "2018-09-02 03:50:38.755863 Training Step 2635 \"loss\" =  3.7768862\n",
      "2018-09-02 03:50:39.422052 Test Step 2640 Finished\n",
      "2018-09-02 03:50:39.422148 Test Step 2640 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:39.422562 Test Step 2640 \"loss\" =  7.530594\n",
      "2018-09-02 03:50:39.568448 Training Step 2640 Finished Timing (Training: 0.919753, Test: 0.0789691) after 0.812526 seconds\n",
      "2018-09-02 03:50:39.568521 Training Step 2640 \"min loss\" =  3.5662894\n",
      "2018-09-02 03:50:39.568577 Training Step 2640 \"loss\" =  3.9467092\n",
      "2018-09-02 03:50:40.223592 Test Step 2645 Finished\n",
      "2018-09-02 03:50:40.223676 Test Step 2645 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:40.223732 Test Step 2645 \"loss\" =  7.367501\n",
      "2018-09-02 03:50:40.373596 Training Step 2645 Finished Timing (Training: 0.919828, Test: 0.0788771) after 0.804969 seconds\n",
      "2018-09-02 03:50:40.373658 Training Step 2645 \"min loss\" =  3.5662894\n",
      "2018-09-02 03:50:40.373726 Training Step 2645 \"loss\" =  4.31865\n",
      "2018-09-02 03:50:41.040232 Test Step 2650 Finished\n",
      "2018-09-02 03:50:41.040333 Test Step 2650 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:41.040815 Test Step 2650 \"loss\" =  7.737737\n",
      "2018-09-02 03:50:41.191728 Training Step 2650 Finished Timing (Training: 0.91987, Test: 0.0788547) after 0.817927 seconds\n",
      "2018-09-02 03:50:41.191790 Training Step 2650 \"min loss\" =  3.5662894\n",
      "2018-09-02 03:50:41.191841 Training Step 2650 \"loss\" =  3.8880708\n",
      "2018-09-02 03:50:41.862300 Test Step 2655 Finished\n",
      "2018-09-02 03:50:41.862408 Test Step 2655 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:41.863181 Test Step 2655 \"loss\" =  8.027291\n",
      "2018-09-02 03:50:42.009803 Training Step 2655 Finished Timing (Training: 0.919689, Test: 0.07895) after 0.817252 seconds\n",
      "2018-09-02 03:50:42.009921 Training Step 2655 \"min loss\" =  3.5662894\n",
      "2018-09-02 03:50:42.009985 Training Step 2655 \"loss\" =  3.79899\n",
      "2018-09-02 03:50:42.666648 Test Step 2660 Finished\n",
      "2018-09-02 03:50:42.667075 Test Step 2660 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:42.667656 Test Step 2660 \"loss\" =  7.409884\n",
      "2018-09-02 03:50:42.815474 Training Step 2660 Finished Timing (Training: 0.919505, Test: 0.0790773) after 0.805402 seconds\n",
      "2018-09-02 03:50:42.815552 Training Step 2660 \"min loss\" =  3.5662894\n",
      "2018-09-02 03:50:42.816167 Training Step 2660 \"loss\" =  4.34239\n",
      "2018-09-02 03:50:43.478901 Test Step 2665 Finished\n",
      "2018-09-02 03:50:43.479005 Test Step 2665 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:43.479627 Test Step 2665 \"loss\" =  7.827921\n",
      "2018-09-02 03:50:43.630114 Training Step 2665 Finished Timing (Training: 0.919135, Test: 0.079368) after 0.813481 seconds\n",
      "2018-09-02 03:50:43.630180 Training Step 2665 \"min loss\" =  3.5662894\n",
      "2018-09-02 03:50:43.630234 Training Step 2665 \"loss\" =  3.748698\n",
      "2018-09-02 03:50:44.295149 Test Step 2670 Finished\n",
      "2018-09-02 03:50:44.295296 Test Step 2670 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:44.295354 Test Step 2670 \"loss\" =  7.454399\n",
      "2018-09-02 03:50:44.450026 Training Step 2670 Finished Timing (Training: 0.919279, Test: 0.079173) after 0.819079 seconds\n",
      "2018-09-02 03:50:44.450096 Training Step 2670 \"min loss\" =  3.5662894\n",
      "2018-09-02 03:50:44.450149 Training Step 2670 \"loss\" =  4.107312\n",
      "2018-09-02 03:50:45.106880 Test Step 2675 Finished\n",
      "2018-09-02 03:50:45.107007 Test Step 2675 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:45.107566 Test Step 2675 \"loss\" =  7.347869\n",
      "2018-09-02 03:50:45.263390 Training Step 2675 Finished Timing (Training: 0.919193, Test: 0.0792413) after 0.812665 seconds\n",
      "2018-09-02 03:50:45.263473 Training Step 2675 \"min loss\" =  3.5662894\n",
      "2018-09-02 03:50:45.263570 Training Step 2675 \"loss\" =  3.884924\n",
      "2018-09-02 03:50:45.941899 Test Step 2680 Finished\n",
      "2018-09-02 03:50:45.942036 Test Step 2680 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:45.942126 Test Step 2680 \"loss\" =  7.212284\n",
      "2018-09-02 03:50:46.094507 Training Step 2680 Finished Timing (Training: 0.919211, Test: 0.0792135) after 0.830875 seconds\n",
      "2018-09-02 03:50:46.094572 Training Step 2680 \"min loss\" =  3.5662894\n",
      "2018-09-02 03:50:46.094629 Training Step 2680 \"loss\" =  3.8040223\n",
      "2018-09-02 03:50:46.747602 Test Step 2685 Finished\n",
      "2018-09-02 03:50:46.748095 Test Step 2685 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:46.748173 Test Step 2685 \"loss\" =  7.3460402\n",
      "2018-09-02 03:50:46.893461 Training Step 2685 Finished Timing (Training: 0.91902, Test: 0.0794071) after 0.798769 seconds\n",
      "2018-09-02 03:50:46.893556 Training Step 2685 \"min loss\" =  3.5662894\n",
      "2018-09-02 03:50:46.893930 Training Step 2685 \"loss\" =  3.7702637\n",
      "2018-09-02 03:50:47.558165 Test Step 2690 Finished\n",
      "2018-09-02 03:50:47.558649 Test Step 2690 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:47.558712 Test Step 2690 \"loss\" =  7.5887175\n",
      "2018-09-02 03:50:47.708810 Training Step 2690 Finished Timing (Training: 0.919066, Test: 0.0793687) after 0.814821 seconds\n",
      "2018-09-02 03:50:47.709063 Training Step 2690 \"min loss\" =  3.5662894\n",
      "2018-09-02 03:50:47.709117 Training Step 2690 \"loss\" =  3.6889198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:50:48.380778 Test Step 2695 Finished\n",
      "2018-09-02 03:50:48.380898 Test Step 2695 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:48.381548 Test Step 2695 \"loss\" =  8.091732\n",
      "2018-09-02 03:50:48.538801 Training Step 2695 Finished Timing (Training: 0.919134, Test: 0.0792965) after 0.829627 seconds\n",
      "2018-09-02 03:50:48.538885 Training Step 2695 \"min loss\" =  3.5662894\n",
      "2018-09-02 03:50:48.538938 Training Step 2695 \"loss\" =  3.7849183\n",
      "2018-09-02 03:50:49.204206 Test Step 2700 Finished\n",
      "2018-09-02 03:50:49.204311 Test Step 2700 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:49.204942 Test Step 2700 \"loss\" =  7.4792414\n",
      "2018-09-02 03:50:49.352542 Training Step 2700 Finished Timing (Training: 0.918928, Test: 0.0794776) after 0.813022 seconds\n",
      "2018-09-02 03:50:49.352627 Training Step 2700 \"min loss\" =  3.5662894\n",
      "2018-09-02 03:50:49.352680 Training Step 2700 \"loss\" =  4.050746\n",
      "2018-09-02 03:50:50.012005 Test Step 2705 Finished\n",
      "2018-09-02 03:50:50.012118 Test Step 2705 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:50.012767 Test Step 2705 \"loss\" =  7.401605\n",
      "2018-09-02 03:50:50.166902 Training Step 2705 Finished Timing (Training: 0.921586, Test: 0.0773711) after 0.814158 seconds\n",
      "2018-09-02 03:50:50.166962 Training Step 2705 \"min loss\" =  3.5629597\n",
      "2018-09-02 03:50:50.167301 Training Step 2705 \"loss\" =  3.5629597\n",
      "2018-09-02 03:50:50.838527 Test Step 2710 Finished\n",
      "2018-09-02 03:50:50.838628 Test Step 2710 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:50.839179 Test Step 2710 \"loss\" =  7.574579\n",
      "2018-09-02 03:50:50.984931 Training Step 2710 Finished Timing (Training: 0.919773, Test: 0.0789767) after 0.817568 seconds\n",
      "2018-09-02 03:50:50.985030 Training Step 2710 \"min loss\" =  3.5629597\n",
      "2018-09-02 03:50:50.985086 Training Step 2710 \"loss\" =  4.156376\n",
      "2018-09-02 03:50:51.643299 Test Step 2715 Finished\n",
      "2018-09-02 03:50:51.643420 Test Step 2715 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:51.644008 Test Step 2715 \"loss\" =  7.236981\n",
      "2018-09-02 03:50:51.794357 Training Step 2715 Finished Timing (Training: 0.921171, Test: 0.0775727) after 0.809194 seconds\n",
      "2018-09-02 03:50:51.794452 Training Step 2715 \"min loss\" =  3.5629597\n",
      "2018-09-02 03:50:51.794921 Training Step 2715 \"loss\" =  4.111477\n",
      "2018-09-02 03:50:52.460153 Test Step 2720 Finished\n",
      "2018-09-02 03:50:52.460302 Test Step 2720 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:52.460826 Test Step 2720 \"loss\" =  7.5020185\n",
      "2018-09-02 03:50:52.608770 Training Step 2720 Finished Timing (Training: 0.920001, Test: 0.0786291) after 0.813788 seconds\n",
      "2018-09-02 03:50:52.608833 Training Step 2720 \"min loss\" =  3.5629597\n",
      "2018-09-02 03:50:52.609289 Training Step 2720 \"loss\" =  3.8988724\n",
      "2018-09-02 03:50:53.275041 Test Step 2725 Finished\n",
      "2018-09-02 03:50:53.275174 Test Step 2725 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:53.275234 Test Step 2725 \"loss\" =  8.235116\n",
      "2018-09-02 03:50:53.422380 Training Step 2725 Finished Timing (Training: 0.919267, Test: 0.0792106) after 0.812851 seconds\n",
      "2018-09-02 03:50:53.422444 Training Step 2725 \"min loss\" =  3.5629597\n",
      "2018-09-02 03:50:53.422492 Training Step 2725 \"loss\" =  4.116308\n",
      "2018-09-02 03:50:54.085265 Test Step 2730 Finished\n",
      "2018-09-02 03:50:54.085388 Test Step 2730 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:54.086006 Test Step 2730 \"loss\" =  7.7021294\n",
      "2018-09-02 03:50:54.235824 Training Step 2730 Finished Timing (Training: 0.918607, Test: 0.0798925) after 0.81327 seconds\n",
      "2018-09-02 03:50:54.235884 Training Step 2730 \"min loss\" =  3.5553687\n",
      "2018-09-02 03:50:54.236387 Training Step 2730 \"loss\" =  3.5553687\n",
      "2018-09-02 03:50:54.897530 Test Step 2735 Finished\n",
      "2018-09-02 03:50:54.897637 Test Step 2735 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:54.897696 Test Step 2735 \"loss\" =  7.5874767\n",
      "2018-09-02 03:50:55.049489 Training Step 2735 Finished Timing (Training: 0.918912, Test: 0.0796223) after 0.812914 seconds\n",
      "2018-09-02 03:50:55.049543 Training Step 2735 \"min loss\" =  3.5553687\n",
      "2018-09-02 03:50:55.049907 Training Step 2735 \"loss\" =  4.1101937\n",
      "2018-09-02 03:50:55.714994 Test Step 2740 Finished\n",
      "2018-09-02 03:50:55.715096 Test Step 2740 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:55.715154 Test Step 2740 \"loss\" =  7.3403625\n",
      "2018-09-02 03:50:55.864933 Training Step 2740 Finished Timing (Training: 0.918941, Test: 0.0795703) after 0.814965 seconds\n",
      "2018-09-02 03:50:55.864994 Training Step 2740 \"min loss\" =  3.5553687\n",
      "2018-09-02 03:50:55.865307 Training Step 2740 \"loss\" =  4.1964874\n",
      "2018-09-02 03:50:56.527020 Test Step 2745 Finished\n",
      "2018-09-02 03:50:56.527156 Test Step 2745 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:56.528035 Test Step 2745 \"loss\" =  7.878316\n",
      "2018-09-02 03:50:56.679974 Training Step 2745 Finished Timing (Training: 0.91923, Test: 0.0791985) after 0.814608 seconds\n",
      "2018-09-02 03:50:56.680053 Training Step 2745 \"min loss\" =  3.5553687\n",
      "2018-09-02 03:50:56.680670 Training Step 2745 \"loss\" =  3.8950994\n",
      "2018-09-02 03:50:57.340018 Test Step 2750 Finished\n",
      "2018-09-02 03:50:57.340179 Test Step 2750 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:57.341185 Test Step 2750 \"loss\" =  7.328577\n",
      "2018-09-02 03:50:57.495906 Training Step 2750 Finished Timing (Training: 0.919315, Test: 0.0789667) after 0.814772 seconds\n",
      "2018-09-02 03:50:57.496278 Training Step 2750 \"min loss\" =  3.5553687\n",
      "2018-09-02 03:50:57.496726 Training Step 2750 \"loss\" =  3.9185011\n",
      "2018-09-02 03:50:58.166248 Test Step 2755 Finished\n",
      "2018-09-02 03:50:58.166364 Test Step 2755 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:58.167220 Test Step 2755 \"loss\" =  7.5941596\n",
      "2018-09-02 03:50:58.316047 Training Step 2755 Finished Timing (Training: 0.919044, Test: 0.0791024) after 0.818904 seconds\n",
      "2018-09-02 03:50:58.316127 Training Step 2755 \"min loss\" =  3.5553687\n",
      "2018-09-02 03:50:58.316730 Training Step 2755 \"loss\" =  3.8222246\n",
      "2018-09-02 03:50:58.985321 Test Step 2760 Finished\n",
      "2018-09-02 03:50:58.985764 Test Step 2760 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:58.986170 Test Step 2760 \"loss\" =  7.7628727\n",
      "2018-09-02 03:50:59.142946 Training Step 2760 Finished Timing (Training: 0.918823, Test: 0.0792955) after 0.826106 seconds\n",
      "2018-09-02 03:50:59.143301 Training Step 2760 \"min loss\" =  3.5553687\n",
      "2018-09-02 03:50:59.143641 Training Step 2760 \"loss\" =  3.8471398\n",
      "2018-09-02 03:50:59.794137 Test Step 2765 Finished\n",
      "2018-09-02 03:50:59.794311 Test Step 2765 \"min loss\" =  7.008738\n",
      "2018-09-02 03:50:59.795173 Test Step 2765 \"loss\" =  7.921598\n",
      "2018-09-02 03:50:59.943075 Training Step 2765 Finished Timing (Training: 0.91923, Test: 0.0787677) after 0.798861 seconds\n",
      "2018-09-02 03:50:59.943468 Training Step 2765 \"min loss\" =  3.5553687\n",
      "2018-09-02 03:50:59.943945 Training Step 2765 \"loss\" =  3.788296\n",
      "2018-09-02 03:51:00.607896 Test Step 2770 Finished\n",
      "2018-09-02 03:51:00.608046 Test Step 2770 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:00.608953 Test Step 2770 \"loss\" =  7.3300796\n",
      "2018-09-02 03:51:00.762426 Training Step 2770 Finished Timing (Training: 0.919215, Test: 0.0787157) after 0.818125 seconds\n",
      "2018-09-02 03:51:00.762506 Training Step 2770 \"min loss\" =  3.5553687\n",
      "2018-09-02 03:51:00.763221 Training Step 2770 \"loss\" =  4.0492406\n",
      "2018-09-02 03:51:01.435269 Test Step 2775 Finished\n",
      "2018-09-02 03:51:01.435397 Test Step 2775 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:01.436298 Test Step 2775 \"loss\" =  8.356903\n",
      "2018-09-02 03:51:01.590909 Training Step 2775 Finished Timing (Training: 0.918771, Test: 0.07911) after 0.827585 seconds\n",
      "2018-09-02 03:51:01.591237 Training Step 2775 \"min loss\" =  3.5553687\n",
      "2018-09-02 03:51:01.591329 Training Step 2775 \"loss\" =  3.9951565\n",
      "2018-09-02 03:51:02.253550 Test Step 2780 Finished\n",
      "2018-09-02 03:51:02.253696 Test Step 2780 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:02.253814 Test Step 2780 \"loss\" =  7.7617316\n",
      "2018-09-02 03:51:02.405923 Training Step 2780 Finished Timing (Training: 0.918817, Test: 0.0790673) after 0.813718 seconds\n",
      "2018-09-02 03:51:02.406084 Training Step 2780 \"min loss\" =  3.5347595\n",
      "2018-09-02 03:51:02.406883 Training Step 2780 \"loss\" =  4.333226\n",
      "2018-09-02 03:51:03.064906 Test Step 2785 Finished\n",
      "2018-09-02 03:51:03.065029 Test Step 2785 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:03.065121 Test Step 2785 \"loss\" =  7.736735\n",
      "2018-09-02 03:51:03.214547 Training Step 2785 Finished Timing (Training: 0.918749, Test: 0.079158) after 0.807554 seconds\n",
      "2018-09-02 03:51:03.214633 Training Step 2785 \"min loss\" =  3.5347595\n",
      "2018-09-02 03:51:03.214686 Training Step 2785 \"loss\" =  3.6353936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:51:03.872398 Test Step 2790 Finished\n",
      "2018-09-02 03:51:03.872905 Test Step 2790 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:03.872972 Test Step 2790 \"loss\" =  8.069674\n",
      "2018-09-02 03:51:04.020293 Training Step 2790 Finished Timing (Training: 0.918742, Test: 0.0791641) after 0.804713 seconds\n",
      "2018-09-02 03:51:04.020406 Training Step 2790 \"min loss\" =  3.5347595\n",
      "2018-09-02 03:51:04.020461 Training Step 2790 \"loss\" =  3.7864377\n",
      "2018-09-02 03:51:04.685815 Test Step 2795 Finished\n",
      "2018-09-02 03:51:04.685921 Test Step 2795 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:04.685983 Test Step 2795 \"loss\" =  7.3628616\n",
      "2018-09-02 03:51:04.836505 Training Step 2795 Finished Timing (Training: 0.91869, Test: 0.0792494) after 0.815971 seconds\n",
      "2018-09-02 03:51:04.836643 Training Step 2795 \"min loss\" =  3.5347595\n",
      "2018-09-02 03:51:04.836698 Training Step 2795 \"loss\" =  3.7988334\n",
      "2018-09-02 03:51:05.496614 Test Step 2800 Finished\n",
      "2018-09-02 03:51:05.496720 Test Step 2800 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:05.497231 Test Step 2800 \"loss\" =  8.045359\n",
      "2018-09-02 03:51:05.647989 Training Step 2800 Finished Timing (Training: 0.918686, Test: 0.0792961) after 0.811217 seconds\n",
      "2018-09-02 03:51:05.648048 Training Step 2800 \"min loss\" =  3.5175145\n",
      "2018-09-02 03:51:05.648456 Training Step 2800 \"loss\" =  4.2690473\n",
      "2018-09-02 03:51:06.318986 Test Step 2805 Finished\n",
      "2018-09-02 03:51:06.319089 Test Step 2805 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:06.319580 Test Step 2805 \"loss\" =  8.055009\n",
      "2018-09-02 03:51:06.473836 Training Step 2805 Finished Timing (Training: 0.918449, Test: 0.0807344) after 0.825307 seconds\n",
      "2018-09-02 03:51:06.473976 Training Step 2805 \"min loss\" =  3.5175145\n",
      "2018-09-02 03:51:06.474048 Training Step 2805 \"loss\" =  3.8772187\n",
      "2018-09-02 03:51:07.151834 Test Step 2810 Finished\n",
      "2018-09-02 03:51:07.151926 Test Step 2810 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:07.152398 Test Step 2810 \"loss\" =  7.233995\n",
      "2018-09-02 03:51:07.301191 Training Step 2810 Finished Timing (Training: 0.916477, Test: 0.0825504) after 0.827085 seconds\n",
      "2018-09-02 03:51:07.301286 Training Step 2810 \"min loss\" =  3.5175145\n",
      "2018-09-02 03:51:07.301687 Training Step 2810 \"loss\" =  3.7084672\n",
      "2018-09-02 03:51:07.974256 Test Step 2815 Finished\n",
      "2018-09-02 03:51:07.974366 Test Step 2815 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:07.974438 Test Step 2815 \"loss\" =  7.513401\n",
      "2018-09-02 03:51:08.120937 Training Step 2815 Finished Timing (Training: 0.91718, Test: 0.081837) after 0.819177 seconds\n",
      "2018-09-02 03:51:08.121073 Training Step 2815 \"min loss\" =  3.5175145\n",
      "2018-09-02 03:51:08.121165 Training Step 2815 \"loss\" =  3.7905796\n",
      "2018-09-02 03:51:08.797000 Test Step 2820 Finished\n",
      "2018-09-02 03:51:08.797087 Test Step 2820 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:08.797322 Test Step 2820 \"loss\" =  7.5663977\n",
      "2018-09-02 03:51:08.949308 Training Step 2820 Finished Timing (Training: 0.916972, Test: 0.0820733) after 0.828068 seconds\n",
      "2018-09-02 03:51:08.949400 Training Step 2820 \"min loss\" =  3.5175145\n",
      "2018-09-02 03:51:08.949455 Training Step 2820 \"loss\" =  3.842254\n",
      "2018-09-02 03:51:09.613089 Test Step 2825 Finished\n",
      "2018-09-02 03:51:09.613183 Test Step 2825 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:09.613240 Test Step 2825 \"loss\" =  7.307957\n",
      "2018-09-02 03:51:09.768731 Training Step 2825 Finished Timing (Training: 0.918242, Test: 0.0806948) after 0.819218 seconds\n",
      "2018-09-02 03:51:09.768814 Training Step 2825 \"min loss\" =  3.5175145\n",
      "2018-09-02 03:51:09.768871 Training Step 2825 \"loss\" =  3.8926852\n",
      "2018-09-02 03:51:10.430962 Test Step 2830 Finished\n",
      "2018-09-02 03:51:10.431070 Test Step 2830 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:10.431141 Test Step 2830 \"loss\" =  7.2836437\n",
      "2018-09-02 03:51:10.581869 Training Step 2830 Finished Timing (Training: 0.918321, Test: 0.0805452) after 0.812937 seconds\n",
      "2018-09-02 03:51:10.581948 Training Step 2830 \"min loss\" =  3.4407382\n",
      "2018-09-02 03:51:10.582023 Training Step 2830 \"loss\" =  3.4407382\n",
      "2018-09-02 03:51:11.247350 Test Step 2835 Finished\n",
      "2018-09-02 03:51:11.247802 Test Step 2835 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:11.248214 Test Step 2835 \"loss\" =  7.359983\n",
      "2018-09-02 03:51:11.399672 Training Step 2835 Finished Timing (Training: 0.918221, Test: 0.080563) after 0.81757 seconds\n",
      "2018-09-02 03:51:11.399766 Training Step 2835 \"min loss\" =  3.4407382\n",
      "2018-09-02 03:51:11.399822 Training Step 2835 \"loss\" =  3.6758373\n",
      "2018-09-02 03:51:12.058450 Test Step 2840 Finished\n",
      "2018-09-02 03:51:12.058552 Test Step 2840 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:12.058609 Test Step 2840 \"loss\" =  7.617376\n",
      "2018-09-02 03:51:12.208686 Training Step 2840 Finished Timing (Training: 0.91855, Test: 0.0803089) after 0.808787 seconds\n",
      "2018-09-02 03:51:12.208761 Training Step 2840 \"min loss\" =  3.4407382\n",
      "2018-09-02 03:51:12.208815 Training Step 2840 \"loss\" =  3.716448\n",
      "2018-09-02 03:51:12.864446 Test Step 2845 Finished\n",
      "2018-09-02 03:51:12.864552 Test Step 2845 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:12.864611 Test Step 2845 \"loss\" =  7.2789226\n",
      "2018-09-02 03:51:13.016671 Training Step 2845 Finished Timing (Training: 0.919949, Test: 0.0789739) after 0.807798 seconds\n",
      "2018-09-02 03:51:13.016735 Training Step 2845 \"min loss\" =  3.4407382\n",
      "2018-09-02 03:51:13.016788 Training Step 2845 \"loss\" =  3.886436\n",
      "2018-09-02 03:51:13.683230 Test Step 2850 Finished\n",
      "2018-09-02 03:51:13.683606 Test Step 2850 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:13.683805 Test Step 2850 \"loss\" =  8.055287\n",
      "2018-09-02 03:51:13.833885 Training Step 2850 Finished Timing (Training: 0.91992, Test: 0.0790069) after 0.81704 seconds\n",
      "2018-09-02 03:51:13.834101 Training Step 2850 \"min loss\" =  3.4407382\n",
      "2018-09-02 03:51:13.834156 Training Step 2850 \"loss\" =  4.161021\n",
      "2018-09-02 03:51:14.493742 Test Step 2855 Finished\n",
      "2018-09-02 03:51:14.493893 Test Step 2855 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:14.493945 Test Step 2855 \"loss\" =  7.2618165\n",
      "2018-09-02 03:51:14.640051 Training Step 2855 Finished Timing (Training: 0.919795, Test: 0.0791565) after 0.805835 seconds\n",
      "2018-09-02 03:51:14.640145 Training Step 2855 \"min loss\" =  3.4407382\n",
      "2018-09-02 03:51:14.640204 Training Step 2855 \"loss\" =  3.6826959\n",
      "2018-09-02 03:51:15.294550 Test Step 2860 Finished\n",
      "2018-09-02 03:51:15.294678 Test Step 2860 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:15.295220 Test Step 2860 \"loss\" =  7.3676753\n",
      "2018-09-02 03:51:15.442964 Training Step 2860 Finished Timing (Training: 0.919704, Test: 0.0792325) after 0.802688 seconds\n",
      "2018-09-02 03:51:15.443064 Training Step 2860 \"min loss\" =  3.4407382\n",
      "2018-09-02 03:51:15.443544 Training Step 2860 \"loss\" =  3.9385633\n",
      "2018-09-02 03:51:16.103388 Test Step 2865 Finished\n",
      "2018-09-02 03:51:16.103517 Test Step 2865 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:16.103576 Test Step 2865 \"loss\" =  7.512573\n",
      "2018-09-02 03:51:16.252366 Training Step 2865 Finished Timing (Training: 0.91958, Test: 0.0792425) after 0.808414 seconds\n",
      "2018-09-02 03:51:16.252837 Training Step 2865 \"min loss\" =  3.4407382\n",
      "2018-09-02 03:51:16.253109 Training Step 2865 \"loss\" =  3.599834\n",
      "2018-09-02 03:51:16.921239 Test Step 2870 Finished\n",
      "2018-09-02 03:51:16.921685 Test Step 2870 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:16.921880 Test Step 2870 \"loss\" =  8.117298\n",
      "2018-09-02 03:51:17.070759 Training Step 2870 Finished Timing (Training: 0.919568, Test: 0.0791795) after 0.817571 seconds\n",
      "2018-09-02 03:51:17.070891 Training Step 2870 \"min loss\" =  3.4407382\n",
      "2018-09-02 03:51:17.071611 Training Step 2870 \"loss\" =  3.6031606\n",
      "2018-09-02 03:51:17.738813 Test Step 2875 Finished\n",
      "2018-09-02 03:51:17.739317 Test Step 2875 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:17.739380 Test Step 2875 \"loss\" =  7.7418885\n",
      "2018-09-02 03:51:17.888110 Training Step 2875 Finished Timing (Training: 0.91933, Test: 0.0793604) after 0.816294 seconds\n",
      "2018-09-02 03:51:17.888178 Training Step 2875 \"min loss\" =  3.4407382\n",
      "2018-09-02 03:51:17.888236 Training Step 2875 \"loss\" =  3.6801157\n",
      "2018-09-02 03:51:18.548387 Test Step 2880 Finished\n",
      "2018-09-02 03:51:18.548500 Test Step 2880 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:18.549082 Test Step 2880 \"loss\" =  7.5336213\n",
      "2018-09-02 03:51:18.697801 Training Step 2880 Finished Timing (Training: 0.919643, Test: 0.079054) after 0.809508 seconds\n",
      "2018-09-02 03:51:18.697864 Training Step 2880 \"min loss\" =  3.4407382\n",
      "2018-09-02 03:51:18.697920 Training Step 2880 \"loss\" =  4.036577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:51:19.366912 Test Step 2885 Finished\n",
      "2018-09-02 03:51:19.367001 Test Step 2885 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:19.367686 Test Step 2885 \"loss\" =  8.093707\n",
      "2018-09-02 03:51:19.516355 Training Step 2885 Finished Timing (Training: 0.919326, Test: 0.0793356) after 0.81793 seconds\n",
      "2018-09-02 03:51:19.516424 Training Step 2885 \"min loss\" =  3.4093852\n",
      "2018-09-02 03:51:19.516474 Training Step 2885 \"loss\" =  3.6974194\n",
      "2018-09-02 03:51:20.168714 Test Step 2890 Finished\n",
      "2018-09-02 03:51:20.168800 Test Step 2890 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:20.168862 Test Step 2890 \"loss\" =  7.6905684\n",
      "2018-09-02 03:51:20.319890 Training Step 2890 Finished Timing (Training: 0.919545, Test: 0.0791596) after 0.803359 seconds\n",
      "2018-09-02 03:51:20.319954 Training Step 2890 \"min loss\" =  3.4093852\n",
      "2018-09-02 03:51:20.320011 Training Step 2890 \"loss\" =  3.565707\n",
      "2018-09-02 03:51:20.990613 Test Step 2895 Finished\n",
      "2018-09-02 03:51:20.991039 Test Step 2895 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:20.991104 Test Step 2895 \"loss\" =  7.4943123\n",
      "2018-09-02 03:51:21.134559 Training Step 2895 Finished Timing (Training: 0.919647, Test: 0.0790509) after 0.814083 seconds\n",
      "2018-09-02 03:51:21.134625 Training Step 2895 \"min loss\" =  3.4093852\n",
      "2018-09-02 03:51:21.135072 Training Step 2895 \"loss\" =  3.6463647\n",
      "2018-09-02 03:51:21.803493 Test Step 2900 Finished\n",
      "2018-09-02 03:51:21.803982 Test Step 2900 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:21.804046 Test Step 2900 \"loss\" =  7.5251255\n",
      "2018-09-02 03:51:21.956003 Training Step 2900 Finished Timing (Training: 0.919737, Test: 0.0789512) after 0.820861 seconds\n",
      "2018-09-02 03:51:21.956073 Training Step 2900 \"min loss\" =  3.4093852\n",
      "2018-09-02 03:51:21.956114 Training Step 2900 \"loss\" =  3.7382238\n",
      "2018-09-02 03:51:22.618014 Test Step 2905 Finished\n",
      "2018-09-02 03:51:22.618427 Test Step 2905 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:22.618816 Test Step 2905 \"loss\" =  7.353629\n",
      "2018-09-02 03:51:22.765965 Training Step 2905 Finished Timing (Training: 0.924032, Test: 0.0748255) after 0.809783 seconds\n",
      "2018-09-02 03:51:22.766091 Training Step 2905 \"min loss\" =  3.4093852\n",
      "2018-09-02 03:51:22.766168 Training Step 2905 \"loss\" =  3.8718925\n",
      "2018-09-02 03:51:23.439237 Test Step 2910 Finished\n",
      "2018-09-02 03:51:23.439349 Test Step 2910 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:23.439413 Test Step 2910 \"loss\" =  7.5283513\n",
      "2018-09-02 03:51:23.589085 Training Step 2910 Finished Timing (Training: 0.923681, Test: 0.0753879) after 0.822823 seconds\n",
      "2018-09-02 03:51:23.589183 Training Step 2910 \"min loss\" =  3.4093852\n",
      "2018-09-02 03:51:23.589224 Training Step 2910 \"loss\" =  3.9221988\n",
      "2018-09-02 03:51:24.249662 Test Step 2915 Finished\n",
      "2018-09-02 03:51:24.249774 Test Step 2915 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:24.250481 Test Step 2915 \"loss\" =  7.275015\n",
      "2018-09-02 03:51:24.401407 Training Step 2915 Finished Timing (Training: 0.924236, Test: 0.0745344) after 0.812081 seconds\n",
      "2018-09-02 03:51:24.401510 Training Step 2915 \"min loss\" =  3.4093852\n",
      "2018-09-02 03:51:24.401549 Training Step 2915 \"loss\" =  3.8258946\n",
      "2018-09-02 03:51:25.062403 Test Step 2920 Finished\n",
      "2018-09-02 03:51:25.062499 Test Step 2920 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:25.062554 Test Step 2920 \"loss\" =  7.5153203\n",
      "2018-09-02 03:51:25.212153 Training Step 2920 Finished Timing (Training: 0.924008, Test: 0.0746992) after 0.809832 seconds\n",
      "2018-09-02 03:51:25.212214 Training Step 2920 \"min loss\" =  3.317803\n",
      "2018-09-02 03:51:25.212283 Training Step 2920 \"loss\" =  3.9810808\n",
      "2018-09-02 03:51:25.879743 Test Step 2925 Finished\n",
      "2018-09-02 03:51:25.880268 Test Step 2925 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:25.880332 Test Step 2925 \"loss\" =  7.6683335\n",
      "2018-09-02 03:51:26.028982 Training Step 2925 Finished Timing (Training: 0.92276, Test: 0.0758386) after 0.81601 seconds\n",
      "2018-09-02 03:51:26.029044 Training Step 2925 \"min loss\" =  3.317803\n",
      "2018-09-02 03:51:26.029124 Training Step 2925 \"loss\" =  3.7385395\n",
      "2018-09-02 03:51:26.691925 Test Step 2930 Finished\n",
      "2018-09-02 03:51:26.692439 Test Step 2930 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:26.692501 Test Step 2930 \"loss\" =  7.335563\n",
      "2018-09-02 03:51:26.845964 Training Step 2930 Finished Timing (Training: 0.922405, Test: 0.0762492) after 0.816779 seconds\n",
      "2018-09-02 03:51:26.846196 Training Step 2930 \"min loss\" =  3.317803\n",
      "2018-09-02 03:51:26.846251 Training Step 2930 \"loss\" =  3.6015499\n",
      "2018-09-02 03:51:27.527907 Test Step 2935 Finished\n",
      "2018-09-02 03:51:27.528041 Test Step 2935 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:27.528747 Test Step 2935 \"loss\" =  7.148147\n",
      "2018-09-02 03:51:27.670506 Training Step 2935 Finished Timing (Training: 0.921911, Test: 0.0767113) after 0.824198 seconds\n",
      "2018-09-02 03:51:27.670575 Training Step 2935 \"min loss\" =  3.317803\n",
      "2018-09-02 03:51:27.670635 Training Step 2935 \"loss\" =  3.9318974\n",
      "2018-09-02 03:51:28.323998 Test Step 2940 Finished\n",
      "2018-09-02 03:51:28.324489 Test Step 2940 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:28.324554 Test Step 2940 \"loss\" =  7.3363714\n",
      "2018-09-02 03:51:28.473400 Training Step 2940 Finished Timing (Training: 0.921362, Test: 0.0772999) after 0.802714 seconds\n",
      "2018-09-02 03:51:28.473485 Training Step 2940 \"min loss\" =  3.317803\n",
      "2018-09-02 03:51:28.473542 Training Step 2940 \"loss\" =  3.8483818\n",
      "2018-09-02 03:51:29.140023 Test Step 2945 Finished\n",
      "2018-09-02 03:51:29.140177 Test Step 2945 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:29.140277 Test Step 2945 \"loss\" =  7.9493833\n",
      "2018-09-02 03:51:29.291221 Training Step 2945 Finished Timing (Training: 0.920977, Test: 0.0777587) after 0.817611 seconds\n",
      "2018-09-02 03:51:29.291324 Training Step 2945 \"min loss\" =  3.317803\n",
      "2018-09-02 03:51:29.291382 Training Step 2945 \"loss\" =  3.6796677\n",
      "2018-09-02 03:51:29.954778 Test Step 2950 Finished\n",
      "2018-09-02 03:51:29.955205 Test Step 2950 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:29.955271 Test Step 2950 \"loss\" =  7.300084\n",
      "2018-09-02 03:51:30.103380 Training Step 2950 Finished Timing (Training: 0.920979, Test: 0.0777833) after 0.811938 seconds\n",
      "2018-09-02 03:51:30.103441 Training Step 2950 \"min loss\" =  3.317803\n",
      "2018-09-02 03:51:30.103488 Training Step 2950 \"loss\" =  3.5601623\n",
      "2018-09-02 03:51:30.763214 Test Step 2955 Finished\n",
      "2018-09-02 03:51:30.763332 Test Step 2955 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:30.763387 Test Step 2955 \"loss\" =  7.89116\n",
      "2018-09-02 03:51:30.915149 Training Step 2955 Finished Timing (Training: 0.92051, Test: 0.0782843) after 0.81133 seconds\n",
      "2018-09-02 03:51:30.915217 Training Step 2955 \"min loss\" =  3.317803\n",
      "2018-09-02 03:51:30.915274 Training Step 2955 \"loss\" =  3.4632947\n",
      "2018-09-02 03:51:31.581463 Test Step 2960 Finished\n",
      "2018-09-02 03:51:31.581576 Test Step 2960 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:31.581636 Test Step 2960 \"loss\" =  8.381376\n",
      "2018-09-02 03:51:31.732301 Training Step 2960 Finished Timing (Training: 0.920448, Test: 0.0784011) after 0.816967 seconds\n",
      "2018-09-02 03:51:31.732373 Training Step 2960 \"min loss\" =  3.317803\n",
      "2018-09-02 03:51:31.732431 Training Step 2960 \"loss\" =  3.7256827\n",
      "2018-09-02 03:51:32.393171 Test Step 2965 Finished\n",
      "2018-09-02 03:51:32.393263 Test Step 2965 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:32.393349 Test Step 2965 \"loss\" =  7.3793125\n",
      "2018-09-02 03:51:32.541380 Training Step 2965 Finished Timing (Training: 0.920622, Test: 0.0782114) after 0.80826 seconds\n",
      "2018-09-02 03:51:32.541495 Training Step 2965 \"min loss\" =  3.317803\n",
      "2018-09-02 03:51:32.541554 Training Step 2965 \"loss\" =  4.00967\n",
      "2018-09-02 03:51:33.209210 Test Step 2970 Finished\n",
      "2018-09-02 03:51:33.209768 Test Step 2970 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:33.210294 Test Step 2970 \"loss\" =  7.576\n",
      "2018-09-02 03:51:33.362993 Training Step 2970 Finished Timing (Training: 0.920814, Test: 0.0779745) after 0.821382 seconds\n",
      "2018-09-02 03:51:33.363078 Training Step 2970 \"min loss\" =  3.317803\n",
      "2018-09-02 03:51:33.363766 Training Step 2970 \"loss\" =  3.6451504\n",
      "2018-09-02 03:51:34.020804 Test Step 2975 Finished\n",
      "2018-09-02 03:51:34.021201 Test Step 2975 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:34.021410 Test Step 2975 \"loss\" =  7.400313\n",
      "2018-09-02 03:51:34.173428 Training Step 2975 Finished Timing (Training: 0.920757, Test: 0.0779548) after 0.80959 seconds\n",
      "2018-09-02 03:51:34.173506 Training Step 2975 \"min loss\" =  3.317803\n",
      "2018-09-02 03:51:34.173561 Training Step 2975 \"loss\" =  3.5782366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:51:34.838530 Test Step 2980 Finished\n",
      "2018-09-02 03:51:34.838655 Test Step 2980 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:34.839307 Test Step 2980 \"loss\" =  7.3605075\n",
      "2018-09-02 03:51:34.992936 Training Step 2980 Finished Timing (Training: 0.920773, Test: 0.0779378) after 0.819312 seconds\n",
      "2018-09-02 03:51:34.992999 Training Step 2980 \"min loss\" =  3.317803\n",
      "2018-09-02 03:51:34.993402 Training Step 2980 \"loss\" =  3.6746662\n",
      "2018-09-02 03:51:35.650366 Test Step 2985 Finished\n",
      "2018-09-02 03:51:35.650712 Test Step 2985 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:35.650906 Test Step 2985 \"loss\" =  7.899947\n",
      "2018-09-02 03:51:35.799492 Training Step 2985 Finished Timing (Training: 0.920867, Test: 0.0778367) after 0.806032 seconds\n",
      "2018-09-02 03:51:35.799549 Training Step 2985 \"min loss\" =  3.317803\n",
      "2018-09-02 03:51:35.799905 Training Step 2985 \"loss\" =  3.668525\n",
      "2018-09-02 03:51:36.462099 Test Step 2990 Finished\n",
      "2018-09-02 03:51:36.462218 Test Step 2990 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:36.462279 Test Step 2990 \"loss\" =  7.1132755\n",
      "2018-09-02 03:51:36.615200 Training Step 2990 Finished Timing (Training: 0.92079, Test: 0.0779343) after 0.815226 seconds\n",
      "2018-09-02 03:51:36.615315 Training Step 2990 \"min loss\" =  3.317803\n",
      "2018-09-02 03:51:36.615926 Training Step 2990 \"loss\" =  3.9059038\n",
      "2018-09-02 03:51:37.275821 Test Step 2995 Finished\n",
      "2018-09-02 03:51:37.276329 Test Step 2995 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:37.276389 Test Step 2995 \"loss\" =  7.539017\n",
      "2018-09-02 03:51:37.433009 Training Step 2995 Finished Timing (Training: 0.921266, Test: 0.0774238) after 0.816911 seconds\n",
      "2018-09-02 03:51:37.433172 Training Step 2995 \"min loss\" =  3.317803\n",
      "2018-09-02 03:51:37.433313 Training Step 2995 \"loss\" =  3.795932\n",
      "2018-09-02 03:51:38.109529 Test Step 3000 Finished\n",
      "2018-09-02 03:51:38.109985 Test Step 3000 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:38.110189 Test Step 3000 \"loss\" =  7.6120057\n",
      "2018-09-02 03:51:38.265773 Training Step 3000 Finished Timing (Training: 0.921182, Test: 0.0774768) after 0.832329 seconds\n",
      "2018-09-02 03:51:38.265921 Training Step 3000 \"min loss\" =  3.317803\n",
      "2018-09-02 03:51:38.266039 Training Step 3000 \"loss\" =  3.7270498\n",
      "2018-09-02 03:51:38.921715 Test Step 3005 Finished\n",
      "2018-09-02 03:51:38.921986 Test Step 3005 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:38.922259 Test Step 3005 \"loss\" =  7.474943\n",
      "2018-09-02 03:51:39.072602 Training Step 3005 Finished Timing (Training: 0.921515, Test: 0.0774131) after 0.8065 seconds\n",
      "2018-09-02 03:51:39.072706 Training Step 3005 \"min loss\" =  3.317803\n",
      "2018-09-02 03:51:39.072860 Training Step 3005 \"loss\" =  3.638211\n",
      "2018-09-02 03:51:39.737767 Test Step 3010 Finished\n",
      "2018-09-02 03:51:39.737882 Test Step 3010 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:39.738378 Test Step 3010 \"loss\" =  7.948435\n",
      "2018-09-02 03:51:39.894385 Training Step 3010 Finished Timing (Training: 0.922293, Test: 0.0761825) after 0.820861 seconds\n",
      "2018-09-02 03:51:39.894584 Training Step 3010 \"min loss\" =  3.317803\n",
      "2018-09-02 03:51:39.894645 Training Step 3010 \"loss\" =  3.4389389\n",
      "2018-09-02 03:51:40.564207 Test Step 3015 Finished\n",
      "2018-09-02 03:51:40.564306 Test Step 3015 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:40.564769 Test Step 3015 \"loss\" =  7.587557\n",
      "2018-09-02 03:51:40.716374 Training Step 3015 Finished Timing (Training: 0.920551, Test: 0.0780447) after 0.821671 seconds\n",
      "2018-09-02 03:51:40.716436 Training Step 3015 \"min loss\" =  3.317803\n",
      "2018-09-02 03:51:40.716487 Training Step 3015 \"loss\" =  3.6606655\n",
      "2018-09-02 03:51:41.381621 Test Step 3020 Finished\n",
      "2018-09-02 03:51:41.381738 Test Step 3020 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:41.382232 Test Step 3020 \"loss\" =  7.5218506\n",
      "2018-09-02 03:51:41.533860 Training Step 3020 Finished Timing (Training: 0.920992, Test: 0.0776903) after 0.817307 seconds\n",
      "2018-09-02 03:51:41.534145 Training Step 3020 \"min loss\" =  3.317803\n",
      "2018-09-02 03:51:41.534378 Training Step 3020 \"loss\" =  3.4197876\n",
      "2018-09-02 03:51:42.193590 Test Step 3025 Finished\n",
      "2018-09-02 03:51:42.193697 Test Step 3025 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:42.194190 Test Step 3025 \"loss\" =  7.611117\n",
      "2018-09-02 03:51:42.345934 Training Step 3025 Finished Timing (Training: 0.92089, Test: 0.077677) after 0.811231 seconds\n",
      "2018-09-02 03:51:42.346011 Training Step 3025 \"min loss\" =  3.317803\n",
      "2018-09-02 03:51:42.346066 Training Step 3025 \"loss\" =  3.573943\n",
      "2018-09-02 03:51:43.012052 Test Step 3030 Finished\n",
      "2018-09-02 03:51:43.012235 Test Step 3030 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:43.012352 Test Step 3030 \"loss\" =  7.379167\n",
      "2018-09-02 03:51:43.159709 Training Step 3030 Finished Timing (Training: 0.921034, Test: 0.0776395) after 0.813578 seconds\n",
      "2018-09-02 03:51:43.159813 Training Step 3030 \"min loss\" =  3.317803\n",
      "2018-09-02 03:51:43.159854 Training Step 3030 \"loss\" =  3.7547011\n",
      "2018-09-02 03:51:43.826659 Test Step 3035 Finished\n",
      "2018-09-02 03:51:43.826773 Test Step 3035 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:43.827277 Test Step 3035 \"loss\" =  7.797228\n",
      "2018-09-02 03:51:43.980685 Training Step 3035 Finished Timing (Training: 0.920938, Test: 0.0777638) after 0.820758 seconds\n",
      "2018-09-02 03:51:43.980773 Training Step 3035 \"min loss\" =  3.317803\n",
      "2018-09-02 03:51:43.980829 Training Step 3035 \"loss\" =  3.5967076\n",
      "2018-09-02 03:51:44.654403 Test Step 3040 Finished\n",
      "2018-09-02 03:51:44.654502 Test Step 3040 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:44.655004 Test Step 3040 \"loss\" =  7.5072527\n",
      "2018-09-02 03:51:44.802983 Training Step 3040 Finished Timing (Training: 0.92003, Test: 0.0786974) after 0.822097 seconds\n",
      "2018-09-02 03:51:44.803041 Training Step 3040 \"min loss\" =  3.317803\n",
      "2018-09-02 03:51:44.803388 Training Step 3040 \"loss\" =  3.490451\n",
      "2018-09-02 03:51:45.471676 Test Step 3045 Finished\n",
      "2018-09-02 03:51:45.472070 Test Step 3045 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:45.472422 Test Step 3045 \"loss\" =  7.6200075\n",
      "2018-09-02 03:51:45.627324 Training Step 3045 Finished Timing (Training: 0.920499, Test: 0.0781764) after 0.823877 seconds\n",
      "2018-09-02 03:51:45.627401 Training Step 3045 \"min loss\" =  3.2563245\n",
      "2018-09-02 03:51:45.627455 Training Step 3045 \"loss\" =  3.4894261\n",
      "2018-09-02 03:51:46.298439 Test Step 3050 Finished\n",
      "2018-09-02 03:51:46.298742 Test Step 3050 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:46.299183 Test Step 3050 \"loss\" =  7.3245106\n",
      "2018-09-02 03:51:46.450349 Training Step 3050 Finished Timing (Training: 0.920773, Test: 0.0779126) after 0.822835 seconds\n",
      "2018-09-02 03:51:46.450439 Training Step 3050 \"min loss\" =  3.2563245\n",
      "2018-09-02 03:51:46.450491 Training Step 3050 \"loss\" =  3.4490716\n",
      "2018-09-02 03:51:47.106701 Test Step 3055 Finished\n",
      "2018-09-02 03:51:47.107167 Test Step 3055 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:47.107529 Test Step 3055 \"loss\" =  7.805752\n",
      "2018-09-02 03:51:47.260368 Training Step 3055 Finished Timing (Training: 0.920776, Test: 0.0778716) after 0.809535 seconds\n",
      "2018-09-02 03:51:47.260436 Training Step 3055 \"min loss\" =  3.2563245\n",
      "2018-09-02 03:51:47.260512 Training Step 3055 \"loss\" =  3.5691047\n",
      "2018-09-02 03:51:47.924139 Test Step 3060 Finished\n",
      "2018-09-02 03:51:47.924577 Test Step 3060 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:47.924942 Test Step 3060 \"loss\" =  7.488163\n",
      "2018-09-02 03:51:48.073722 Training Step 3060 Finished Timing (Training: 0.920294, Test: 0.0782289) after 0.8121 seconds\n",
      "2018-09-02 03:51:48.073989 Training Step 3060 \"min loss\" =  3.2563245\n",
      "2018-09-02 03:51:48.074396 Training Step 3060 \"loss\" =  3.6401157\n",
      "2018-09-02 03:51:48.745493 Test Step 3065 Finished\n",
      "2018-09-02 03:51:48.745928 Test Step 3065 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:48.746293 Test Step 3065 \"loss\" =  7.877978\n",
      "2018-09-02 03:51:48.891341 Training Step 3065 Finished Timing (Training: 0.920229, Test: 0.0782085) after 0.816639 seconds\n",
      "2018-09-02 03:51:48.891433 Training Step 3065 \"min loss\" =  3.2563245\n",
      "2018-09-02 03:51:48.891980 Training Step 3065 \"loss\" =  3.3683004\n",
      "2018-09-02 03:51:49.554675 Test Step 3070 Finished\n",
      "2018-09-02 03:51:49.555010 Test Step 3070 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:49.555457 Test Step 3070 \"loss\" =  7.6918845\n",
      "2018-09-02 03:51:49.709942 Training Step 3070 Finished Timing (Training: 0.920242, Test: 0.0781479) after 0.817648 seconds\n",
      "2018-09-02 03:51:49.710312 Training Step 3070 \"min loss\" =  3.2563245\n",
      "2018-09-02 03:51:49.710521 Training Step 3070 \"loss\" =  3.416467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:51:50.363069 Test Step 3075 Finished\n",
      "2018-09-02 03:51:50.363408 Test Step 3075 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:50.363853 Test Step 3075 \"loss\" =  7.780999\n",
      "2018-09-02 03:51:50.511406 Training Step 3075 Finished Timing (Training: 0.919978, Test: 0.0783523) after 0.800565 seconds\n",
      "2018-09-02 03:51:50.511548 Training Step 3075 \"min loss\" =  3.2563245\n",
      "2018-09-02 03:51:50.512076 Training Step 3075 \"loss\" =  3.571171\n",
      "2018-09-02 03:51:51.171677 Test Step 3080 Finished\n",
      "2018-09-02 03:51:51.171956 Test Step 3080 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:51.172226 Test Step 3080 \"loss\" =  7.55005\n",
      "2018-09-02 03:51:51.322663 Training Step 3080 Finished Timing (Training: 0.920195, Test: 0.0781154) after 0.810279 seconds\n",
      "2018-09-02 03:51:51.322745 Training Step 3080 \"min loss\" =  3.2563245\n",
      "2018-09-02 03:51:51.322800 Training Step 3080 \"loss\" =  3.536811\n",
      "2018-09-02 03:51:51.983721 Test Step 3085 Finished\n",
      "2018-09-02 03:51:51.983831 Test Step 3085 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:51.984485 Test Step 3085 \"loss\" =  7.4826856\n",
      "2018-09-02 03:51:52.133795 Training Step 3085 Finished Timing (Training: 0.920259, Test: 0.0780733) after 0.81092 seconds\n",
      "2018-09-02 03:51:52.133877 Training Step 3085 \"min loss\" =  3.2563245\n",
      "2018-09-02 03:51:52.133928 Training Step 3085 \"loss\" =  3.7412255\n",
      "2018-09-02 03:51:52.787371 Test Step 3090 Finished\n",
      "2018-09-02 03:51:52.787472 Test Step 3090 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:52.787516 Test Step 3090 \"loss\" =  7.7148557\n",
      "2018-09-02 03:51:52.940579 Training Step 3090 Finished Timing (Training: 0.920099, Test: 0.0782968) after 0.806592 seconds\n",
      "2018-09-02 03:51:52.940645 Training Step 3090 \"min loss\" =  3.2563245\n",
      "2018-09-02 03:51:52.940681 Training Step 3090 \"loss\" =  3.3239424\n",
      "2018-09-02 03:51:53.596702 Test Step 3095 Finished\n",
      "2018-09-02 03:51:53.596799 Test Step 3095 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:53.596856 Test Step 3095 \"loss\" =  7.437434\n",
      "2018-09-02 03:51:53.751006 Training Step 3095 Finished Timing (Training: 0.920104, Test: 0.0783512) after 0.810283 seconds\n",
      "2018-09-02 03:51:53.751066 Training Step 3095 \"min loss\" =  3.2563245\n",
      "2018-09-02 03:51:53.751104 Training Step 3095 \"loss\" =  3.4876769\n",
      "2018-09-02 03:51:54.412328 Test Step 3100 Finished\n",
      "2018-09-02 03:51:54.412408 Test Step 3100 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:54.412450 Test Step 3100 \"loss\" =  7.73137\n",
      "2018-09-02 03:51:54.564602 Training Step 3100 Finished Timing (Training: 0.920283, Test: 0.0782288) after 0.813455 seconds\n",
      "2018-09-02 03:51:54.564660 Training Step 3100 \"min loss\" =  3.2563245\n",
      "2018-09-02 03:51:54.564713 Training Step 3100 \"loss\" =  3.3978415\n",
      "2018-09-02 03:51:55.228257 Test Step 3105 Finished\n",
      "2018-09-02 03:51:55.228330 Test Step 3105 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:55.228370 Test Step 3105 \"loss\" =  7.338567\n",
      "2018-09-02 03:51:55.379658 Training Step 3105 Finished Timing (Training: 0.921969, Test: 0.077791) after 0.814903 seconds\n",
      "2018-09-02 03:51:55.379718 Training Step 3105 \"min loss\" =  3.2563245\n",
      "2018-09-02 03:51:55.379757 Training Step 3105 \"loss\" =  3.8198626\n",
      "2018-09-02 03:51:56.045684 Test Step 3110 Finished\n",
      "2018-09-02 03:51:56.046108 Test Step 3110 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:56.046394 Test Step 3110 \"loss\" =  7.581979\n",
      "2018-09-02 03:51:56.198491 Training Step 3110 Finished Timing (Training: 0.921129, Test: 0.0780264) after 0.818676 seconds\n",
      "2018-09-02 03:51:56.198740 Training Step 3110 \"min loss\" =  3.2563245\n",
      "2018-09-02 03:51:56.199027 Training Step 3110 \"loss\" =  3.505355\n",
      "2018-09-02 03:51:56.858892 Test Step 3115 Finished\n",
      "2018-09-02 03:51:56.859369 Test Step 3115 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:56.859654 Test Step 3115 \"loss\" =  7.6454396\n",
      "2018-09-02 03:51:57.016904 Training Step 3115 Finished Timing (Training: 0.920345, Test: 0.0783174) after 0.817588 seconds\n",
      "2018-09-02 03:51:57.017160 Training Step 3115 \"min loss\" =  3.2563245\n",
      "2018-09-02 03:51:57.017477 Training Step 3115 \"loss\" =  3.558016\n",
      "2018-09-02 03:51:57.663518 Test Step 3120 Finished\n",
      "2018-09-02 03:51:57.663959 Test Step 3120 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:57.664244 Test Step 3120 \"loss\" =  7.4047427\n",
      "2018-09-02 03:51:57.819993 Training Step 3120 Finished Timing (Training: 0.920307, Test: 0.078102) after 0.802227 seconds\n",
      "2018-09-02 03:51:57.820266 Training Step 3120 \"min loss\" =  3.2563245\n",
      "2018-09-02 03:51:57.820551 Training Step 3120 \"loss\" =  3.700569\n",
      "2018-09-02 03:51:58.481403 Test Step 3125 Finished\n",
      "2018-09-02 03:51:58.481843 Test Step 3125 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:58.482134 Test Step 3125 \"loss\" =  7.3992877\n",
      "2018-09-02 03:51:58.625519 Training Step 3125 Finished Timing (Training: 0.919542, Test: 0.0787175) after 0.804681 seconds\n",
      "2018-09-02 03:51:58.625796 Training Step 3125 \"min loss\" =  3.2563245\n",
      "2018-09-02 03:51:58.626082 Training Step 3125 \"loss\" =  3.4391074\n",
      "2018-09-02 03:51:59.274785 Test Step 3130 Finished\n",
      "2018-09-02 03:51:59.275169 Test Step 3130 \"min loss\" =  7.008738\n",
      "2018-09-02 03:51:59.275455 Test Step 3130 \"loss\" =  7.4403872\n",
      "2018-09-02 03:51:59.422892 Training Step 3130 Finished Timing (Training: 0.919145, Test: 0.0790255) after 0.796527 seconds\n",
      "2018-09-02 03:51:59.423145 Training Step 3130 \"min loss\" =  3.1991065\n",
      "2018-09-02 03:51:59.423433 Training Step 3130 \"loss\" =  3.408414\n",
      "2018-09-02 03:52:00.087061 Test Step 3135 Finished\n",
      "2018-09-02 03:52:00.087141 Test Step 3135 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:00.087200 Test Step 3135 \"loss\" =  7.2836027\n",
      "2018-09-02 03:52:00.242346 Training Step 3135 Finished Timing (Training: 0.918305, Test: 0.079947) after 0.818623 seconds\n",
      "2018-09-02 03:52:00.242402 Training Step 3135 \"min loss\" =  3.1991065\n",
      "2018-09-02 03:52:00.242438 Training Step 3135 \"loss\" =  3.470173\n",
      "2018-09-02 03:52:00.917178 Test Step 3140 Finished\n",
      "2018-09-02 03:52:00.917299 Test Step 3140 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:00.917361 Test Step 3140 \"loss\" =  7.975497\n",
      "2018-09-02 03:52:01.070118 Training Step 3140 Finished Timing (Training: 0.918397, Test: 0.0800141) after 0.827635 seconds\n",
      "2018-09-02 03:52:01.070172 Training Step 3140 \"min loss\" =  3.1991065\n",
      "2018-09-02 03:52:01.070208 Training Step 3140 \"loss\" =  3.6143022\n",
      "2018-09-02 03:52:01.717228 Test Step 3145 Finished\n",
      "2018-09-02 03:52:01.717334 Test Step 3145 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:01.717378 Test Step 3145 \"loss\" =  7.411924\n",
      "2018-09-02 03:52:01.861721 Training Step 3145 Finished Timing (Training: 0.918281, Test: 0.0802548) after 0.791462 seconds\n",
      "2018-09-02 03:52:01.861860 Training Step 3145 \"min loss\" =  3.1991065\n",
      "2018-09-02 03:52:01.861896 Training Step 3145 \"loss\" =  3.7316792\n",
      "2018-09-02 03:52:02.531443 Test Step 3150 Finished\n",
      "2018-09-02 03:52:02.531579 Test Step 3150 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:02.531627 Test Step 3150 \"loss\" =  7.6468034\n",
      "2018-09-02 03:52:02.685593 Training Step 3150 Finished Timing (Training: 0.918661, Test: 0.0799627) after 0.823644 seconds\n",
      "2018-09-02 03:52:02.685700 Training Step 3150 \"min loss\" =  3.1991065\n",
      "2018-09-02 03:52:02.685742 Training Step 3150 \"loss\" =  3.25685\n",
      "2018-09-02 03:52:03.353576 Test Step 3155 Finished\n",
      "2018-09-02 03:52:03.353726 Test Step 3155 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:03.353768 Test Step 3155 \"loss\" =  7.542702\n",
      "2018-09-02 03:52:03.499470 Training Step 3155 Finished Timing (Training: 0.918301, Test: 0.0803932) after 0.813682 seconds\n",
      "2018-09-02 03:52:03.499530 Training Step 3155 \"min loss\" =  3.1991065\n",
      "2018-09-02 03:52:03.499567 Training Step 3155 \"loss\" =  3.6703298\n",
      "2018-09-02 03:52:04.154965 Test Step 3160 Finished\n",
      "2018-09-02 03:52:04.155051 Test Step 3160 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:04.155092 Test Step 3160 \"loss\" =  7.2915998\n",
      "2018-09-02 03:52:04.308509 Training Step 3160 Finished Timing (Training: 0.919261, Test: 0.0795073) after 0.808901 seconds\n",
      "2018-09-02 03:52:04.308564 Training Step 3160 \"min loss\" =  3.185923\n",
      "2018-09-02 03:52:04.308600 Training Step 3160 \"loss\" =  3.185923\n",
      "2018-09-02 03:52:04.974177 Test Step 3165 Finished\n",
      "2018-09-02 03:52:04.974629 Test Step 3165 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:04.974917 Test Step 3165 \"loss\" =  7.5974264\n",
      "2018-09-02 03:52:05.125946 Training Step 3165 Finished Timing (Training: 0.919407, Test: 0.0793444) after 0.817278 seconds\n",
      "2018-09-02 03:52:05.126332 Training Step 3165 \"min loss\" =  3.185923\n",
      "2018-09-02 03:52:05.126651 Training Step 3165 \"loss\" =  3.4153016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:52:05.790294 Test Step 3170 Finished\n",
      "2018-09-02 03:52:05.790696 Test Step 3170 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:05.791025 Test Step 3170 \"loss\" =  7.6107583\n",
      "2018-09-02 03:52:05.941262 Training Step 3170 Finished Timing (Training: 0.919531, Test: 0.0791233) after 0.814284 seconds\n",
      "2018-09-02 03:52:05.941598 Training Step 3170 \"min loss\" =  3.185923\n",
      "2018-09-02 03:52:05.941885 Training Step 3170 \"loss\" =  3.3953962\n",
      "2018-09-02 03:52:06.610834 Test Step 3175 Finished\n",
      "2018-09-02 03:52:06.611271 Test Step 3175 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:06.611558 Test Step 3175 \"loss\" =  7.5066814\n",
      "2018-09-02 03:52:06.756476 Training Step 3175 Finished Timing (Training: 0.919446, Test: 0.079137) after 0.814302 seconds\n",
      "2018-09-02 03:52:06.756728 Training Step 3175 \"min loss\" =  3.185923\n",
      "2018-09-02 03:52:06.757017 Training Step 3175 \"loss\" =  3.4549148\n",
      "2018-09-02 03:52:07.423035 Test Step 3180 Finished\n",
      "2018-09-02 03:52:07.423413 Test Step 3180 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:07.423701 Test Step 3180 \"loss\" =  7.793776\n",
      "2018-09-02 03:52:07.573355 Training Step 3180 Finished Timing (Training: 0.919212, Test: 0.0793195) after 0.816014 seconds\n",
      "2018-09-02 03:52:07.573741 Training Step 3180 \"min loss\" =  3.185923\n",
      "2018-09-02 03:52:07.574075 Training Step 3180 \"loss\" =  3.3156528\n",
      "2018-09-02 03:52:08.229564 Test Step 3185 Finished\n",
      "2018-09-02 03:52:08.229952 Test Step 3185 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:08.230239 Test Step 3185 \"loss\" =  7.6987057\n",
      "2018-09-02 03:52:08.376120 Training Step 3185 Finished Timing (Training: 0.919442, Test: 0.0790277) after 0.801719 seconds\n",
      "2018-09-02 03:52:08.376414 Training Step 3185 \"min loss\" =  3.185923\n",
      "2018-09-02 03:52:08.376705 Training Step 3185 \"loss\" =  3.530275\n",
      "2018-09-02 03:52:09.045484 Test Step 3190 Finished\n",
      "2018-09-02 03:52:09.045942 Test Step 3190 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:09.046229 Test Step 3190 \"loss\" =  7.3170924\n",
      "2018-09-02 03:52:09.200109 Training Step 3190 Finished Timing (Training: 0.919531, Test: 0.078892) after 0.823119 seconds\n",
      "2018-09-02 03:52:09.200366 Training Step 3190 \"min loss\" =  3.185923\n",
      "2018-09-02 03:52:09.200652 Training Step 3190 \"loss\" =  3.4833868\n",
      "2018-09-02 03:52:09.858452 Test Step 3195 Finished\n",
      "2018-09-02 03:52:09.858822 Test Step 3195 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:09.859110 Test Step 3195 \"loss\" =  7.5297165\n",
      "2018-09-02 03:52:10.007909 Training Step 3195 Finished Timing (Training: 0.919298, Test: 0.0790911) after 0.806971 seconds\n",
      "2018-09-02 03:52:10.008234 Training Step 3195 \"min loss\" =  3.185923\n",
      "2018-09-02 03:52:10.008556 Training Step 3195 \"loss\" =  3.3782785\n",
      "2018-09-02 03:52:10.671883 Test Step 3200 Finished\n",
      "2018-09-02 03:52:10.672273 Test Step 3200 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:10.672564 Test Step 3200 \"loss\" =  7.6941185\n",
      "2018-09-02 03:52:10.823032 Training Step 3200 Finished Timing (Training: 0.919323, Test: 0.0790287) after 0.814193 seconds\n",
      "2018-09-02 03:52:10.823290 Training Step 3200 \"min loss\" =  3.185923\n",
      "2018-09-02 03:52:10.823576 Training Step 3200 \"loss\" =  3.3417504\n",
      "2018-09-02 03:52:11.488199 Test Step 3205 Finished\n",
      "2018-09-02 03:52:11.488634 Test Step 3205 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:11.488922 Test Step 3205 \"loss\" =  7.32075\n",
      "2018-09-02 03:52:11.641493 Training Step 3205 Finished Timing (Training: 0.922674, Test: 0.076065) after 0.817628 seconds\n",
      "2018-09-02 03:52:11.641807 Training Step 3205 \"min loss\" =  3.185923\n",
      "2018-09-02 03:52:11.642097 Training Step 3205 \"loss\" =  3.4350624\n",
      "2018-09-02 03:52:12.311773 Test Step 3210 Finished\n",
      "2018-09-02 03:52:12.312197 Test Step 3210 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:12.312489 Test Step 3210 \"loss\" =  7.83112\n",
      "2018-09-02 03:52:12.465398 Training Step 3210 Finished Timing (Training: 0.922301, Test: 0.075902) after 0.823003 seconds\n",
      "2018-09-02 03:52:12.465677 Training Step 3210 \"min loss\" =  3.173195\n",
      "2018-09-02 03:52:12.465976 Training Step 3210 \"loss\" =  3.3405473\n",
      "2018-09-02 03:52:13.138200 Test Step 3215 Finished\n",
      "2018-09-02 03:52:13.138635 Test Step 3215 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:13.138923 Test Step 3215 \"loss\" =  7.734196\n",
      "2018-09-02 03:52:13.296876 Training Step 3215 Finished Timing (Training: 0.920774, Test: 0.0772512) after 0.830599 seconds\n",
      "2018-09-02 03:52:13.297133 Training Step 3215 \"min loss\" =  3.173195\n",
      "2018-09-02 03:52:13.297446 Training Step 3215 \"loss\" =  3.1965415\n",
      "2018-09-02 03:52:13.956706 Test Step 3220 Finished\n",
      "2018-09-02 03:52:13.957155 Test Step 3220 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:13.957471 Test Step 3220 \"loss\" =  7.2002788\n",
      "2018-09-02 03:52:14.111404 Training Step 3220 Finished Timing (Training: 0.920148, Test: 0.0777764) after 0.813666 seconds\n",
      "2018-09-02 03:52:14.111708 Training Step 3220 \"min loss\" =  3.173195\n",
      "2018-09-02 03:52:14.111992 Training Step 3220 \"loss\" =  3.2860327\n",
      "2018-09-02 03:52:14.773093 Test Step 3225 Finished\n",
      "2018-09-02 03:52:14.773523 Test Step 3225 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:14.773810 Test Step 3225 \"loss\" =  8.369335\n",
      "2018-09-02 03:52:14.930144 Training Step 3225 Finished Timing (Training: 0.920379, Test: 0.0774974) after 0.817868 seconds\n",
      "2018-09-02 03:52:14.930426 Training Step 3225 \"min loss\" =  3.173195\n",
      "2018-09-02 03:52:14.930711 Training Step 3225 \"loss\" =  3.3529272\n",
      "2018-09-02 03:52:15.590704 Test Step 3230 Finished\n",
      "2018-09-02 03:52:15.591185 Test Step 3230 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:15.591492 Test Step 3230 \"loss\" =  7.9225807\n",
      "2018-09-02 03:52:15.745289 Training Step 3230 Finished Timing (Training: 0.919407, Test: 0.0784196) after 0.814276 seconds\n",
      "2018-09-02 03:52:15.745543 Training Step 3230 \"min loss\" =  3.173195\n",
      "2018-09-02 03:52:15.745834 Training Step 3230 \"loss\" =  3.349662\n",
      "2018-09-02 03:52:16.407567 Test Step 3235 Finished\n",
      "2018-09-02 03:52:16.408061 Test Step 3235 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:16.408353 Test Step 3235 \"loss\" =  8.034494\n",
      "2018-09-02 03:52:16.561972 Training Step 3235 Finished Timing (Training: 0.91995, Test: 0.0778409) after 0.815818 seconds\n",
      "2018-09-02 03:52:16.562230 Training Step 3235 \"min loss\" =  3.173195\n",
      "2018-09-02 03:52:16.562519 Training Step 3235 \"loss\" =  3.5363708\n",
      "2018-09-02 03:52:17.228678 Test Step 3240 Finished\n",
      "2018-09-02 03:52:17.229142 Test Step 3240 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:17.229461 Test Step 3240 \"loss\" =  7.6061554\n",
      "2018-09-02 03:52:17.384780 Training Step 3240 Finished Timing (Training: 0.919604, Test: 0.078165) after 0.821972 seconds\n",
      "2018-09-02 03:52:17.385047 Training Step 3240 \"min loss\" =  3.173195\n",
      "2018-09-02 03:52:17.385357 Training Step 3240 \"loss\" =  3.400002\n",
      "2018-09-02 03:52:18.048500 Test Step 3245 Finished\n",
      "2018-09-02 03:52:18.048958 Test Step 3245 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:18.049258 Test Step 3245 \"loss\" =  7.4347644\n",
      "2018-09-02 03:52:18.195104 Training Step 3245 Finished Timing (Training: 0.919365, Test: 0.0783812) after 0.809455 seconds\n",
      "2018-09-02 03:52:18.195421 Training Step 3245 \"min loss\" =  3.173195\n",
      "2018-09-02 03:52:18.195715 Training Step 3245 \"loss\" =  3.5570211\n",
      "2018-09-02 03:52:18.850958 Test Step 3250 Finished\n",
      "2018-09-02 03:52:18.851403 Test Step 3250 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:18.851693 Test Step 3250 \"loss\" =  7.6482973\n",
      "2018-09-02 03:52:18.998219 Training Step 3250 Finished Timing (Training: 0.91957, Test: 0.0781577) after 0.802195 seconds\n",
      "2018-09-02 03:52:18.998292 Training Step 3250 \"min loss\" =  3.173195\n",
      "2018-09-02 03:52:18.998333 Training Step 3250 \"loss\" =  3.1795583\n",
      "2018-09-02 03:52:19.661806 Test Step 3255 Finished\n",
      "2018-09-02 03:52:19.661876 Test Step 3255 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:19.661919 Test Step 3255 \"loss\" =  7.658906\n",
      "2018-09-02 03:52:19.810311 Training Step 3255 Finished Timing (Training: 0.9196, Test: 0.0782932) after 0.81193 seconds\n",
      "2018-09-02 03:52:19.810380 Training Step 3255 \"min loss\" =  3.173195\n",
      "2018-09-02 03:52:19.810418 Training Step 3255 \"loss\" =  3.4720962\n",
      "2018-09-02 03:52:20.476281 Test Step 3260 Finished\n",
      "2018-09-02 03:52:20.476372 Test Step 3260 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:20.476415 Test Step 3260 \"loss\" =  7.546234\n",
      "2018-09-02 03:52:20.622497 Training Step 3260 Finished Timing (Training: 0.919541, Test: 0.07849) after 0.812033 seconds\n",
      "2018-09-02 03:52:20.622553 Training Step 3260 \"min loss\" =  3.173195\n",
      "2018-09-02 03:52:20.622588 Training Step 3260 \"loss\" =  3.3557181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:52:21.285386 Test Step 3265 Finished\n",
      "2018-09-02 03:52:21.285491 Test Step 3265 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:21.285537 Test Step 3265 \"loss\" =  8.092419\n",
      "2018-09-02 03:52:21.437340 Training Step 3265 Finished Timing (Training: 0.919795, Test: 0.0783504) after 0.814708 seconds\n",
      "2018-09-02 03:52:21.437413 Training Step 3265 \"min loss\" =  3.1646225\n",
      "2018-09-02 03:52:21.437453 Training Step 3265 \"loss\" =  3.1646225\n",
      "2018-09-02 03:52:22.118378 Test Step 3270 Finished\n",
      "2018-09-02 03:52:22.118491 Test Step 3270 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:22.118553 Test Step 3270 \"loss\" =  8.09107\n",
      "2018-09-02 03:52:22.266079 Training Step 3270 Finished Timing (Training: 0.919663, Test: 0.0785814) after 0.828582 seconds\n",
      "2018-09-02 03:52:22.266136 Training Step 3270 \"min loss\" =  3.1646225\n",
      "2018-09-02 03:52:22.266172 Training Step 3270 \"loss\" =  3.4277484\n",
      "2018-09-02 03:52:22.930473 Test Step 3275 Finished\n",
      "2018-09-02 03:52:22.930895 Test Step 3275 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:22.931181 Test Step 3275 \"loss\" =  7.2662616\n",
      "2018-09-02 03:52:23.076124 Training Step 3275 Finished Timing (Training: 0.919499, Test: 0.0787661) after 0.809901 seconds\n",
      "2018-09-02 03:52:23.076405 Training Step 3275 \"min loss\" =  3.1646225\n",
      "2018-09-02 03:52:23.076696 Training Step 3275 \"loss\" =  3.4118383\n",
      "2018-09-02 03:52:23.746247 Test Step 3280 Finished\n",
      "2018-09-02 03:52:23.746654 Test Step 3280 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:23.746957 Test Step 3280 \"loss\" =  7.9542265\n",
      "2018-09-02 03:52:23.897448 Training Step 3280 Finished Timing (Training: 0.919292, Test: 0.078937) after 0.820459 seconds\n",
      "2018-09-02 03:52:23.897767 Training Step 3280 \"min loss\" =  3.1646225\n",
      "2018-09-02 03:52:23.898052 Training Step 3280 \"loss\" =  3.411766\n",
      "2018-09-02 03:52:24.552630 Test Step 3285 Finished\n",
      "2018-09-02 03:52:24.553057 Test Step 3285 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:24.553375 Test Step 3285 \"loss\" =  8.246441\n",
      "2018-09-02 03:52:24.703264 Training Step 3285 Finished Timing (Training: 0.919487, Test: 0.0787049) after 0.804929 seconds\n",
      "2018-09-02 03:52:24.703543 Training Step 3285 \"min loss\" =  3.1646225\n",
      "2018-09-02 03:52:24.703832 Training Step 3285 \"loss\" =  3.3822875\n",
      "2018-09-02 03:52:25.371563 Test Step 3290 Finished\n",
      "2018-09-02 03:52:25.371650 Test Step 3290 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:25.371696 Test Step 3290 \"loss\" =  7.5411425\n",
      "2018-09-02 03:52:25.521954 Training Step 3290 Finished Timing (Training: 0.919459, Test: 0.0787614) after 0.817828 seconds\n",
      "2018-09-02 03:52:25.522091 Training Step 3290 \"min loss\" =  3.1646225\n",
      "2018-09-02 03:52:25.522127 Training Step 3290 \"loss\" =  3.6251452\n",
      "2018-09-02 03:52:26.176806 Test Step 3295 Finished\n",
      "2018-09-02 03:52:26.176873 Test Step 3295 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:26.176911 Test Step 3295 \"loss\" =  7.508766\n",
      "2018-09-02 03:52:26.328915 Training Step 3295 Finished Timing (Training: 0.919644, Test: 0.0786441) after 0.806738 seconds\n",
      "2018-09-02 03:52:26.329001 Training Step 3295 \"min loss\" =  3.054328\n",
      "2018-09-02 03:52:26.329037 Training Step 3295 \"loss\" =  3.054328\n",
      "2018-09-02 03:52:26.998224 Test Step 3300 Finished\n",
      "2018-09-02 03:52:26.998327 Test Step 3300 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:26.998370 Test Step 3300 \"loss\" =  8.072709\n",
      "2018-09-02 03:52:27.150602 Training Step 3300 Finished Timing (Training: 0.919604, Test: 0.0787456) after 0.821523 seconds\n",
      "2018-09-02 03:52:27.150658 Training Step 3300 \"min loss\" =  3.054328\n",
      "2018-09-02 03:52:27.150695 Training Step 3300 \"loss\" =  3.2285178\n",
      "2018-09-02 03:52:27.811743 Test Step 3305 Finished\n",
      "2018-09-02 03:52:27.811844 Test Step 3305 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:27.811885 Test Step 3305 \"loss\" =  7.959788\n",
      "2018-09-02 03:52:27.967343 Training Step 3305 Finished Timing (Training: 0.920221, Test: 0.0795227) after 0.816606 seconds\n",
      "2018-09-02 03:52:27.967400 Training Step 3305 \"min loss\" =  3.054328\n",
      "2018-09-02 03:52:27.967439 Training Step 3305 \"loss\" =  3.4710526\n",
      "2018-09-02 03:52:28.625373 Test Step 3310 Finished\n",
      "2018-09-02 03:52:28.625795 Test Step 3310 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:28.626084 Test Step 3310 \"loss\" =  7.537575\n",
      "2018-09-02 03:52:28.775682 Training Step 3310 Finished Timing (Training: 0.921514, Test: 0.077643) after 0.808198 seconds\n",
      "2018-09-02 03:52:28.775976 Training Step 3310 \"min loss\" =  3.054328\n",
      "2018-09-02 03:52:28.776263 Training Step 3310 \"loss\" =  3.2078955\n",
      "2018-09-02 03:52:29.439232 Test Step 3315 Finished\n",
      "2018-09-02 03:52:29.439637 Test Step 3315 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:29.439925 Test Step 3315 \"loss\" =  7.516722\n",
      "2018-09-02 03:52:29.589022 Training Step 3315 Finished Timing (Training: 0.919882, Test: 0.078786) after 0.812473 seconds\n",
      "2018-09-02 03:52:29.589318 Training Step 3315 \"min loss\" =  3.054328\n",
      "2018-09-02 03:52:29.589612 Training Step 3315 \"loss\" =  3.3680804\n",
      "2018-09-02 03:52:30.255298 Test Step 3320 Finished\n",
      "2018-09-02 03:52:30.255723 Test Step 3320 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:30.256020 Test Step 3320 \"loss\" =  7.770162\n",
      "2018-09-02 03:52:30.411599 Training Step 3320 Finished Timing (Training: 0.919094, Test: 0.0793186) after 0.821671 seconds\n",
      "2018-09-02 03:52:30.411965 Training Step 3320 \"min loss\" =  3.054328\n",
      "2018-09-02 03:52:30.412254 Training Step 3320 \"loss\" =  3.2159405\n",
      "2018-09-02 03:52:31.075623 Test Step 3325 Finished\n",
      "2018-09-02 03:52:31.076008 Test Step 3325 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:31.076297 Test Step 3325 \"loss\" =  7.878922\n",
      "2018-09-02 03:52:31.228349 Training Step 3325 Finished Timing (Training: 0.919675, Test: 0.0785772) after 0.8158 seconds\n",
      "2018-09-02 03:52:31.228604 Training Step 3325 \"min loss\" =  3.054328\n",
      "2018-09-02 03:52:31.228897 Training Step 3325 \"loss\" =  3.2355068\n",
      "2018-09-02 03:52:31.892820 Test Step 3330 Finished\n",
      "2018-09-02 03:52:31.893332 Test Step 3330 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:31.893649 Test Step 3330 \"loss\" =  7.8355093\n",
      "2018-09-02 03:52:32.042850 Training Step 3330 Finished Timing (Training: 0.920213, Test: 0.0779197) after 0.813662 seconds\n",
      "2018-09-02 03:52:32.043096 Training Step 3330 \"min loss\" =  3.054328\n",
      "2018-09-02 03:52:32.043381 Training Step 3330 \"loss\" =  3.2045083\n",
      "2018-09-02 03:52:32.696923 Test Step 3335 Finished\n",
      "2018-09-02 03:52:32.697449 Test Step 3335 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:32.697757 Test Step 3335 \"loss\" =  7.8686504\n",
      "2018-09-02 03:52:32.846663 Training Step 3335 Finished Timing (Training: 0.919692, Test: 0.0783556) after 0.802995 seconds\n",
      "2018-09-02 03:52:32.846984 Training Step 3335 \"min loss\" =  2.9913793\n",
      "2018-09-02 03:52:32.847334 Training Step 3335 \"loss\" =  3.342975\n",
      "2018-09-02 03:52:33.522115 Test Step 3340 Finished\n",
      "2018-09-02 03:52:33.522551 Test Step 3340 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:33.522857 Test Step 3340 \"loss\" =  7.6453958\n",
      "2018-09-02 03:52:33.672764 Training Step 3340 Finished Timing (Training: 0.919817, Test: 0.0781674) after 0.825145 seconds\n",
      "2018-09-02 03:52:33.673019 Training Step 3340 \"min loss\" =  2.9913793\n",
      "2018-09-02 03:52:33.673331 Training Step 3340 \"loss\" =  3.2259274\n",
      "2018-09-02 03:52:34.340626 Test Step 3345 Finished\n",
      "2018-09-02 03:52:34.341085 Test Step 3345 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:34.341433 Test Step 3345 \"loss\" =  7.8110304\n",
      "2018-09-02 03:52:34.488093 Training Step 3345 Finished Timing (Training: 0.919747, Test: 0.0781854) after 0.814469 seconds\n",
      "2018-09-02 03:52:34.488364 Training Step 3345 \"min loss\" =  2.9913793\n",
      "2018-09-02 03:52:34.488679 Training Step 3345 \"loss\" =  3.2711737\n",
      "2018-09-02 03:52:35.147524 Test Step 3350 Finished\n",
      "2018-09-02 03:52:35.147970 Test Step 3350 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:35.148288 Test Step 3350 \"loss\" =  8.134833\n",
      "2018-09-02 03:52:35.303639 Training Step 3350 Finished Timing (Training: 0.919289, Test: 0.0786035) after 0.814643 seconds\n",
      "2018-09-02 03:52:35.303936 Training Step 3350 \"min loss\" =  2.937697\n",
      "2018-09-02 03:52:35.304256 Training Step 3350 \"loss\" =  3.1371336\n",
      "2018-09-02 03:52:35.963149 Test Step 3355 Finished\n",
      "2018-09-02 03:52:35.963219 Test Step 3355 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:35.963262 Test Step 3355 \"loss\" =  8.323266\n",
      "2018-09-02 03:52:36.118098 Training Step 3355 Finished Timing (Training: 0.918967, Test: 0.0789927) after 0.813521 seconds\n",
      "2018-09-02 03:52:36.118157 Training Step 3355 \"min loss\" =  2.937697\n",
      "2018-09-02 03:52:36.118199 Training Step 3355 \"loss\" =  3.0989995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:52:36.776815 Test Step 3360 Finished\n",
      "2018-09-02 03:52:36.776918 Test Step 3360 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:36.776964 Test Step 3360 \"loss\" =  7.6113324\n",
      "2018-09-02 03:52:36.927472 Training Step 3360 Finished Timing (Training: 0.919143, Test: 0.0789473) after 0.809212 seconds\n",
      "2018-09-02 03:52:36.927586 Training Step 3360 \"min loss\" =  2.937697\n",
      "2018-09-02 03:52:36.927628 Training Step 3360 \"loss\" =  3.2224934\n",
      "2018-09-02 03:52:37.601125 Test Step 3365 Finished\n",
      "2018-09-02 03:52:37.601215 Test Step 3365 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:37.601262 Test Step 3365 \"loss\" =  8.700525\n",
      "2018-09-02 03:52:37.743947 Training Step 3365 Finished Timing (Training: 0.919051, Test: 0.079142) after 0.816262 seconds\n",
      "2018-09-02 03:52:37.744092 Training Step 3365 \"min loss\" =  2.937697\n",
      "2018-09-02 03:52:37.744139 Training Step 3365 \"loss\" =  3.4745598\n",
      "2018-09-02 03:52:38.419052 Test Step 3370 Finished\n",
      "2018-09-02 03:52:38.419490 Test Step 3370 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:38.419809 Test Step 3370 \"loss\" =  8.206396\n",
      "2018-09-02 03:52:38.568108 Training Step 3370 Finished Timing (Training: 0.919171, Test: 0.0790362) after 0.82392 seconds\n",
      "2018-09-02 03:52:38.568415 Training Step 3370 \"min loss\" =  2.937697\n",
      "2018-09-02 03:52:38.568733 Training Step 3370 \"loss\" =  3.0910473\n",
      "2018-09-02 03:52:39.237673 Test Step 3375 Finished\n",
      "2018-09-02 03:52:39.238118 Test Step 3375 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:39.238444 Test Step 3375 \"loss\" =  7.6804743\n",
      "2018-09-02 03:52:39.389973 Training Step 3375 Finished Timing (Training: 0.919009, Test: 0.0791493) after 0.820922 seconds\n",
      "2018-09-02 03:52:39.390248 Training Step 3375 \"min loss\" =  2.937697\n",
      "2018-09-02 03:52:39.390566 Training Step 3375 \"loss\" =  3.2346735\n",
      "2018-09-02 03:52:40.065258 Test Step 3380 Finished\n",
      "2018-09-02 03:52:40.065711 Test Step 3380 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:40.066026 Test Step 3380 \"loss\" =  7.7719984\n",
      "2018-09-02 03:52:40.219814 Training Step 3380 Finished Timing (Training: 0.918791, Test: 0.0793301) after 0.828929 seconds\n",
      "2018-09-02 03:52:40.220104 Training Step 3380 \"min loss\" =  2.937697\n",
      "2018-09-02 03:52:40.220423 Training Step 3380 \"loss\" =  3.2190673\n",
      "2018-09-02 03:52:40.878635 Test Step 3385 Finished\n",
      "2018-09-02 03:52:40.879048 Test Step 3385 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:40.879379 Test Step 3385 \"loss\" =  7.542752\n",
      "2018-09-02 03:52:41.031681 Training Step 3385 Finished Timing (Training: 0.9189, Test: 0.0791855) after 0.810937 seconds\n",
      "2018-09-02 03:52:41.031979 Training Step 3385 \"min loss\" =  2.937697\n",
      "2018-09-02 03:52:41.032346 Training Step 3385 \"loss\" =  3.2546554\n",
      "2018-09-02 03:52:41.694996 Test Step 3390 Finished\n",
      "2018-09-02 03:52:41.695409 Test Step 3390 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:41.695757 Test Step 3390 \"loss\" =  7.9083576\n",
      "2018-09-02 03:52:41.845194 Training Step 3390 Finished Timing (Training: 0.918811, Test: 0.079231) after 0.81243 seconds\n",
      "2018-09-02 03:52:41.845594 Training Step 3390 \"min loss\" =  2.937697\n",
      "2018-09-02 03:52:41.845912 Training Step 3390 \"loss\" =  3.1911066\n",
      "2018-09-02 03:52:42.500658 Test Step 3395 Finished\n",
      "2018-09-02 03:52:42.501153 Test Step 3395 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:42.501546 Test Step 3395 \"loss\" =  7.706563\n",
      "2018-09-02 03:52:42.652472 Training Step 3395 Finished Timing (Training: 0.918597, Test: 0.079399) after 0.806243 seconds\n",
      "2018-09-02 03:52:42.652767 Training Step 3395 \"min loss\" =  2.937697\n",
      "2018-09-02 03:52:42.653085 Training Step 3395 \"loss\" =  3.1914473\n",
      "2018-09-02 03:52:43.320396 Test Step 3400 Finished\n",
      "2018-09-02 03:52:43.320830 Test Step 3400 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:43.321146 Test Step 3400 \"loss\" =  8.29854\n",
      "2018-09-02 03:52:43.472720 Training Step 3400 Finished Timing (Training: 0.918494, Test: 0.0794743) after 0.819286 seconds\n",
      "2018-09-02 03:52:43.473000 Training Step 3400 \"min loss\" =  2.937697\n",
      "2018-09-02 03:52:43.473346 Training Step 3400 \"loss\" =  3.0719216\n",
      "2018-09-02 03:52:44.137658 Test Step 3405 Finished\n",
      "2018-09-02 03:52:44.138107 Test Step 3405 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:44.138441 Test Step 3405 \"loss\" =  8.376183\n",
      "2018-09-02 03:52:44.287244 Training Step 3405 Finished Timing (Training: 0.919064, Test: 0.0795474) after 0.813554 seconds\n",
      "2018-09-02 03:52:44.287607 Training Step 3405 \"min loss\" =  2.937697\n",
      "2018-09-02 03:52:44.287922 Training Step 3405 \"loss\" =  3.266787\n",
      "2018-09-02 03:52:44.963717 Test Step 3410 Finished\n",
      "2018-09-02 03:52:44.964142 Test Step 3410 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:44.964463 Test Step 3410 \"loss\" =  7.9968195\n",
      "2018-09-02 03:52:45.117737 Training Step 3410 Finished Timing (Training: 0.91795, Test: 0.0800739) after 0.829464 seconds\n",
      "2018-09-02 03:52:45.118006 Training Step 3410 \"min loss\" =  2.937697\n",
      "2018-09-02 03:52:45.118322 Training Step 3410 \"loss\" =  3.1194701\n",
      "2018-09-02 03:52:45.775434 Test Step 3415 Finished\n",
      "2018-09-02 03:52:45.775840 Test Step 3415 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:45.776155 Test Step 3415 \"loss\" =  8.708389\n",
      "2018-09-02 03:52:45.930221 Training Step 3415 Finished Timing (Training: 0.917668, Test: 0.0802031) after 0.811577 seconds\n",
      "2018-09-02 03:52:45.930688 Training Step 3415 \"min loss\" =  2.937697\n",
      "2018-09-02 03:52:45.931224 Training Step 3415 \"loss\" =  3.2768972\n",
      "2018-09-02 03:52:46.591105 Test Step 3420 Finished\n",
      "2018-09-02 03:52:46.591545 Test Step 3420 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:46.591861 Test Step 3420 \"loss\" =  7.717211\n",
      "2018-09-02 03:52:46.741473 Training Step 3420 Finished Timing (Training: 0.91791, Test: 0.0796694) after 0.809673 seconds\n",
      "2018-09-02 03:52:46.741758 Training Step 3420 \"min loss\" =  2.937697\n",
      "2018-09-02 03:52:46.742076 Training Step 3420 \"loss\" =  3.3453262\n",
      "2018-09-02 03:52:47.401050 Test Step 3425 Finished\n",
      "2018-09-02 03:52:47.401577 Test Step 3425 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:47.401914 Test Step 3425 \"loss\" =  7.7291646\n",
      "2018-09-02 03:52:47.552744 Training Step 3425 Finished Timing (Training: 0.917587, Test: 0.0799506) after 0.810338 seconds\n",
      "2018-09-02 03:52:47.553136 Training Step 3425 \"min loss\" =  2.8953269\n",
      "2018-09-02 03:52:47.553494 Training Step 3425 \"loss\" =  3.149503\n",
      "2018-09-02 03:52:48.230234 Test Step 3430 Finished\n",
      "2018-09-02 03:52:48.230723 Test Step 3430 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:48.231040 Test Step 3430 \"loss\" =  8.305842\n",
      "2018-09-02 03:52:48.382918 Training Step 3430 Finished Timing (Training: 0.917261, Test: 0.0802356) after 0.829105 seconds\n",
      "2018-09-02 03:52:48.383189 Training Step 3430 \"min loss\" =  2.8953269\n",
      "2018-09-02 03:52:48.383510 Training Step 3430 \"loss\" =  3.402365\n",
      "2018-09-02 03:52:49.048616 Test Step 3435 Finished\n",
      "2018-09-02 03:52:49.049011 Test Step 3435 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:49.049360 Test Step 3435 \"loss\" =  7.8299465\n",
      "2018-09-02 03:52:49.206141 Training Step 3435 Finished Timing (Training: 0.918166, Test: 0.0793415) after 0.822312 seconds\n",
      "2018-09-02 03:52:49.206434 Training Step 3435 \"min loss\" =  2.8953269\n",
      "2018-09-02 03:52:49.206750 Training Step 3435 \"loss\" =  3.1558921\n",
      "2018-09-02 03:52:49.884942 Test Step 3440 Finished\n",
      "2018-09-02 03:52:49.885396 Test Step 3440 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:49.885715 Test Step 3440 \"loss\" =  7.7744255\n",
      "2018-09-02 03:52:50.032312 Training Step 3440 Finished Timing (Training: 0.917809, Test: 0.0796995) after 0.825245 seconds\n",
      "2018-09-02 03:52:50.032635 Training Step 3440 \"min loss\" =  2.8953269\n",
      "2018-09-02 03:52:50.032960 Training Step 3440 \"loss\" =  3.4007626\n",
      "2018-09-02 03:52:50.699894 Test Step 3445 Finished\n",
      "2018-09-02 03:52:50.700334 Test Step 3445 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:50.700655 Test Step 3445 \"loss\" =  7.714882\n",
      "2018-09-02 03:52:50.853905 Training Step 3445 Finished Timing (Training: 0.917998, Test: 0.0794996) after 0.820562 seconds\n",
      "2018-09-02 03:52:50.854199 Training Step 3445 \"min loss\" =  2.8953269\n",
      "2018-09-02 03:52:50.854513 Training Step 3445 \"loss\" =  3.2447176\n",
      "2018-09-02 03:52:51.523942 Test Step 3450 Finished\n",
      "2018-09-02 03:52:51.524407 Test Step 3450 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:51.524724 Test Step 3450 \"loss\" =  7.7255945\n",
      "2018-09-02 03:52:51.679733 Training Step 3450 Finished Timing (Training: 0.918184, Test: 0.079316) after 0.824905 seconds\n",
      "2018-09-02 03:52:51.680020 Training Step 3450 \"min loss\" =  2.8953269\n",
      "2018-09-02 03:52:51.680337 Training Step 3450 \"loss\" =  3.2999325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:52:52.351627 Test Step 3455 Finished\n",
      "2018-09-02 03:52:52.352078 Test Step 3455 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:52.352398 Test Step 3455 \"loss\" =  7.78105\n",
      "2018-09-02 03:52:52.503729 Training Step 3455 Finished Timing (Training: 0.91827, Test: 0.0792264) after 0.823015 seconds\n",
      "2018-09-02 03:52:52.504119 Training Step 3455 \"min loss\" =  2.8953269\n",
      "2018-09-02 03:52:52.504441 Training Step 3455 \"loss\" =  3.4407365\n",
      "2018-09-02 03:52:53.175890 Test Step 3460 Finished\n",
      "2018-09-02 03:52:53.176338 Test Step 3460 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:53.176657 Test Step 3460 \"loss\" =  8.416797\n",
      "2018-09-02 03:52:53.328233 Training Step 3460 Finished Timing (Training: 0.91823, Test: 0.0792571) after 0.823472 seconds\n",
      "2018-09-02 03:52:53.328502 Training Step 3460 \"min loss\" =  2.8953269\n",
      "2018-09-02 03:52:53.328814 Training Step 3460 \"loss\" =  3.5509598\n",
      "2018-09-02 03:52:54.002796 Test Step 3465 Finished\n",
      "2018-09-02 03:52:54.003213 Test Step 3465 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:54.003528 Test Step 3465 \"loss\" =  7.9624085\n",
      "2018-09-02 03:52:54.154644 Training Step 3465 Finished Timing (Training: 0.918118, Test: 0.0793792) after 0.825515 seconds\n",
      "2018-09-02 03:52:54.154966 Training Step 3465 \"min loss\" =  2.8953269\n",
      "2018-09-02 03:52:54.155283 Training Step 3465 \"loss\" =  3.1516085\n",
      "2018-09-02 03:52:54.834473 Test Step 3470 Finished\n",
      "2018-09-02 03:52:54.834921 Test Step 3470 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:54.835241 Test Step 3470 \"loss\" =  8.649142\n",
      "2018-09-02 03:52:54.986702 Training Step 3470 Finished Timing (Training: 0.918344, Test: 0.0791541) after 0.831099 seconds\n",
      "2018-09-02 03:52:54.987004 Training Step 3470 \"min loss\" =  2.8953269\n",
      "2018-09-02 03:52:54.987318 Training Step 3470 \"loss\" =  3.1999276\n",
      "2018-09-02 03:52:55.637348 Test Step 3475 Finished\n",
      "2018-09-02 03:52:55.637795 Test Step 3475 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:55.638085 Test Step 3475 \"loss\" =  8.01213\n",
      "2018-09-02 03:52:55.791908 Training Step 3475 Finished Timing (Training: 0.918209, Test: 0.0792914) after 0.804259 seconds\n",
      "2018-09-02 03:52:55.792176 Training Step 3475 \"min loss\" =  2.8953269\n",
      "2018-09-02 03:52:55.792489 Training Step 3475 \"loss\" =  3.2403958\n",
      "2018-09-02 03:52:56.461162 Test Step 3480 Finished\n",
      "2018-09-02 03:52:56.461660 Test Step 3480 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:56.461958 Test Step 3480 \"loss\" =  8.141771\n",
      "2018-09-02 03:52:56.611397 Training Step 3480 Finished Timing (Training: 0.918456, Test: 0.0790458) after 0.818604 seconds\n",
      "2018-09-02 03:52:56.611651 Training Step 3480 \"min loss\" =  2.8953269\n",
      "2018-09-02 03:52:56.611935 Training Step 3480 \"loss\" =  3.279121\n",
      "2018-09-02 03:52:57.287075 Test Step 3485 Finished\n",
      "2018-09-02 03:52:57.287526 Test Step 3485 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:57.287813 Test Step 3485 \"loss\" =  7.7003117\n",
      "2018-09-02 03:52:57.439445 Training Step 3485 Finished Timing (Training: 0.918331, Test: 0.0791848) after 0.827224 seconds\n",
      "2018-09-02 03:52:57.439699 Training Step 3485 \"min loss\" =  2.8953269\n",
      "2018-09-02 03:52:57.439985 Training Step 3485 \"loss\" =  3.1460812\n",
      "2018-09-02 03:52:58.095491 Test Step 3490 Finished\n",
      "2018-09-02 03:52:58.095945 Test Step 3490 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:58.096230 Test Step 3490 \"loss\" =  7.749701\n",
      "2018-09-02 03:52:58.242531 Training Step 3490 Finished Timing (Training: 0.918586, Test: 0.0789374) after 0.802258 seconds\n",
      "2018-09-02 03:52:58.242786 Training Step 3490 \"min loss\" =  2.8953269\n",
      "2018-09-02 03:52:58.243072 Training Step 3490 \"loss\" =  3.2348\n",
      "2018-09-02 03:52:58.903502 Test Step 3495 Finished\n",
      "2018-09-02 03:52:58.903895 Test Step 3495 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:58.904206 Test Step 3495 \"loss\" =  8.696543\n",
      "2018-09-02 03:52:59.050172 Training Step 3495 Finished Timing (Training: 0.918591, Test: 0.0789419) after 0.806794 seconds\n",
      "2018-09-02 03:52:59.050421 Training Step 3495 \"min loss\" =  2.8953269\n",
      "2018-09-02 03:52:59.050705 Training Step 3495 \"loss\" =  3.4820426\n",
      "2018-09-02 03:52:59.708759 Test Step 3500 Finished\n",
      "2018-09-02 03:52:59.709182 Test Step 3500 \"min loss\" =  7.008738\n",
      "2018-09-02 03:52:59.709498 Test Step 3500 \"loss\" =  7.6292677\n",
      "2018-09-02 03:52:59.861692 Training Step 3500 Finished Timing (Training: 0.918393, Test: 0.0791476) after 0.810699 seconds\n",
      "2018-09-02 03:52:59.862010 Training Step 3500 \"min loss\" =  2.8953269\n",
      "2018-09-02 03:52:59.862322 Training Step 3500 \"loss\" =  3.0905142\n",
      "2018-09-02 03:53:00.518110 Test Step 3505 Finished\n",
      "2018-09-02 03:53:00.518563 Test Step 3505 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:00.518885 Test Step 3505 \"loss\" =  8.289594\n",
      "2018-09-02 03:53:00.672684 Training Step 3505 Finished Timing (Training: 0.919826, Test: 0.0787918) after 0.810068 seconds\n",
      "2018-09-02 03:53:00.672967 Training Step 3505 \"min loss\" =  2.8953269\n",
      "2018-09-02 03:53:00.673317 Training Step 3505 \"loss\" =  3.160208\n",
      "2018-09-02 03:53:01.340311 Test Step 3510 Finished\n",
      "2018-09-02 03:53:01.340757 Test Step 3510 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:01.341073 Test Step 3510 \"loss\" =  7.5100875\n",
      "2018-09-02 03:53:01.493810 Training Step 3510 Finished Timing (Training: 0.920491, Test: 0.0774886) after 0.820165 seconds\n",
      "2018-09-02 03:53:01.494083 Training Step 3510 \"min loss\" =  2.8953269\n",
      "2018-09-02 03:53:01.494403 Training Step 3510 \"loss\" =  3.3992493\n",
      "2018-09-02 03:53:02.149679 Test Step 3515 Finished\n",
      "2018-09-02 03:53:02.150187 Test Step 3515 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:02.150488 Test Step 3515 \"loss\" =  7.766525\n",
      "2018-09-02 03:53:02.303153 Training Step 3515 Finished Timing (Training: 0.919079, Test: 0.0787307) after 0.808432 seconds\n",
      "2018-09-02 03:53:02.303408 Training Step 3515 \"min loss\" =  2.8953269\n",
      "2018-09-02 03:53:02.303733 Training Step 3515 \"loss\" =  3.3515394\n",
      "2018-09-02 03:53:02.967997 Test Step 3520 Finished\n",
      "2018-09-02 03:53:02.968458 Test Step 3520 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:02.968749 Test Step 3520 \"loss\" =  7.8255057\n",
      "2018-09-02 03:53:03.117099 Training Step 3520 Finished Timing (Training: 0.918481, Test: 0.0791968) after 0.812799 seconds\n",
      "2018-09-02 03:53:03.117412 Training Step 3520 \"min loss\" =  2.8953269\n",
      "2018-09-02 03:53:03.117730 Training Step 3520 \"loss\" =  3.0547101\n",
      "2018-09-02 03:53:03.782582 Test Step 3525 Finished\n",
      "2018-09-02 03:53:03.783031 Test Step 3525 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:03.783320 Test Step 3525 \"loss\" =  7.8429847\n",
      "2018-09-02 03:53:03.928755 Training Step 3525 Finished Timing (Training: 0.918616, Test: 0.079038) after 0.81073 seconds\n",
      "2018-09-02 03:53:03.929028 Training Step 3525 \"min loss\" =  2.8953269\n",
      "2018-09-02 03:53:03.929342 Training Step 3525 \"loss\" =  3.124281\n",
      "2018-09-02 03:53:04.586100 Test Step 3530 Finished\n",
      "2018-09-02 03:53:04.586533 Test Step 3530 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:04.586817 Test Step 3530 \"loss\" =  7.8143086\n",
      "2018-09-02 03:53:04.731752 Training Step 3530 Finished Timing (Training: 0.918967, Test: 0.0786819) after 0.802109 seconds\n",
      "2018-09-02 03:53:04.732100 Training Step 3530 \"min loss\" =  2.8953269\n",
      "2018-09-02 03:53:04.732390 Training Step 3530 \"loss\" =  3.1043637\n",
      "2018-09-02 03:53:05.395443 Test Step 3535 Finished\n",
      "2018-09-02 03:53:05.395884 Test Step 3535 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:05.396174 Test Step 3535 \"loss\" =  8.458072\n",
      "2018-09-02 03:53:05.550460 Training Step 3535 Finished Timing (Training: 0.919145, Test: 0.0784887) after 0.817776 seconds\n",
      "2018-09-02 03:53:05.550745 Training Step 3535 \"min loss\" =  2.8953269\n",
      "2018-09-02 03:53:05.551031 Training Step 3535 \"loss\" =  3.008675\n",
      "2018-09-02 03:53:06.204500 Test Step 3540 Finished\n",
      "2018-09-02 03:53:06.204926 Test Step 3540 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:06.205221 Test Step 3540 \"loss\" =  7.4478555\n",
      "2018-09-02 03:53:06.347682 Training Step 3540 Finished Timing (Training: 0.918852, Test: 0.0787779) after 0.796363 seconds\n",
      "2018-09-02 03:53:06.347936 Training Step 3540 \"min loss\" =  2.8953269\n",
      "2018-09-02 03:53:06.348222 Training Step 3540 \"loss\" =  3.1172664\n",
      "2018-09-02 03:53:07.017120 Test Step 3545 Finished\n",
      "2018-09-02 03:53:07.017577 Test Step 3545 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:07.017863 Test Step 3545 \"loss\" =  7.8379593\n",
      "2018-09-02 03:53:07.164066 Training Step 3545 Finished Timing (Training: 0.918855, Test: 0.078782) after 0.815551 seconds\n",
      "2018-09-02 03:53:07.164328 Training Step 3545 \"min loss\" =  2.8953269\n",
      "2018-09-02 03:53:07.164617 Training Step 3545 \"loss\" =  3.242116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:53:07.819590 Test Step 3550 Finished\n",
      "2018-09-02 03:53:07.820079 Test Step 3550 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:07.820369 Test Step 3550 \"loss\" =  7.917463\n",
      "2018-09-02 03:53:07.972538 Training Step 3550 Finished Timing (Training: 0.91925, Test: 0.0783833) after 0.80763 seconds\n",
      "2018-09-02 03:53:07.972829 Training Step 3550 \"min loss\" =  2.8953269\n",
      "2018-09-02 03:53:07.973112 Training Step 3550 \"loss\" =  3.0324018\n",
      "2018-09-02 03:53:08.639363 Test Step 3555 Finished\n",
      "2018-09-02 03:53:08.639815 Test Step 3555 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:08.640103 Test Step 3555 \"loss\" =  7.965896\n",
      "2018-09-02 03:53:08.793127 Training Step 3555 Finished Timing (Training: 0.91943, Test: 0.0781962) after 0.819664 seconds\n",
      "2018-09-02 03:53:08.793444 Training Step 3555 \"min loss\" =  2.8953269\n",
      "2018-09-02 03:53:08.793727 Training Step 3555 \"loss\" =  3.230213\n",
      "2018-09-02 03:53:09.443188 Test Step 3560 Finished\n",
      "2018-09-02 03:53:09.443585 Test Step 3560 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:09.443873 Test Step 3560 \"loss\" =  7.7819047\n",
      "2018-09-02 03:53:09.598594 Training Step 3560 Finished Timing (Training: 0.920015, Test: 0.0776144) after 0.80458 seconds\n",
      "2018-09-02 03:53:09.598863 Training Step 3560 \"min loss\" =  2.8953269\n",
      "2018-09-02 03:53:09.599149 Training Step 3560 \"loss\" =  3.1741624\n",
      "2018-09-02 03:53:10.260392 Test Step 3565 Finished\n",
      "2018-09-02 03:53:10.260840 Test Step 3565 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:10.261129 Test Step 3565 \"loss\" =  7.958766\n",
      "2018-09-02 03:53:10.412257 Training Step 3565 Finished Timing (Training: 0.920016, Test: 0.0776139) after 0.812813 seconds\n",
      "2018-09-02 03:53:10.412573 Training Step 3565 \"min loss\" =  2.8814006\n",
      "2018-09-02 03:53:10.412860 Training Step 3565 \"loss\" =  2.8814006\n",
      "2018-09-02 03:53:11.084951 Test Step 3570 Finished\n",
      "2018-09-02 03:53:11.085332 Test Step 3570 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:11.085623 Test Step 3570 \"loss\" =  7.7626863\n",
      "2018-09-02 03:53:11.236088 Training Step 3570 Finished Timing (Training: 0.919965, Test: 0.0776712) after 0.82294 seconds\n",
      "2018-09-02 03:53:11.236372 Training Step 3570 \"min loss\" =  2.8814006\n",
      "2018-09-02 03:53:11.236675 Training Step 3570 \"loss\" =  3.3734267\n",
      "2018-09-02 03:53:11.895262 Test Step 3575 Finished\n",
      "2018-09-02 03:53:11.895724 Test Step 3575 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:11.896010 Test Step 3575 \"loss\" =  8.119651\n",
      "2018-09-02 03:53:12.045936 Training Step 3575 Finished Timing (Training: 0.91996, Test: 0.0776743) after 0.808965 seconds\n",
      "2018-09-02 03:53:12.046210 Training Step 3575 \"min loss\" =  2.8814006\n",
      "2018-09-02 03:53:12.046496 Training Step 3575 \"loss\" =  3.2836854\n",
      "2018-09-02 03:53:12.708911 Test Step 3580 Finished\n",
      "2018-09-02 03:53:12.709401 Test Step 3580 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:12.709688 Test Step 3580 \"loss\" =  7.65353\n",
      "2018-09-02 03:53:12.860170 Training Step 3580 Finished Timing (Training: 0.919952, Test: 0.0776816) after 0.813374 seconds\n",
      "2018-09-02 03:53:12.860556 Training Step 3580 \"min loss\" =  2.8814006\n",
      "2018-09-02 03:53:12.860845 Training Step 3580 \"loss\" =  3.497661\n",
      "2018-09-02 03:53:13.535559 Test Step 3585 Finished\n",
      "2018-09-02 03:53:13.536020 Test Step 3585 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:13.536329 Test Step 3585 \"loss\" =  7.71226\n",
      "2018-09-02 03:53:13.691910 Training Step 3585 Finished Timing (Training: 0.919751, Test: 0.0778739) after 0.830776 seconds\n",
      "2018-09-02 03:53:13.692187 Training Step 3585 \"min loss\" =  2.8814006\n",
      "2018-09-02 03:53:13.692471 Training Step 3585 \"loss\" =  3.3834631\n",
      "2018-09-02 03:53:14.357239 Test Step 3590 Finished\n",
      "2018-09-02 03:53:14.357694 Test Step 3590 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:14.357985 Test Step 3590 \"loss\" =  8.282956\n",
      "2018-09-02 03:53:14.511776 Training Step 3590 Finished Timing (Training: 0.919571, Test: 0.0780563) after 0.819016 seconds\n",
      "2018-09-02 03:53:14.512031 Training Step 3590 \"min loss\" =  2.8814006\n",
      "2018-09-02 03:53:14.512317 Training Step 3590 \"loss\" =  3.2671955\n",
      "2018-09-02 03:53:15.184983 Test Step 3595 Finished\n",
      "2018-09-02 03:53:15.185481 Test Step 3595 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:15.185773 Test Step 3595 \"loss\" =  7.6108065\n",
      "2018-09-02 03:53:15.335700 Training Step 3595 Finished Timing (Training: 0.919345, Test: 0.0782826) after 0.823079 seconds\n",
      "2018-09-02 03:53:15.335978 Training Step 3595 \"min loss\" =  2.8814006\n",
      "2018-09-02 03:53:15.336285 Training Step 3595 \"loss\" =  3.3960598\n",
      "2018-09-02 03:53:16.004195 Test Step 3600 Finished\n",
      "2018-09-02 03:53:16.004581 Test Step 3600 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:16.004865 Test Step 3600 \"loss\" =  8.1355505\n",
      "2018-09-02 03:53:16.155124 Training Step 3600 Finished Timing (Training: 0.919349, Test: 0.0782828) after 0.818515 seconds\n",
      "2018-09-02 03:53:16.155412 Training Step 3600 \"min loss\" =  2.8814006\n",
      "2018-09-02 03:53:16.155702 Training Step 3600 \"loss\" =  3.0899196\n",
      "2018-09-02 03:53:16.817522 Test Step 3605 Finished\n",
      "2018-09-02 03:53:16.817868 Test Step 3605 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:16.818179 Test Step 3605 \"loss\" =  7.753172\n",
      "2018-09-02 03:53:16.968510 Training Step 3605 Finished Timing (Training: 0.920068, Test: 0.0787417) after 0.812518 seconds\n",
      "2018-09-02 03:53:16.968784 Training Step 3605 \"min loss\" =  2.8814006\n",
      "2018-09-02 03:53:16.969080 Training Step 3605 \"loss\" =  3.2258084\n",
      "2018-09-02 03:53:17.632478 Test Step 3610 Finished\n",
      "2018-09-02 03:53:17.632908 Test Step 3610 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:17.633192 Test Step 3610 \"loss\" =  7.754495\n",
      "2018-09-02 03:53:17.782023 Training Step 3610 Finished Timing (Training: 0.919346, Test: 0.0788703) after 0.812626 seconds\n",
      "2018-09-02 03:53:17.782303 Training Step 3610 \"min loss\" =  2.8814006\n",
      "2018-09-02 03:53:17.782592 Training Step 3610 \"loss\" =  3.1632807\n",
      "2018-09-02 03:53:18.449767 Test Step 3615 Finished\n",
      "2018-09-02 03:53:18.450235 Test Step 3615 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:18.450524 Test Step 3615 \"loss\" =  7.7853775\n",
      "2018-09-02 03:53:18.603017 Training Step 3615 Finished Timing (Training: 0.917746, Test: 0.0802798) after 0.82014 seconds\n",
      "2018-09-02 03:53:18.603291 Training Step 3615 \"min loss\" =  2.8814006\n",
      "2018-09-02 03:53:18.603573 Training Step 3615 \"loss\" =  3.2164214\n",
      "2018-09-02 03:53:19.273208 Test Step 3620 Finished\n",
      "2018-09-02 03:53:19.273673 Test Step 3620 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:19.273959 Test Step 3620 \"loss\" =  8.414937\n",
      "2018-09-02 03:53:19.424180 Training Step 3620 Finished Timing (Training: 0.917156, Test: 0.0807825) after 0.82032 seconds\n",
      "2018-09-02 03:53:19.424527 Training Step 3620 \"min loss\" =  2.8421512\n",
      "2018-09-02 03:53:19.424817 Training Step 3620 \"loss\" =  3.101979\n",
      "2018-09-02 03:53:20.096865 Test Step 3625 Finished\n",
      "2018-09-02 03:53:20.097354 Test Step 3625 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:20.097646 Test Step 3625 \"loss\" =  7.8555856\n",
      "2018-09-02 03:53:20.251828 Training Step 3625 Finished Timing (Training: 0.916935, Test: 0.0809128) after 0.826675 seconds\n",
      "2018-09-02 03:53:20.252080 Training Step 3625 \"min loss\" =  2.8421512\n",
      "2018-09-02 03:53:20.252364 Training Step 3625 \"loss\" =  2.8986344\n",
      "2018-09-02 03:53:20.920316 Test Step 3630 Finished\n",
      "2018-09-02 03:53:20.920733 Test Step 3630 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:20.921039 Test Step 3630 \"loss\" =  7.797605\n",
      "2018-09-02 03:53:21.072546 Training Step 3630 Finished Timing (Training: 0.917359, Test: 0.0804571) after 0.819891 seconds\n",
      "2018-09-02 03:53:21.072830 Training Step 3630 \"min loss\" =  2.8421512\n",
      "2018-09-02 03:53:21.073115 Training Step 3630 \"loss\" =  3.1058445\n",
      "2018-09-02 03:53:21.744669 Test Step 3635 Finished\n",
      "2018-09-02 03:53:21.745091 Test Step 3635 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:21.745412 Test Step 3635 \"loss\" =  8.136833\n",
      "2018-09-02 03:53:21.891194 Training Step 3635 Finished Timing (Training: 0.917499, Test: 0.080292) after 0.817762 seconds\n",
      "2018-09-02 03:53:21.891508 Training Step 3635 \"min loss\" =  2.8421512\n",
      "2018-09-02 03:53:21.891794 Training Step 3635 \"loss\" =  3.3634892\n",
      "2018-09-02 03:53:22.568430 Test Step 3640 Finished\n",
      "2018-09-02 03:53:22.568883 Test Step 3640 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:22.569197 Test Step 3640 \"loss\" =  7.571014\n",
      "2018-09-02 03:53:22.724879 Training Step 3640 Finished Timing (Training: 0.917339, Test: 0.0804245) after 0.832783 seconds\n",
      "2018-09-02 03:53:22.725170 Training Step 3640 \"min loss\" =  2.8421512\n",
      "2018-09-02 03:53:22.725481 Training Step 3640 \"loss\" =  3.045802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:53:23.392103 Test Step 3645 Finished\n",
      "2018-09-02 03:53:23.392559 Test Step 3645 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:23.392845 Test Step 3645 \"loss\" =  7.528817\n",
      "2018-09-02 03:53:23.547132 Training Step 3645 Finished Timing (Training: 0.917383, Test: 0.0803655) after 0.821362 seconds\n",
      "2018-09-02 03:53:23.547415 Training Step 3645 \"min loss\" =  2.8421512\n",
      "2018-09-02 03:53:23.547698 Training Step 3645 \"loss\" =  2.86794\n",
      "2018-09-02 03:53:24.210614 Test Step 3650 Finished\n",
      "2018-09-02 03:53:24.211041 Test Step 3650 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:24.211325 Test Step 3650 \"loss\" =  7.963068\n",
      "2018-09-02 03:53:24.361505 Training Step 3650 Finished Timing (Training: 0.9175, Test: 0.0802448) after 0.813523 seconds\n",
      "2018-09-02 03:53:24.361808 Training Step 3650 \"min loss\" =  2.8421512\n",
      "2018-09-02 03:53:24.362094 Training Step 3650 \"loss\" =  3.18215\n",
      "2018-09-02 03:53:25.038792 Test Step 3655 Finished\n",
      "2018-09-02 03:53:25.039210 Test Step 3655 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:25.039739 Test Step 3655 \"loss\" =  7.680214\n",
      "2018-09-02 03:53:25.190572 Training Step 3655 Finished Timing (Training: 0.917559, Test: 0.0801555) after 0.828191 seconds\n",
      "2018-09-02 03:53:25.190859 Training Step 3655 \"min loss\" =  2.8421512\n",
      "2018-09-02 03:53:25.191143 Training Step 3655 \"loss\" =  3.372072\n",
      "2018-09-02 03:53:25.875344 Test Step 3660 Finished\n",
      "2018-09-02 03:53:25.875790 Test Step 3660 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:25.876080 Test Step 3660 \"loss\" =  7.79217\n",
      "2018-09-02 03:53:26.029136 Training Step 3660 Finished Timing (Training: 0.917457, Test: 0.08026) after 0.837708 seconds\n",
      "2018-09-02 03:53:26.029449 Training Step 3660 \"min loss\" =  2.8421512\n",
      "2018-09-02 03:53:26.029772 Training Step 3660 \"loss\" =  3.1409607\n",
      "2018-09-02 03:53:26.701468 Test Step 3665 Finished\n",
      "2018-09-02 03:53:26.701568 Test Step 3665 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:26.701614 Test Step 3665 \"loss\" =  8.228172\n",
      "2018-09-02 03:53:26.854044 Training Step 3665 Finished Timing (Training: 0.917688, Test: 0.0800941) after 0.82398 seconds\n",
      "2018-09-02 03:53:26.854102 Training Step 3665 \"min loss\" =  2.8421512\n",
      "2018-09-02 03:53:26.854139 Training Step 3665 \"loss\" =  3.1948779\n",
      "2018-09-02 03:53:27.530640 Test Step 3670 Finished\n",
      "2018-09-02 03:53:27.530726 Test Step 3670 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:27.530768 Test Step 3670 \"loss\" =  7.7345366\n",
      "2018-09-02 03:53:27.684432 Training Step 3670 Finished Timing (Training: 0.917863, Test: 0.0800503) after 0.830249 seconds\n",
      "2018-09-02 03:53:27.684490 Training Step 3670 \"min loss\" =  2.8421512\n",
      "2018-09-02 03:53:27.684526 Training Step 3670 \"loss\" =  3.1308565\n",
      "2018-09-02 03:53:28.357897 Test Step 3675 Finished\n",
      "2018-09-02 03:53:28.357990 Test Step 3675 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:28.358033 Test Step 3675 \"loss\" =  8.169207\n",
      "2018-09-02 03:53:28.510944 Training Step 3675 Finished Timing (Training: 0.917919, Test: 0.0801044) after 0.826358 seconds\n",
      "2018-09-02 03:53:28.511001 Training Step 3675 \"min loss\" =  2.8421512\n",
      "2018-09-02 03:53:28.511038 Training Step 3675 \"loss\" =  3.1503234\n",
      "2018-09-02 03:53:29.186656 Test Step 3680 Finished\n",
      "2018-09-02 03:53:29.186748 Test Step 3680 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:29.186788 Test Step 3680 \"loss\" =  7.708706\n",
      "2018-09-02 03:53:29.331446 Training Step 3680 Finished Timing (Training: 0.918046, Test: 0.080075) after 0.82035 seconds\n",
      "2018-09-02 03:53:29.331501 Training Step 3680 \"min loss\" =  2.8121667\n",
      "2018-09-02 03:53:29.331537 Training Step 3680 \"loss\" =  2.9945557\n",
      "2018-09-02 03:53:29.997087 Test Step 3685 Finished\n",
      "2018-09-02 03:53:29.997203 Test Step 3685 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:29.997266 Test Step 3685 \"loss\" =  7.7540317\n",
      "2018-09-02 03:53:30.150363 Training Step 3685 Finished Timing (Training: 0.918119, Test: 0.0800822) after 0.818774 seconds\n",
      "2018-09-02 03:53:30.150632 Training Step 3685 \"min loss\" =  2.8121667\n",
      "2018-09-02 03:53:30.150671 Training Step 3685 \"loss\" =  2.8125954\n",
      "2018-09-02 03:53:30.819658 Test Step 3690 Finished\n",
      "2018-09-02 03:53:30.820104 Test Step 3690 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:30.820401 Test Step 3690 \"loss\" =  7.419499\n",
      "2018-09-02 03:53:30.969205 Training Step 3690 Finished Timing (Training: 0.918307, Test: 0.0798962) after 0.81849 seconds\n",
      "2018-09-02 03:53:30.969270 Training Step 3690 \"min loss\" =  2.8121667\n",
      "2018-09-02 03:53:30.969908 Training Step 3690 \"loss\" =  3.1725154\n",
      "2018-09-02 03:53:31.623572 Test Step 3695 Finished\n",
      "2018-09-02 03:53:31.623712 Test Step 3695 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:31.624075 Test Step 3695 \"loss\" =  7.1360283\n",
      "2018-09-02 03:53:31.769563 Training Step 3695 Finished Timing (Training: 0.918087, Test: 0.0800607) after 0.799204 seconds\n",
      "2018-09-02 03:53:31.769632 Training Step 3695 \"min loss\" =  2.8121667\n",
      "2018-09-02 03:53:31.770070 Training Step 3695 \"loss\" =  3.3545544\n",
      "2018-09-02 03:53:32.441080 Test Step 3700 Finished\n",
      "2018-09-02 03:53:32.441187 Test Step 3700 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:32.441246 Test Step 3700 \"loss\" =  8.0039\n",
      "2018-09-02 03:53:32.587027 Training Step 3700 Finished Timing (Training: 0.918084, Test: 0.0801026) after 0.816886 seconds\n",
      "2018-09-02 03:53:32.587092 Training Step 3700 \"min loss\" =  2.8121667\n",
      "2018-09-02 03:53:32.587144 Training Step 3700 \"loss\" =  3.1946366\n",
      "2018-09-02 03:53:33.247273 Test Step 3705 Finished\n",
      "2018-09-02 03:53:33.247430 Test Step 3705 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:33.247507 Test Step 3705 \"loss\" =  7.5607033\n",
      "2018-09-02 03:53:33.405383 Training Step 3705 Finished Timing (Training: 0.920701, Test: 0.0789042) after 0.817427 seconds\n",
      "2018-09-02 03:53:33.405457 Training Step 3705 \"min loss\" =  2.8121667\n",
      "2018-09-02 03:53:33.406039 Training Step 3705 \"loss\" =  3.0810285\n",
      "2018-09-02 03:53:34.072492 Test Step 3710 Finished\n",
      "2018-09-02 03:53:34.072615 Test Step 3710 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:34.072707 Test Step 3710 \"loss\" =  7.6042314\n",
      "2018-09-02 03:53:34.226047 Training Step 3710 Finished Timing (Training: 0.920468, Test: 0.0786876) after 0.819934 seconds\n",
      "2018-09-02 03:53:34.226116 Training Step 3710 \"min loss\" =  2.8121667\n",
      "2018-09-02 03:53:34.226162 Training Step 3710 \"loss\" =  3.2526338\n",
      "2018-09-02 03:53:34.909390 Test Step 3715 Finished\n",
      "2018-09-02 03:53:34.909496 Test Step 3715 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:34.909864 Test Step 3715 \"loss\" =  7.845461\n",
      "2018-09-02 03:53:35.063455 Training Step 3715 Finished Timing (Training: 0.921745, Test: 0.0773829) after 0.837205 seconds\n",
      "2018-09-02 03:53:35.063525 Training Step 3715 \"min loss\" =  2.8012264\n",
      "2018-09-02 03:53:35.063914 Training Step 3715 \"loss\" =  2.8012264\n",
      "2018-09-02 03:53:35.744814 Test Step 3720 Finished\n",
      "2018-09-02 03:53:35.745314 Test Step 3720 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:35.745686 Test Step 3720 \"loss\" =  7.79591\n",
      "2018-09-02 03:53:35.900806 Training Step 3720 Finished Timing (Training: 0.921024, Test: 0.0776845) after 0.836508 seconds\n",
      "2018-09-02 03:53:35.900880 Training Step 3720 \"min loss\" =  2.8012264\n",
      "2018-09-02 03:53:35.901456 Training Step 3720 \"loss\" =  3.1069407\n",
      "2018-09-02 03:53:36.563672 Test Step 3725 Finished\n",
      "2018-09-02 03:53:36.563799 Test Step 3725 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:36.563863 Test Step 3725 \"loss\" =  8.274889\n",
      "2018-09-02 03:53:36.712494 Training Step 3725 Finished Timing (Training: 0.920431, Test: 0.0782197) after 0.810688 seconds\n",
      "2018-09-02 03:53:36.712708 Training Step 3725 \"min loss\" =  2.8012264\n",
      "2018-09-02 03:53:36.712761 Training Step 3725 \"loss\" =  2.8514736\n",
      "2018-09-02 03:53:37.381535 Test Step 3730 Finished\n",
      "2018-09-02 03:53:37.382011 Test Step 3730 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:37.382069 Test Step 3730 \"loss\" =  7.8378167\n",
      "2018-09-02 03:53:37.527991 Training Step 3730 Finished Timing (Training: 0.920689, Test: 0.0779224) after 0.815171 seconds\n",
      "2018-09-02 03:53:37.528374 Training Step 3730 \"min loss\" =  2.7355967\n",
      "2018-09-02 03:53:37.528433 Training Step 3730 \"loss\" =  3.101043\n",
      "2018-09-02 03:53:38.195219 Test Step 3735 Finished\n",
      "2018-09-02 03:53:38.195332 Test Step 3735 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:38.195430 Test Step 3735 \"loss\" =  7.8907356\n",
      "2018-09-02 03:53:38.343905 Training Step 3735 Finished Timing (Training: 0.920986, Test: 0.0776799) after 0.815418 seconds\n",
      "2018-09-02 03:53:38.344018 Training Step 3735 \"min loss\" =  2.7355967\n",
      "2018-09-02 03:53:38.344122 Training Step 3735 \"loss\" =  2.8374221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:53:39.006040 Test Step 3740 Finished\n",
      "2018-09-02 03:53:39.006605 Test Step 3740 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:39.006667 Test Step 3740 \"loss\" =  7.714892\n",
      "2018-09-02 03:53:39.158100 Training Step 3740 Finished Timing (Training: 0.920456, Test: 0.0781111) after 0.813172 seconds\n",
      "2018-09-02 03:53:39.158170 Training Step 3740 \"min loss\" =  2.7355967\n",
      "2018-09-02 03:53:39.158211 Training Step 3740 \"loss\" =  2.9284334\n",
      "2018-09-02 03:53:39.833418 Test Step 3745 Finished\n",
      "2018-09-02 03:53:39.833531 Test Step 3745 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:39.833594 Test Step 3745 \"loss\" =  7.6548257\n",
      "2018-09-02 03:53:39.987784 Training Step 3745 Finished Timing (Training: 0.920416, Test: 0.0782489) after 0.829501 seconds\n",
      "2018-09-02 03:53:39.987848 Training Step 3745 \"min loss\" =  2.7355967\n",
      "2018-09-02 03:53:39.987890 Training Step 3745 \"loss\" =  2.9489803\n",
      "2018-09-02 03:53:40.660343 Test Step 3750 Finished\n",
      "2018-09-02 03:53:40.660461 Test Step 3750 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:40.661195 Test Step 3750 \"loss\" =  7.425142\n",
      "2018-09-02 03:53:40.816411 Training Step 3750 Finished Timing (Training: 0.920092, Test: 0.0785668) after 0.828414 seconds\n",
      "2018-09-02 03:53:40.816474 Training Step 3750 \"min loss\" =  2.7355967\n",
      "2018-09-02 03:53:40.816513 Training Step 3750 \"loss\" =  2.8270833\n",
      "2018-09-02 03:53:41.481329 Test Step 3755 Finished\n",
      "2018-09-02 03:53:41.481820 Test Step 3755 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:41.481885 Test Step 3755 \"loss\" =  7.454931\n",
      "2018-09-02 03:53:41.638635 Training Step 3755 Finished Timing (Training: 0.920499, Test: 0.0781938) after 0.822073 seconds\n",
      "2018-09-02 03:53:41.638701 Training Step 3755 \"min loss\" =  2.7355967\n",
      "2018-09-02 03:53:41.638741 Training Step 3755 \"loss\" =  3.041931\n",
      "2018-09-02 03:53:42.311682 Test Step 3760 Finished\n",
      "2018-09-02 03:53:42.312258 Test Step 3760 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:42.312479 Test Step 3760 \"loss\" =  7.4321885\n",
      "2018-09-02 03:53:42.463913 Training Step 3760 Finished Timing (Training: 0.920727, Test: 0.0779672) after 0.825098 seconds\n",
      "2018-09-02 03:53:42.463977 Training Step 3760 \"min loss\" =  2.7355967\n",
      "2018-09-02 03:53:42.464539 Training Step 3760 \"loss\" =  3.026853\n",
      "2018-09-02 03:53:43.133296 Test Step 3765 Finished\n",
      "2018-09-02 03:53:43.133450 Test Step 3765 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:43.133514 Test Step 3765 \"loss\" =  7.315334\n",
      "2018-09-02 03:53:43.289131 Training Step 3765 Finished Timing (Training: 0.920668, Test: 0.0780196) after 0.824377 seconds\n",
      "2018-09-02 03:53:43.289202 Training Step 3765 \"min loss\" =  2.7355967\n",
      "2018-09-02 03:53:43.289259 Training Step 3765 \"loss\" =  3.1261048\n",
      "2018-09-02 03:53:43.965712 Test Step 3770 Finished\n",
      "2018-09-02 03:53:43.965817 Test Step 3770 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:43.965873 Test Step 3770 \"loss\" =  7.2935185\n",
      "2018-09-02 03:53:44.122587 Training Step 3770 Finished Timing (Training: 0.920548, Test: 0.0781479) after 0.833241 seconds\n",
      "2018-09-02 03:53:44.122683 Training Step 3770 \"min loss\" =  2.7355967\n",
      "2018-09-02 03:53:44.122737 Training Step 3770 \"loss\" =  2.9567878\n",
      "2018-09-02 03:53:44.792208 Test Step 3775 Finished\n",
      "2018-09-02 03:53:44.792314 Test Step 3775 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:44.792374 Test Step 3775 \"loss\" =  7.463302\n",
      "2018-09-02 03:53:44.949024 Training Step 3775 Finished Timing (Training: 0.92069, Test: 0.0780024) after 0.826228 seconds\n",
      "2018-09-02 03:53:44.949085 Training Step 3775 \"min loss\" =  2.7355967\n",
      "2018-09-02 03:53:44.949609 Training Step 3775 \"loss\" =  2.773412\n",
      "2018-09-02 03:53:45.623011 Test Step 3780 Finished\n",
      "2018-09-02 03:53:45.623457 Test Step 3780 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:45.623522 Test Step 3780 \"loss\" =  8.135567\n",
      "2018-09-02 03:53:45.779207 Training Step 3780 Finished Timing (Training: 0.920752, Test: 0.0779256) after 0.829527 seconds\n",
      "2018-09-02 03:53:45.779425 Training Step 3780 \"min loss\" =  2.7355967\n",
      "2018-09-02 03:53:45.779486 Training Step 3780 \"loss\" =  3.3083158\n",
      "2018-09-02 03:53:46.444909 Test Step 3785 Finished\n",
      "2018-09-02 03:53:46.445013 Test Step 3785 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:46.445088 Test Step 3785 \"loss\" =  7.1130204\n",
      "2018-09-02 03:53:46.597643 Training Step 3785 Finished Timing (Training: 0.920715, Test: 0.0779977) after 0.818096 seconds\n",
      "2018-09-02 03:53:46.597726 Training Step 3785 \"min loss\" =  2.7355967\n",
      "2018-09-02 03:53:46.598078 Training Step 3785 \"loss\" =  2.8874338\n",
      "2018-09-02 03:53:47.270493 Test Step 3790 Finished\n",
      "2018-09-02 03:53:47.270626 Test Step 3790 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:47.270695 Test Step 3790 \"loss\" =  7.160808\n",
      "2018-09-02 03:53:47.419731 Training Step 3790 Finished Timing (Training: 0.92059, Test: 0.0781405) after 0.821591 seconds\n",
      "2018-09-02 03:53:47.419794 Training Step 3790 \"min loss\" =  2.7355967\n",
      "2018-09-02 03:53:47.419834 Training Step 3790 \"loss\" =  2.7812445\n",
      "2018-09-02 03:53:48.097164 Test Step 3795 Finished\n",
      "2018-09-02 03:53:48.097295 Test Step 3795 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:48.097397 Test Step 3795 \"loss\" =  7.2473106\n",
      "2018-09-02 03:53:48.245420 Training Step 3795 Finished Timing (Training: 0.920659, Test: 0.078105) after 0.825496 seconds\n",
      "2018-09-02 03:53:48.245485 Training Step 3795 \"min loss\" =  2.7355967\n",
      "2018-09-02 03:53:48.245524 Training Step 3795 \"loss\" =  3.0145273\n",
      "2018-09-02 03:53:48.904543 Test Step 3800 Finished\n",
      "2018-09-02 03:53:48.904632 Test Step 3800 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:48.904689 Test Step 3800 \"loss\" =  7.4151654\n",
      "2018-09-02 03:53:49.053384 Training Step 3800 Finished Timing (Training: 0.920687, Test: 0.0781114) after 0.807754 seconds\n",
      "2018-09-02 03:53:49.053454 Training Step 3800 \"min loss\" =  2.7355967\n",
      "2018-09-02 03:53:49.053517 Training Step 3800 \"loss\" =  2.9954388\n",
      "2018-09-02 03:53:49.729394 Test Step 3805 Finished\n",
      "2018-09-02 03:53:49.729841 Test Step 3805 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:49.729903 Test Step 3805 \"loss\" =  7.4297132\n",
      "2018-09-02 03:53:49.889585 Training Step 3805 Finished Timing (Training: 0.922791, Test: 0.076501) after 0.836019 seconds\n",
      "2018-09-02 03:53:49.889649 Training Step 3805 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:53:49.890172 Training Step 3805 \"loss\" =  2.897159\n",
      "2018-09-02 03:53:50.569107 Test Step 3810 Finished\n",
      "2018-09-02 03:53:50.569230 Test Step 3810 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:50.569303 Test Step 3810 \"loss\" =  7.568864\n",
      "2018-09-02 03:53:50.721234 Training Step 3810 Finished Timing (Training: 0.92062, Test: 0.0784476) after 0.830969 seconds\n",
      "2018-09-02 03:53:50.721325 Training Step 3810 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:53:50.721375 Training Step 3810 \"loss\" =  2.9863713\n",
      "2018-09-02 03:53:51.388916 Test Step 3815 Finished\n",
      "2018-09-02 03:53:51.389453 Test Step 3815 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:51.389868 Test Step 3815 \"loss\" =  7.9691315\n",
      "2018-09-02 03:53:51.539820 Training Step 3815 Finished Timing (Training: 0.920263, Test: 0.0785301) after 0.818351 seconds\n",
      "2018-09-02 03:53:51.539884 Training Step 3815 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:53:51.540316 Training Step 3815 \"loss\" =  2.9378192\n",
      "2018-09-02 03:53:52.213316 Test Step 3820 Finished\n",
      "2018-09-02 03:53:52.213432 Test Step 3820 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:52.214146 Test Step 3820 \"loss\" =  8.1403055\n",
      "2018-09-02 03:53:52.370448 Training Step 3820 Finished Timing (Training: 0.920183, Test: 0.0784581) after 0.830042 seconds\n",
      "2018-09-02 03:53:52.370562 Training Step 3820 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:53:52.370606 Training Step 3820 \"loss\" =  2.969628\n",
      "2018-09-02 03:53:53.036182 Test Step 3825 Finished\n",
      "2018-09-02 03:53:53.036664 Test Step 3825 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:53.036727 Test Step 3825 \"loss\" =  7.738777\n",
      "2018-09-02 03:53:53.182969 Training Step 3825 Finished Timing (Training: 0.921017, Test: 0.0773924) after 0.811459 seconds\n",
      "2018-09-02 03:53:53.183038 Training Step 3825 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:53:53.183469 Training Step 3825 \"loss\" =  2.8944263\n",
      "2018-09-02 03:53:53.863279 Test Step 3830 Finished\n",
      "2018-09-02 03:53:53.863780 Test Step 3830 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:53.863843 Test Step 3830 \"loss\" =  7.225093\n",
      "2018-09-02 03:53:54.015626 Training Step 3830 Finished Timing (Training: 0.921731, Test: 0.0766311) after 0.832096 seconds\n",
      "2018-09-02 03:53:54.015688 Training Step 3830 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:53:54.016198 Training Step 3830 \"loss\" =  2.8155706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:53:54.684920 Test Step 3835 Finished\n",
      "2018-09-02 03:53:54.685400 Test Step 3835 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:54.685644 Test Step 3835 \"loss\" =  7.6200705\n",
      "2018-09-02 03:53:54.843047 Training Step 3835 Finished Timing (Training: 0.921612, Test: 0.0766904) after 0.826785 seconds\n",
      "2018-09-02 03:53:54.843107 Training Step 3835 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:53:54.843460 Training Step 3835 \"loss\" =  2.8839934\n",
      "2018-09-02 03:53:55.519561 Test Step 3840 Finished\n",
      "2018-09-02 03:53:55.519997 Test Step 3840 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:55.520198 Test Step 3840 \"loss\" =  7.565883\n",
      "2018-09-02 03:53:55.672482 Training Step 3840 Finished Timing (Training: 0.920486, Test: 0.0777276) after 0.828549 seconds\n",
      "2018-09-02 03:53:55.672774 Training Step 3840 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:53:55.673009 Training Step 3840 \"loss\" =  3.2399957\n",
      "2018-09-02 03:53:56.354200 Test Step 3845 Finished\n",
      "2018-09-02 03:53:56.354310 Test Step 3845 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:56.354802 Test Step 3845 \"loss\" =  7.554531\n",
      "2018-09-02 03:53:56.508363 Training Step 3845 Finished Timing (Training: 0.920469, Test: 0.0777366) after 0.835042 seconds\n",
      "2018-09-02 03:53:56.508502 Training Step 3845 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:53:56.508597 Training Step 3845 \"loss\" =  2.955165\n",
      "2018-09-02 03:53:57.181817 Test Step 3850 Finished\n",
      "2018-09-02 03:53:57.181984 Test Step 3850 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:57.182456 Test Step 3850 \"loss\" =  7.642058\n",
      "2018-09-02 03:53:57.331788 Training Step 3850 Finished Timing (Training: 0.920238, Test: 0.0780209) after 0.823132 seconds\n",
      "2018-09-02 03:53:57.331867 Training Step 3850 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:53:57.332224 Training Step 3850 \"loss\" =  2.8451836\n",
      "2018-09-02 03:53:57.993439 Test Step 3855 Finished\n",
      "2018-09-02 03:53:57.993575 Test Step 3855 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:57.994090 Test Step 3855 \"loss\" =  7.781189\n",
      "2018-09-02 03:53:58.145854 Training Step 3855 Finished Timing (Training: 0.920413, Test: 0.0777929) after 0.813323 seconds\n",
      "2018-09-02 03:53:58.146141 Training Step 3855 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:53:58.146199 Training Step 3855 \"loss\" =  3.2091026\n",
      "2018-09-02 03:53:58.819583 Test Step 3860 Finished\n",
      "2018-09-02 03:53:58.819701 Test Step 3860 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:58.820195 Test Step 3860 \"loss\" =  7.525331\n",
      "2018-09-02 03:53:58.977234 Training Step 3860 Finished Timing (Training: 0.919966, Test: 0.0782394) after 0.830967 seconds\n",
      "2018-09-02 03:53:58.977392 Training Step 3860 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:53:58.977479 Training Step 3860 \"loss\" =  2.8482687\n",
      "2018-09-02 03:53:59.658049 Test Step 3865 Finished\n",
      "2018-09-02 03:53:59.658509 Test Step 3865 \"min loss\" =  7.008738\n",
      "2018-09-02 03:53:59.658569 Test Step 3865 \"loss\" =  7.3616533\n",
      "2018-09-02 03:53:59.807231 Training Step 3865 Finished Timing (Training: 0.919711, Test: 0.0784552) after 0.829029 seconds\n",
      "2018-09-02 03:53:59.807291 Training Step 3865 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:53:59.807343 Training Step 3865 \"loss\" =  3.0640182\n",
      "2018-09-02 03:54:00.475213 Test Step 3870 Finished\n",
      "2018-09-02 03:54:00.475679 Test Step 3870 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:00.475744 Test Step 3870 \"loss\" =  7.156638\n",
      "2018-09-02 03:54:00.632149 Training Step 3870 Finished Timing (Training: 0.919392, Test: 0.0787911) after 0.82422 seconds\n",
      "2018-09-02 03:54:00.632242 Training Step 3870 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:00.632287 Training Step 3870 \"loss\" =  2.8721519\n",
      "2018-09-02 03:54:01.306533 Test Step 3875 Finished\n",
      "2018-09-02 03:54:01.306702 Test Step 3875 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:01.307596 Test Step 3875 \"loss\" =  7.635671\n",
      "2018-09-02 03:54:01.455176 Training Step 3875 Finished Timing (Training: 0.919202, Test: 0.0789876) after 0.822807 seconds\n",
      "2018-09-02 03:54:01.455609 Training Step 3875 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:01.455949 Training Step 3875 \"loss\" =  2.954498\n",
      "2018-09-02 03:54:02.117560 Test Step 3880 Finished\n",
      "2018-09-02 03:54:02.118092 Test Step 3880 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:02.118733 Test Step 3880 \"loss\" =  7.176629\n",
      "2018-09-02 03:54:02.265738 Training Step 3880 Finished Timing (Training: 0.919189, Test: 0.0788885) after 0.809215 seconds\n",
      "2018-09-02 03:54:02.265822 Training Step 3880 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:02.266432 Training Step 3880 \"loss\" =  3.3128464\n",
      "2018-09-02 03:54:02.936813 Test Step 3885 Finished\n",
      "2018-09-02 03:54:02.937424 Test Step 3885 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:02.937790 Test Step 3885 \"loss\" =  7.704836\n",
      "2018-09-02 03:54:03.093748 Training Step 3885 Finished Timing (Training: 0.919551, Test: 0.0784591) after 0.826847 seconds\n",
      "2018-09-02 03:54:03.094172 Training Step 3885 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:03.094476 Training Step 3885 \"loss\" =  2.922739\n",
      "2018-09-02 03:54:03.751379 Test Step 3890 Finished\n",
      "2018-09-02 03:54:03.751526 Test Step 3890 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:03.752408 Test Step 3890 \"loss\" =  9.083467\n",
      "2018-09-02 03:54:03.903273 Training Step 3890 Finished Timing (Training: 0.919527, Test: 0.0784005) after 0.808103 seconds\n",
      "2018-09-02 03:54:03.903352 Training Step 3890 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:03.903964 Training Step 3890 \"loss\" =  3.421786\n",
      "2018-09-02 03:54:04.572867 Test Step 3895 Finished\n",
      "2018-09-02 03:54:04.573358 Test Step 3895 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:04.573666 Test Step 3895 \"loss\" =  7.5077047\n",
      "2018-09-02 03:54:04.729219 Training Step 3895 Finished Timing (Training: 0.919511, Test: 0.0783685) after 0.824788 seconds\n",
      "2018-09-02 03:54:04.729603 Training Step 3895 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:04.729947 Training Step 3895 \"loss\" =  2.9051058\n",
      "2018-09-02 03:54:05.405527 Test Step 3900 Finished\n",
      "2018-09-02 03:54:05.405644 Test Step 3900 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:05.406378 Test Step 3900 \"loss\" =  7.5872126\n",
      "2018-09-02 03:54:05.561728 Training Step 3900 Finished Timing (Training: 0.919367, Test: 0.0784516) after 0.831209 seconds\n",
      "2018-09-02 03:54:05.561808 Training Step 3900 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:05.562417 Training Step 3900 \"loss\" =  2.812188\n",
      "2018-09-02 03:54:06.236821 Test Step 3905 Finished\n",
      "2018-09-02 03:54:06.237432 Test Step 3905 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:06.237783 Test Step 3905 \"loss\" =  7.5399256\n",
      "2018-09-02 03:54:06.391288 Training Step 3905 Finished Timing (Training: 0.92019, Test: 0.0780553) after 0.82853 seconds\n",
      "2018-09-02 03:54:06.391394 Training Step 3905 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:06.392134 Training Step 3905 \"loss\" =  3.028753\n",
      "2018-09-02 03:54:07.064369 Test Step 3910 Finished\n",
      "2018-09-02 03:54:07.064541 Test Step 3910 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:07.065439 Test Step 3910 \"loss\" =  8.353618\n",
      "2018-09-02 03:54:07.219351 Training Step 3910 Finished Timing (Training: 0.918145, Test: 0.0793841) after 0.826873 seconds\n",
      "2018-09-02 03:54:07.219429 Training Step 3910 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:07.220151 Training Step 3910 \"loss\" =  3.099796\n",
      "2018-09-02 03:54:07.893541 Test Step 3915 Finished\n",
      "2018-09-02 03:54:07.893683 Test Step 3915 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:07.894569 Test Step 3915 \"loss\" =  7.519113\n",
      "2018-09-02 03:54:08.047356 Training Step 3915 Finished Timing (Training: 0.918488, Test: 0.0788412) after 0.826853 seconds\n",
      "2018-09-02 03:54:08.047498 Training Step 3915 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:08.048373 Training Step 3915 \"loss\" =  2.9706905\n",
      "2018-09-02 03:54:08.711291 Test Step 3920 Finished\n",
      "2018-09-02 03:54:08.711932 Test Step 3920 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:08.712459 Test Step 3920 \"loss\" =  7.356281\n",
      "2018-09-02 03:54:08.868537 Training Step 3920 Finished Timing (Training: 0.917815, Test: 0.0792842) after 0.819788 seconds\n",
      "2018-09-02 03:54:08.868616 Training Step 3920 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:08.869112 Training Step 3920 \"loss\" =  3.0174744\n",
      "2018-09-02 03:54:09.534357 Test Step 3925 Finished\n",
      "2018-09-02 03:54:09.534789 Test Step 3925 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:09.535318 Test Step 3925 \"loss\" =  7.8674107\n",
      "2018-09-02 03:54:09.687233 Training Step 3925 Finished Timing (Training: 0.917605, Test: 0.0794659) after 0.817531 seconds\n",
      "2018-09-02 03:54:09.687316 Training Step 3925 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:09.687943 Training Step 3925 \"loss\" =  2.969202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:54:10.366030 Test Step 3930 Finished\n",
      "2018-09-02 03:54:10.366494 Test Step 3930 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:10.367025 Test Step 3930 \"loss\" =  8.011255\n",
      "2018-09-02 03:54:10.518010 Training Step 3930 Finished Timing (Training: 0.917628, Test: 0.0794449) after 0.829484 seconds\n",
      "2018-09-02 03:54:10.518090 Training Step 3930 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:10.518699 Training Step 3930 \"loss\" =  2.9087877\n",
      "2018-09-02 03:54:11.189895 Test Step 3935 Finished\n",
      "2018-09-02 03:54:11.190405 Test Step 3935 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:11.190988 Test Step 3935 \"loss\" =  7.476887\n",
      "2018-09-02 03:54:11.343857 Training Step 3935 Finished Timing (Training: 0.917023, Test: 0.0799649) after 0.824519 seconds\n",
      "2018-09-02 03:54:11.344285 Training Step 3935 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:11.344689 Training Step 3935 \"loss\" =  3.0388541\n",
      "2018-09-02 03:54:12.001541 Test Step 3940 Finished\n",
      "2018-09-02 03:54:12.001662 Test Step 3940 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:12.002269 Test Step 3940 \"loss\" =  7.859748\n",
      "2018-09-02 03:54:12.153594 Training Step 3940 Finished Timing (Training: 0.916809, Test: 0.0802104) after 0.808325 seconds\n",
      "2018-09-02 03:54:12.153709 Training Step 3940 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:12.153752 Training Step 3940 \"loss\" =  2.7968867\n",
      "2018-09-02 03:54:12.816897 Test Step 3945 Finished\n",
      "2018-09-02 03:54:12.816996 Test Step 3945 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:12.817047 Test Step 3945 \"loss\" =  8.091982\n",
      "2018-09-02 03:54:12.971554 Training Step 3945 Finished Timing (Training: 0.918325, Test: 0.0789628) after 0.817743 seconds\n",
      "2018-09-02 03:54:12.971666 Training Step 3945 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:12.971705 Training Step 3945 \"loss\" =  2.893577\n",
      "2018-09-02 03:54:13.640677 Test Step 3950 Finished\n",
      "2018-09-02 03:54:13.641220 Test Step 3950 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:13.641392 Test Step 3950 \"loss\" =  8.125976\n",
      "2018-09-02 03:54:13.794313 Training Step 3950 Finished Timing (Training: 0.918323, Test: 0.0791024) after 0.82252 seconds\n",
      "2018-09-02 03:54:13.794468 Training Step 3950 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:13.794568 Training Step 3950 \"loss\" =  2.9819865\n",
      "2018-09-02 03:54:14.460779 Test Step 3955 Finished\n",
      "2018-09-02 03:54:14.460879 Test Step 3955 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:14.460972 Test Step 3955 \"loss\" =  7.6727595\n",
      "2018-09-02 03:54:14.616949 Training Step 3955 Finished Timing (Training: 0.918893, Test: 0.0786972) after 0.822318 seconds\n",
      "2018-09-02 03:54:14.617036 Training Step 3955 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:14.617101 Training Step 3955 \"loss\" =  2.865987\n",
      "2018-09-02 03:54:15.290548 Test Step 3960 Finished\n",
      "2018-09-02 03:54:15.290651 Test Step 3960 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:15.291223 Test Step 3960 \"loss\" =  7.2364435\n",
      "2018-09-02 03:54:15.448548 Training Step 3960 Finished Timing (Training: 0.919136, Test: 0.0785563) after 0.831372 seconds\n",
      "2018-09-02 03:54:15.448604 Training Step 3960 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:15.448642 Training Step 3960 \"loss\" =  2.7853465\n",
      "2018-09-02 03:54:16.118944 Test Step 3965 Finished\n",
      "2018-09-02 03:54:16.119087 Test Step 3965 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:16.119149 Test Step 3965 \"loss\" =  7.3493204\n",
      "2018-09-02 03:54:16.266975 Training Step 3965 Finished Timing (Training: 0.918857, Test: 0.0788715) after 0.817212 seconds\n",
      "2018-09-02 03:54:16.267054 Training Step 3965 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:16.267463 Training Step 3965 \"loss\" =  3.0183258\n",
      "2018-09-02 03:54:16.939548 Test Step 3970 Finished\n",
      "2018-09-02 03:54:16.939650 Test Step 3970 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:16.940277 Test Step 3970 \"loss\" =  7.957377\n",
      "2018-09-02 03:54:17.088395 Training Step 3970 Finished Timing (Training: 0.919038, Test: 0.0787327) after 0.820862 seconds\n",
      "2018-09-02 03:54:17.088466 Training Step 3970 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:17.088946 Training Step 3970 \"loss\" =  3.1091526\n",
      "2018-09-02 03:54:17.760948 Test Step 3975 Finished\n",
      "2018-09-02 03:54:17.761054 Test Step 3975 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:17.761705 Test Step 3975 \"loss\" =  7.326009\n",
      "2018-09-02 03:54:17.913572 Training Step 3975 Finished Timing (Training: 0.919179, Test: 0.0786215) after 0.824557 seconds\n",
      "2018-09-02 03:54:17.913647 Training Step 3975 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:17.914091 Training Step 3975 \"loss\" =  3.1538322\n",
      "2018-09-02 03:54:18.586404 Test Step 3980 Finished\n",
      "2018-09-02 03:54:18.586546 Test Step 3980 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:18.587264 Test Step 3980 \"loss\" =  7.529049\n",
      "2018-09-02 03:54:18.743480 Training Step 3980 Finished Timing (Training: 0.919182, Test: 0.078633) after 0.829316 seconds\n",
      "2018-09-02 03:54:18.743560 Training Step 3980 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:18.743992 Training Step 3980 \"loss\" =  2.6766121\n",
      "2018-09-02 03:54:19.407934 Test Step 3985 Finished\n",
      "2018-09-02 03:54:19.408038 Test Step 3985 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:19.408098 Test Step 3985 \"loss\" =  7.6339025\n",
      "2018-09-02 03:54:19.558859 Training Step 3985 Finished Timing (Training: 0.91938, Test: 0.078504) after 0.814805 seconds\n",
      "2018-09-02 03:54:19.558924 Training Step 3985 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:19.559337 Training Step 3985 \"loss\" =  2.926109\n",
      "2018-09-02 03:54:20.231771 Test Step 3990 Finished\n",
      "2018-09-02 03:54:20.231927 Test Step 3990 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:20.231988 Test Step 3990 \"loss\" =  7.585248\n",
      "2018-09-02 03:54:20.384196 Training Step 3990 Finished Timing (Training: 0.919268, Test: 0.0786769) after 0.824795 seconds\n",
      "2018-09-02 03:54:20.384260 Training Step 3990 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:20.384637 Training Step 3990 \"loss\" =  3.045949\n",
      "2018-09-02 03:54:21.044920 Test Step 3995 Finished\n",
      "2018-09-02 03:54:21.045034 Test Step 3995 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:21.045785 Test Step 3995 \"loss\" =  7.440523\n",
      "2018-09-02 03:54:21.202119 Training Step 3995 Finished Timing (Training: 0.919182, Test: 0.0787601) after 0.817407 seconds\n",
      "2018-09-02 03:54:21.202248 Training Step 3995 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:21.202326 Training Step 3995 \"loss\" =  2.961142\n",
      "2018-09-02 03:54:21.855373 Test Step 4000 Finished\n",
      "2018-09-02 03:54:21.855793 Test Step 4000 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:21.855854 Test Step 4000 \"loss\" =  7.7300267\n",
      "2018-09-02 03:54:22.005895 Training Step 4000 Finished Timing (Training: 0.919178, Test: 0.0788126) after 0.803504 seconds\n",
      "2018-09-02 03:54:22.006278 Training Step 4000 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:22.006595 Training Step 4000 \"loss\" =  2.932429\n",
      "2018-09-02 03:54:22.666041 Test Step 4005 Finished\n",
      "2018-09-02 03:54:22.666533 Test Step 4005 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:22.666600 Test Step 4005 \"loss\" =  7.5922604\n",
      "2018-09-02 03:54:22.815570 Training Step 4005 Finished Timing (Training: 0.929144, Test: 0.0700311) after 0.808906 seconds\n",
      "2018-09-02 03:54:22.815877 Training Step 4005 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:22.816102 Training Step 4005 \"loss\" =  2.973527\n",
      "2018-09-02 03:54:23.479623 Test Step 4010 Finished\n",
      "2018-09-02 03:54:23.480067 Test Step 4010 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:23.480127 Test Step 4010 \"loss\" =  7.571798\n",
      "2018-09-02 03:54:23.635468 Training Step 4010 Finished Timing (Training: 0.926224, Test: 0.0724245) after 0.818961 seconds\n",
      "2018-09-02 03:54:23.635866 Training Step 4010 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:23.635935 Training Step 4010 \"loss\" =  2.6799679\n",
      "2018-09-02 03:54:24.307092 Test Step 4015 Finished\n",
      "2018-09-02 03:54:24.307243 Test Step 4015 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:24.307318 Test Step 4015 \"loss\" =  7.6157107\n",
      "2018-09-02 03:54:24.461780 Training Step 4015 Finished Timing (Training: 0.924331, Test: 0.0744278) after 0.825782 seconds\n",
      "2018-09-02 03:54:24.461848 Training Step 4015 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:24.461906 Training Step 4015 \"loss\" =  2.8697383\n",
      "2018-09-02 03:54:25.123588 Test Step 4020 Finished\n",
      "2018-09-02 03:54:25.123698 Test Step 4020 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:25.123766 Test Step 4020 \"loss\" =  7.3894134\n",
      "2018-09-02 03:54:25.279155 Training Step 4020 Finished Timing (Training: 0.923101, Test: 0.0756337) after 0.816543 seconds\n",
      "2018-09-02 03:54:25.279228 Training Step 4020 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:25.279288 Training Step 4020 \"loss\" =  3.0507135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:54:25.953183 Test Step 4025 Finished\n",
      "2018-09-02 03:54:25.953299 Test Step 4025 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:25.953406 Test Step 4025 \"loss\" =  7.337921\n",
      "2018-09-02 03:54:26.100061 Training Step 4025 Finished Timing (Training: 0.921561, Test: 0.0772196) after 0.820358 seconds\n",
      "2018-09-02 03:54:26.100135 Training Step 4025 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:26.100185 Training Step 4025 \"loss\" =  2.8257327\n",
      "2018-09-02 03:54:26.768181 Test Step 4030 Finished\n",
      "2018-09-02 03:54:26.768352 Test Step 4030 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:26.768958 Test Step 4030 \"loss\" =  7.7502847\n",
      "2018-09-02 03:54:26.922005 Training Step 4030 Finished Timing (Training: 0.921351, Test: 0.0772606) after 0.820993 seconds\n",
      "2018-09-02 03:54:26.922373 Training Step 4030 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:26.922617 Training Step 4030 \"loss\" =  3.0359373\n",
      "2018-09-02 03:54:27.576123 Test Step 4035 Finished\n",
      "2018-09-02 03:54:27.576663 Test Step 4035 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:27.576823 Test Step 4035 \"loss\" =  7.7221866\n",
      "2018-09-02 03:54:27.730131 Training Step 4035 Finished Timing (Training: 0.920632, Test: 0.0778924) after 0.807399 seconds\n",
      "2018-09-02 03:54:27.730216 Training Step 4035 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:27.730255 Training Step 4035 \"loss\" =  2.6801548\n",
      "2018-09-02 03:54:28.381301 Test Step 4040 Finished\n",
      "2018-09-02 03:54:28.381455 Test Step 4040 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:28.382037 Test Step 4040 \"loss\" =  7.375621\n",
      "2018-09-02 03:54:28.528977 Training Step 4040 Finished Timing (Training: 0.920686, Test: 0.0778609) after 0.798673 seconds\n",
      "2018-09-02 03:54:28.529052 Training Step 4040 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:28.529105 Training Step 4040 \"loss\" =  2.6786819\n",
      "2018-09-02 03:54:29.187169 Test Step 4045 Finished\n",
      "2018-09-02 03:54:29.187277 Test Step 4045 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:29.187912 Test Step 4045 \"loss\" =  7.1625204\n",
      "2018-09-02 03:54:29.336522 Training Step 4045 Finished Timing (Training: 0.920263, Test: 0.0783042) after 0.807343 seconds\n",
      "2018-09-02 03:54:29.336605 Training Step 4045 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:29.336659 Training Step 4045 \"loss\" =  2.7776437\n",
      "2018-09-02 03:54:29.998811 Test Step 4050 Finished\n",
      "2018-09-02 03:54:29.999200 Test Step 4050 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:29.999704 Test Step 4050 \"loss\" =  7.065752\n",
      "2018-09-02 03:54:30.149679 Training Step 4050 Finished Timing (Training: 0.919817, Test: 0.078637) after 0.812428 seconds\n",
      "2018-09-02 03:54:30.149917 Training Step 4050 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:30.150146 Training Step 4050 \"loss\" =  2.7536533\n",
      "2018-09-02 03:54:30.820994 Test Step 4055 Finished\n",
      "2018-09-02 03:54:30.821136 Test Step 4055 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:30.821808 Test Step 4055 \"loss\" =  7.6224623\n",
      "2018-09-02 03:54:30.962875 Training Step 4055 Finished Timing (Training: 0.919848, Test: 0.0785595) after 0.812428 seconds\n",
      "2018-09-02 03:54:30.962958 Training Step 4055 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:30.963014 Training Step 4055 \"loss\" =  2.8798852\n",
      "2018-09-02 03:54:31.630438 Test Step 4060 Finished\n",
      "2018-09-02 03:54:31.630865 Test Step 4060 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:31.631056 Test Step 4060 \"loss\" =  7.5528193\n",
      "2018-09-02 03:54:31.782864 Training Step 4060 Finished Timing (Training: 0.91975, Test: 0.0785974) after 0.819114 seconds\n",
      "2018-09-02 03:54:31.783104 Training Step 4060 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:31.783178 Training Step 4060 \"loss\" =  2.7777054\n",
      "2018-09-02 03:54:32.442336 Test Step 4065 Finished\n",
      "2018-09-02 03:54:32.442478 Test Step 4065 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:32.443096 Test Step 4065 \"loss\" =  7.884107\n",
      "2018-09-02 03:54:32.592797 Training Step 4065 Finished Timing (Training: 0.919734, Test: 0.0785536) after 0.809143 seconds\n",
      "2018-09-02 03:54:32.592871 Training Step 4065 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:32.592926 Training Step 4065 \"loss\" =  3.0385761\n",
      "2018-09-02 03:54:33.254973 Test Step 4070 Finished\n",
      "2018-09-02 03:54:33.255102 Test Step 4070 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:33.255737 Test Step 4070 \"loss\" =  7.1124144\n",
      "2018-09-02 03:54:33.407865 Training Step 4070 Finished Timing (Training: 0.919334, Test: 0.0789211) after 0.81432 seconds\n",
      "2018-09-02 03:54:33.407941 Training Step 4070 \"min loss\" =  2.6727693\n",
      "2018-09-02 03:54:33.407996 Training Step 4070 \"loss\" =  2.8121285\n",
      "2018-09-02 03:54:34.077409 Test Step 4075 Finished\n",
      "2018-09-02 03:54:34.077508 Test Step 4075 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:34.077991 Test Step 4075 \"loss\" =  7.4735975\n",
      "2018-09-02 03:54:34.225390 Training Step 4075 Finished Timing (Training: 0.919351, Test: 0.0789498) after 0.817319 seconds\n",
      "2018-09-02 03:54:34.225688 Training Step 4075 \"min loss\" =  2.594028\n",
      "2018-09-02 03:54:34.225912 Training Step 4075 \"loss\" =  2.594028\n",
      "2018-09-02 03:54:34.902799 Test Step 4080 Finished\n",
      "2018-09-02 03:54:34.902967 Test Step 4080 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:34.903021 Test Step 4080 \"loss\" =  7.5716333\n",
      "2018-09-02 03:54:35.047754 Training Step 4080 Finished Timing (Training: 0.919153, Test: 0.0791866) after 0.821782 seconds\n",
      "2018-09-02 03:54:35.047835 Training Step 4080 \"min loss\" =  2.594028\n",
      "2018-09-02 03:54:35.047908 Training Step 4080 \"loss\" =  2.6952364\n",
      "2018-09-02 03:54:35.704687 Test Step 4085 Finished\n",
      "2018-09-02 03:54:35.705093 Test Step 4085 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:35.705484 Test Step 4085 \"loss\" =  7.993836\n",
      "2018-09-02 03:54:35.862025 Training Step 4085 Finished Timing (Training: 0.919069, Test: 0.0792878) after 0.814038 seconds\n",
      "2018-09-02 03:54:35.862102 Training Step 4085 \"min loss\" =  2.594028\n",
      "2018-09-02 03:54:35.862180 Training Step 4085 \"loss\" =  2.9373047\n",
      "2018-09-02 03:54:36.524840 Test Step 4090 Finished\n",
      "2018-09-02 03:54:36.525249 Test Step 4090 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:36.525466 Test Step 4090 \"loss\" =  7.403237\n",
      "2018-09-02 03:54:36.678946 Training Step 4090 Finished Timing (Training: 0.919208, Test: 0.0791564) after 0.816662 seconds\n",
      "2018-09-02 03:54:36.679017 Training Step 4090 \"min loss\" =  2.594028\n",
      "2018-09-02 03:54:36.679527 Training Step 4090 \"loss\" =  2.991984\n",
      "2018-09-02 03:54:37.346280 Test Step 4095 Finished\n",
      "2018-09-02 03:54:37.346711 Test Step 4095 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:37.346901 Test Step 4095 \"loss\" =  7.252746\n",
      "2018-09-02 03:54:37.494410 Training Step 4095 Finished Timing (Training: 0.918957, Test: 0.0793906) after 0.81482 seconds\n",
      "2018-09-02 03:54:37.494656 Training Step 4095 \"min loss\" =  2.594028\n",
      "2018-09-02 03:54:37.494849 Training Step 4095 \"loss\" =  2.8818443\n",
      "2018-09-02 03:54:38.152379 Test Step 4100 Finished\n",
      "2018-09-02 03:54:38.152523 Test Step 4100 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:38.152870 Test Step 4100 \"loss\" =  7.6661158\n",
      "2018-09-02 03:54:38.308210 Training Step 4100 Finished Timing (Training: 0.918944, Test: 0.0793727) after 0.813059 seconds\n",
      "2018-09-02 03:54:38.308275 Training Step 4100 \"min loss\" =  2.594028\n",
      "2018-09-02 03:54:38.308755 Training Step 4100 \"loss\" =  2.7348766\n",
      "2018-09-02 03:54:38.983151 Test Step 4105 Finished\n",
      "2018-09-02 03:54:38.983258 Test Step 4105 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:38.983900 Test Step 4105 \"loss\" =  7.1942806\n",
      "2018-09-02 03:54:39.132892 Training Step 4105 Finished Timing (Training: 0.919697, Test: 0.0792876) after 0.824074 seconds\n",
      "2018-09-02 03:54:39.132965 Training Step 4105 \"min loss\" =  2.594028\n",
      "2018-09-02 03:54:39.133020 Training Step 4105 \"loss\" =  2.866714\n",
      "2018-09-02 03:54:39.785305 Test Step 4110 Finished\n",
      "2018-09-02 03:54:39.785452 Test Step 4110 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:39.785514 Test Step 4110 \"loss\" =  7.576325\n",
      "2018-09-02 03:54:39.934158 Training Step 4110 Finished Timing (Training: 0.917422, Test: 0.0813192) after 0.800373 seconds\n",
      "2018-09-02 03:54:39.934260 Training Step 4110 \"min loss\" =  2.5914214\n",
      "2018-09-02 03:54:39.934313 Training Step 4110 \"loss\" =  2.7522502\n",
      "2018-09-02 03:54:40.599281 Test Step 4115 Finished\n",
      "2018-09-02 03:54:40.599381 Test Step 4115 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:40.599442 Test Step 4115 \"loss\" =  7.5923285\n",
      "2018-09-02 03:54:40.751159 Training Step 4115 Finished Timing (Training: 0.919339, Test: 0.0793788) after 0.81679 seconds\n",
      "2018-09-02 03:54:40.751243 Training Step 4115 \"min loss\" =  2.5914214\n",
      "2018-09-02 03:54:40.751298 Training Step 4115 \"loss\" =  2.659765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:54:41.414323 Test Step 4120 Finished\n",
      "2018-09-02 03:54:41.414452 Test Step 4120 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:41.415350 Test Step 4120 \"loss\" =  7.173494\n",
      "2018-09-02 03:54:41.567497 Training Step 4120 Finished Timing (Training: 0.918395, Test: 0.0802242) after 0.816127 seconds\n",
      "2018-09-02 03:54:41.567880 Training Step 4120 \"min loss\" =  2.5914214\n",
      "2018-09-02 03:54:41.568340 Training Step 4120 \"loss\" =  2.7401233\n",
      "2018-09-02 03:54:42.215562 Test Step 4125 Finished\n",
      "2018-09-02 03:54:42.215682 Test Step 4125 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:42.216260 Test Step 4125 \"loss\" =  7.068342\n",
      "2018-09-02 03:54:42.361179 Training Step 4125 Finished Timing (Training: 0.918015, Test: 0.0803548) after 0.792365 seconds\n",
      "2018-09-02 03:54:42.361253 Training Step 4125 \"min loss\" =  2.5914214\n",
      "2018-09-02 03:54:42.361637 Training Step 4125 \"loss\" =  2.7110026\n",
      "2018-09-02 03:54:43.021121 Test Step 4130 Finished\n",
      "2018-09-02 03:54:43.021233 Test Step 4130 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:43.021769 Test Step 4130 \"loss\" =  7.7481503\n",
      "2018-09-02 03:54:43.175772 Training Step 4130 Finished Timing (Training: 0.918298, Test: 0.0799842) after 0.813824 seconds\n",
      "2018-09-02 03:54:43.175950 Training Step 4130 \"min loss\" =  2.5914214\n",
      "2018-09-02 03:54:43.176678 Training Step 4130 \"loss\" =  2.9063025\n",
      "2018-09-02 03:54:43.855312 Test Step 4135 Finished\n",
      "2018-09-02 03:54:43.855440 Test Step 4135 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:43.855534 Test Step 4135 \"loss\" =  7.353638\n",
      "2018-09-02 03:54:44.010684 Training Step 4135 Finished Timing (Training: 0.918777, Test: 0.0795257) after 0.833914 seconds\n",
      "2018-09-02 03:54:44.010774 Training Step 4135 \"min loss\" =  2.5914214\n",
      "2018-09-02 03:54:44.010840 Training Step 4135 \"loss\" =  3.2393754\n",
      "2018-09-02 03:54:44.680302 Test Step 4140 Finished\n",
      "2018-09-02 03:54:44.680637 Test Step 4140 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:44.680698 Test Step 4140 \"loss\" =  7.581183\n",
      "2018-09-02 03:54:44.827597 Training Step 4140 Finished Timing (Training: 0.918707, Test: 0.0796009) after 0.816054 seconds\n",
      "2018-09-02 03:54:44.827664 Training Step 4140 \"min loss\" =  2.5914214\n",
      "2018-09-02 03:54:44.827706 Training Step 4140 \"loss\" =  2.8420932\n",
      "2018-09-02 03:54:45.492788 Test Step 4145 Finished\n",
      "2018-09-02 03:54:45.493207 Test Step 4145 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:45.493271 Test Step 4145 \"loss\" =  7.575558\n",
      "2018-09-02 03:54:45.646146 Training Step 4145 Finished Timing (Training: 0.918713, Test: 0.0796757) after 0.818348 seconds\n",
      "2018-09-02 03:54:45.646216 Training Step 4145 \"min loss\" =  2.5914214\n",
      "2018-09-02 03:54:45.646273 Training Step 4145 \"loss\" =  2.613728\n",
      "2018-09-02 03:54:46.315351 Test Step 4150 Finished\n",
      "2018-09-02 03:54:46.315765 Test Step 4150 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:46.315829 Test Step 4150 \"loss\" =  7.5086956\n",
      "2018-09-02 03:54:46.467289 Training Step 4150 Finished Timing (Training: 0.918443, Test: 0.0799733) after 0.820605 seconds\n",
      "2018-09-02 03:54:46.467370 Training Step 4150 \"min loss\" =  2.5914214\n",
      "2018-09-02 03:54:46.467428 Training Step 4150 \"loss\" =  2.8549511\n",
      "2018-09-02 03:54:47.140637 Test Step 4155 Finished\n",
      "2018-09-02 03:54:47.141149 Test Step 4155 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:47.141214 Test Step 4155 \"loss\" =  7.9364915\n",
      "2018-09-02 03:54:47.291750 Training Step 4155 Finished Timing (Training: 0.918602, Test: 0.0797969) after 0.823666 seconds\n",
      "2018-09-02 03:54:47.291976 Training Step 4155 \"min loss\" =  2.5914214\n",
      "2018-09-02 03:54:47.292036 Training Step 4155 \"loss\" =  3.0065033\n",
      "2018-09-02 03:54:47.945843 Test Step 4160 Finished\n",
      "2018-09-02 03:54:47.945944 Test Step 4160 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:47.945995 Test Step 4160 \"loss\" =  7.8198442\n",
      "2018-09-02 03:54:48.093082 Training Step 4160 Finished Timing (Training: 0.918261, Test: 0.0802092) after 0.800975 seconds\n",
      "2018-09-02 03:54:48.093176 Training Step 4160 \"min loss\" =  2.5914214\n",
      "2018-09-02 03:54:48.093626 Training Step 4160 \"loss\" =  2.7205796\n",
      "2018-09-02 03:54:48.754003 Test Step 4165 Finished\n",
      "2018-09-02 03:54:48.754125 Test Step 4165 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:48.754877 Test Step 4165 \"loss\" =  7.493439\n",
      "2018-09-02 03:54:48.906173 Training Step 4165 Finished Timing (Training: 0.918376, Test: 0.0800327) after 0.812175 seconds\n",
      "2018-09-02 03:54:48.906248 Training Step 4165 \"min loss\" =  2.5914214\n",
      "2018-09-02 03:54:48.906305 Training Step 4165 \"loss\" =  2.8244512\n",
      "2018-09-02 03:54:49.576054 Test Step 4170 Finished\n",
      "2018-09-02 03:54:49.576215 Test Step 4170 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:49.576316 Test Step 4170 \"loss\" =  7.7633743\n",
      "2018-09-02 03:54:49.726681 Training Step 4170 Finished Timing (Training: 0.918178, Test: 0.0802277) after 0.820309 seconds\n",
      "2018-09-02 03:54:49.726757 Training Step 4170 \"min loss\" =  2.5914214\n",
      "2018-09-02 03:54:49.726798 Training Step 4170 \"loss\" =  2.764306\n",
      "2018-09-02 03:54:50.394475 Test Step 4175 Finished\n",
      "2018-09-02 03:54:50.394558 Test Step 4175 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:50.395250 Test Step 4175 \"loss\" =  7.3801394\n",
      "2018-09-02 03:54:50.546120 Training Step 4175 Finished Timing (Training: 0.917889, Test: 0.0805338) after 0.819221 seconds\n",
      "2018-09-02 03:54:50.546441 Training Step 4175 \"min loss\" =  2.5914214\n",
      "2018-09-02 03:54:50.546655 Training Step 4175 \"loss\" =  2.9115388\n",
      "2018-09-02 03:54:51.207879 Test Step 4180 Finished\n",
      "2018-09-02 03:54:51.208008 Test Step 4180 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:51.208107 Test Step 4180 \"loss\" =  7.5754137\n",
      "2018-09-02 03:54:51.361158 Training Step 4180 Finished Timing (Training: 0.917991, Test: 0.0804595) after 0.814441 seconds\n",
      "2018-09-02 03:54:51.361222 Training Step 4180 \"min loss\" =  2.5914214\n",
      "2018-09-02 03:54:51.361269 Training Step 4180 \"loss\" =  2.6793776\n",
      "2018-09-02 03:54:52.030707 Test Step 4185 Finished\n",
      "2018-09-02 03:54:52.031201 Test Step 4185 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:52.031509 Test Step 4185 \"loss\" =  7.764547\n",
      "2018-09-02 03:54:52.187775 Training Step 4185 Finished Timing (Training: 0.918174, Test: 0.0802782) after 0.826434 seconds\n",
      "2018-09-02 03:54:52.187879 Training Step 4185 \"min loss\" =  2.5914214\n",
      "2018-09-02 03:54:52.188411 Training Step 4185 \"loss\" =  3.0762653\n",
      "2018-09-02 03:54:52.848973 Test Step 4190 Finished\n",
      "2018-09-02 03:54:52.849471 Test Step 4190 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:52.849812 Test Step 4190 \"loss\" =  7.3400273\n",
      "2018-09-02 03:54:53.004413 Training Step 4190 Finished Timing (Training: 0.918412, Test: 0.0800041) after 0.815771 seconds\n",
      "2018-09-02 03:54:53.004488 Training Step 4190 \"min loss\" =  2.5914214\n",
      "2018-09-02 03:54:53.004877 Training Step 4190 \"loss\" =  2.8308046\n",
      "2018-09-02 03:54:53.665315 Test Step 4195 Finished\n",
      "2018-09-02 03:54:53.665801 Test Step 4195 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:53.665991 Test Step 4195 \"loss\" =  7.510053\n",
      "2018-09-02 03:54:53.817334 Training Step 4195 Finished Timing (Training: 0.918167, Test: 0.0802135) after 0.812393 seconds\n",
      "2018-09-02 03:54:53.817671 Training Step 4195 \"min loss\" =  2.5914214\n",
      "2018-09-02 03:54:53.817729 Training Step 4195 \"loss\" =  2.727477\n",
      "2018-09-02 03:54:54.455941 Test Step 4200 Finished\n",
      "2018-09-02 03:54:54.456385 Test Step 4200 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:54.456577 Test Step 4200 \"loss\" =  7.981264\n",
      "2018-09-02 03:54:54.602918 Training Step 4200 Finished Timing (Training: 0.91823, Test: 0.0801563) after 0.785132 seconds\n",
      "2018-09-02 03:54:54.602987 Training Step 4200 \"min loss\" =  2.5914214\n",
      "2018-09-02 03:54:54.603042 Training Step 4200 \"loss\" =  2.8057892\n",
      "2018-09-02 03:54:55.269248 Test Step 4205 Finished\n",
      "2018-09-02 03:54:55.269675 Test Step 4205 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:55.269874 Test Step 4205 \"loss\" =  7.8249283\n",
      "2018-09-02 03:54:55.423651 Training Step 4205 Finished Timing (Training: 0.91555, Test: 0.0832604) after 0.820547 seconds\n",
      "2018-09-02 03:54:55.423728 Training Step 4205 \"min loss\" =  2.5914214\n",
      "2018-09-02 03:54:55.423783 Training Step 4205 \"loss\" =  2.737586\n",
      "2018-09-02 03:54:56.083259 Test Step 4210 Finished\n",
      "2018-09-02 03:54:56.083685 Test Step 4210 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:56.083970 Test Step 4210 \"loss\" =  7.521468\n",
      "2018-09-02 03:54:56.231491 Training Step 4210 Finished Timing (Training: 0.91672, Test: 0.0816711) after 0.807116 seconds\n",
      "2018-09-02 03:54:56.231554 Training Step 4210 \"min loss\" =  2.586626\n",
      "2018-09-02 03:54:56.232012 Training Step 4210 \"loss\" =  2.8584104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:54:56.887590 Test Step 4215 Finished\n",
      "2018-09-02 03:54:56.887751 Test Step 4215 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:56.887815 Test Step 4215 \"loss\" =  7.715588\n",
      "2018-09-02 03:54:57.037722 Training Step 4215 Finished Timing (Training: 0.918029, Test: 0.0805244) after 0.805645 seconds\n",
      "2018-09-02 03:54:57.037783 Training Step 4215 \"min loss\" =  2.586626\n",
      "2018-09-02 03:54:57.038098 Training Step 4215 \"loss\" =  2.7587667\n",
      "2018-09-02 03:54:57.700959 Test Step 4220 Finished\n",
      "2018-09-02 03:54:57.701060 Test Step 4220 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:57.701606 Test Step 4220 \"loss\" =  7.614184\n",
      "2018-09-02 03:54:57.844189 Training Step 4220 Finished Timing (Training: 0.917293, Test: 0.08121) after 0.806032 seconds\n",
      "2018-09-02 03:54:57.844260 Training Step 4220 \"min loss\" =  2.586626\n",
      "2018-09-02 03:54:57.844655 Training Step 4220 \"loss\" =  2.9396122\n",
      "2018-09-02 03:54:58.513064 Test Step 4225 Finished\n",
      "2018-09-02 03:54:58.513172 Test Step 4225 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:58.513357 Test Step 4225 \"loss\" =  7.6552353\n",
      "2018-09-02 03:54:58.664862 Training Step 4225 Finished Timing (Training: 0.917568, Test: 0.0810124) after 0.820147 seconds\n",
      "2018-09-02 03:54:58.665159 Training Step 4225 \"min loss\" =  2.4666429\n",
      "2018-09-02 03:54:58.665221 Training Step 4225 \"loss\" =  2.4666429\n",
      "2018-09-02 03:54:59.341719 Test Step 4230 Finished\n",
      "2018-09-02 03:54:59.342005 Test Step 4230 \"min loss\" =  7.008738\n",
      "2018-09-02 03:54:59.342281 Test Step 4230 \"loss\" =  7.983662\n",
      "2018-09-02 03:54:59.493237 Training Step 4230 Finished Timing (Training: 0.917897, Test: 0.0807022) after 0.827939 seconds\n",
      "2018-09-02 03:54:59.493524 Training Step 4230 \"min loss\" =  2.4666429\n",
      "2018-09-02 03:54:59.493581 Training Step 4230 \"loss\" =  2.8001251\n",
      "2018-09-02 03:55:00.159079 Test Step 4235 Finished\n",
      "2018-09-02 03:55:00.159180 Test Step 4235 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:00.159269 Test Step 4235 \"loss\" =  7.3809266\n",
      "2018-09-02 03:55:00.310711 Training Step 4235 Finished Timing (Training: 0.917556, Test: 0.0811247) after 0.817072 seconds\n",
      "2018-09-02 03:55:00.310776 Training Step 4235 \"min loss\" =  2.4666429\n",
      "2018-09-02 03:55:00.310822 Training Step 4235 \"loss\" =  2.7300174\n",
      "2018-09-02 03:55:00.985095 Test Step 4240 Finished\n",
      "2018-09-02 03:55:00.985227 Test Step 4240 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:00.985806 Test Step 4240 \"loss\" =  7.046528\n",
      "2018-09-02 03:55:01.135571 Training Step 4240 Finished Timing (Training: 0.917479, Test: 0.0812198) after 0.824697 seconds\n",
      "2018-09-02 03:55:01.135639 Training Step 4240 \"min loss\" =  2.4666429\n",
      "2018-09-02 03:55:01.136242 Training Step 4240 \"loss\" =  2.7707572\n",
      "2018-09-02 03:55:01.798941 Test Step 4245 Finished\n",
      "2018-09-02 03:55:01.799018 Test Step 4245 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:01.799797 Test Step 4245 \"loss\" =  7.5408216\n",
      "2018-09-02 03:55:01.957437 Training Step 4245 Finished Timing (Training: 0.917824, Test: 0.0807922) after 0.821127 seconds\n",
      "2018-09-02 03:55:01.957514 Training Step 4245 \"min loss\" =  2.4666429\n",
      "2018-09-02 03:55:01.957564 Training Step 4245 \"loss\" =  2.7911887\n",
      "2018-09-02 03:55:02.617768 Test Step 4250 Finished\n",
      "2018-09-02 03:55:02.617880 Test Step 4250 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:02.617948 Test Step 4250 \"loss\" =  7.350402\n",
      "2018-09-02 03:55:02.772956 Training Step 4250 Finished Timing (Training: 0.918126, Test: 0.0804754) after 0.814548 seconds\n",
      "2018-09-02 03:55:02.773022 Training Step 4250 \"min loss\" =  2.4666429\n",
      "2018-09-02 03:55:02.773085 Training Step 4250 \"loss\" =  2.8810153\n",
      "2018-09-02 03:55:03.438140 Test Step 4255 Finished\n",
      "2018-09-02 03:55:03.438256 Test Step 4255 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:03.438299 Test Step 4255 \"loss\" =  7.9577904\n",
      "2018-09-02 03:55:03.587796 Training Step 4255 Finished Timing (Training: 0.918227, Test: 0.0803457) after 0.813714 seconds\n",
      "2018-09-02 03:55:03.587864 Training Step 4255 \"min loss\" =  2.4666429\n",
      "2018-09-02 03:55:03.587903 Training Step 4255 \"loss\" =  2.671431\n",
      "2018-09-02 03:55:04.254990 Test Step 4260 Finished\n",
      "2018-09-02 03:55:04.255107 Test Step 4260 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:04.255151 Test Step 4260 \"loss\" =  8.049269\n",
      "2018-09-02 03:55:04.411188 Training Step 4260 Finished Timing (Training: 0.918305, Test: 0.0803391) after 0.823202 seconds\n",
      "2018-09-02 03:55:04.411262 Training Step 4260 \"min loss\" =  2.4666429\n",
      "2018-09-02 03:55:04.411331 Training Step 4260 \"loss\" =  2.6948068\n",
      "2018-09-02 03:55:05.072390 Test Step 4265 Finished\n",
      "2018-09-02 03:55:05.072521 Test Step 4265 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:05.073093 Test Step 4265 \"loss\" =  7.43974\n",
      "2018-09-02 03:55:05.229374 Training Step 4265 Finished Timing (Training: 0.918222, Test: 0.080431) after 0.81797 seconds\n",
      "2018-09-02 03:55:05.229440 Training Step 4265 \"min loss\" =  2.4666429\n",
      "2018-09-02 03:55:05.229491 Training Step 4265 \"loss\" =  2.6736803\n",
      "2018-09-02 03:55:05.901293 Test Step 4270 Finished\n",
      "2018-09-02 03:55:05.901649 Test Step 4270 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:05.901703 Test Step 4270 \"loss\" =  7.681647\n",
      "2018-09-02 03:55:06.052236 Training Step 4270 Finished Timing (Training: 0.918054, Test: 0.0806356) after 0.822686 seconds\n",
      "2018-09-02 03:55:06.052323 Training Step 4270 \"min loss\" =  2.4666429\n",
      "2018-09-02 03:55:06.052720 Training Step 4270 \"loss\" =  2.6670706\n",
      "2018-09-02 03:55:06.721976 Test Step 4275 Finished\n",
      "2018-09-02 03:55:06.722080 Test Step 4275 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:06.722580 Test Step 4275 \"loss\" =  7.222012\n",
      "2018-09-02 03:55:06.873606 Training Step 4275 Finished Timing (Training: 0.918293, Test: 0.0803835) after 0.820812 seconds\n",
      "2018-09-02 03:55:06.873812 Training Step 4275 \"min loss\" =  2.4666429\n",
      "2018-09-02 03:55:06.873864 Training Step 4275 \"loss\" =  2.607639\n",
      "2018-09-02 03:55:07.536545 Test Step 4280 Finished\n",
      "2018-09-02 03:55:07.536679 Test Step 4280 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:07.537198 Test Step 4280 \"loss\" =  7.388635\n",
      "2018-09-02 03:55:07.684728 Training Step 4280 Finished Timing (Training: 0.918023, Test: 0.0806534) after 0.810807 seconds\n",
      "2018-09-02 03:55:07.684792 Training Step 4280 \"min loss\" =  2.4666429\n",
      "2018-09-02 03:55:07.684843 Training Step 4280 \"loss\" =  2.6841552\n",
      "2018-09-02 03:55:08.340782 Test Step 4285 Finished\n",
      "2018-09-02 03:55:08.341222 Test Step 4285 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:08.341449 Test Step 4285 \"loss\" =  7.5825543\n",
      "2018-09-02 03:55:08.497262 Training Step 4285 Finished Timing (Training: 0.918061, Test: 0.0806242) after 0.812357 seconds\n",
      "2018-09-02 03:55:08.497404 Training Step 4285 \"min loss\" =  2.4666429\n",
      "2018-09-02 03:55:08.497863 Training Step 4285 \"loss\" =  2.744434\n",
      "2018-09-02 03:55:09.161174 Test Step 4290 Finished\n",
      "2018-09-02 03:55:09.161628 Test Step 4290 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:09.161839 Test Step 4290 \"loss\" =  7.6518717\n",
      "2018-09-02 03:55:09.317020 Training Step 4290 Finished Timing (Training: 0.91797, Test: 0.0806886) after 0.819041 seconds\n",
      "2018-09-02 03:55:09.317233 Training Step 4290 \"min loss\" =  2.4527154\n",
      "2018-09-02 03:55:09.317505 Training Step 4290 \"loss\" =  2.7873137\n",
      "2018-09-02 03:55:09.982764 Test Step 4295 Finished\n",
      "2018-09-02 03:55:09.983200 Test Step 4295 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:09.983256 Test Step 4295 \"loss\" =  7.5325985\n",
      "2018-09-02 03:55:10.136260 Training Step 4295 Finished Timing (Training: 0.91805, Test: 0.0806078) after 0.818694 seconds\n",
      "2018-09-02 03:55:10.136333 Training Step 4295 \"min loss\" =  2.4527154\n",
      "2018-09-02 03:55:10.136386 Training Step 4295 \"loss\" =  2.8551395\n",
      "2018-09-02 03:55:10.799917 Test Step 4300 Finished\n",
      "2018-09-02 03:55:10.800006 Test Step 4300 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:10.800065 Test Step 4300 \"loss\" =  8.172641\n",
      "2018-09-02 03:55:10.951183 Training Step 4300 Finished Timing (Training: 0.918323, Test: 0.0803751) after 0.814732 seconds\n",
      "2018-09-02 03:55:10.951315 Training Step 4300 \"min loss\" =  2.4527154\n",
      "2018-09-02 03:55:10.951383 Training Step 4300 \"loss\" =  2.7266426\n",
      "2018-09-02 03:55:11.611326 Test Step 4305 Finished\n",
      "2018-09-02 03:55:11.611445 Test Step 4305 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:11.611982 Test Step 4305 \"loss\" =  7.502367\n",
      "2018-09-02 03:55:11.762749 Training Step 4305 Finished Timing (Training: 0.920205, Test: 0.0788813) after 0.81131 seconds\n",
      "2018-09-02 03:55:11.762830 Training Step 4305 \"min loss\" =  2.4527154\n",
      "2018-09-02 03:55:11.762884 Training Step 4305 \"loss\" =  2.8514318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:55:12.433687 Test Step 4310 Finished\n",
      "2018-09-02 03:55:12.434168 Test Step 4310 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:12.434233 Test Step 4310 \"loss\" =  7.3551426\n",
      "2018-09-02 03:55:12.588430 Training Step 4310 Finished Timing (Training: 0.921045, Test: 0.077981) after 0.825471 seconds\n",
      "2018-09-02 03:55:12.588668 Training Step 4310 \"min loss\" =  2.4527154\n",
      "2018-09-02 03:55:12.588725 Training Step 4310 \"loss\" =  2.8402472\n",
      "2018-09-02 03:55:13.247893 Test Step 4315 Finished\n",
      "2018-09-02 03:55:13.248105 Test Step 4315 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:13.248175 Test Step 4315 \"loss\" =  7.739947\n",
      "2018-09-02 03:55:13.399755 Training Step 4315 Finished Timing (Training: 0.920073, Test: 0.0787755) after 0.810484 seconds\n",
      "2018-09-02 03:55:13.399834 Training Step 4315 \"min loss\" =  2.4527154\n",
      "2018-09-02 03:55:13.399908 Training Step 4315 \"loss\" =  2.9407403\n",
      "2018-09-02 03:55:14.073485 Test Step 4320 Finished\n",
      "2018-09-02 03:55:14.073604 Test Step 4320 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:14.074075 Test Step 4320 \"loss\" =  7.7313175\n",
      "2018-09-02 03:55:14.230440 Training Step 4320 Finished Timing (Training: 0.919897, Test: 0.0787844) after 0.829869 seconds\n",
      "2018-09-02 03:55:14.230506 Training Step 4320 \"min loss\" =  2.4527154\n",
      "2018-09-02 03:55:14.230602 Training Step 4320 \"loss\" =  2.7870653\n",
      "2018-09-02 03:55:14.895351 Test Step 4325 Finished\n",
      "2018-09-02 03:55:14.895476 Test Step 4325 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:14.895534 Test Step 4325 \"loss\" =  7.2506657\n",
      "2018-09-02 03:55:15.052552 Training Step 4325 Finished Timing (Training: 0.920361, Test: 0.0784609) after 0.821879 seconds\n",
      "2018-09-02 03:55:15.052684 Training Step 4325 \"min loss\" =  2.4527154\n",
      "2018-09-02 03:55:15.053095 Training Step 4325 \"loss\" =  2.6664293\n",
      "2018-09-02 03:55:15.717483 Test Step 4330 Finished\n",
      "2018-09-02 03:55:15.717565 Test Step 4330 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:15.718211 Test Step 4330 \"loss\" =  8.147487\n",
      "2018-09-02 03:55:15.872724 Training Step 4330 Finished Timing (Training: 0.920288, Test: 0.0784351) after 0.819561 seconds\n",
      "2018-09-02 03:55:15.872795 Training Step 4330 \"min loss\" =  2.4527154\n",
      "2018-09-02 03:55:15.872857 Training Step 4330 \"loss\" =  2.7895746\n",
      "2018-09-02 03:55:16.527271 Test Step 4335 Finished\n",
      "2018-09-02 03:55:16.527836 Test Step 4335 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:16.528143 Test Step 4335 \"loss\" =  7.978001\n",
      "2018-09-02 03:55:16.678341 Training Step 4335 Finished Timing (Training: 0.920278, Test: 0.0784218) after 0.805418 seconds\n",
      "2018-09-02 03:55:16.678480 Training Step 4335 \"min loss\" =  2.4527154\n",
      "2018-09-02 03:55:16.678603 Training Step 4335 \"loss\" =  2.660491\n",
      "2018-09-02 03:55:17.340809 Test Step 4340 Finished\n",
      "2018-09-02 03:55:17.340930 Test Step 4340 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:17.340982 Test Step 4340 \"loss\" =  7.602468\n",
      "2018-09-02 03:55:17.493185 Training Step 4340 Finished Timing (Training: 0.920237, Test: 0.0784282) after 0.814523 seconds\n",
      "2018-09-02 03:55:17.493496 Training Step 4340 \"min loss\" =  2.4527154\n",
      "2018-09-02 03:55:17.493556 Training Step 4340 \"loss\" =  2.7034314\n",
      "2018-09-02 03:55:18.160827 Test Step 4345 Finished\n",
      "2018-09-02 03:55:18.160925 Test Step 4345 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:18.161030 Test Step 4345 \"loss\" =  7.518336\n",
      "2018-09-02 03:55:18.305829 Training Step 4345 Finished Timing (Training: 0.919686, Test: 0.0790281) after 0.812208 seconds\n",
      "2018-09-02 03:55:18.305945 Training Step 4345 \"min loss\" =  2.4378684\n",
      "2018-09-02 03:55:18.306018 Training Step 4345 \"loss\" =  2.4378684\n",
      "2018-09-02 03:55:18.964908 Test Step 4350 Finished\n",
      "2018-09-02 03:55:18.965003 Test Step 4350 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:18.965057 Test Step 4350 \"loss\" =  7.8312078\n",
      "2018-09-02 03:55:19.110730 Training Step 4350 Finished Timing (Training: 0.919977, Test: 0.0787291) after 0.804078 seconds\n",
      "2018-09-02 03:55:19.110801 Training Step 4350 \"min loss\" =  2.4378684\n",
      "2018-09-02 03:55:19.110858 Training Step 4350 \"loss\" =  2.9074502\n",
      "2018-09-02 03:55:19.771022 Test Step 4355 Finished\n",
      "2018-09-02 03:55:19.771138 Test Step 4355 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:19.771620 Test Step 4355 \"loss\" =  7.3418365\n",
      "2018-09-02 03:55:19.925916 Training Step 4355 Finished Timing (Training: 0.919707, Test: 0.0789473) after 0.814342 seconds\n",
      "2018-09-02 03:55:19.926405 Training Step 4355 \"min loss\" =  2.4378684\n",
      "2018-09-02 03:55:19.926472 Training Step 4355 \"loss\" =  2.6310594\n",
      "2018-09-02 03:55:20.585272 Test Step 4360 Finished\n",
      "2018-09-02 03:55:20.585390 Test Step 4360 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:20.585462 Test Step 4360 \"loss\" =  7.512809\n",
      "2018-09-02 03:55:20.738037 Training Step 4360 Finished Timing (Training: 0.919885, Test: 0.0787099) after 0.811502 seconds\n",
      "2018-09-02 03:55:20.738101 Training Step 4360 \"min loss\" =  2.4378684\n",
      "2018-09-02 03:55:20.738161 Training Step 4360 \"loss\" =  2.6397438\n",
      "2018-09-02 03:55:21.412605 Test Step 4365 Finished\n",
      "2018-09-02 03:55:21.412709 Test Step 4365 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:21.412780 Test Step 4365 \"loss\" =  8.077343\n",
      "2018-09-02 03:55:21.567785 Training Step 4365 Finished Timing (Training: 0.919704, Test: 0.0789573) after 0.829564 seconds\n",
      "2018-09-02 03:55:21.567852 Training Step 4365 \"min loss\" =  2.4378684\n",
      "2018-09-02 03:55:21.567892 Training Step 4365 \"loss\" =  2.715414\n",
      "2018-09-02 03:55:22.227011 Test Step 4370 Finished\n",
      "2018-09-02 03:55:22.227104 Test Step 4370 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:22.227162 Test Step 4370 \"loss\" =  7.5284634\n",
      "2018-09-02 03:55:22.379608 Training Step 4370 Finished Timing (Training: 0.919738, Test: 0.078981) after 0.811622 seconds\n",
      "2018-09-02 03:55:22.379747 Training Step 4370 \"min loss\" =  2.4378684\n",
      "2018-09-02 03:55:22.379817 Training Step 4370 \"loss\" =  2.9651017\n",
      "2018-09-02 03:55:23.036994 Test Step 4375 Finished\n",
      "2018-09-02 03:55:23.037088 Test Step 4375 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:23.037778 Test Step 4375 \"loss\" =  7.453182\n",
      "2018-09-02 03:55:23.190294 Training Step 4375 Finished Timing (Training: 0.919587, Test: 0.079099) after 0.810412 seconds\n",
      "2018-09-02 03:55:23.190420 Training Step 4375 \"min loss\" =  2.4378684\n",
      "2018-09-02 03:55:23.190969 Training Step 4375 \"loss\" =  2.7308493\n",
      "2018-09-02 03:55:23.854272 Test Step 4380 Finished\n",
      "2018-09-02 03:55:23.854389 Test Step 4380 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:23.854986 Test Step 4380 \"loss\" =  7.118603\n",
      "2018-09-02 03:55:24.008810 Training Step 4380 Finished Timing (Training: 0.91955, Test: 0.079098) after 0.817771 seconds\n",
      "2018-09-02 03:55:24.008882 Training Step 4380 \"min loss\" =  2.4378684\n",
      "2018-09-02 03:55:24.008935 Training Step 4380 \"loss\" =  2.7926536\n",
      "2018-09-02 03:55:24.664503 Test Step 4385 Finished\n",
      "2018-09-02 03:55:24.664636 Test Step 4385 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:24.665231 Test Step 4385 \"loss\" =  7.7949476\n",
      "2018-09-02 03:55:24.814777 Training Step 4385 Finished Timing (Training: 0.919331, Test: 0.0792532) after 0.805116 seconds\n",
      "2018-09-02 03:55:24.814843 Training Step 4385 \"min loss\" =  2.4378684\n",
      "2018-09-02 03:55:24.814882 Training Step 4385 \"loss\" =  2.495047\n",
      "2018-09-02 03:55:25.493554 Test Step 4390 Finished\n",
      "2018-09-02 03:55:25.493657 Test Step 4390 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:25.493747 Test Step 4390 \"loss\" =  7.481183\n",
      "2018-09-02 03:55:25.639472 Training Step 4390 Finished Timing (Training: 0.919334, Test: 0.0792536) after 0.824513 seconds\n",
      "2018-09-02 03:55:25.639543 Training Step 4390 \"min loss\" =  2.4378684\n",
      "2018-09-02 03:55:25.639582 Training Step 4390 \"loss\" =  3.1319883\n",
      "2018-09-02 03:55:26.293991 Test Step 4395 Finished\n",
      "2018-09-02 03:55:26.294079 Test Step 4395 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:26.294143 Test Step 4395 \"loss\" =  7.8148727\n",
      "2018-09-02 03:55:26.445385 Training Step 4395 Finished Timing (Training: 0.919406, Test: 0.079228) after 0.805749 seconds\n",
      "2018-09-02 03:55:26.445471 Training Step 4395 \"min loss\" =  2.4378684\n",
      "2018-09-02 03:55:26.445529 Training Step 4395 \"loss\" =  2.5948002\n",
      "2018-09-02 03:55:27.108852 Test Step 4400 Finished\n",
      "2018-09-02 03:55:27.109295 Test Step 4400 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:27.109496 Test Step 4400 \"loss\" =  7.48528\n",
      "2018-09-02 03:55:27.256530 Training Step 4400 Finished Timing (Training: 0.919312, Test: 0.0793068) after 0.810925 seconds\n",
      "2018-09-02 03:55:27.256769 Training Step 4400 \"min loss\" =  2.4378684\n",
      "2018-09-02 03:55:27.257001 Training Step 4400 \"loss\" =  2.7631402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:55:27.917988 Test Step 4405 Finished\n",
      "2018-09-02 03:55:27.918119 Test Step 4405 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:27.918173 Test Step 4405 \"loss\" =  7.772566\n",
      "2018-09-02 03:55:28.073976 Training Step 4405 Finished Timing (Training: 0.921725, Test: 0.0779389) after 0.816918 seconds\n",
      "2018-09-02 03:55:28.074040 Training Step 4405 \"min loss\" =  2.4378684\n",
      "2018-09-02 03:55:28.074099 Training Step 4405 \"loss\" =  2.6593075\n",
      "2018-09-02 03:55:28.742193 Test Step 4410 Finished\n",
      "2018-09-02 03:55:28.742297 Test Step 4410 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:28.742370 Test Step 4410 \"loss\" =  7.9245186\n",
      "2018-09-02 03:55:28.886873 Training Step 4410 Finished Timing (Training: 0.918934, Test: 0.0800694) after 0.812709 seconds\n",
      "2018-09-02 03:55:28.886970 Training Step 4410 \"min loss\" =  2.4378684\n",
      "2018-09-02 03:55:28.887480 Training Step 4410 \"loss\" =  2.750099\n",
      "2018-09-02 03:55:29.549306 Test Step 4415 Finished\n",
      "2018-09-02 03:55:29.549446 Test Step 4415 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:29.550092 Test Step 4415 \"loss\" =  8.380268\n",
      "2018-09-02 03:55:29.701007 Training Step 4415 Finished Timing (Training: 0.918031, Test: 0.0806601) after 0.813446 seconds\n",
      "2018-09-02 03:55:29.701139 Training Step 4415 \"min loss\" =  2.4378684\n",
      "2018-09-02 03:55:29.701189 Training Step 4415 \"loss\" =  2.671301\n",
      "2018-09-02 03:55:30.370493 Test Step 4420 Finished\n",
      "2018-09-02 03:55:30.370678 Test Step 4420 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:30.371700 Test Step 4420 \"loss\" =  7.653707\n",
      "2018-09-02 03:55:30.526411 Training Step 4420 Finished Timing (Training: 0.917669, Test: 0.0805277) after 0.824438 seconds\n",
      "2018-09-02 03:55:30.526781 Training Step 4420 \"min loss\" =  2.4378684\n",
      "2018-09-02 03:55:30.527127 Training Step 4420 \"loss\" =  2.6692486\n",
      "2018-09-02 03:55:31.183148 Test Step 4425 Finished\n",
      "2018-09-02 03:55:31.183266 Test Step 4425 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:31.183763 Test Step 4425 \"loss\" =  7.879492\n",
      "2018-09-02 03:55:31.335739 Training Step 4425 Finished Timing (Training: 0.918012, Test: 0.0800821) after 0.808157 seconds\n",
      "2018-09-02 03:55:31.335808 Training Step 4425 \"min loss\" =  2.4378684\n",
      "2018-09-02 03:55:31.335866 Training Step 4425 \"loss\" =  2.6056936\n",
      "2018-09-02 03:55:31.988060 Test Step 4430 Finished\n",
      "2018-09-02 03:55:31.988168 Test Step 4430 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:31.988805 Test Step 4430 \"loss\" =  8.441659\n",
      "2018-09-02 03:55:32.139163 Training Step 4430 Finished Timing (Training: 0.919493, Test: 0.0786607) after 0.803235 seconds\n",
      "2018-09-02 03:55:32.139222 Training Step 4430 \"min loss\" =  2.4378684\n",
      "2018-09-02 03:55:32.139271 Training Step 4430 \"loss\" =  2.8150785\n",
      "2018-09-02 03:55:32.808012 Test Step 4435 Finished\n",
      "2018-09-02 03:55:32.808135 Test Step 4435 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:32.808215 Test Step 4435 \"loss\" =  7.9540462\n",
      "2018-09-02 03:55:32.966078 Training Step 4435 Finished Timing (Training: 0.919284, Test: 0.0788844) after 0.826744 seconds\n",
      "2018-09-02 03:55:32.966172 Training Step 4435 \"min loss\" =  2.4378684\n",
      "2018-09-02 03:55:32.966668 Training Step 4435 \"loss\" =  2.6099958\n",
      "2018-09-02 03:55:33.627016 Test Step 4440 Finished\n",
      "2018-09-02 03:55:33.627135 Test Step 4440 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:33.627884 Test Step 4440 \"loss\" =  8.005828\n",
      "2018-09-02 03:55:33.781284 Training Step 4440 Finished Timing (Training: 0.918703, Test: 0.0793966) after 0.814552 seconds\n",
      "2018-09-02 03:55:33.781363 Training Step 4440 \"min loss\" =  2.4378684\n",
      "2018-09-02 03:55:33.781410 Training Step 4440 \"loss\" =  2.5625775\n",
      "2018-09-02 03:55:34.449405 Test Step 4445 Finished\n",
      "2018-09-02 03:55:34.449525 Test Step 4445 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:34.450185 Test Step 4445 \"loss\" =  7.741134\n",
      "2018-09-02 03:55:34.599035 Training Step 4445 Finished Timing (Training: 0.918693, Test: 0.079428) after 0.817507 seconds\n",
      "2018-09-02 03:55:34.599220 Training Step 4445 \"min loss\" =  2.4378684\n",
      "2018-09-02 03:55:34.599276 Training Step 4445 \"loss\" =  2.6768415\n",
      "2018-09-02 03:55:35.274079 Test Step 4450 Finished\n",
      "2018-09-02 03:55:35.274558 Test Step 4450 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:35.274618 Test Step 4450 \"loss\" =  7.6361837\n",
      "2018-09-02 03:55:35.432177 Training Step 4450 Finished Timing (Training: 0.919529, Test: 0.0785867) after 0.832169 seconds\n",
      "2018-09-02 03:55:35.432243 Training Step 4450 \"min loss\" =  2.4378684\n",
      "2018-09-02 03:55:35.432299 Training Step 4450 \"loss\" =  2.5127444\n",
      "2018-09-02 03:55:36.109564 Test Step 4455 Finished\n",
      "2018-09-02 03:55:36.109699 Test Step 4455 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:36.109764 Test Step 4455 \"loss\" =  7.6086826\n",
      "2018-09-02 03:55:36.262167 Training Step 4455 Finished Timing (Training: 0.919328, Test: 0.0789077) after 0.829808 seconds\n",
      "2018-09-02 03:55:36.262235 Training Step 4455 \"min loss\" =  2.3790567\n",
      "2018-09-02 03:55:36.262295 Training Step 4455 \"loss\" =  2.3790567\n",
      "2018-09-02 03:55:36.928694 Test Step 4460 Finished\n",
      "2018-09-02 03:55:36.928840 Test Step 4460 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:36.929545 Test Step 4460 \"loss\" =  7.9082165\n",
      "2018-09-02 03:55:37.076547 Training Step 4460 Finished Timing (Training: 0.919202, Test: 0.0790649) after 0.814197 seconds\n",
      "2018-09-02 03:55:37.076854 Training Step 4460 \"min loss\" =  2.3790567\n",
      "2018-09-02 03:55:37.076913 Training Step 4460 \"loss\" =  2.66875\n",
      "2018-09-02 03:55:37.742120 Test Step 4465 Finished\n",
      "2018-09-02 03:55:37.742602 Test Step 4465 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:37.742661 Test Step 4465 \"loss\" =  8.071997\n",
      "2018-09-02 03:55:37.893106 Training Step 4465 Finished Timing (Training: 0.91917, Test: 0.0791316) after 0.816129 seconds\n",
      "2018-09-02 03:55:37.893190 Training Step 4465 \"min loss\" =  2.3790567\n",
      "2018-09-02 03:55:37.893707 Training Step 4465 \"loss\" =  2.446465\n",
      "2018-09-02 03:55:38.553556 Test Step 4470 Finished\n",
      "2018-09-02 03:55:38.553671 Test Step 4470 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:38.553780 Test Step 4470 \"loss\" =  7.6734924\n",
      "2018-09-02 03:55:38.705595 Training Step 4470 Finished Timing (Training: 0.9191, Test: 0.0792343) after 0.811821 seconds\n",
      "2018-09-02 03:55:38.705671 Training Step 4470 \"min loss\" =  2.3790567\n",
      "2018-09-02 03:55:38.706165 Training Step 4470 \"loss\" =  2.474731\n",
      "2018-09-02 03:55:39.361202 Test Step 4475 Finished\n",
      "2018-09-02 03:55:39.361373 Test Step 4475 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:39.362194 Test Step 4475 \"loss\" =  7.9109087\n",
      "2018-09-02 03:55:39.510968 Training Step 4475 Finished Timing (Training: 0.918937, Test: 0.0793649) after 0.804739 seconds\n",
      "2018-09-02 03:55:39.511029 Training Step 4475 \"min loss\" =  2.3790567\n",
      "2018-09-02 03:55:39.511067 Training Step 4475 \"loss\" =  2.6566248\n",
      "2018-09-02 03:55:40.171033 Test Step 4480 Finished\n",
      "2018-09-02 03:55:40.171121 Test Step 4480 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:40.171757 Test Step 4480 \"loss\" =  7.1200957\n",
      "2018-09-02 03:55:40.322352 Training Step 4480 Finished Timing (Training: 0.918664, Test: 0.0796437) after 0.811233 seconds\n",
      "2018-09-02 03:55:40.322665 Training Step 4480 \"min loss\" =  2.3790567\n",
      "2018-09-02 03:55:40.322730 Training Step 4480 \"loss\" =  2.8647346\n",
      "2018-09-02 03:55:40.998318 Test Step 4485 Finished\n",
      "2018-09-02 03:55:40.998409 Test Step 4485 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:40.998460 Test Step 4485 \"loss\" =  7.459521\n",
      "2018-09-02 03:55:41.143569 Training Step 4485 Finished Timing (Training: 0.91864, Test: 0.0796479) after 0.820779 seconds\n",
      "2018-09-02 03:55:41.143632 Training Step 4485 \"min loss\" =  2.296646\n",
      "2018-09-02 03:55:41.144290 Training Step 4485 \"loss\" =  2.3792758\n",
      "2018-09-02 03:55:41.795708 Test Step 4490 Finished\n",
      "2018-09-02 03:55:41.795817 Test Step 4490 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:41.796354 Test Step 4490 \"loss\" =  7.522142\n",
      "2018-09-02 03:55:41.940916 Training Step 4490 Finished Timing (Training: 0.918713, Test: 0.0795374) after 0.796176 seconds\n",
      "2018-09-02 03:55:41.940991 Training Step 4490 \"min loss\" =  2.296646\n",
      "2018-09-02 03:55:41.941074 Training Step 4490 \"loss\" =  2.3885489\n",
      "2018-09-02 03:55:42.607992 Test Step 4495 Finished\n",
      "2018-09-02 03:55:42.608108 Test Step 4495 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:42.608168 Test Step 4495 \"loss\" =  7.563551\n",
      "2018-09-02 03:55:42.757650 Training Step 4495 Finished Timing (Training: 0.918986, Test: 0.0793267) after 0.816509 seconds\n",
      "2018-09-02 03:55:42.757760 Training Step 4495 \"min loss\" =  2.296646\n",
      "2018-09-02 03:55:42.758391 Training Step 4495 \"loss\" =  2.651324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:55:43.423466 Test Step 4500 Finished\n",
      "2018-09-02 03:55:43.423587 Test Step 4500 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:43.424298 Test Step 4500 \"loss\" =  7.790623\n",
      "2018-09-02 03:55:43.574791 Training Step 4500 Finished Timing (Training: 0.918941, Test: 0.0793379) after 0.816162 seconds\n",
      "2018-09-02 03:55:43.574860 Training Step 4500 \"min loss\" =  2.296646\n",
      "2018-09-02 03:55:43.575442 Training Step 4500 \"loss\" =  2.8656507\n",
      "2018-09-02 03:55:44.230639 Test Step 4505 Finished\n",
      "2018-09-02 03:55:44.230759 Test Step 4505 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:44.230821 Test Step 4505 \"loss\" =  8.036598\n",
      "2018-09-02 03:55:44.383417 Training Step 4505 Finished Timing (Training: 0.916306, Test: 0.0833465) after 0.807909 seconds\n",
      "2018-09-02 03:55:44.383480 Training Step 4505 \"min loss\" =  2.296646\n",
      "2018-09-02 03:55:44.383529 Training Step 4505 \"loss\" =  2.6414807\n",
      "2018-09-02 03:55:45.051373 Test Step 4510 Finished\n",
      "2018-09-02 03:55:45.051791 Test Step 4510 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:45.051854 Test Step 4510 \"loss\" =  7.914387\n",
      "2018-09-02 03:55:45.203641 Training Step 4510 Finished Timing (Training: 0.916837, Test: 0.0820978) after 0.819333 seconds\n",
      "2018-09-02 03:55:45.203808 Training Step 4510 \"min loss\" =  2.296646\n",
      "2018-09-02 03:55:45.203898 Training Step 4510 \"loss\" =  2.6704257\n",
      "2018-09-02 03:55:45.866069 Test Step 4515 Finished\n",
      "2018-09-02 03:55:45.866161 Test Step 4515 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:45.866213 Test Step 4515 \"loss\" =  7.4138427\n",
      "2018-09-02 03:55:46.019470 Training Step 4515 Finished Timing (Training: 0.918127, Test: 0.0803986) after 0.814862 seconds\n",
      "2018-09-02 03:55:46.019537 Training Step 4515 \"min loss\" =  2.296646\n",
      "2018-09-02 03:55:46.019598 Training Step 4515 \"loss\" =  2.6256547\n",
      "2018-09-02 03:55:46.687636 Test Step 4520 Finished\n",
      "2018-09-02 03:55:46.687746 Test Step 4520 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:46.687792 Test Step 4520 \"loss\" =  7.459825\n",
      "2018-09-02 03:55:46.839310 Training Step 4520 Finished Timing (Training: 0.920205, Test: 0.0783748) after 0.819044 seconds\n",
      "2018-09-02 03:55:46.839462 Training Step 4520 \"min loss\" =  2.296646\n",
      "2018-09-02 03:55:46.839534 Training Step 4520 \"loss\" =  2.8152404\n",
      "2018-09-02 03:55:47.500864 Test Step 4525 Finished\n",
      "2018-09-02 03:55:47.500978 Test Step 4525 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:47.501021 Test Step 4525 \"loss\" =  8.063367\n",
      "2018-09-02 03:55:47.652631 Training Step 4525 Finished Timing (Training: 0.920966, Test: 0.0775828) after 0.812305 seconds\n",
      "2018-09-02 03:55:47.652711 Training Step 4525 \"min loss\" =  2.296646\n",
      "2018-09-02 03:55:47.652750 Training Step 4525 \"loss\" =  2.6655939\n",
      "2018-09-02 03:55:48.321554 Test Step 4530 Finished\n",
      "2018-09-02 03:55:48.321690 Test Step 4530 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:48.321771 Test Step 4530 \"loss\" =  8.122998\n",
      "2018-09-02 03:55:48.472638 Training Step 4530 Finished Timing (Training: 0.920501, Test: 0.0780493) after 0.819153 seconds\n",
      "2018-09-02 03:55:48.472799 Training Step 4530 \"min loss\" =  2.296646\n",
      "2018-09-02 03:55:48.473278 Training Step 4530 \"loss\" =  2.617995\n",
      "2018-09-02 03:55:49.143944 Test Step 4535 Finished\n",
      "2018-09-02 03:55:49.144062 Test Step 4535 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:49.144706 Test Step 4535 \"loss\" =  8.162229\n",
      "2018-09-02 03:55:49.299410 Training Step 4535 Finished Timing (Training: 0.920752, Test: 0.077675) after 0.825735 seconds\n",
      "2018-09-02 03:55:49.299484 Training Step 4535 \"min loss\" =  2.296646\n",
      "2018-09-02 03:55:49.299543 Training Step 4535 \"loss\" =  2.6663933\n",
      "2018-09-02 03:55:49.974381 Test Step 4540 Finished\n",
      "2018-09-02 03:55:49.974505 Test Step 4540 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:49.974567 Test Step 4540 \"loss\" =  7.8629723\n",
      "2018-09-02 03:55:50.123995 Training Step 4540 Finished Timing (Training: 0.920633, Test: 0.0779171) after 0.824372 seconds\n",
      "2018-09-02 03:55:50.124070 Training Step 4540 \"min loss\" =  2.296646\n",
      "2018-09-02 03:55:50.124587 Training Step 4540 \"loss\" =  2.6530583\n",
      "2018-09-02 03:55:50.792418 Test Step 4545 Finished\n",
      "2018-09-02 03:55:50.792525 Test Step 4545 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:50.792585 Test Step 4545 \"loss\" =  7.877503\n",
      "2018-09-02 03:55:50.946624 Training Step 4545 Finished Timing (Training: 0.920572, Test: 0.0780133) after 0.821957 seconds\n",
      "2018-09-02 03:55:50.946717 Training Step 4545 \"min loss\" =  2.296646\n",
      "2018-09-02 03:55:50.946767 Training Step 4545 \"loss\" =  2.8654394\n",
      "2018-09-02 03:55:51.609112 Test Step 4550 Finished\n",
      "2018-09-02 03:55:51.609538 Test Step 4550 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:51.609729 Test Step 4550 \"loss\" =  7.8230004\n",
      "2018-09-02 03:55:51.758535 Training Step 4550 Finished Timing (Training: 0.920155, Test: 0.0783601) after 0.810889 seconds\n",
      "2018-09-02 03:55:51.758862 Training Step 4550 \"min loss\" =  2.296646\n",
      "2018-09-02 03:55:51.758914 Training Step 4550 \"loss\" =  2.6969492\n",
      "2018-09-02 03:55:52.444561 Test Step 4555 Finished\n",
      "2018-09-02 03:55:52.444686 Test Step 4555 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:52.445516 Test Step 4555 \"loss\" =  8.003395\n",
      "2018-09-02 03:55:52.594931 Training Step 4555 Finished Timing (Training: 0.919654, Test: 0.0787866) after 0.835948 seconds\n",
      "2018-09-02 03:55:52.595074 Training Step 4555 \"min loss\" =  2.296646\n",
      "2018-09-02 03:55:52.595150 Training Step 4555 \"loss\" =  2.4632766\n",
      "2018-09-02 03:55:53.266849 Test Step 4560 Finished\n",
      "2018-09-02 03:55:53.266986 Test Step 4560 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:53.267649 Test Step 4560 \"loss\" =  7.8167706\n",
      "2018-09-02 03:55:53.418223 Training Step 4560 Finished Timing (Training: 0.91948, Test: 0.0789491) after 0.822995 seconds\n",
      "2018-09-02 03:55:53.418358 Training Step 4560 \"min loss\" =  2.296646\n",
      "2018-09-02 03:55:53.418792 Training Step 4560 \"loss\" =  2.7448282\n",
      "2018-09-02 03:55:54.092570 Test Step 4565 Finished\n",
      "2018-09-02 03:55:54.092731 Test Step 4565 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:54.093375 Test Step 4565 \"loss\" =  7.5528364\n",
      "2018-09-02 03:55:54.245912 Training Step 4565 Finished Timing (Training: 0.919277, Test: 0.0790792) after 0.826669 seconds\n",
      "2018-09-02 03:55:54.246163 Training Step 4565 \"min loss\" =  2.296646\n",
      "2018-09-02 03:55:54.246223 Training Step 4565 \"loss\" =  2.7236598\n",
      "2018-09-02 03:55:54.906087 Test Step 4570 Finished\n",
      "2018-09-02 03:55:54.906188 Test Step 4570 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:54.906639 Test Step 4570 \"loss\" =  7.4545593\n",
      "2018-09-02 03:55:55.057043 Training Step 4570 Finished Timing (Training: 0.919831, Test: 0.0785085) after 0.810227 seconds\n",
      "2018-09-02 03:55:55.057132 Training Step 4570 \"min loss\" =  2.296646\n",
      "2018-09-02 03:55:55.057262 Training Step 4570 \"loss\" =  2.5293207\n",
      "2018-09-02 03:55:55.719554 Test Step 4575 Finished\n",
      "2018-09-02 03:55:55.719905 Test Step 4575 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:55.720180 Test Step 4575 \"loss\" =  7.9374413\n",
      "2018-09-02 03:55:55.866347 Training Step 4575 Finished Timing (Training: 0.919854, Test: 0.0784711) after 0.808944 seconds\n",
      "2018-09-02 03:55:55.866547 Training Step 4575 \"min loss\" =  2.296646\n",
      "2018-09-02 03:55:55.866924 Training Step 4575 \"loss\" =  2.56109\n",
      "2018-09-02 03:55:56.536768 Test Step 4580 Finished\n",
      "2018-09-02 03:55:56.536883 Test Step 4580 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:56.537387 Test Step 4580 \"loss\" =  7.577777\n",
      "2018-09-02 03:55:56.681322 Training Step 4580 Finished Timing (Training: 0.919961, Test: 0.0783649) after 0.814334 seconds\n",
      "2018-09-02 03:55:56.681655 Training Step 4580 \"min loss\" =  2.296646\n",
      "2018-09-02 03:55:56.681896 Training Step 4580 \"loss\" =  2.5551336\n",
      "2018-09-02 03:55:57.329394 Test Step 4585 Finished\n",
      "2018-09-02 03:55:57.329942 Test Step 4585 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:57.330002 Test Step 4585 \"loss\" =  7.721464\n",
      "2018-09-02 03:55:57.480524 Training Step 4585 Finished Timing (Training: 0.919853, Test: 0.0784507) after 0.798245 seconds\n",
      "2018-09-02 03:55:57.480632 Training Step 4585 \"min loss\" =  2.296646\n",
      "2018-09-02 03:55:57.480708 Training Step 4585 \"loss\" =  2.7375252\n",
      "2018-09-02 03:55:58.145265 Test Step 4590 Finished\n",
      "2018-09-02 03:55:58.145397 Test Step 4590 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:58.145469 Test Step 4590 \"loss\" =  7.495063\n",
      "2018-09-02 03:55:58.296582 Training Step 4590 Finished Timing (Training: 0.919914, Test: 0.0784448) after 0.815812 seconds\n",
      "2018-09-02 03:55:58.296650 Training Step 4590 \"min loss\" =  2.296646\n",
      "2018-09-02 03:55:58.296706 Training Step 4590 \"loss\" =  2.7301002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:55:58.962756 Test Step 4595 Finished\n",
      "2018-09-02 03:55:58.962879 Test Step 4595 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:58.962940 Test Step 4595 \"loss\" =  7.4906545\n",
      "2018-09-02 03:55:59.115604 Training Step 4595 Finished Timing (Training: 0.920075, Test: 0.078303) after 0.818263 seconds\n",
      "2018-09-02 03:55:59.115675 Training Step 4595 \"min loss\" =  2.296646\n",
      "2018-09-02 03:55:59.115732 Training Step 4595 \"loss\" =  2.4541113\n",
      "2018-09-02 03:55:59.777393 Test Step 4600 Finished\n",
      "2018-09-02 03:55:59.777513 Test Step 4600 \"min loss\" =  7.008738\n",
      "2018-09-02 03:55:59.778257 Test Step 4600 \"loss\" =  7.8170896\n",
      "2018-09-02 03:55:59.931399 Training Step 4600 Finished Timing (Training: 0.920079, Test: 0.0782572) after 0.814913 seconds\n",
      "2018-09-02 03:55:59.931755 Training Step 4600 \"min loss\" =  2.296646\n",
      "2018-09-02 03:55:59.931821 Training Step 4600 \"loss\" =  2.8156035\n",
      "2018-09-02 03:56:00.592479 Test Step 4605 Finished\n",
      "2018-09-02 03:56:00.592591 Test Step 4605 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:00.592639 Test Step 4605 \"loss\" =  7.5693727\n",
      "2018-09-02 03:56:00.745013 Training Step 4605 Finished Timing (Training: 0.920833, Test: 0.0788516) after 0.813129 seconds\n",
      "2018-09-02 03:56:00.745087 Training Step 4605 \"min loss\" =  2.296646\n",
      "2018-09-02 03:56:00.745142 Training Step 4605 \"loss\" =  2.539157\n",
      "2018-09-02 03:56:01.409850 Test Step 4610 Finished\n",
      "2018-09-02 03:56:01.409941 Test Step 4610 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:01.410505 Test Step 4610 \"loss\" =  7.3847294\n",
      "2018-09-02 03:56:01.561224 Training Step 4610 Finished Timing (Training: 0.920048, Test: 0.0787791) after 0.815298 seconds\n",
      "2018-09-02 03:56:01.561543 Training Step 4610 \"min loss\" =  2.296646\n",
      "2018-09-02 03:56:01.561605 Training Step 4610 \"loss\" =  2.552412\n",
      "2018-09-02 03:56:02.220319 Test Step 4615 Finished\n",
      "2018-09-02 03:56:02.220743 Test Step 4615 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:02.220804 Test Step 4615 \"loss\" =  7.65568\n",
      "2018-09-02 03:56:02.374712 Training Step 4615 Finished Timing (Training: 0.918764, Test: 0.0800394) after 0.813031 seconds\n",
      "2018-09-02 03:56:02.374838 Training Step 4615 \"min loss\" =  2.296646\n",
      "2018-09-02 03:56:02.375393 Training Step 4615 \"loss\" =  2.9244733\n",
      "2018-09-02 03:56:03.038918 Test Step 4620 Finished\n",
      "2018-09-02 03:56:03.039421 Test Step 4620 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:03.039489 Test Step 4620 \"loss\" =  7.9570546\n",
      "2018-09-02 03:56:03.196025 Training Step 4620 Finished Timing (Training: 0.918676, Test: 0.0798706) after 0.820153 seconds\n",
      "2018-09-02 03:56:03.196161 Training Step 4620 \"min loss\" =  2.296646\n",
      "2018-09-02 03:56:03.196654 Training Step 4620 \"loss\" =  2.607372\n",
      "2018-09-02 03:56:03.863708 Test Step 4625 Finished\n",
      "2018-09-02 03:56:03.863839 Test Step 4625 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:03.863890 Test Step 4625 \"loss\" =  7.7114096\n",
      "2018-09-02 03:56:04.015525 Training Step 4625 Finished Timing (Training: 0.919579, Test: 0.0790183) after 0.818804 seconds\n",
      "2018-09-02 03:56:04.015601 Training Step 4625 \"min loss\" =  2.296646\n",
      "2018-09-02 03:56:04.015670 Training Step 4625 \"loss\" =  2.5371344\n",
      "2018-09-02 03:56:04.686870 Test Step 4630 Finished\n",
      "2018-09-02 03:56:04.687317 Test Step 4630 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:04.687377 Test Step 4630 \"loss\" =  7.4844217\n",
      "2018-09-02 03:56:04.837267 Training Step 4630 Finished Timing (Training: 0.919458, Test: 0.0790539) after 0.820774 seconds\n",
      "2018-09-02 03:56:04.837369 Training Step 4630 \"min loss\" =  2.296646\n",
      "2018-09-02 03:56:04.837423 Training Step 4630 \"loss\" =  2.535156\n",
      "2018-09-02 03:56:05.507949 Test Step 4635 Finished\n",
      "2018-09-02 03:56:05.508053 Test Step 4635 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:05.508637 Test Step 4635 \"loss\" =  7.7549334\n",
      "2018-09-02 03:56:05.657118 Training Step 4635 Finished Timing (Training: 0.920068, Test: 0.0783664) after 0.818952 seconds\n",
      "2018-09-02 03:56:05.657201 Training Step 4635 \"min loss\" =  2.296646\n",
      "2018-09-02 03:56:05.657742 Training Step 4635 \"loss\" =  2.3064592\n",
      "2018-09-02 03:56:06.321038 Test Step 4640 Finished\n",
      "2018-09-02 03:56:06.321143 Test Step 4640 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:06.321202 Test Step 4640 \"loss\" =  7.5706143\n",
      "2018-09-02 03:56:06.468319 Training Step 4640 Finished Timing (Training: 0.919938, Test: 0.0785046) after 0.810253 seconds\n",
      "2018-09-02 03:56:06.468379 Training Step 4640 \"min loss\" =  2.296646\n",
      "2018-09-02 03:56:06.468418 Training Step 4640 \"loss\" =  2.5415409\n",
      "2018-09-02 03:56:07.145113 Test Step 4645 Finished\n",
      "2018-09-02 03:56:07.145619 Test Step 4645 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:07.145682 Test Step 4645 \"loss\" =  7.966006\n",
      "2018-09-02 03:56:07.294411 Training Step 4645 Finished Timing (Training: 0.919769, Test: 0.0787324) after 0.825902 seconds\n",
      "2018-09-02 03:56:07.294472 Training Step 4645 \"min loss\" =  2.296646\n",
      "2018-09-02 03:56:07.294523 Training Step 4645 \"loss\" =  2.6771803\n",
      "2018-09-02 03:56:07.959881 Test Step 4650 Finished\n",
      "2018-09-02 03:56:07.959985 Test Step 4650 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:07.960040 Test Step 4650 \"loss\" =  7.5582776\n",
      "2018-09-02 03:56:08.114201 Training Step 4650 Finished Timing (Training: 0.91995, Test: 0.0785375) after 0.819619 seconds\n",
      "2018-09-02 03:56:08.114262 Training Step 4650 \"min loss\" =  2.296646\n",
      "2018-09-02 03:56:08.114320 Training Step 4650 \"loss\" =  2.4945755\n",
      "2018-09-02 03:56:08.787270 Test Step 4655 Finished\n",
      "2018-09-02 03:56:08.787400 Test Step 4655 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:08.787499 Test Step 4655 \"loss\" =  7.9853826\n",
      "2018-09-02 03:56:08.935390 Training Step 4655 Finished Timing (Training: 0.919904, Test: 0.0786637) after 0.821011 seconds\n",
      "2018-09-02 03:56:08.935457 Training Step 4655 \"min loss\" =  2.296646\n",
      "2018-09-02 03:56:08.935513 Training Step 4655 \"loss\" =  2.3967302\n",
      "2018-09-02 03:56:09.612471 Test Step 4660 Finished\n",
      "2018-09-02 03:56:09.612580 Test Step 4660 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:09.613209 Test Step 4660 \"loss\" =  7.381549\n",
      "2018-09-02 03:56:09.767260 Training Step 4660 Finished Timing (Training: 0.919835, Test: 0.0787501) after 0.831677 seconds\n",
      "2018-09-02 03:56:09.767375 Training Step 4660 \"min loss\" =  2.296646\n",
      "2018-09-02 03:56:09.767424 Training Step 4660 \"loss\" =  2.7478518\n",
      "2018-09-02 03:56:10.428226 Test Step 4665 Finished\n",
      "2018-09-02 03:56:10.428328 Test Step 4665 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:10.428404 Test Step 4665 \"loss\" =  8.514826\n",
      "2018-09-02 03:56:10.576091 Training Step 4665 Finished Timing (Training: 0.91975, Test: 0.0788248) after 0.807862 seconds\n",
      "2018-09-02 03:56:10.576189 Training Step 4665 \"min loss\" =  2.296646\n",
      "2018-09-02 03:56:10.576360 Training Step 4665 \"loss\" =  2.4470265\n",
      "2018-09-02 03:56:11.239341 Test Step 4670 Finished\n",
      "2018-09-02 03:56:11.239436 Test Step 4670 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:11.239488 Test Step 4670 \"loss\" =  7.366211\n",
      "2018-09-02 03:56:11.394236 Training Step 4670 Finished Timing (Training: 0.919489, Test: 0.0791196) after 0.817583 seconds\n",
      "2018-09-02 03:56:11.394339 Training Step 4670 \"min loss\" =  2.296646\n",
      "2018-09-02 03:56:11.394391 Training Step 4670 \"loss\" =  2.6046722\n",
      "2018-09-02 03:56:12.056841 Test Step 4675 Finished\n",
      "2018-09-02 03:56:12.056949 Test Step 4675 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:12.056999 Test Step 4675 \"loss\" =  7.7229342\n",
      "2018-09-02 03:56:12.209772 Training Step 4675 Finished Timing (Training: 0.919595, Test: 0.0789435) after 0.814603 seconds\n",
      "2018-09-02 03:56:12.209868 Training Step 4675 \"min loss\" =  2.296646\n",
      "2018-09-02 03:56:12.210532 Training Step 4675 \"loss\" =  2.4695988\n",
      "2018-09-02 03:56:12.885552 Test Step 4680 Finished\n",
      "2018-09-02 03:56:12.885684 Test Step 4680 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:12.886324 Test Step 4680 \"loss\" =  8.06811\n",
      "2018-09-02 03:56:13.029271 Training Step 4680 Finished Timing (Training: 0.919283, Test: 0.0791964) after 0.818668 seconds\n",
      "2018-09-02 03:56:13.029353 Training Step 4680 \"min loss\" =  2.296646\n",
      "2018-09-02 03:56:13.029426 Training Step 4680 \"loss\" =  2.407058\n",
      "2018-09-02 03:56:13.709682 Test Step 4685 Finished\n",
      "2018-09-02 03:56:13.709812 Test Step 4685 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:13.710319 Test Step 4685 \"loss\" =  7.802794\n",
      "2018-09-02 03:56:13.863891 Training Step 4685 Finished Timing (Training: 0.919199, Test: 0.0792859) after 0.834399 seconds\n",
      "2018-09-02 03:56:13.864135 Training Step 4685 \"min loss\" =  2.296646\n",
      "2018-09-02 03:56:13.864368 Training Step 4685 \"loss\" =  2.6702714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:56:14.538524 Test Step 4690 Finished\n",
      "2018-09-02 03:56:14.538657 Test Step 4690 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:14.539330 Test Step 4690 \"loss\" =  8.515266\n",
      "2018-09-02 03:56:14.691238 Training Step 4690 Finished Timing (Training: 0.919135, Test: 0.0793201) after 0.826564 seconds\n",
      "2018-09-02 03:56:14.691338 Training Step 4690 \"min loss\" =  2.296646\n",
      "2018-09-02 03:56:14.691889 Training Step 4690 \"loss\" =  2.6273637\n",
      "2018-09-02 03:56:15.356166 Test Step 4695 Finished\n",
      "2018-09-02 03:56:15.356603 Test Step 4695 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:15.357180 Test Step 4695 \"loss\" =  7.7585907\n",
      "2018-09-02 03:56:15.507630 Training Step 4695 Finished Timing (Training: 0.919084, Test: 0.0793168) after 0.815677 seconds\n",
      "2018-09-02 03:56:15.507710 Training Step 4695 \"min loss\" =  2.296646\n",
      "2018-09-02 03:56:15.508427 Training Step 4695 \"loss\" =  2.6281178\n",
      "2018-09-02 03:56:16.177428 Test Step 4700 Finished\n",
      "2018-09-02 03:56:16.177963 Test Step 4700 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:16.178306 Test Step 4700 \"loss\" =  7.4684176\n",
      "2018-09-02 03:56:16.326665 Training Step 4700 Finished Timing (Training: 0.919035, Test: 0.0793139) after 0.817886 seconds\n",
      "2018-09-02 03:56:16.327015 Training Step 4700 \"min loss\" =  2.296646\n",
      "2018-09-02 03:56:16.327350 Training Step 4700 \"loss\" =  2.7414248\n",
      "2018-09-02 03:56:16.990981 Test Step 4705 Finished\n",
      "2018-09-02 03:56:16.991072 Test Step 4705 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:16.991132 Test Step 4705 \"loss\" =  7.3999267\n",
      "2018-09-02 03:56:17.138483 Training Step 4705 Finished Timing (Training: 0.916875, Test: 0.0828442) after 0.810561 seconds\n",
      "2018-09-02 03:56:17.138567 Training Step 4705 \"min loss\" =  2.296646\n",
      "2018-09-02 03:56:17.138622 Training Step 4705 \"loss\" =  2.4405372\n",
      "2018-09-02 03:56:17.800877 Test Step 4710 Finished\n",
      "2018-09-02 03:56:17.801017 Test Step 4710 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:17.801921 Test Step 4710 \"loss\" =  7.4907227\n",
      "2018-09-02 03:56:17.956027 Training Step 4710 Finished Timing (Training: 0.917742, Test: 0.0811272) after 0.817346 seconds\n",
      "2018-09-02 03:56:17.956116 Training Step 4710 \"min loss\" =  2.296646\n",
      "2018-09-02 03:56:17.956741 Training Step 4710 \"loss\" =  2.5698595\n",
      "2018-09-02 03:56:18.616044 Test Step 4715 Finished\n",
      "2018-09-02 03:56:18.616511 Test Step 4715 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:18.616701 Test Step 4715 \"loss\" =  7.5508204\n",
      "2018-09-02 03:56:18.770913 Training Step 4715 Finished Timing (Training: 0.918753, Test: 0.0795572) after 0.813586 seconds\n",
      "2018-09-02 03:56:18.771008 Training Step 4715 \"min loss\" =  2.296646\n",
      "2018-09-02 03:56:18.771063 Training Step 4715 \"loss\" =  2.8537626\n",
      "2018-09-02 03:56:19.440041 Test Step 4720 Finished\n",
      "2018-09-02 03:56:19.440162 Test Step 4720 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:19.440223 Test Step 4720 \"loss\" =  7.869817\n",
      "2018-09-02 03:56:19.585817 Training Step 4720 Finished Timing (Training: 0.918551, Test: 0.0798612) after 0.814141 seconds\n",
      "2018-09-02 03:56:19.585886 Training Step 4720 \"min loss\" =  2.296646\n",
      "2018-09-02 03:56:19.586512 Training Step 4720 \"loss\" =  2.5705137\n",
      "2018-09-02 03:56:20.258559 Test Step 4725 Finished\n",
      "2018-09-02 03:56:20.258675 Test Step 4725 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:20.259296 Test Step 4725 \"loss\" =  7.322426\n",
      "2018-09-02 03:56:20.404769 Training Step 4725 Finished Timing (Training: 0.91884, Test: 0.0794631) after 0.818194 seconds\n",
      "2018-09-02 03:56:20.405066 Training Step 4725 \"min loss\" =  2.296646\n",
      "2018-09-02 03:56:20.405324 Training Step 4725 \"loss\" =  2.6700256\n",
      "2018-09-02 03:56:21.070735 Test Step 4730 Finished\n",
      "2018-09-02 03:56:21.071191 Test Step 4730 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:21.071383 Test Step 4730 \"loss\" =  7.5884843\n",
      "2018-09-02 03:56:21.222341 Training Step 4730 Finished Timing (Training: 0.918711, Test: 0.0795507) after 0.816954 seconds\n",
      "2018-09-02 03:56:21.222422 Training Step 4730 \"min loss\" =  2.296646\n",
      "2018-09-02 03:56:21.222800 Training Step 4730 \"loss\" =  2.4666014\n",
      "2018-09-02 03:56:21.896112 Test Step 4735 Finished\n",
      "2018-09-02 03:56:21.896229 Test Step 4735 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:21.896716 Test Step 4735 \"loss\" =  8.312929\n",
      "2018-09-02 03:56:22.049353 Training Step 4735 Finished Timing (Training: 0.918661, Test: 0.0796376) after 0.826489 seconds\n",
      "2018-09-02 03:56:22.049435 Training Step 4735 \"min loss\" =  2.296646\n",
      "2018-09-02 03:56:22.049493 Training Step 4735 \"loss\" =  2.5713804\n",
      "2018-09-02 03:56:22.720610 Test Step 4740 Finished\n",
      "2018-09-02 03:56:22.721189 Test Step 4740 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:22.721515 Test Step 4740 \"loss\" =  7.7729473\n",
      "2018-09-02 03:56:22.868340 Training Step 4740 Finished Timing (Training: 0.918266, Test: 0.08006) after 0.818775 seconds\n",
      "2018-09-02 03:56:22.868448 Training Step 4740 \"min loss\" =  2.296646\n",
      "2018-09-02 03:56:22.868503 Training Step 4740 \"loss\" =  2.59683\n",
      "2018-09-02 03:56:23.537002 Test Step 4745 Finished\n",
      "2018-09-02 03:56:23.537148 Test Step 4745 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:23.537716 Test Step 4745 \"loss\" =  7.385493\n",
      "2018-09-02 03:56:23.688011 Training Step 4745 Finished Timing (Training: 0.91875, Test: 0.079496) after 0.818927 seconds\n",
      "2018-09-02 03:56:23.688072 Training Step 4745 \"min loss\" =  2.296646\n",
      "2018-09-02 03:56:23.688138 Training Step 4745 \"loss\" =  2.4259973\n",
      "2018-09-02 03:56:24.353467 Test Step 4750 Finished\n",
      "2018-09-02 03:56:24.353925 Test Step 4750 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:24.354117 Test Step 4750 \"loss\" =  7.575007\n",
      "2018-09-02 03:56:24.500041 Training Step 4750 Finished Timing (Training: 0.91856, Test: 0.0796358) after 0.81131 seconds\n",
      "2018-09-02 03:56:24.500215 Training Step 4750 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:24.500866 Training Step 4750 \"loss\" =  2.2188735\n",
      "2018-09-02 03:56:25.169535 Test Step 4755 Finished\n",
      "2018-09-02 03:56:25.169631 Test Step 4755 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:25.169672 Test Step 4755 \"loss\" =  8.062537\n",
      "2018-09-02 03:56:25.318857 Training Step 4755 Finished Timing (Training: 0.918491, Test: 0.0797208) after 0.817695 seconds\n",
      "2018-09-02 03:56:25.318911 Training Step 4755 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:25.318947 Training Step 4755 \"loss\" =  2.3729146\n",
      "2018-09-02 03:56:25.975283 Test Step 4760 Finished\n",
      "2018-09-02 03:56:25.975379 Test Step 4760 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:25.976055 Test Step 4760 \"loss\" =  8.086535\n",
      "2018-09-02 03:56:26.130113 Training Step 4760 Finished Timing (Training: 0.919241, Test: 0.0790116) after 0.811122 seconds\n",
      "2018-09-02 03:56:26.130186 Training Step 4760 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:26.130228 Training Step 4760 \"loss\" =  2.5584857\n",
      "2018-09-02 03:56:26.791019 Test Step 4765 Finished\n",
      "2018-09-02 03:56:26.791117 Test Step 4765 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:26.791190 Test Step 4765 \"loss\" =  7.652768\n",
      "2018-09-02 03:56:26.939518 Training Step 4765 Finished Timing (Training: 0.919048, Test: 0.0792271) after 0.808505 seconds\n",
      "2018-09-02 03:56:26.939585 Training Step 4765 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:26.939627 Training Step 4765 \"loss\" =  2.80422\n",
      "2018-09-02 03:56:27.613266 Test Step 4770 Finished\n",
      "2018-09-02 03:56:27.613449 Test Step 4770 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:27.614279 Test Step 4770 \"loss\" =  7.9211335\n",
      "2018-09-02 03:56:27.766611 Training Step 4770 Finished Timing (Training: 0.919015, Test: 0.0792415) after 0.826906 seconds\n",
      "2018-09-02 03:56:27.766815 Training Step 4770 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:27.766894 Training Step 4770 \"loss\" =  2.6318092\n",
      "2018-09-02 03:56:28.435199 Test Step 4775 Finished\n",
      "2018-09-02 03:56:28.435641 Test Step 4775 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:28.436100 Test Step 4775 \"loss\" =  8.654102\n",
      "2018-09-02 03:56:28.591246 Training Step 4775 Finished Timing (Training: 0.919005, Test: 0.0791507) after 0.823366 seconds\n",
      "2018-09-02 03:56:28.591410 Training Step 4775 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:28.592085 Training Step 4775 \"loss\" =  2.510729\n",
      "2018-09-02 03:56:29.259800 Test Step 4780 Finished\n",
      "2018-09-02 03:56:29.259951 Test Step 4780 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:29.260688 Test Step 4780 \"loss\" =  7.529281\n",
      "2018-09-02 03:56:29.413424 Training Step 4780 Finished Timing (Training: 0.918669, Test: 0.0793963) after 0.82087 seconds\n",
      "2018-09-02 03:56:29.413857 Training Step 4780 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:29.414200 Training Step 4780 \"loss\" =  2.4116793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:56:30.091759 Test Step 4785 Finished\n",
      "2018-09-02 03:56:30.091881 Test Step 4785 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:30.092621 Test Step 4785 \"loss\" =  8.00535\n",
      "2018-09-02 03:56:30.235017 Training Step 4785 Finished Timing (Training: 0.91853, Test: 0.0794553) after 0.820249 seconds\n",
      "2018-09-02 03:56:30.235102 Training Step 4785 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:30.235181 Training Step 4785 \"loss\" =  2.4002485\n",
      "2018-09-02 03:56:30.901983 Test Step 4790 Finished\n",
      "2018-09-02 03:56:30.902114 Test Step 4790 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:30.902975 Test Step 4790 \"loss\" =  7.6009216\n",
      "2018-09-02 03:56:31.053111 Training Step 4790 Finished Timing (Training: 0.918487, Test: 0.0794262) after 0.816854 seconds\n",
      "2018-09-02 03:56:31.053303 Training Step 4790 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:31.054028 Training Step 4790 \"loss\" =  2.7391865\n",
      "2018-09-02 03:56:31.709735 Test Step 4795 Finished\n",
      "2018-09-02 03:56:31.709849 Test Step 4795 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:31.710748 Test Step 4795 \"loss\" =  7.9150634\n",
      "2018-09-02 03:56:31.864839 Training Step 4795 Finished Timing (Training: 0.91849, Test: 0.0793545) after 0.810466 seconds\n",
      "2018-09-02 03:56:31.864917 Training Step 4795 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:31.865661 Training Step 4795 \"loss\" =  2.220709\n",
      "2018-09-02 03:56:32.521146 Test Step 4800 Finished\n",
      "2018-09-02 03:56:32.521299 Test Step 4800 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:32.521399 Test Step 4800 \"loss\" =  8.173281\n",
      "2018-09-02 03:56:32.666459 Training Step 4800 Finished Timing (Training: 0.918491, Test: 0.0793092) after 0.800692 seconds\n",
      "2018-09-02 03:56:32.666544 Training Step 4800 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:32.667161 Training Step 4800 \"loss\" =  2.3233852\n",
      "2018-09-02 03:56:33.340212 Test Step 4805 Finished\n",
      "2018-09-02 03:56:33.340706 Test Step 4805 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:33.341226 Test Step 4805 \"loss\" =  8.246881\n",
      "2018-09-02 03:56:33.494852 Training Step 4805 Finished Timing (Training: 0.921542, Test: 0.0766761) after 0.827217 seconds\n",
      "2018-09-02 03:56:33.494971 Training Step 4805 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:33.495833 Training Step 4805 \"loss\" =  2.5887175\n",
      "2018-09-02 03:56:34.164676 Test Step 4810 Finished\n",
      "2018-09-02 03:56:34.164811 Test Step 4810 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:34.164904 Test Step 4810 \"loss\" =  7.8972864\n",
      "2018-09-02 03:56:34.321559 Training Step 4810 Finished Timing (Training: 0.920721, Test: 0.0766567) after 0.825349 seconds\n",
      "2018-09-02 03:56:34.321653 Training Step 4810 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:34.322266 Training Step 4810 \"loss\" =  2.450974\n",
      "2018-09-02 03:56:34.991880 Test Step 4815 Finished\n",
      "2018-09-02 03:56:34.991997 Test Step 4815 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:34.992705 Test Step 4815 \"loss\" =  8.010416\n",
      "2018-09-02 03:56:35.151897 Training Step 4815 Finished Timing (Training: 0.919866, Test: 0.0773452) after 0.829166 seconds\n",
      "2018-09-02 03:56:35.152036 Training Step 4815 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:35.152123 Training Step 4815 \"loss\" =  2.395592\n",
      "2018-09-02 03:56:35.820809 Test Step 4820 Finished\n",
      "2018-09-02 03:56:35.820908 Test Step 4820 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:35.821389 Test Step 4820 \"loss\" =  8.171813\n",
      "2018-09-02 03:56:35.968541 Training Step 4820 Finished Timing (Training: 0.920079, Test: 0.0771428) after 0.815325 seconds\n",
      "2018-09-02 03:56:35.968631 Training Step 4820 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:35.968693 Training Step 4820 \"loss\" =  2.564622\n",
      "2018-09-02 03:56:36.633092 Test Step 4825 Finished\n",
      "2018-09-02 03:56:36.633193 Test Step 4825 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:36.633287 Test Step 4825 \"loss\" =  8.0881605\n",
      "2018-09-02 03:56:36.778778 Training Step 4825 Finished Timing (Training: 0.920265, Test: 0.0772176) after 0.810009 seconds\n",
      "2018-09-02 03:56:36.778942 Training Step 4825 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:36.779363 Training Step 4825 \"loss\" =  2.3411756\n",
      "2018-09-02 03:56:37.445838 Test Step 4830 Finished\n",
      "2018-09-02 03:56:37.446312 Test Step 4830 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:37.446685 Test Step 4830 \"loss\" =  7.843101\n",
      "2018-09-02 03:56:37.599740 Training Step 4830 Finished Timing (Training: 0.919419, Test: 0.0781054) after 0.820066 seconds\n",
      "2018-09-02 03:56:37.600059 Training Step 4830 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:37.600291 Training Step 4830 \"loss\" =  2.5786495\n",
      "2018-09-02 03:56:38.265608 Test Step 4835 Finished\n",
      "2018-09-02 03:56:38.265695 Test Step 4835 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:38.265764 Test Step 4835 \"loss\" =  8.502354\n",
      "2018-09-02 03:56:38.415402 Training Step 4835 Finished Timing (Training: 0.919304, Test: 0.0783078) after 0.815054 seconds\n",
      "2018-09-02 03:56:38.415465 Training Step 4835 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:38.415814 Training Step 4835 \"loss\" =  2.5997095\n",
      "2018-09-02 03:56:39.084058 Test Step 4840 Finished\n",
      "2018-09-02 03:56:39.084171 Test Step 4840 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:39.084688 Test Step 4840 \"loss\" =  8.928014\n",
      "2018-09-02 03:56:39.230566 Training Step 4840 Finished Timing (Training: 0.919694, Test: 0.0779956) after 0.814451 seconds\n",
      "2018-09-02 03:56:39.230623 Training Step 4840 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:39.231086 Training Step 4840 \"loss\" =  2.5208478\n",
      "2018-09-02 03:56:39.899625 Test Step 4845 Finished\n",
      "2018-09-02 03:56:39.899693 Test Step 4845 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:39.900077 Test Step 4845 \"loss\" =  7.6062865\n",
      "2018-09-02 03:56:40.055651 Training Step 4845 Finished Timing (Training: 0.920105, Test: 0.0776923) after 0.824502 seconds\n",
      "2018-09-02 03:56:40.055730 Training Step 4845 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:40.056058 Training Step 4845 \"loss\" =  2.6188297\n",
      "2018-09-02 03:56:40.723507 Test Step 4850 Finished\n",
      "2018-09-02 03:56:40.723661 Test Step 4850 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:40.723801 Test Step 4850 \"loss\" =  7.7444963\n",
      "2018-09-02 03:56:40.875100 Training Step 4850 Finished Timing (Training: 0.919769, Test: 0.0780389) after 0.818702 seconds\n",
      "2018-09-02 03:56:40.875171 Training Step 4850 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:40.875237 Training Step 4850 \"loss\" =  2.4139798\n",
      "2018-09-02 03:56:41.548213 Test Step 4855 Finished\n",
      "2018-09-02 03:56:41.548364 Test Step 4855 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:41.548440 Test Step 4855 \"loss\" =  7.77005\n",
      "2018-09-02 03:56:41.700280 Training Step 4855 Finished Timing (Training: 0.919784, Test: 0.0781678) after 0.824978 seconds\n",
      "2018-09-02 03:56:41.700412 Training Step 4855 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:41.700465 Training Step 4855 \"loss\" =  2.5149233\n",
      "2018-09-02 03:56:42.361553 Test Step 4860 Finished\n",
      "2018-09-02 03:56:42.361679 Test Step 4860 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:42.361803 Test Step 4860 \"loss\" =  7.952148\n",
      "2018-09-02 03:56:42.506483 Training Step 4860 Finished Timing (Training: 0.91966, Test: 0.0783977) after 0.80596 seconds\n",
      "2018-09-02 03:56:42.506558 Training Step 4860 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:42.506605 Training Step 4860 \"loss\" =  2.5947654\n",
      "2018-09-02 03:56:43.177165 Test Step 4865 Finished\n",
      "2018-09-02 03:56:43.177272 Test Step 4865 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:43.177369 Test Step 4865 \"loss\" =  8.111019\n",
      "2018-09-02 03:56:43.329258 Training Step 4865 Finished Timing (Training: 0.919599, Test: 0.0784931) after 0.821849 seconds\n",
      "2018-09-02 03:56:43.329340 Training Step 4865 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:43.329401 Training Step 4865 \"loss\" =  2.341741\n",
      "2018-09-02 03:56:43.987100 Test Step 4870 Finished\n",
      "2018-09-02 03:56:43.987213 Test Step 4870 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:43.987962 Test Step 4870 \"loss\" =  7.8941483\n",
      "2018-09-02 03:56:44.139474 Training Step 4870 Finished Timing (Training: 0.919226, Test: 0.0788733) after 0.80997 seconds\n",
      "2018-09-02 03:56:44.139539 Training Step 4870 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:44.139600 Training Step 4870 \"loss\" =  2.8614142\n",
      "2018-09-02 03:56:44.811276 Test Step 4875 Finished\n",
      "2018-09-02 03:56:44.811390 Test Step 4875 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:44.811455 Test Step 4875 \"loss\" =  7.6994405\n",
      "2018-09-02 03:56:44.966395 Training Step 4875 Finished Timing (Training: 0.919132, Test: 0.0789971) after 0.825999 seconds\n",
      "2018-09-02 03:56:44.966463 Training Step 4875 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:44.966512 Training Step 4875 \"loss\" =  2.541761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:56:45.610437 Test Step 4880 Finished\n",
      "2018-09-02 03:56:45.610516 Test Step 4880 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:45.610577 Test Step 4880 \"loss\" =  7.731065\n",
      "2018-09-02 03:56:45.766189 Training Step 4880 Finished Timing (Training: 0.919192, Test: 0.0790196) after 0.799614 seconds\n",
      "2018-09-02 03:56:45.766271 Training Step 4880 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:45.766713 Training Step 4880 \"loss\" =  2.358318\n",
      "2018-09-02 03:56:46.418504 Test Step 4885 Finished\n",
      "2018-09-02 03:56:46.418584 Test Step 4885 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:46.418668 Test Step 4885 \"loss\" =  7.5206795\n",
      "2018-09-02 03:56:46.558273 Training Step 4885 Finished Timing (Training: 0.91914, Test: 0.079112) after 0.791494 seconds\n",
      "2018-09-02 03:56:46.558341 Training Step 4885 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:46.558396 Training Step 4885 \"loss\" =  2.486442\n",
      "2018-09-02 03:56:47.235991 Test Step 4890 Finished\n",
      "2018-09-02 03:56:47.236098 Test Step 4890 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:47.236160 Test Step 4890 \"loss\" =  9.133477\n",
      "2018-09-02 03:56:47.388514 Training Step 4890 Finished Timing (Training: 0.919253, Test: 0.0790677) after 0.830061 seconds\n",
      "2018-09-02 03:56:47.388582 Training Step 4890 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:47.389168 Training Step 4890 \"loss\" =  2.6291406\n",
      "2018-09-02 03:56:48.045875 Test Step 4895 Finished\n",
      "2018-09-02 03:56:48.046010 Test Step 4895 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:48.046067 Test Step 4895 \"loss\" =  8.102161\n",
      "2018-09-02 03:56:48.201731 Training Step 4895 Finished Timing (Training: 0.919185, Test: 0.0791583) after 0.81248 seconds\n",
      "2018-09-02 03:56:48.202056 Training Step 4895 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:48.202272 Training Step 4895 \"loss\" =  2.2705722\n",
      "2018-09-02 03:56:48.874187 Test Step 4900 Finished\n",
      "2018-09-02 03:56:48.874644 Test Step 4900 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:48.874834 Test Step 4900 \"loss\" =  7.356428\n",
      "2018-09-02 03:56:49.022496 Training Step 4900 Finished Timing (Training: 0.919091, Test: 0.0792384) after 0.820155 seconds\n",
      "2018-09-02 03:56:49.022572 Training Step 4900 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:49.022629 Training Step 4900 \"loss\" =  2.4865665\n",
      "2018-09-02 03:56:49.682148 Test Step 4905 Finished\n",
      "2018-09-02 03:56:49.682572 Test Step 4905 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:49.683023 Test Step 4905 \"loss\" =  7.9794283\n",
      "2018-09-02 03:56:49.833379 Training Step 4905 Finished Timing (Training: 0.922183, Test: 0.0762837) after 0.809959 seconds\n",
      "2018-09-02 03:56:49.833574 Training Step 4905 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:49.833805 Training Step 4905 \"loss\" =  2.4355795\n",
      "2018-09-02 03:56:50.500714 Test Step 4910 Finished\n",
      "2018-09-02 03:56:50.501167 Test Step 4910 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:50.501227 Test Step 4910 \"loss\" =  7.932277\n",
      "2018-09-02 03:56:50.653212 Training Step 4910 Finished Timing (Training: 0.920503, Test: 0.0777131) after 0.81935 seconds\n",
      "2018-09-02 03:56:50.653293 Training Step 4910 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:50.653349 Training Step 4910 \"loss\" =  2.4158266\n",
      "2018-09-02 03:56:51.322529 Test Step 4915 Finished\n",
      "2018-09-02 03:56:51.322604 Test Step 4915 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:51.322644 Test Step 4915 \"loss\" =  7.750038\n",
      "2018-09-02 03:56:51.470910 Training Step 4915 Finished Timing (Training: 0.919747, Test: 0.0786091) after 0.816799 seconds\n",
      "2018-09-02 03:56:51.470973 Training Step 4915 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:51.471029 Training Step 4915 \"loss\" =  2.6811595\n",
      "2018-09-02 03:56:52.144146 Test Step 4920 Finished\n",
      "2018-09-02 03:56:52.144358 Test Step 4920 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:52.144447 Test Step 4920 \"loss\" =  8.718149\n",
      "2018-09-02 03:56:52.293233 Training Step 4920 Finished Timing (Training: 0.918465, Test: 0.0798996) after 0.821399 seconds\n",
      "2018-09-02 03:56:52.293324 Training Step 4920 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:52.293397 Training Step 4920 \"loss\" =  2.5338092\n",
      "2018-09-02 03:56:52.965320 Test Step 4925 Finished\n",
      "2018-09-02 03:56:52.965448 Test Step 4925 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:52.965511 Test Step 4925 \"loss\" =  8.390244\n",
      "2018-09-02 03:56:53.114959 Training Step 4925 Finished Timing (Training: 0.918768, Test: 0.0797966) after 0.821494 seconds\n",
      "2018-09-02 03:56:53.115030 Training Step 4925 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:53.115087 Training Step 4925 \"loss\" =  2.6597552\n",
      "2018-09-02 03:56:53.788525 Test Step 4930 Finished\n",
      "2018-09-02 03:56:53.788643 Test Step 4930 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:53.789145 Test Step 4930 \"loss\" =  7.894521\n",
      "2018-09-02 03:56:53.944578 Training Step 4930 Finished Timing (Training: 0.918765, Test: 0.0797328) after 0.828819 seconds\n",
      "2018-09-02 03:56:53.944843 Training Step 4930 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:53.944906 Training Step 4930 \"loss\" =  2.288846\n",
      "2018-09-02 03:56:54.609831 Test Step 4935 Finished\n",
      "2018-09-02 03:56:54.609950 Test Step 4935 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:54.609995 Test Step 4935 \"loss\" =  7.723799\n",
      "2018-09-02 03:56:54.767630 Training Step 4935 Finished Timing (Training: 0.918755, Test: 0.079689) after 0.822656 seconds\n",
      "2018-09-02 03:56:54.767711 Training Step 4935 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:54.767749 Training Step 4935 \"loss\" =  2.5651772\n",
      "2018-09-02 03:56:55.417786 Test Step 4940 Finished\n",
      "2018-09-02 03:56:55.417892 Test Step 4940 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:55.417948 Test Step 4940 \"loss\" =  8.027486\n",
      "2018-09-02 03:56:55.565805 Training Step 4940 Finished Timing (Training: 0.918578, Test: 0.0799897) after 0.798005 seconds\n",
      "2018-09-02 03:56:55.565892 Training Step 4940 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:55.565950 Training Step 4940 \"loss\" =  2.3755994\n",
      "2018-09-02 03:56:56.233169 Test Step 4945 Finished\n",
      "2018-09-02 03:56:56.233257 Test Step 4945 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:56.233337 Test Step 4945 \"loss\" =  7.740909\n",
      "2018-09-02 03:56:56.380947 Training Step 4945 Finished Timing (Training: 0.918432, Test: 0.0801419) after 0.814262 seconds\n",
      "2018-09-02 03:56:56.381041 Training Step 4945 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:56.381098 Training Step 4945 \"loss\" =  2.4312527\n",
      "2018-09-02 03:56:57.048433 Test Step 4950 Finished\n",
      "2018-09-02 03:56:57.048516 Test Step 4950 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:57.048568 Test Step 4950 \"loss\" =  8.371645\n",
      "2018-09-02 03:56:57.202172 Training Step 4950 Finished Timing (Training: 0.918612, Test: 0.0800497) after 0.821006 seconds\n",
      "2018-09-02 03:56:57.202487 Training Step 4950 \"min loss\" =  2.2188735\n",
      "2018-09-02 03:56:57.202825 Training Step 4950 \"loss\" =  2.3373723\n",
      "2018-09-02 03:56:57.883679 Test Step 4955 Finished\n",
      "2018-09-02 03:56:57.883806 Test Step 4955 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:57.884459 Test Step 4955 \"loss\" =  7.7362833\n",
      "2018-09-02 03:56:58.037121 Training Step 4955 Finished Timing (Training: 0.918447, Test: 0.0801431) after 0.834229 seconds\n",
      "2018-09-02 03:56:58.037423 Training Step 4955 \"min loss\" =  2.1705089\n",
      "2018-09-02 03:56:58.037663 Training Step 4955 \"loss\" =  2.1705089\n",
      "2018-09-02 03:56:58.682687 Test Step 4960 Finished\n",
      "2018-09-02 03:56:58.683028 Test Step 4960 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:58.683493 Test Step 4960 \"loss\" =  7.757967\n",
      "2018-09-02 03:56:58.829522 Training Step 4960 Finished Timing (Training: 0.917956, Test: 0.0805405) after 0.791465 seconds\n",
      "2018-09-02 03:56:58.829606 Training Step 4960 \"min loss\" =  2.1705089\n",
      "2018-09-02 03:56:58.830150 Training Step 4960 \"loss\" =  2.254979\n",
      "2018-09-02 03:56:59.495747 Test Step 4965 Finished\n",
      "2018-09-02 03:56:59.496146 Test Step 4965 \"min loss\" =  7.008738\n",
      "2018-09-02 03:56:59.496528 Test Step 4965 \"loss\" =  8.266068\n",
      "2018-09-02 03:56:59.648177 Training Step 4965 Finished Timing (Training: 0.918025, Test: 0.0803995) after 0.817791 seconds\n",
      "2018-09-02 03:56:59.648249 Training Step 4965 \"min loss\" =  2.119584\n",
      "2018-09-02 03:56:59.648643 Training Step 4965 \"loss\" =  2.427639\n",
      "2018-09-02 03:57:00.325769 Test Step 4970 Finished\n",
      "2018-09-02 03:57:00.326070 Test Step 4970 \"min loss\" =  7.008738\n",
      "2018-09-02 03:57:00.326507 Test Step 4970 \"loss\" =  8.873398\n",
      "2018-09-02 03:57:00.471986 Training Step 4970 Finished Timing (Training: 0.91794, Test: 0.0804245) after 0.822803 seconds\n",
      "2018-09-02 03:57:00.472125 Training Step 4970 \"min loss\" =  2.119584\n",
      "2018-09-02 03:57:00.472550 Training Step 4970 \"loss\" =  2.353443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 03:57:01.140968 Test Step 4975 Finished\n",
      "2018-09-02 03:57:01.141342 Test Step 4975 \"min loss\" =  7.008738\n",
      "2018-09-02 03:57:01.141743 Test Step 4975 \"loss\" =  8.110425\n",
      "2018-09-02 03:57:01.292897 Training Step 4975 Finished Timing (Training: 0.918415, Test: 0.0798877) after 0.819852 seconds\n",
      "2018-09-02 03:57:01.292959 Training Step 4975 \"min loss\" =  2.119584\n",
      "2018-09-02 03:57:01.293033 Training Step 4975 \"loss\" =  2.5163836\n",
      "2018-09-02 03:57:01.950847 Test Step 4980 Finished\n",
      "2018-09-02 03:57:01.950941 Test Step 4980 \"min loss\" =  7.008738\n",
      "2018-09-02 03:57:01.951469 Test Step 4980 \"loss\" =  7.969039\n",
      "2018-09-02 03:57:02.098090 Training Step 4980 Finished Timing (Training: 0.918636, Test: 0.0796229) after 0.804291 seconds\n",
      "2018-09-02 03:57:02.098156 Training Step 4980 \"min loss\" =  2.119584\n",
      "2018-09-02 03:57:02.098689 Training Step 4980 \"loss\" =  2.4302516\n",
      "2018-09-02 03:57:02.775137 Test Step 4985 Finished\n",
      "2018-09-02 03:57:02.775552 Test Step 4985 \"min loss\" =  7.008738\n",
      "2018-09-02 03:57:02.775611 Test Step 4985 \"loss\" =  8.111279\n",
      "2018-09-02 03:57:02.927486 Training Step 4985 Finished Timing (Training: 0.918471, Test: 0.0798032) after 0.828729 seconds\n",
      "2018-09-02 03:57:02.927721 Training Step 4985 \"min loss\" =  2.119584\n",
      "2018-09-02 03:57:02.927779 Training Step 4985 \"loss\" =  2.4226167\n",
      "2018-09-02 03:57:03.572769 Test Step 4990 Finished\n",
      "2018-09-02 03:57:03.572862 Test Step 4990 \"min loss\" =  7.008738\n",
      "2018-09-02 03:57:03.572920 Test Step 4990 \"loss\" =  7.7242856\n",
      "2018-09-02 03:57:03.718392 Training Step 4990 Finished Timing (Training: 0.918383, Test: 0.0798991) after 0.790547 seconds\n",
      "2018-09-02 03:57:03.718502 Training Step 4990 \"min loss\" =  2.119584\n",
      "2018-09-02 03:57:03.718590 Training Step 4990 \"loss\" =  2.4189484\n",
      "2018-09-02 03:57:04.379135 Test Step 4995 Finished\n",
      "2018-09-02 03:57:04.379246 Test Step 4995 \"min loss\" =  7.008738\n",
      "2018-09-02 03:57:04.379323 Test Step 4995 \"loss\" =  7.624213\n",
      "2018-09-02 03:57:04.531918 Training Step 4995 Finished Timing (Training: 0.918483, Test: 0.0798553) after 0.813272 seconds\n",
      "2018-09-02 03:57:04.531996 Training Step 4995 \"min loss\" =  2.119584\n",
      "2018-09-02 03:57:04.532051 Training Step 4995 \"loss\" =  2.7128952\n",
      "2018-09-02 03:57:06.016918 Test Step 5000 Finished\n",
      "2018-09-02 03:57:06.017039 Training completed, starting cleanup!\n",
      "2018-09-02 03:57:06.017137 Cleanup completed!\n"
     ]
    }
   ],
   "source": [
    "expParameters = {\"reverseLinkagePosition\": \"Early\", \"linkagePosition\": \"Late\", \"linkageActFun\": False, \"linkageBatchNorm\": True,\n",
    "                 \"linkageNeurons\": None, \"auxilaryEmbedding1\": False, \"auxilaryEmbedding2\": False, \"auxilaryGraph\": True,\n",
    "                 \"linkage_adjustment_components\": 3}\n",
    "\n",
    "results, idx_split = run(supervised = False, expParameters = expParameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(results[0])\n",
    "test_df = pd.DataFrame(results[1])\n",
    "test_df.set_index(test_df.index * 5, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_df['accuracy'].plot()\n",
    "test_df['accuracy'].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df['cross_entropy'].loc[10:].plot()\n",
    "test_df['cross_entropy'].loc[10:].plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.008738040924072\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_df['loss'].loc[500:].plot()\n",
    "test_df['loss'].loc[500:].plot()\n",
    "train_df['min loss'].loc[500:].plot()\n",
    "test_df['min loss'].loc[500:].plot()\n",
    "print(test_df['min loss'].iloc[-1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = np.flatnonzero(idx_split == 1)\n",
    "\n",
    "predictions = results[-1].ravel()[test_idx]\n",
    "actual = dataset[2].ravel()[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max error:  23.091601316227496\n"
     ]
    }
   ],
   "source": [
    "plt.scatter(actual, predictions); plt.xlabel('Actual'); plt.ylabel('Predicted'); plt.show()\n",
    "print('Max error: ', np.max(np.abs(actual - predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAE0lJREFUeJzt3X+MZeV93/H3pxBInSgBzODg3aVDmk0abLkymmDa9Ac1MT8tr1sFCRLVWwdplQQnTp3KLOEPqkSW1kplYjcO0tZsAYlCkOOEVcElG2yXVgqYxXEwsHYYYcqOIey4i0laFNO1v/3jPpu9nr2zMzt3du7uPu+XNLrnfM9z73nu2dn7meecc89JVSFJ6s/fmXQHJEmTYQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOnXqUg2S7ADeDeyrqrcO1X8F+ABwAHigqj7c6jcB1wPfAX61qh5q9SuAjwOnAJ+qqm1Lrfvss8+u6enpo31PktS1J5544ptVNbVUuyUDALgD+F3groOFJP8C2AS8raq+neScVr8AuBZ4C/Bm4E+S/Hh72ieBdwFzwONJdlbVM0da8fT0NLt3715GFyVJByX5X8tpt2QAVNUjSaYXlH8J2FZV325t9rX6JuDeVv96klngorZstqqea527t7U9YgBIko6dlR4D+HHgnyZ5LMl/T/JTrb4O2DvUbq7VFqtLkiZkObuAFnvemcDFwE8B9yX5USAj2hajg2bkZUiTbAG2AJx33nkr7J4kaSkrHQHMAZ+pgS8C3wXObvUNQ+3WAy8eoX6YqtpeVTNVNTM1teQxDEnSCq00AP4IeCdAO8h7GvBNYCdwbZLTk5wPbAS+CDwObExyfpLTGBwo3jlu5yVJK7ec00DvAS4Bzk4yB9wC7AB2JHkKeB3YXIM7yzyd5D4GB3cPADdU1Xfa63wAeIjBaaA7qurpY/B+JEnLlOP5jmAzMzPlaaCSdHSSPFFVM0u185vAktQpA0CSOrXS00Cl7kxvfeB75p/fdvWEeiKtDkcAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVOeBiqtkKeF6kTnCECSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUqSUDIMmOJPva/X8XLvt3SSrJ2W0+ST6RZDbJk0kuHGq7Ocmz7Wfz6r4NSdLRWs4I4A7gioXFJBuAdwEvDJWvBDa2ny3Aba3tWQxuJv8O4CLgliRnjtNxSdJ4lgyAqnoE2D9i0a3Ah4Hhu8pvAu6qgUeBM5KcC1wO7Kqq/VX1CrCLEaEiSVo7KzoGkOQ9wDeq6s8XLFoH7B2an2u1xeqSpAk56ovBJXkDcDNw2ajFI2p1hPqo19/CYPcR55133tF2T5K0TCsZAfx94Hzgz5M8D6wHvpTkRxj8Zb9hqO164MUj1A9TVduraqaqZqamplbQPUnSchx1AFTVV6rqnKqarqppBh/uF1bVXwI7gfe1s4EuBl6tqpeAh4DLkpzZDv5e1mqSpAlZzmmg9wB/CvxEkrkk1x+h+YPAc8As8J+AXwaoqv3AbwGPt5/fbDVJ0oQseQygqq5bYvn00HQBNyzSbgew4yj7J0k6RvwmsCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkTi3nnsA7kuxL8tRQ7beTfDXJk0n+MMkZQ8tuSjKb5GtJLh+qX9Fqs0m2rv5bkSQdjeWMAO4ArlhQ2wW8tareBvwFcBNAkguAa4G3tOf8XpJTkpwCfBK4ErgAuK61lSRNyJIBUFWPAPsX1P64qg602UeB9W16E3BvVX27qr4OzAIXtZ/Zqnquql4H7m1tJUkTshrHAH4B+GybXgfsHVo212qL1Q+TZEuS3Ul2z8/Pr0L3JEmjnDrOk5PcDBwA7j5YGtGsGB00Neo1q2o7sB1gZmZmZBvpeDS99YG/nX5+29UT7Im0PCsOgCSbgXcDl1bVwQ/qOWDDULP1wItterG6JGkCVhQASa4AbgT+eVW9NrRoJ/BfknwMeDOwEfgig5HBxiTnA99gcKD458bpuHSsDf9FL52MlgyAJPcAlwBnJ5kDbmFw1s/pwK4kAI9W1S9W1dNJ7gOeYbBr6Iaq+k57nQ8ADwGnADuq6ulj8H4kScu0ZABU1XUjyrcfof1HgI+MqD8IPHhUvZMkHTN+E1iSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqeWDIAkO5LsS/LUUO2sJLuSPNsez2z1JPlEktkkTya5cOg5m1v7Z5NsPjZvR5K0XMsZAdwBXLGgthV4uKo2Ag+3eYArgY3tZwtwGwwCg8HN5N8BXATccjA0JEmTsWQAVNUjwP4F5U3AnW36TuC9Q/W7auBR4Iwk5wKXA7uqan9VvQLs4vBQkSStoZUeA3hTVb0E0B7PafV1wN6hdnOttlj9MEm2JNmdZPf8/PwKuydJWspqHwTOiFodoX54sWp7Vc1U1czU1NSqdk6SdMhKA+DltmuH9riv1eeADUPt1gMvHqEuSZqQlQbATuDgmTybgfuH6u9rZwNdDLzadhE9BFyW5Mx28PeyVpMkTcipSzVIcg9wCXB2kjkGZ/NsA+5Lcj3wAnBNa/4gcBUwC7wGvB+gqvYn+S3g8dbuN6tq4YFlSdIaWjIAquq6RRZdOqJtATcs8jo7gB1H1TtJ0jHjN4ElqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASerUkt8DkHoxvfWBSXdBWlOOACSpUwaAJHXKAJCkTnkMQDoGFh5PeH7b1RPqibQ4RwCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0aKwCS/NskTyd5Ksk9Sb4/yflJHkvybJLfT3Jaa3t6m59ty6dX4w1IklZmxQGQZB3wq8BMVb0VOAW4FvgocGtVbQReAa5vT7keeKWqfgy4tbWTJE3IuLuATgX+bpJTgTcALwHvBD7dlt8JvLdNb2rztOWXJsmY65ckrdCKA6CqvgH8B+AFBh/8rwJPAN+qqgOt2Rywrk2vA/a25x5o7d+40vVLksYzzi6gMxn8VX8+8GbgB4ArRzStg085wrLh192SZHeS3fPz8yvtniRpCePsAvoZ4OtVNV9V/w/4DPCPgTPaLiGA9cCLbXoO2ADQlv8wsH/hi1bV9qqaqaqZqampMbonSTqScQLgBeDiJG9o+/IvBZ4BPg/8bGuzGbi/Te9s87Tln6uqw0YAkqS1Mc4xgMcYHMz9EvCV9lrbgRuBDyWZZbCP//b2lNuBN7b6h4CtY/RbkjSmsa4GWlW3ALcsKD8HXDSi7d8A14yzPknS6vGbwJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOjVWACQ5I8mnk3w1yZ4k/yjJWUl2JXm2PZ7Z2ibJJ5LMJnkyyYWr8xYkSSsx7gjg48B/q6p/APxDYA+Dm70/XFUbgYc5dPP3K4GN7WcLcNuY65YkjWHFN4VP8kPAPwP+DUBVvQ68nmQTcElrdifwBeBGYBNwV1UV8GgbPZxbVS+tuPfSmKa3PjDpLkgTM84I4EeBeeA/J/mzJJ9K8gPAmw5+qLfHc1r7dcDeoefPtZokaQLGCYBTgQuB26rq7cD/5dDunlEyolaHNUq2JNmdZPf8/PwY3ZMkHck4ATAHzFXVY23+0wwC4eUk5wK0x31D7TcMPX898OLCF62q7VU1U1UzU1NTY3RPknQkKw6AqvpLYG+Sn2ilS4FngJ3A5lbbDNzfpncC72tnA10MvOr+f0manBUfBG5+Bbg7yWnAc8D7GYTKfUmuB14ArmltHwSuAmaB11pbSdKEjBUAVfVlYGbEoktHtC3ghnHWJ0laPeOOACQtw8LTTZ/fdvWEeiId4qUgJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVNjB0CSU5L8WZL/2ubPT/JYkmeT/H67XzBJTm/zs2359LjrliSt3GqMAD4I7Bma/yhwa1VtBF4Brm/164FXqurHgFtbO0nShIx1T+Ak64GrgY8AH0oS4J3Az7UmdwL/HrgN2NSmAT4N/G6StJvFS2ti4b15pZ6NOwL4HeDDwHfb/BuBb1XVgTY/B6xr0+uAvQBt+aut/fdIsiXJ7iS75+fnx+yeJGkxKw6AJO8G9lXVE8PlEU1rGcsOFaq2V9VMVc1MTU2ttHuSpCWMswvop4H3JLkK+H7ghxiMCM5Icmr7K3898GJrPwdsAOaSnAr8MLB/jPVLksaw4hFAVd1UVeurahq4FvhcVf088HngZ1uzzcD9bXpnm6ct/5z7/yVpco7F9wBuZHBAeJbBPv7bW/124I2t/iFg6zFYtyRpmcY6C+igqvoC8IU2/Rxw0Yg2fwNcsxrrkySNz28CS1KnVmUEIOnoLPw+wvPbrp5QT9QzRwCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQXg9NJzZvAS4tzBCBJnTIAJKlTKw6AJBuSfD7JniRPJ/lgq5+VZFeSZ9vjma2eJJ9IMpvkySQXrtabkCQdvXFGAAeAX6+qnwQuBm5IcgGDe/0+XFUbgYc5dO/fK4GN7WcLcNsY65YkjWnFB4Gr6iXgpTb910n2AOuATcAlrdmdDO4VfGOr31VVBTya5Iwk57bXkbrmHcI0CatyDCDJNPB24DHgTQc/1NvjOa3ZOmDv0NPmWk2SNAFjB0CSHwT+APi1qvqrIzUdUasRr7clye4ku+fn58ftniRpEWN9DyDJ9zH48L+7qj7Tyi8f3LWT5FxgX6vPARuGnr4eeHHha1bVdmA7wMzMzGEBIR2J5/1LyzfOWUABbgf2VNXHhhbtBDa36c3A/UP197WzgS4GXnX/vyRNzjgjgJ8G/jXwlSRfbrXfALYB9yW5HngBuKYtexC4CpgFXgPeP8a6JUljGucsoP/J6P36AJeOaF/ADStdnyRpdflNYEnqlAEgSZ3yaqA6oZ2sZ/0Mvy+/FKZjxRGAJHXKAJCkThkAktQpA0CSOmUASFKnPAtIOs55qWgdK44AJKlTjgB03DtZz/WXJs0RgCR1yhGAdILxmIBWiyMASeqUIwAdd9znL60NA0A6wblLSCtlAGji/ItfmgwDQGvOD/xjyxGBlmvNAyDJFcDHgVOAT1XVtrXug449P+SPH0f6tzAc+ramAZDkFOCTwLuAOeDxJDur6pm17IekAUcLfVvrEcBFwGxVPQeQ5F5gE2AAHAf8q10LGRAnt7UOgHXA3qH5OeAda9yHiVvNIbkf2lpNS/0+HS+/b0v9Pzma/2M9h9xaB0BG1Op7GiRbgC1t9v8k+dox79WRnQ18c61Wlo+u1ZpWZE23xXHM7XDIRLbFOP9PlnruCl/7ePud+HvLabTWATAHbBiaXw+8ONygqrYD29eyU0eSZHdVzUy6H8cDt8WA2+EQt8XAibod1vpSEI8DG5Ocn+Q04Fpg5xr3QZLEGo8AqupAkg8ADzE4DXRHVT29ln2QJA2s+fcAqupB4MG1Xu8YjpvdUccBt8WA2+EQt8XACbkdUlVLt5IknXS8HLQkdcoAWESS307y1SRPJvnDJGcMLbspyWySryW5fJL9PNaSXJPk6STfTTKzYFk32+GgJFe09zubZOuk+7OWkuxIsi/JU0O1s5LsSvJsezxzkn1cC0k2JPl8kj3t/8YHW/2E2xYGwOJ2AW+tqrcBfwHcBJDkAgZnL70FuAL4vXaJi5PVU8C/Ah4ZLna4HYYvZXIlcAFwXdsOvbiDwb/1sK3Aw1W1EXi4zZ/sDgC/XlU/CVwM3NB+D064bWEALKKq/riqDrTZRxl8ZwEGl664t6q+XVVfB2YZXOLipFRVe6pq1JfxutoOzd9eyqSqXgcOXsqkC1X1CLB/QXkTcGebvhN475p2agKq6qWq+lKb/mtgD4OrHJxw28IAWJ5fAD7bpkddzmLdmvdo8nrcDj2+56W8qapegsEHI3DOhPuzppJMA28HHuME3BZd3w8gyZ8APzJi0c1VdX9rczODId/dB582ov0JfSrVcrbDqKeNqJ3Q22EZenzPWkSSHwT+APi1qvqrZNSvx/Gt6wCoqp850vIkm4F3A5fWofNll7ycxYlmqe2wiJNuOyxDj+95KS8nObeqXkpyLrBv0h1aC0m+j8GH/91V9ZlWPuG2hbuAFtFuXHMj8J6qem1o0U7g2iSnJzkf2Ah8cRJ9nLAet4OXMjncTmBzm94MLDZiPGlk8Kf+7cCeqvrY0KITblv4RbBFJJkFTgf+dys9WlW/2JbdzOC4wAEGw7/Pjn6VE1+Sfwn8R2AK+Bbw5aq6vC3rZjsclOQq4Hc4dCmTj0y4S2smyT3AJQyufPkycAvwR8B9wHnAC8A1VbXwQPFJJck/Af4H8BXgu638GwyOA5xQ28IAkKROuQtIkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1Kn/D+KGheh8yJiHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(actual - predictions, bins = 80); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9594218638137143"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "sklearn.metrics.r2_score(predictions, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.     , 0.98213],\n",
       "       [0.98213, 1.     ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(predictions, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save predictions\n",
    "predictions_df = pd.DataFrame(np.hstack((results[-1], dataset[2].reshape((-1,1)), idx_split)), columns=['Prediction', 'Actual', 'idx_split'])\n",
    "predictions_df.index = np.array(keys[0], dtype = int)\n",
    "predictions_df.to_csv('PredictionsNoAuxilarySemisupervised.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
