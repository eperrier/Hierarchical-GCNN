{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-28 01:53:35.418382 Creating training Tensorflow Tensors\n",
      "2018-08-28 01:53:35.419201 Creating training network\n",
      "2018-08-28 01:53:36.059083 Creating loss function and summaries\n",
      "2018-08-28 01:53:36.108261 Training model \"2018-08-28-SA1SA2\"!\n",
      "2018-08-28 01:53:36.108340 Preparing training\n",
      "2018-08-28 01:53:38.607828 Starting threads\n",
      "2018-08-28 01:53:38.608528 Starting training. train_batch_size: 0 test_batch_size: 0\n",
      "2018-08-28 01:53:38.980436 Test Step 0 Finished\n",
      "2018-08-28 01:53:38.980871 Test Step 0 \"min loss\" =  6.310109e+18\n",
      "2018-08-28 01:53:38.980958 Test Step 0 \"loss\" =  6.310109e+18\n",
      "2018-08-28 01:53:40.062979 Training Step 0 Finished Timing (Training: 0.743944, Test: 0.255637) after 1.45432 seconds\n",
      "2018-08-28 01:53:40.063120 Training Step 0 \"min loss\" =  2880.5945\n",
      "2018-08-28 01:53:40.063186 Training Step 0 \"loss\" =  2880.5945\n",
      "2018-08-28 01:53:40.643767 Test Step 5 Finished\n",
      "2018-08-28 01:53:40.643907 Test Step 5 \"min loss\" =  2658.7876\n",
      "2018-08-28 01:53:40.644467 Test Step 5 \"loss\" =  2658.7876\n",
      "2018-08-28 01:53:40.776188 Training Step 5 Finished Timing (Training: 0.915926, Test: 0.0829469) after 0.712929 seconds\n",
      "2018-08-28 01:53:40.776277 Training Step 5 \"min loss\" =  2549.9617\n",
      "2018-08-28 01:53:40.776751 Training Step 5 \"loss\" =  2549.9617\n",
      "2018-08-28 01:53:41.357404 Test Step 10 Finished\n",
      "2018-08-28 01:53:41.357544 Test Step 10 \"min loss\" =  2484.2708\n",
      "2018-08-28 01:53:41.357609 Test Step 10 \"loss\" =  2484.2708\n",
      "2018-08-28 01:53:41.495164 Training Step 10 Finished Timing (Training: 0.918041, Test: 0.0807502) after 0.718336 seconds\n",
      "2018-08-28 01:53:41.495304 Training Step 10 \"min loss\" =  2212.3074\n",
      "2018-08-28 01:53:41.495367 Training Step 10 \"loss\" =  2212.3074\n",
      "2018-08-28 01:53:42.073630 Test Step 15 Finished\n",
      "2018-08-28 01:53:42.073754 Test Step 15 \"min loss\" =  2054.1575\n",
      "2018-08-28 01:53:42.073826 Test Step 15 \"loss\" =  2054.1575\n",
      "2018-08-28 01:53:42.210007 Training Step 15 Finished Timing (Training: 0.918108, Test: 0.0804234) after 0.713732 seconds\n",
      "2018-08-28 01:53:42.210087 Training Step 15 \"min loss\" =  1488.9824\n",
      "2018-08-28 01:53:42.210175 Training Step 15 \"loss\" =  1488.9824\n",
      "2018-08-28 01:53:42.788814 Test Step 20 Finished\n",
      "2018-08-28 01:53:42.788934 Test Step 20 \"min loss\" =  1231.4725\n",
      "2018-08-28 01:53:42.789055 Test Step 20 \"loss\" =  1231.4725\n",
      "2018-08-28 01:53:42.920136 Training Step 20 Finished Timing (Training: 0.917597, Test: 0.0811022) after 0.709898 seconds\n",
      "2018-08-28 01:53:42.920250 Training Step 20 \"min loss\" =  629.37537\n",
      "2018-08-28 01:53:42.920970 Training Step 20 \"loss\" =  629.37537\n",
      "2018-08-28 01:53:43.506529 Test Step 25 Finished\n",
      "2018-08-28 01:53:43.506654 Test Step 25 \"min loss\" =  540.2878\n",
      "2018-08-28 01:53:43.506751 Test Step 25 \"loss\" =  540.2878\n",
      "2018-08-28 01:53:43.635456 Training Step 25 Finished Timing (Training: 0.918205, Test: 0.0804122) after 0.714407 seconds\n",
      "2018-08-28 01:53:43.635553 Training Step 25 \"min loss\" =  525.78644\n",
      "2018-08-28 01:53:43.635642 Training Step 25 \"loss\" =  663.9986\n",
      "2018-08-28 01:53:44.213056 Test Step 30 Finished\n",
      "2018-08-28 01:53:44.213161 Test Step 30 \"min loss\" =  540.2878\n",
      "2018-08-28 01:53:44.213231 Test Step 30 \"loss\" =  667.65125\n",
      "2018-08-28 01:53:44.344237 Training Step 30 Finished Timing (Training: 0.9185, Test: 0.0800567) after 0.707824 seconds\n",
      "2018-08-28 01:53:44.344329 Training Step 30 \"min loss\" =  428.32336\n",
      "2018-08-28 01:53:44.344398 Training Step 30 \"loss\" =  428.32336\n",
      "2018-08-28 01:53:44.934210 Test Step 35 Finished\n",
      "2018-08-28 01:53:44.934832 Test Step 35 \"min loss\" =  540.2878\n",
      "2018-08-28 01:53:44.934907 Test Step 35 \"loss\" =  810.8589\n",
      "2018-08-28 01:53:45.063267 Training Step 35 Finished Timing (Training: 0.918871, Test: 0.0795236) after 0.717981 seconds\n",
      "2018-08-28 01:53:45.063567 Training Step 35 \"min loss\" =  359.90933\n",
      "2018-08-28 01:53:45.063634 Training Step 35 \"loss\" =  390.42816\n",
      "2018-08-28 01:53:45.633407 Test Step 40 Finished\n",
      "2018-08-28 01:53:45.634295 Test Step 40 \"min loss\" =  540.2878\n",
      "2018-08-28 01:53:45.634379 Test Step 40 \"loss\" =  654.0516\n",
      "2018-08-28 01:53:45.770878 Training Step 40 Finished Timing (Training: 0.918499, Test: 0.0796753) after 0.707159 seconds\n",
      "2018-08-28 01:53:45.771315 Training Step 40 \"min loss\" =  331.45584\n",
      "2018-08-28 01:53:45.771706 Training Step 40 \"loss\" =  349.3306\n",
      "2018-08-28 01:53:46.354086 Test Step 45 Finished\n",
      "2018-08-28 01:53:46.354198 Test Step 45 \"min loss\" =  540.2878\n",
      "2018-08-28 01:53:46.354263 Test Step 45 \"loss\" =  629.6082\n",
      "2018-08-28 01:53:46.486086 Training Step 45 Finished Timing (Training: 0.918753, Test: 0.0793515) after 0.713714 seconds\n",
      "2018-08-28 01:53:46.486236 Training Step 45 \"min loss\" =  300.0124\n",
      "2018-08-28 01:53:46.486303 Training Step 45 \"loss\" =  304.20853\n",
      "2018-08-28 01:53:47.057896 Test Step 50 Finished\n",
      "2018-08-28 01:53:47.058027 Test Step 50 \"min loss\" =  540.2878\n",
      "2018-08-28 01:53:47.058092 Test Step 50 \"loss\" =  700.7748\n",
      "2018-08-28 01:53:47.203899 Training Step 50 Finished Timing (Training: 0.918626, Test: 0.0794817) after 0.717524 seconds\n",
      "2018-08-28 01:53:47.204007 Training Step 50 \"min loss\" =  266.52295\n",
      "2018-08-28 01:53:47.204066 Training Step 50 \"loss\" =  277.02728\n",
      "2018-08-28 01:53:47.785178 Test Step 55 Finished\n",
      "2018-08-28 01:53:47.785641 Test Step 55 \"min loss\" =  540.2878\n",
      "2018-08-28 01:53:47.785730 Test Step 55 \"loss\" =  595.44714\n",
      "2018-08-28 01:53:47.920467 Training Step 55 Finished Timing (Training: 0.918552, Test: 0.0796143) after 0.71633 seconds\n",
      "2018-08-28 01:53:47.920552 Training Step 55 \"min loss\" =  253.19345\n",
      "2018-08-28 01:53:47.920612 Training Step 55 \"loss\" =  278.25714\n",
      "2018-08-28 01:53:48.506783 Test Step 60 Finished\n",
      "2018-08-28 01:53:48.506911 Test Step 60 \"min loss\" =  540.2878\n",
      "2018-08-28 01:53:48.506976 Test Step 60 \"loss\" =  552.1506\n",
      "2018-08-28 01:53:48.645041 Training Step 60 Finished Timing (Training: 0.918348, Test: 0.0796986) after 0.723745 seconds\n",
      "2018-08-28 01:53:48.645159 Training Step 60 \"min loss\" =  253.19345\n",
      "2018-08-28 01:53:48.645262 Training Step 60 \"loss\" =  317.8696\n",
      "2018-08-28 01:53:49.215489 Test Step 65 Finished\n",
      "2018-08-28 01:53:49.216154 Test Step 65 \"min loss\" =  540.2878\n",
      "2018-08-28 01:53:49.216332 Test Step 65 \"loss\" =  637.2731\n",
      "2018-08-28 01:53:49.345740 Training Step 65 Finished Timing (Training: 0.918167, Test: 0.0797515) after 0.699423 seconds\n",
      "2018-08-28 01:53:49.345863 Training Step 65 \"min loss\" =  232.35025\n",
      "2018-08-28 01:53:49.346337 Training Step 65 \"loss\" =  241.97398\n",
      "2018-08-28 01:53:49.918976 Test Step 70 Finished\n",
      "2018-08-28 01:53:49.919507 Test Step 70 \"min loss\" =  540.2878\n",
      "2018-08-28 01:53:49.919577 Test Step 70 \"loss\" =  612.9148\n",
      "2018-08-28 01:53:50.055232 Training Step 70 Finished Timing (Training: 0.918259, Test: 0.0796293) after 0.708411 seconds\n",
      "2018-08-28 01:53:50.055315 Training Step 70 \"min loss\" =  221.1236\n",
      "2018-08-28 01:53:50.055378 Training Step 70 \"loss\" =  247.04196\n",
      "2018-08-28 01:53:50.633504 Test Step 75 Finished\n",
      "2018-08-28 01:53:50.634121 Test Step 75 \"min loss\" =  540.2878\n",
      "2018-08-28 01:53:50.634202 Test Step 75 \"loss\" =  607.2156\n",
      "2018-08-28 01:53:50.763692 Training Step 75 Finished Timing (Training: 0.918175, Test: 0.0797595) after 0.708247 seconds\n",
      "2018-08-28 01:53:50.763800 Training Step 75 \"min loss\" =  205.8629\n",
      "2018-08-28 01:53:50.764293 Training Step 75 \"loss\" =  205.8629\n",
      "2018-08-28 01:53:51.348492 Test Step 80 Finished\n",
      "2018-08-28 01:53:51.348617 Test Step 80 \"min loss\" =  540.2878\n",
      "2018-08-28 01:53:51.348717 Test Step 80 \"loss\" =  685.31964\n",
      "2018-08-28 01:53:51.478486 Training Step 80 Finished Timing (Training: 0.918405, Test: 0.0795317) after 0.71366 seconds\n",
      "2018-08-28 01:53:51.478601 Training Step 80 \"min loss\" =  205.52213\n",
      "2018-08-28 01:53:51.478663 Training Step 80 \"loss\" =  232.33755\n",
      "2018-08-28 01:53:52.056058 Test Step 85 Finished\n",
      "2018-08-28 01:53:52.056187 Test Step 85 \"min loss\" =  540.2878\n",
      "2018-08-28 01:53:52.057090 Test Step 85 \"loss\" =  649.1433\n",
      "2018-08-28 01:53:52.185239 Training Step 85 Finished Timing (Training: 0.918392, Test: 0.0795502) after 0.706511 seconds\n",
      "2018-08-28 01:53:52.185330 Training Step 85 \"min loss\" =  200.7659\n",
      "2018-08-28 01:53:52.185882 Training Step 85 \"loss\" =  229.42659\n",
      "2018-08-28 01:53:52.768136 Test Step 90 Finished\n",
      "2018-08-28 01:53:52.768263 Test Step 90 \"min loss\" =  540.2878\n",
      "2018-08-28 01:53:52.768327 Test Step 90 \"loss\" =  614.706\n",
      "2018-08-28 01:53:52.900663 Training Step 90 Finished Timing (Training: 0.918495, Test: 0.0794803) after 0.714677 seconds\n",
      "2018-08-28 01:53:52.900771 Training Step 90 \"min loss\" =  186.27339\n",
      "2018-08-28 01:53:52.901455 Training Step 90 \"loss\" =  212.57327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-28 01:53:53.477274 Test Step 95 Finished\n",
      "2018-08-28 01:53:53.477413 Test Step 95 \"min loss\" =  540.2878\n",
      "2018-08-28 01:53:53.477559 Test Step 95 \"loss\" =  680.7856\n",
      "2018-08-28 01:53:53.611170 Training Step 95 Finished Timing (Training: 0.918532, Test: 0.0793237) after 0.709064 seconds\n",
      "2018-08-28 01:53:53.611535 Training Step 95 \"min loss\" =  186.27339\n",
      "2018-08-28 01:53:53.612276 Training Step 95 \"loss\" =  206.00185\n",
      "2018-08-28 01:53:54.193250 Test Step 100 Finished\n",
      "2018-08-28 01:53:54.193788 Test Step 100 \"min loss\" =  540.2878\n",
      "2018-08-28 01:53:54.193858 Test Step 100 \"loss\" =  634.4383\n",
      "2018-08-28 01:53:54.317971 Training Step 100 Finished Timing (Training: 0.918572, Test: 0.0792467) after 0.70545 seconds\n",
      "2018-08-28 01:53:54.318079 Training Step 100 \"min loss\" =  182.44594\n",
      "2018-08-28 01:53:54.318180 Training Step 100 \"loss\" =  194.979\n",
      "2018-08-28 01:53:54.927756 Test Step 105 Finished\n",
      "2018-08-28 01:53:54.927904 Test Step 105 \"min loss\" =  540.2878\n",
      "2018-08-28 01:53:54.927969 Test Step 105 \"loss\" =  625.6338\n",
      "2018-08-28 01:53:55.057228 Training Step 105 Finished Timing (Training: 0.918354, Test: 0.0802188) after 0.738941 seconds\n",
      "2018-08-28 01:53:55.057354 Training Step 105 \"min loss\" =  182.44594\n",
      "2018-08-28 01:53:55.057401 Training Step 105 \"loss\" =  185.3927\n",
      "2018-08-28 01:53:55.633469 Test Step 110 Finished\n",
      "2018-08-28 01:53:55.633610 Test Step 110 \"min loss\" =  540.2878\n",
      "2018-08-28 01:53:55.634253 Test Step 110 \"loss\" =  684.33527\n",
      "2018-08-28 01:53:55.772524 Training Step 110 Finished Timing (Training: 0.918474, Test: 0.0800144) after 0.71504 seconds\n",
      "2018-08-28 01:53:55.772663 Training Step 110 \"min loss\" =  182.44594\n",
      "2018-08-28 01:53:55.772735 Training Step 110 \"loss\" =  184.34308\n",
      "2018-08-28 01:53:56.360874 Test Step 115 Finished\n",
      "2018-08-28 01:53:56.361080 Test Step 115 \"min loss\" =  540.2878\n",
      "2018-08-28 01:53:56.361634 Test Step 115 \"loss\" =  623.5462\n",
      "2018-08-28 01:53:56.497667 Training Step 115 Finished Timing (Training: 0.917842, Test: 0.0804165) after 0.724854 seconds\n",
      "2018-08-28 01:53:56.497796 Training Step 115 \"min loss\" =  160.11284\n",
      "2018-08-28 01:53:56.497855 Training Step 115 \"loss\" =  179.24889\n",
      "2018-08-28 01:53:57.066347 Test Step 120 Finished\n",
      "2018-08-28 01:53:57.066480 Test Step 120 \"min loss\" =  540.2878\n",
      "2018-08-28 01:53:57.066564 Test Step 120 \"loss\" =  655.4064\n",
      "2018-08-28 01:53:57.197673 Training Step 120 Finished Timing (Training: 0.918041, Test: 0.0804266) after 0.699744 seconds\n",
      "2018-08-28 01:53:57.197809 Training Step 120 \"min loss\" =  160.11284\n",
      "2018-08-28 01:53:57.197906 Training Step 120 \"loss\" =  164.88985\n",
      "2018-08-28 01:53:57.792683 Test Step 125 Finished\n",
      "2018-08-28 01:53:57.793293 Test Step 125 \"min loss\" =  540.2878\n",
      "2018-08-28 01:53:57.793628 Test Step 125 \"loss\" =  712.03217\n",
      "2018-08-28 01:53:57.918025 Training Step 125 Finished Timing (Training: 0.917417, Test: 0.080975) after 0.720036 seconds\n",
      "2018-08-28 01:53:57.918102 Training Step 125 \"min loss\" =  160.11284\n",
      "2018-08-28 01:53:57.918188 Training Step 125 \"loss\" =  179.11227\n",
      "2018-08-28 01:53:58.508485 Test Step 130 Finished\n",
      "2018-08-28 01:53:58.508646 Test Step 130 \"min loss\" =  540.2878\n",
      "2018-08-28 01:53:58.508734 Test Step 130 \"loss\" =  731.4044\n",
      "2018-08-28 01:53:58.629572 Training Step 130 Finished Timing (Training: 0.91764, Test: 0.0806547) after 0.710329 seconds\n",
      "2018-08-28 01:53:58.629733 Training Step 130 \"min loss\" =  153.08008\n",
      "2018-08-28 01:53:58.629805 Training Step 130 \"loss\" =  180.37888\n",
      "2018-08-28 01:53:59.206423 Test Step 135 Finished\n",
      "2018-08-28 01:53:59.206852 Test Step 135 \"min loss\" =  540.2878\n",
      "2018-08-28 01:53:59.207062 Test Step 135 \"loss\" =  727.10535\n",
      "2018-08-28 01:53:59.335136 Training Step 135 Finished Timing (Training: 0.918032, Test: 0.0802934) after 0.705267 seconds\n",
      "2018-08-28 01:53:59.335217 Training Step 135 \"min loss\" =  148.36569\n",
      "2018-08-28 01:53:59.335269 Training Step 135 \"loss\" =  166.02562\n",
      "2018-08-28 01:53:59.926300 Test Step 140 Finished\n",
      "2018-08-28 01:53:59.926416 Test Step 140 \"min loss\" =  540.2878\n",
      "2018-08-28 01:53:59.927105 Test Step 140 \"loss\" =  694.83405\n",
      "2018-08-28 01:54:00.059432 Training Step 140 Finished Timing (Training: 0.917822, Test: 0.0804684) after 0.724054 seconds\n",
      "2018-08-28 01:54:00.059510 Training Step 140 \"min loss\" =  145.9826\n",
      "2018-08-28 01:54:00.060188 Training Step 140 \"loss\" =  158.38596\n",
      "2018-08-28 01:54:00.643756 Test Step 145 Finished\n",
      "2018-08-28 01:54:00.644347 Test Step 145 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:00.644721 Test Step 145 \"loss\" =  681.0103\n",
      "2018-08-28 01:54:00.774463 Training Step 145 Finished Timing (Training: 0.917599, Test: 0.0805444) after 0.714181 seconds\n",
      "2018-08-28 01:54:00.774537 Training Step 145 \"min loss\" =  140.29268\n",
      "2018-08-28 01:54:00.774601 Training Step 145 \"loss\" =  156.7775\n",
      "2018-08-28 01:54:01.352169 Test Step 150 Finished\n",
      "2018-08-28 01:54:01.352770 Test Step 150 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:01.352842 Test Step 150 \"loss\" =  728.4026\n",
      "2018-08-28 01:54:01.481215 Training Step 150 Finished Timing (Training: 0.917507, Test: 0.0806823) after 0.706541 seconds\n",
      "2018-08-28 01:54:01.481301 Training Step 150 \"min loss\" =  140.29268\n",
      "2018-08-28 01:54:01.481976 Training Step 150 \"loss\" =  144.71495\n",
      "2018-08-28 01:54:02.062102 Test Step 155 Finished\n",
      "2018-08-28 01:54:02.062658 Test Step 155 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:02.062930 Test Step 155 \"loss\" =  695.8452\n",
      "2018-08-28 01:54:02.192827 Training Step 155 Finished Timing (Training: 0.917293, Test: 0.0808013) after 0.710498 seconds\n",
      "2018-08-28 01:54:02.192960 Training Step 155 \"min loss\" =  140.29268\n",
      "2018-08-28 01:54:02.193019 Training Step 155 \"loss\" =  151.2377\n",
      "2018-08-28 01:54:02.776165 Test Step 160 Finished\n",
      "2018-08-28 01:54:02.776638 Test Step 160 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:02.776697 Test Step 160 \"loss\" =  729.3802\n",
      "2018-08-28 01:54:02.902365 Training Step 160 Finished Timing (Training: 0.917355, Test: 0.0807487) after 0.709281 seconds\n",
      "2018-08-28 01:54:02.902435 Training Step 160 \"min loss\" =  135.18929\n",
      "2018-08-28 01:54:02.902495 Training Step 160 \"loss\" =  140.2612\n",
      "2018-08-28 01:54:03.469031 Test Step 165 Finished\n",
      "2018-08-28 01:54:03.469505 Test Step 165 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:03.469563 Test Step 165 \"loss\" =  782.3751\n",
      "2018-08-28 01:54:03.599607 Training Step 165 Finished Timing (Training: 0.917292, Test: 0.0807109) after 0.696175 seconds\n",
      "2018-08-28 01:54:03.599851 Training Step 165 \"min loss\" =  135.18929\n",
      "2018-08-28 01:54:03.599908 Training Step 165 \"loss\" =  141.43593\n",
      "2018-08-28 01:54:04.170468 Test Step 170 Finished\n",
      "2018-08-28 01:54:04.171155 Test Step 170 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:04.171276 Test Step 170 \"loss\" =  755.35175\n",
      "2018-08-28 01:54:04.306755 Training Step 170 Finished Timing (Training: 0.917098, Test: 0.0809151) after 0.706784 seconds\n",
      "2018-08-28 01:54:04.307137 Training Step 170 \"min loss\" =  135.18929\n",
      "2018-08-28 01:54:04.307224 Training Step 170 \"loss\" =  159.76256\n",
      "2018-08-28 01:54:04.879751 Test Step 175 Finished\n",
      "2018-08-28 01:54:04.879882 Test Step 175 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:04.879939 Test Step 175 \"loss\" =  806.5289\n",
      "2018-08-28 01:54:05.019532 Training Step 175 Finished Timing (Training: 0.917433, Test: 0.080636) after 0.712237 seconds\n",
      "2018-08-28 01:54:05.019634 Training Step 175 \"min loss\" =  129.06001\n",
      "2018-08-28 01:54:05.019696 Training Step 175 \"loss\" =  139.47823\n",
      "2018-08-28 01:54:05.592566 Test Step 180 Finished\n",
      "2018-08-28 01:54:05.592704 Test Step 180 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:05.592767 Test Step 180 \"loss\" =  790.5625\n",
      "2018-08-28 01:54:05.721064 Training Step 180 Finished Timing (Training: 0.917501, Test: 0.0806395) after 0.701286 seconds\n",
      "2018-08-28 01:54:05.721167 Training Step 180 \"min loss\" =  119.25749\n",
      "2018-08-28 01:54:05.721696 Training Step 180 \"loss\" =  135.57646\n",
      "2018-08-28 01:54:06.312453 Test Step 185 Finished\n",
      "2018-08-28 01:54:06.312583 Test Step 185 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:06.312643 Test Step 185 \"loss\" =  836.5773\n",
      "2018-08-28 01:54:06.448233 Training Step 185 Finished Timing (Training: 0.917339, Test: 0.0808328) after 0.72647 seconds\n",
      "2018-08-28 01:54:06.448594 Training Step 185 \"min loss\" =  119.25749\n",
      "2018-08-28 01:54:06.448871 Training Step 185 \"loss\" =  129.89989\n",
      "2018-08-28 01:54:07.017863 Test Step 190 Finished\n",
      "2018-08-28 01:54:07.018405 Test Step 190 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:07.018678 Test Step 190 \"loss\" =  823.2016\n",
      "2018-08-28 01:54:07.151896 Training Step 190 Finished Timing (Training: 0.917202, Test: 0.0809434) after 0.70295 seconds\n",
      "2018-08-28 01:54:07.152038 Training Step 190 \"min loss\" =  119.25749\n",
      "2018-08-28 01:54:07.152661 Training Step 190 \"loss\" =  128.92293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-28 01:54:07.719083 Test Step 195 Finished\n",
      "2018-08-28 01:54:07.719609 Test Step 195 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:07.720145 Test Step 195 \"loss\" =  822.9792\n",
      "2018-08-28 01:54:07.850623 Training Step 195 Finished Timing (Training: 0.916985, Test: 0.0810743) after 0.697891 seconds\n",
      "2018-08-28 01:54:07.850708 Training Step 195 \"min loss\" =  119.25749\n",
      "2018-08-28 01:54:07.851358 Training Step 195 \"loss\" =  138.53381\n",
      "2018-08-28 01:54:08.418955 Test Step 200 Finished\n",
      "2018-08-28 01:54:08.419103 Test Step 200 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:08.419956 Test Step 200 \"loss\" =  846.001\n",
      "2018-08-28 01:54:08.555300 Training Step 200 Finished Timing (Training: 0.916919, Test: 0.0810602) after 0.703273 seconds\n",
      "2018-08-28 01:54:08.555441 Training Step 200 \"min loss\" =  114.784836\n",
      "2018-08-28 01:54:08.555503 Training Step 200 \"loss\" =  114.784836\n",
      "2018-08-28 01:54:09.148443 Test Step 205 Finished\n",
      "2018-08-28 01:54:09.148588 Test Step 205 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:09.149138 Test Step 205 \"loss\" =  800.9844\n",
      "2018-08-28 01:54:09.276203 Training Step 205 Finished Timing (Training: 0.918788, Test: 0.0801221) after 0.719912 seconds\n",
      "2018-08-28 01:54:09.276284 Training Step 205 \"min loss\" =  114.784836\n",
      "2018-08-28 01:54:09.276340 Training Step 205 \"loss\" =  120.558556\n",
      "2018-08-28 01:54:09.855832 Test Step 210 Finished\n",
      "2018-08-28 01:54:09.856324 Test Step 210 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:09.856390 Test Step 210 \"loss\" =  870.5614\n",
      "2018-08-28 01:54:09.981839 Training Step 210 Finished Timing (Training: 0.919585, Test: 0.0792709) after 0.705436 seconds\n",
      "2018-08-28 01:54:09.981910 Training Step 210 \"min loss\" =  114.784836\n",
      "2018-08-28 01:54:09.981965 Training Step 210 \"loss\" =  130.9177\n",
      "2018-08-28 01:54:10.557484 Test Step 215 Finished\n",
      "2018-08-28 01:54:10.557633 Test Step 215 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:10.557693 Test Step 215 \"loss\" =  834.73645\n",
      "2018-08-28 01:54:10.687897 Training Step 215 Finished Timing (Training: 0.919395, Test: 0.0792865) after 0.705869 seconds\n",
      "2018-08-28 01:54:10.687989 Training Step 215 \"min loss\" =  114.784836\n",
      "2018-08-28 01:54:10.688050 Training Step 215 \"loss\" =  122.783615\n",
      "2018-08-28 01:54:11.279440 Test Step 220 Finished\n",
      "2018-08-28 01:54:11.279591 Test Step 220 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:11.279654 Test Step 220 \"loss\" =  876.3338\n",
      "2018-08-28 01:54:11.421860 Training Step 220 Finished Timing (Training: 0.91988, Test: 0.0789551) after 0.733742 seconds\n",
      "2018-08-28 01:54:11.421958 Training Step 220 \"min loss\" =  114.784836\n",
      "2018-08-28 01:54:11.422012 Training Step 220 \"loss\" =  125.09875\n",
      "2018-08-28 01:54:11.999927 Test Step 225 Finished\n",
      "2018-08-28 01:54:12.000079 Test Step 225 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:12.000682 Test Step 225 \"loss\" =  892.71436\n",
      "2018-08-28 01:54:12.126939 Training Step 225 Finished Timing (Training: 0.919102, Test: 0.0794807) after 0.70421 seconds\n",
      "2018-08-28 01:54:12.127358 Training Step 225 \"min loss\" =  114.784836\n",
      "2018-08-28 01:54:12.127601 Training Step 225 \"loss\" =  117.512245\n",
      "2018-08-28 01:54:12.719853 Test Step 230 Finished\n",
      "2018-08-28 01:54:12.719979 Test Step 230 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:12.720045 Test Step 230 \"loss\" =  825.1748\n",
      "2018-08-28 01:54:12.851749 Training Step 230 Finished Timing (Training: 0.918861, Test: 0.0794296) after 0.723787 seconds\n",
      "2018-08-28 01:54:12.852064 Training Step 230 \"min loss\" =  107.9162\n",
      "2018-08-28 01:54:12.852394 Training Step 230 \"loss\" =  124.959915\n",
      "2018-08-28 01:54:13.439421 Test Step 235 Finished\n",
      "2018-08-28 01:54:13.439555 Test Step 235 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:13.439618 Test Step 235 \"loss\" =  901.17896\n",
      "2018-08-28 01:54:13.580269 Training Step 235 Finished Timing (Training: 0.919346, Test: 0.0789906) after 0.727808 seconds\n",
      "2018-08-28 01:54:13.580679 Training Step 235 \"min loss\" =  107.83811\n",
      "2018-08-28 01:54:13.580771 Training Step 235 \"loss\" =  120.12511\n",
      "2018-08-28 01:54:14.163064 Test Step 240 Finished\n",
      "2018-08-28 01:54:14.163175 Test Step 240 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:14.163254 Test Step 240 \"loss\" =  890.7445\n",
      "2018-08-28 01:54:14.292037 Training Step 240 Finished Timing (Training: 0.919296, Test: 0.0788626) after 0.710697 seconds\n",
      "2018-08-28 01:54:14.292119 Training Step 240 \"min loss\" =  99.466286\n",
      "2018-08-28 01:54:14.292169 Training Step 240 \"loss\" =  99.466286\n",
      "2018-08-28 01:54:14.865336 Test Step 245 Finished\n",
      "2018-08-28 01:54:14.865453 Test Step 245 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:14.866107 Test Step 245 \"loss\" =  904.9847\n",
      "2018-08-28 01:54:14.995225 Training Step 245 Finished Timing (Training: 0.91918, Test: 0.0790098) after 0.70298 seconds\n",
      "2018-08-28 01:54:14.995301 Training Step 245 \"min loss\" =  99.466286\n",
      "2018-08-28 01:54:14.995376 Training Step 245 \"loss\" =  107.45825\n",
      "2018-08-28 01:54:15.577108 Test Step 250 Finished\n",
      "2018-08-28 01:54:15.577775 Test Step 250 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:15.578007 Test Step 250 \"loss\" =  964.0644\n",
      "2018-08-28 01:54:15.710517 Training Step 250 Finished Timing (Training: 0.91869, Test: 0.0794823) after 0.715051 seconds\n",
      "2018-08-28 01:54:15.710603 Training Step 250 \"min loss\" =  99.466286\n",
      "2018-08-28 01:54:15.710666 Training Step 250 \"loss\" =  120.78119\n",
      "2018-08-28 01:54:16.283992 Test Step 255 Finished\n",
      "2018-08-28 01:54:16.284581 Test Step 255 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:16.284745 Test Step 255 \"loss\" =  939.59406\n",
      "2018-08-28 01:54:16.421220 Training Step 255 Finished Timing (Training: 0.918618, Test: 0.0795724) after 0.710481 seconds\n",
      "2018-08-28 01:54:16.421309 Training Step 255 \"min loss\" =  99.466286\n",
      "2018-08-28 01:54:16.421979 Training Step 255 \"loss\" =  119.088295\n",
      "2018-08-28 01:54:17.026988 Test Step 260 Finished\n",
      "2018-08-28 01:54:17.027569 Test Step 260 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:17.027745 Test Step 260 \"loss\" =  937.6817\n",
      "2018-08-28 01:54:17.159858 Training Step 260 Finished Timing (Training: 0.918448, Test: 0.0796893) after 0.737787 seconds\n",
      "2018-08-28 01:54:17.159946 Training Step 260 \"min loss\" =  92.3696\n",
      "2018-08-28 01:54:17.160606 Training Step 260 \"loss\" =  109.72679\n",
      "2018-08-28 01:54:17.746121 Test Step 265 Finished\n",
      "2018-08-28 01:54:17.746679 Test Step 265 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:17.747033 Test Step 265 \"loss\" =  988.7852\n",
      "2018-08-28 01:54:17.873260 Training Step 265 Finished Timing (Training: 0.917908, Test: 0.0801384) after 0.712543 seconds\n",
      "2018-08-28 01:54:17.873356 Training Step 265 \"min loss\" =  92.3696\n",
      "2018-08-28 01:54:17.873878 Training Step 265 \"loss\" =  107.41904\n",
      "2018-08-28 01:54:18.466427 Test Step 270 Finished\n",
      "2018-08-28 01:54:18.466542 Test Step 270 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:18.466603 Test Step 270 \"loss\" =  950.1471\n",
      "2018-08-28 01:54:18.596467 Training Step 270 Finished Timing (Training: 0.918274, Test: 0.079809) after 0.722434 seconds\n",
      "2018-08-28 01:54:18.596564 Training Step 270 \"min loss\" =  92.3696\n",
      "2018-08-28 01:54:18.596624 Training Step 270 \"loss\" =  109.51397\n",
      "2018-08-28 01:54:19.177111 Test Step 275 Finished\n",
      "2018-08-28 01:54:19.177238 Test Step 275 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:19.177313 Test Step 275 \"loss\" =  982.51965\n",
      "2018-08-28 01:54:19.314106 Training Step 275 Finished Timing (Training: 0.918409, Test: 0.0796711) after 0.717415 seconds\n",
      "2018-08-28 01:54:19.314191 Training Step 275 \"min loss\" =  92.3696\n",
      "2018-08-28 01:54:19.314250 Training Step 275 \"loss\" =  105.30773\n",
      "2018-08-28 01:54:19.906145 Test Step 280 Finished\n",
      "2018-08-28 01:54:19.906263 Test Step 280 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:19.906338 Test Step 280 \"loss\" =  928.03864\n",
      "2018-08-28 01:54:20.037477 Training Step 280 Finished Timing (Training: 0.918531, Test: 0.0795577) after 0.723161 seconds\n",
      "2018-08-28 01:54:20.037581 Training Step 280 \"min loss\" =  92.3696\n",
      "2018-08-28 01:54:20.037640 Training Step 280 \"loss\" =  101.30696\n",
      "2018-08-28 01:54:20.613250 Test Step 285 Finished\n",
      "2018-08-28 01:54:20.613393 Test Step 285 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:20.614148 Test Step 285 \"loss\" =  966.91925\n",
      "2018-08-28 01:54:20.745690 Training Step 285 Finished Timing (Training: 0.918582, Test: 0.0795164) after 0.707987 seconds\n",
      "2018-08-28 01:54:20.745766 Training Step 285 \"min loss\" =  87.52433\n",
      "2018-08-28 01:54:20.745830 Training Step 285 \"loss\" =  97.056274\n",
      "2018-08-28 01:54:21.327007 Test Step 290 Finished\n",
      "2018-08-28 01:54:21.327157 Test Step 290 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:21.327221 Test Step 290 \"loss\" =  947.44806\n",
      "2018-08-28 01:54:21.462532 Training Step 290 Finished Timing (Training: 0.91852, Test: 0.0796428) after 0.716628 seconds\n",
      "2018-08-28 01:54:21.462638 Training Step 290 \"min loss\" =  87.52433\n",
      "2018-08-28 01:54:21.463263 Training Step 290 \"loss\" =  99.46803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-28 01:54:22.046587 Test Step 295 Finished\n",
      "2018-08-28 01:54:22.046731 Test Step 295 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:22.046791 Test Step 295 \"loss\" =  932.48016\n",
      "2018-08-28 01:54:22.187765 Training Step 295 Finished Timing (Training: 0.918524, Test: 0.0796015) after 0.724405 seconds\n",
      "2018-08-28 01:54:22.187893 Training Step 295 \"min loss\" =  87.52433\n",
      "2018-08-28 01:54:22.187958 Training Step 295 \"loss\" =  97.013985\n",
      "2018-08-28 01:54:22.764053 Test Step 300 Finished\n",
      "2018-08-28 01:54:22.764191 Test Step 300 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:22.764258 Test Step 300 \"loss\" =  889.1042\n",
      "2018-08-28 01:54:22.903003 Training Step 300 Finished Timing (Training: 0.918452, Test: 0.0796741) after 0.714976 seconds\n",
      "2018-08-28 01:54:22.903077 Training Step 300 \"min loss\" =  87.52433\n",
      "2018-08-28 01:54:22.903143 Training Step 300 \"loss\" =  102.954544\n",
      "2018-08-28 01:54:23.490811 Test Step 305 Finished\n",
      "2018-08-28 01:54:23.490952 Test Step 305 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:23.491657 Test Step 305 \"loss\" =  901.02277\n",
      "2018-08-28 01:54:23.623190 Training Step 305 Finished Timing (Training: 0.920159, Test: 0.0785218) after 0.719969 seconds\n",
      "2018-08-28 01:54:23.623378 Training Step 305 \"min loss\" =  87.52433\n",
      "2018-08-28 01:54:23.623443 Training Step 305 \"loss\" =  96.26835\n",
      "2018-08-28 01:54:24.225919 Test Step 310 Finished\n",
      "2018-08-28 01:54:24.226063 Test Step 310 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:24.226139 Test Step 310 \"loss\" =  922.93384\n",
      "2018-08-28 01:54:24.359075 Training Step 310 Finished Timing (Training: 0.921872, Test: 0.076511) after 0.735565 seconds\n",
      "2018-08-28 01:54:24.359145 Training Step 310 \"min loss\" =  87.52433\n",
      "2018-08-28 01:54:24.359202 Training Step 310 \"loss\" =  88.91823\n",
      "2018-08-28 01:54:24.950354 Test Step 315 Finished\n",
      "2018-08-28 01:54:24.950518 Test Step 315 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:24.951493 Test Step 315 \"loss\" =  925.2303\n",
      "2018-08-28 01:54:25.082949 Training Step 315 Finished Timing (Training: 0.920988, Test: 0.077242) after 0.723675 seconds\n",
      "2018-08-28 01:54:25.083097 Training Step 315 \"min loss\" =  83.61473\n",
      "2018-08-28 01:54:25.083786 Training Step 315 \"loss\" =  83.61473\n",
      "2018-08-28 01:54:25.665052 Test Step 320 Finished\n",
      "2018-08-28 01:54:25.665228 Test Step 320 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:25.665339 Test Step 320 \"loss\" =  929.96075\n",
      "2018-08-28 01:54:25.786199 Training Step 320 Finished Timing (Training: 0.91896, Test: 0.07868) after 0.701932 seconds\n",
      "2018-08-28 01:54:25.786310 Training Step 320 \"min loss\" =  83.61473\n",
      "2018-08-28 01:54:25.786366 Training Step 320 \"loss\" =  91.49705\n",
      "2018-08-28 01:54:26.350677 Test Step 325 Finished\n",
      "2018-08-28 01:54:26.350793 Test Step 325 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:26.351506 Test Step 325 \"loss\" =  945.38184\n",
      "2018-08-28 01:54:26.487599 Training Step 325 Finished Timing (Training: 0.918754, Test: 0.0788428) after 0.700526 seconds\n",
      "2018-08-28 01:54:26.487739 Training Step 325 \"min loss\" =  83.61473\n",
      "2018-08-28 01:54:26.487809 Training Step 325 \"loss\" =  88.76811\n",
      "2018-08-28 01:54:27.073667 Test Step 330 Finished\n",
      "2018-08-28 01:54:27.073839 Test Step 330 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:27.073911 Test Step 330 \"loss\" =  995.2103\n",
      "2018-08-28 01:54:27.208657 Training Step 330 Finished Timing (Training: 0.918859, Test: 0.0786335) after 0.72011 seconds\n",
      "2018-08-28 01:54:27.208757 Training Step 330 \"min loss\" =  83.61473\n",
      "2018-08-28 01:54:27.208846 Training Step 330 \"loss\" =  94.56543\n",
      "2018-08-28 01:54:27.794491 Test Step 335 Finished\n",
      "2018-08-28 01:54:27.794622 Test Step 335 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:27.794685 Test Step 335 \"loss\" =  999.589\n",
      "2018-08-28 01:54:27.926911 Training Step 335 Finished Timing (Training: 0.919092, Test: 0.0783478) after 0.717341 seconds\n",
      "2018-08-28 01:54:27.926979 Training Step 335 \"min loss\" =  83.61473\n",
      "2018-08-28 01:54:27.927808 Training Step 335 \"loss\" =  95.2328\n",
      "2018-08-28 01:54:28.504747 Test Step 340 Finished\n",
      "2018-08-28 01:54:28.504861 Test Step 340 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:28.504926 Test Step 340 \"loss\" =  969.0287\n",
      "2018-08-28 01:54:28.636733 Training Step 340 Finished Timing (Training: 0.918708, Test: 0.0786653) after 0.708515 seconds\n",
      "2018-08-28 01:54:28.636847 Training Step 340 \"min loss\" =  83.61473\n",
      "2018-08-28 01:54:28.636908 Training Step 340 \"loss\" =  90.11272\n",
      "2018-08-28 01:54:29.203992 Test Step 345 Finished\n",
      "2018-08-28 01:54:29.204114 Test Step 345 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:29.204177 Test Step 345 \"loss\" =  1010.5637\n",
      "2018-08-28 01:54:29.333210 Training Step 345 Finished Timing (Training: 0.918451, Test: 0.0789703) after 0.696206 seconds\n",
      "2018-08-28 01:54:29.333289 Training Step 345 \"min loss\" =  82.164345\n",
      "2018-08-28 01:54:29.333802 Training Step 345 \"loss\" =  91.46333\n",
      "2018-08-28 01:54:29.918915 Test Step 350 Finished\n",
      "2018-08-28 01:54:29.919349 Test Step 350 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:29.919412 Test Step 350 \"loss\" =  961.8431\n",
      "2018-08-28 01:54:30.049614 Training Step 350 Finished Timing (Training: 0.9187, Test: 0.0787335) after 0.715729 seconds\n",
      "2018-08-28 01:54:30.049687 Training Step 350 \"min loss\" =  82.164345\n",
      "2018-08-28 01:54:30.049784 Training Step 350 \"loss\" =  94.869934\n",
      "2018-08-28 01:54:30.626040 Test Step 355 Finished\n",
      "2018-08-28 01:54:30.626180 Test Step 355 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:30.626287 Test Step 355 \"loss\" =  966.87524\n",
      "2018-08-28 01:54:30.757596 Training Step 355 Finished Timing (Training: 0.918565, Test: 0.0790207) after 0.707736 seconds\n",
      "2018-08-28 01:54:30.757698 Training Step 355 \"min loss\" =  82.164345\n",
      "2018-08-28 01:54:30.758306 Training Step 355 \"loss\" =  88.80255\n",
      "2018-08-28 01:54:31.342842 Test Step 360 Finished\n",
      "2018-08-28 01:54:31.342987 Test Step 360 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:31.343698 Test Step 360 \"loss\" =  982.54877\n",
      "2018-08-28 01:54:31.477971 Training Step 360 Finished Timing (Training: 0.918734, Test: 0.0788501) after 0.719577 seconds\n",
      "2018-08-28 01:54:31.478076 Training Step 360 \"min loss\" =  76.544174\n",
      "2018-08-28 01:54:31.478137 Training Step 360 \"loss\" =  87.8277\n",
      "2018-08-28 01:54:32.061157 Test Step 365 Finished\n",
      "2018-08-28 01:54:32.061291 Test Step 365 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:32.061371 Test Step 365 \"loss\" =  1014.0151\n",
      "2018-08-28 01:54:32.183509 Training Step 365 Finished Timing (Training: 0.918734, Test: 0.0788786) after 0.705269 seconds\n",
      "2018-08-28 01:54:32.183644 Training Step 365 \"min loss\" =  76.544174\n",
      "2018-08-28 01:54:32.183746 Training Step 365 \"loss\" =  87.42271\n",
      "2018-08-28 01:54:32.751014 Test Step 370 Finished\n",
      "2018-08-28 01:54:32.751583 Test Step 370 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:32.751657 Test Step 370 \"loss\" =  935.17474\n",
      "2018-08-28 01:54:32.882955 Training Step 370 Finished Timing (Training: 0.91859, Test: 0.0789861) after 0.698168 seconds\n",
      "2018-08-28 01:54:32.883034 Training Step 370 \"min loss\" =  76.544174\n",
      "2018-08-28 01:54:32.883105 Training Step 370 \"loss\" =  97.81208\n",
      "2018-08-28 01:54:33.465132 Test Step 375 Finished\n",
      "2018-08-28 01:54:33.465256 Test Step 375 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:33.465333 Test Step 375 \"loss\" =  900.86536\n",
      "2018-08-28 01:54:33.593970 Training Step 375 Finished Timing (Training: 0.91879, Test: 0.0788148) after 0.710814 seconds\n",
      "2018-08-28 01:54:33.594066 Training Step 375 \"min loss\" =  75.89058\n",
      "2018-08-28 01:54:33.594133 Training Step 375 \"loss\" =  79.21303\n",
      "2018-08-28 01:54:34.191065 Test Step 380 Finished\n",
      "2018-08-28 01:54:34.191191 Test Step 380 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:34.191281 Test Step 380 \"loss\" =  969.1016\n",
      "2018-08-28 01:54:34.322479 Training Step 380 Finished Timing (Training: 0.919119, Test: 0.0785913) after 0.728277 seconds\n",
      "2018-08-28 01:54:34.322562 Training Step 380 \"min loss\" =  75.89058\n",
      "2018-08-28 01:54:34.322960 Training Step 380 \"loss\" =  79.358246\n",
      "2018-08-28 01:54:34.916982 Test Step 385 Finished\n",
      "2018-08-28 01:54:34.917106 Test Step 385 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:34.917174 Test Step 385 \"loss\" =  933.10077\n",
      "2018-08-28 01:54:35.048422 Training Step 385 Finished Timing (Training: 0.919233, Test: 0.0785054) after 0.72494 seconds\n",
      "2018-08-28 01:54:35.048503 Training Step 385 \"min loss\" =  75.89058\n",
      "2018-08-28 01:54:35.048891 Training Step 385 \"loss\" =  81.273575\n",
      "2018-08-28 01:54:35.646829 Test Step 390 Finished\n",
      "2018-08-28 01:54:35.647005 Test Step 390 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:35.647078 Test Step 390 \"loss\" =  972.8926\n",
      "2018-08-28 01:54:35.783874 Training Step 390 Finished Timing (Training: 0.919094, Test: 0.0787022) after 0.734889 seconds\n",
      "2018-08-28 01:54:35.783958 Training Step 390 \"min loss\" =  73.41544\n",
      "2018-08-28 01:54:35.784380 Training Step 390 \"loss\" =  85.74575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-28 01:54:36.359350 Test Step 395 Finished\n",
      "2018-08-28 01:54:36.359478 Test Step 395 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:36.360029 Test Step 395 \"loss\" =  985.1378\n",
      "2018-08-28 01:54:36.495801 Training Step 395 Finished Timing (Training: 0.918893, Test: 0.0788909) after 0.710955 seconds\n",
      "2018-08-28 01:54:36.496292 Training Step 395 \"min loss\" =  73.41544\n",
      "2018-08-28 01:54:36.496406 Training Step 395 \"loss\" =  83.0519\n",
      "2018-08-28 01:54:37.074055 Test Step 400 Finished\n",
      "2018-08-28 01:54:37.074266 Test Step 400 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:37.075022 Test Step 400 \"loss\" =  970.807\n",
      "2018-08-28 01:54:37.199804 Training Step 400 Finished Timing (Training: 0.918849, Test: 0.078873) after 0.702645 seconds\n",
      "2018-08-28 01:54:37.199939 Training Step 400 \"min loss\" =  73.41544\n",
      "2018-08-28 01:54:37.200552 Training Step 400 \"loss\" =  87.67885\n",
      "2018-08-28 01:54:37.769964 Test Step 405 Finished\n",
      "2018-08-28 01:54:37.770516 Test Step 405 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:37.770864 Test Step 405 \"loss\" =  988.6174\n",
      "2018-08-28 01:54:37.903414 Training Step 405 Finished Timing (Training: 0.91906, Test: 0.07951) after 0.70245 seconds\n",
      "2018-08-28 01:54:37.903485 Training Step 405 \"min loss\" =  73.41544\n",
      "2018-08-28 01:54:37.903547 Training Step 405 \"loss\" =  76.23306\n",
      "2018-08-28 01:54:38.493506 Test Step 410 Finished\n",
      "2018-08-28 01:54:38.493709 Test Step 410 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:38.493778 Test Step 410 \"loss\" =  962.6608\n",
      "2018-08-28 01:54:38.620569 Training Step 410 Finished Timing (Training: 0.918235, Test: 0.0796706) after 0.716958 seconds\n",
      "2018-08-28 01:54:38.620641 Training Step 410 \"min loss\" =  73.41544\n",
      "2018-08-28 01:54:38.621392 Training Step 410 \"loss\" =  80.280396\n",
      "2018-08-28 01:54:39.197110 Test Step 415 Finished\n",
      "2018-08-28 01:54:39.197229 Test Step 415 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:39.197334 Test Step 415 \"loss\" =  957.8409\n",
      "2018-08-28 01:54:39.322907 Training Step 415 Finished Timing (Training: 0.917673, Test: 0.0803306) after 0.70143 seconds\n",
      "2018-08-28 01:54:39.322999 Training Step 415 \"min loss\" =  73.41544\n",
      "2018-08-28 01:54:39.323049 Training Step 415 \"loss\" =  82.102135\n",
      "2018-08-28 01:54:39.904925 Test Step 420 Finished\n",
      "2018-08-28 01:54:39.905054 Test Step 420 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:39.905114 Test Step 420 \"loss\" =  956.17267\n",
      "2018-08-28 01:54:40.040424 Training Step 420 Finished Timing (Training: 0.918323, Test: 0.0797869) after 0.716674 seconds\n",
      "2018-08-28 01:54:40.040781 Training Step 420 \"min loss\" =  73.41544\n",
      "2018-08-28 01:54:40.041081 Training Step 420 \"loss\" =  76.35065\n",
      "2018-08-28 01:54:40.629545 Test Step 425 Finished\n",
      "2018-08-28 01:54:40.629744 Test Step 425 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:40.630278 Test Step 425 \"loss\" =  950.2518\n",
      "2018-08-28 01:54:40.769951 Training Step 425 Finished Timing (Training: 0.918498, Test: 0.0794131) after 0.728302 seconds\n",
      "2018-08-28 01:54:40.770092 Training Step 425 \"min loss\" =  71.24305\n",
      "2018-08-28 01:54:40.770153 Training Step 425 \"loss\" =  81.44477\n",
      "2018-08-28 01:54:41.365747 Test Step 430 Finished\n",
      "2018-08-28 01:54:41.365891 Test Step 430 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:41.365962 Test Step 430 \"loss\" =  985.5136\n",
      "2018-08-28 01:54:41.499109 Training Step 430 Finished Timing (Training: 0.918922, Test: 0.079207) after 0.728884 seconds\n",
      "2018-08-28 01:54:41.499498 Training Step 430 \"min loss\" =  70.31811\n",
      "2018-08-28 01:54:41.499563 Training Step 430 \"loss\" =  80.88735\n",
      "2018-08-28 01:54:42.102165 Test Step 435 Finished\n",
      "2018-08-28 01:54:42.102299 Test Step 435 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:42.103033 Test Step 435 \"loss\" =  984.65405\n",
      "2018-08-28 01:54:42.234017 Training Step 435 Finished Timing (Training: 0.918201, Test: 0.0797823) after 0.733771 seconds\n",
      "2018-08-28 01:54:42.234162 Training Step 435 \"min loss\" =  70.31811\n",
      "2018-08-28 01:54:42.234767 Training Step 435 \"loss\" =  82.395546\n",
      "2018-08-28 01:54:42.836563 Test Step 440 Finished\n",
      "2018-08-28 01:54:42.836679 Test Step 440 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:42.837466 Test Step 440 \"loss\" =  990.27515\n",
      "2018-08-28 01:54:42.971138 Training Step 440 Finished Timing (Training: 0.918264, Test: 0.0796511) after 0.736301 seconds\n",
      "2018-08-28 01:54:42.971207 Training Step 440 \"min loss\" =  70.31811\n",
      "2018-08-28 01:54:42.971777 Training Step 440 \"loss\" =  74.308304\n",
      "2018-08-28 01:54:43.559051 Test Step 445 Finished\n",
      "2018-08-28 01:54:43.559565 Test Step 445 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:43.559981 Test Step 445 \"loss\" =  981.67584\n",
      "2018-08-28 01:54:43.698799 Training Step 445 Finished Timing (Training: 0.917778, Test: 0.0800317) after 0.726486 seconds\n",
      "2018-08-28 01:54:43.698946 Training Step 445 \"min loss\" =  70.31811\n",
      "2018-08-28 01:54:43.699500 Training Step 445 \"loss\" =  72.56907\n",
      "2018-08-28 01:54:44.304367 Test Step 450 Finished\n",
      "2018-08-28 01:54:44.304882 Test Step 450 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:44.305157 Test Step 450 \"loss\" =  976.8474\n",
      "2018-08-28 01:54:44.443599 Training Step 450 Finished Timing (Training: 0.917787, Test: 0.0799782) after 0.74375 seconds\n",
      "2018-08-28 01:54:44.443924 Training Step 450 \"min loss\" =  70.31811\n",
      "2018-08-28 01:54:44.444004 Training Step 450 \"loss\" =  74.48871\n",
      "2018-08-28 01:54:45.036830 Test Step 455 Finished\n",
      "2018-08-28 01:54:45.036971 Test Step 455 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:45.037530 Test Step 455 \"loss\" =  965.5918\n",
      "2018-08-28 01:54:45.177332 Training Step 455 Finished Timing (Training: 0.918124, Test: 0.0796228) after 0.733252 seconds\n",
      "2018-08-28 01:54:45.177795 Training Step 455 \"min loss\" =  70.31811\n",
      "2018-08-28 01:54:45.178261 Training Step 455 \"loss\" =  73.73535\n",
      "2018-08-28 01:54:45.780283 Test Step 460 Finished\n",
      "2018-08-28 01:54:45.780759 Test Step 460 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:45.780821 Test Step 460 \"loss\" =  964.2539\n",
      "2018-08-28 01:54:45.913840 Training Step 460 Finished Timing (Training: 0.918193, Test: 0.0795525) after 0.735501 seconds\n",
      "2018-08-28 01:54:45.913933 Training Step 460 \"min loss\" =  70.31811\n",
      "2018-08-28 01:54:45.913991 Training Step 460 \"loss\" =  78.752785\n",
      "2018-08-28 01:54:46.501233 Test Step 465 Finished\n",
      "2018-08-28 01:54:46.501419 Test Step 465 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:46.502125 Test Step 465 \"loss\" =  940.4676\n",
      "2018-08-28 01:54:46.642812 Training Step 465 Finished Timing (Training: 0.91834, Test: 0.0794458) after 0.728757 seconds\n",
      "2018-08-28 01:54:46.643211 Training Step 465 \"min loss\" =  63.994816\n",
      "2018-08-28 01:54:46.643537 Training Step 465 \"loss\" =  72.1159\n",
      "2018-08-28 01:54:47.249918 Test Step 470 Finished\n",
      "2018-08-28 01:54:47.250072 Test Step 470 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:47.250141 Test Step 470 \"loss\" =  927.8248\n",
      "2018-08-28 01:54:47.386805 Training Step 470 Finished Timing (Training: 0.918636, Test: 0.0791724) after 0.742917 seconds\n",
      "2018-08-28 01:54:47.386900 Training Step 470 \"min loss\" =  63.994816\n",
      "2018-08-28 01:54:47.386967 Training Step 470 \"loss\" =  68.59624\n",
      "2018-08-28 01:54:47.989365 Test Step 475 Finished\n",
      "2018-08-28 01:54:47.990005 Test Step 475 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:47.990390 Test Step 475 \"loss\" =  940.73553\n",
      "2018-08-28 01:54:48.129847 Training Step 475 Finished Timing (Training: 0.918869, Test: 0.0789154) after 0.742473 seconds\n",
      "2018-08-28 01:54:48.129931 Training Step 475 \"min loss\" =  63.994816\n",
      "2018-08-28 01:54:48.130416 Training Step 475 \"loss\" =  78.084946\n",
      "2018-08-28 01:54:48.727513 Test Step 480 Finished\n",
      "2018-08-28 01:54:48.727629 Test Step 480 \"min loss\" =  540.2878\n",
      "2018-08-28 01:54:48.727699 Test Step 480 \"loss\" =  960.2081\n",
      "2018-08-28 01:54:48.863398 Training Step 480 Finished Timing (Training: 0.918721, Test: 0.079124) after 0.732906 seconds\n",
      "2018-08-28 01:54:48.863500 Training Step 480 \"min loss\" =  63.994816\n",
      "2018-08-28 01:54:48.863556 Training Step 480 \"loss\" =  75.757454\n",
      "2018-08-28 01:54:49.402511 Training interrupted at 484\n",
      "2018-08-28 01:54:49.402631 Training completed, starting cleanup!\n",
      "2018-08-28 01:54:49.402742 Cleanup completed!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GraphCNNNetwork' object has no attribute 'dist_beta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-aa284b7f6951>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/GGCNN/src/ggcnn/experiment.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0;31m# writer.close()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m                 \u001b[0mcurrent_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist_beta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist_beta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_A\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_beta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GraphCNNNetwork' object has no attribute 'dist_beta'"
     ]
    }
   ],
   "source": [
    "# %load runSA1SA2.py\n",
    "import ggcnn.experiment as experiment\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "SA1DatasetSize = 0\n",
    "dataFolder = ''\n",
    "\n",
    "def load_sa1_dataset():\n",
    "    global SA1DatasetSize\n",
    "    keys = []\n",
    "    features = []\n",
    "    labels = []\n",
    "    # Load SA1 Node Features\n",
    "    with open(dataFolder + 'Data/2018-08-24-NSW-SA1Input-Normalised.csv', 'r') as file:\n",
    "        for i, line in enumerate(file):\n",
    "            if i == 0:  # Skip first line (header)\n",
    "                continue\n",
    "            s = line[:-1].split(',')  # Last value in line is \\n\n",
    "            keys.append(s[0])\n",
    "            features.extend([float(v) for v in s[1:-1]])  # Last column is the outcome y\n",
    "#             labels.append(np.floor(float(s[-1]) / 10).astype(int))\n",
    "            labels.append(float(s[-1]))\n",
    "    \n",
    "    SA1DatasetSize = len(labels)\n",
    "    \n",
    "    # Load SA2 Node Features\n",
    "    with open(dataFolder + 'Data/2018-08-28-NSW-SA2Input-Normalised.csv', 'r') as file:\n",
    "        for i, line in enumerate(file):\n",
    "            if i == 0:  # Skip first line (header)\n",
    "                continue\n",
    "            s = line[:-1].split(',')  # Last value in line is \\n\n",
    "            keys.append(s[0])\n",
    "            features.extend([float(v) for v in s[1:-1]])  # Last column is the outcome y\n",
    "            labels.append(0)\n",
    "\n",
    "    labels = np.array(labels)\n",
    "    features = np.array(features).reshape((len(keys), -1))\n",
    "    \n",
    "    # Load SA1 Link Features\n",
    "    with open(dataFolder + 'Data/2018-08-25-NSW-NeighbourDistance.csv', 'r') as file:\n",
    "        adj_mat = np.zeros((len(labels), 4, len(labels)))\n",
    "        for i, line in enumerate(file):\n",
    "            if i == 0:  # Skip first line (header)\n",
    "                continue\n",
    "            s = line[:-1].split(',')\n",
    "            a = keys.index(s[0])\n",
    "            b = keys.index(s[1])\n",
    "            adj_mat[a, 0, b] = 1\n",
    "            adj_mat[b, 0, a] = 1\n",
    "\n",
    "    # Load SA2 Link Features\n",
    "    with open(dataFolder + 'Data/Geography/2018-08-28-NSW-SA2_Neighbouring_Suburbs_With_Bridges-GCC.csv', 'r') as file:\n",
    "        for i, line in enumerate(file):\n",
    "            if i == 0:  # Skip first line (header)\n",
    "                continue\n",
    "            s = line[:-1].split(',')\n",
    "            a = keys.index(s[0])\n",
    "            b = keys.index(s[1])\n",
    "            adj_mat[a, 1, b] = 1\n",
    "            adj_mat[b, 1, a] = 1\n",
    "    \n",
    "    # Load SA1, SA2 Links\n",
    "    with open(dataFolder + 'Data/SA1SA2Links.csv', 'r') as file:\n",
    "        for i, line in enumerate(file):\n",
    "            if i == 0:  # Skip first line (header)\n",
    "                continue\n",
    "            s = line[:-1].split(',')\n",
    "            a = keys.index(s[0])\n",
    "            b = keys.index(s[1])\n",
    "            adj_mat[a, 2, b] = 1\n",
    "            adj_mat[b, 3, a] = 1   \n",
    "    \n",
    "    return features, adj_mat, labels\n",
    "\n",
    "dataset = load_sa1_dataset()\n",
    "\n",
    "class SA1Experiment():\n",
    "    def __init__(self, neurons, blocks):\n",
    "        self.blocks = blocks\n",
    "        self.neurons = neurons\n",
    "    \n",
    "    def create_network(self, net, input):\n",
    "        net.create_network(input)\n",
    "#        net.make_adjacency_adjustment_layer()\n",
    "        net.make_embedding_layer(self.neurons)\n",
    "        net.make_dropout_layer()\n",
    "        \n",
    "        for _ in range(self.blocks):\n",
    "            net.make_graphcnn_layer(self.neurons)\n",
    "            net.make_dropout_layer()\n",
    "            net.make_embedding_layer(self.neurons)\n",
    "            net.make_dropout_layer()\n",
    "        \n",
    "        net.make_embedding_layer(self.neurons)\n",
    "        net.make_graphcnn_layer(1, name='final', with_bn=False, with_act_func = False)\n",
    "\n",
    "\n",
    "no_folds = 5 ##\n",
    "inst = KFold(n_splits = no_folds, shuffle=True, random_state=125)\n",
    "\n",
    "\n",
    "l = 2\n",
    "n = 64\n",
    "i = 2\n",
    "\n",
    "\n",
    "exp = experiment.GGCNNExperiment('2018-08-28-SA1SA2', '2018-08-28-SA1SA2', SA1Experiment(neurons = n, blocks = l))\n",
    "\n",
    "exp.num_iterations = 2000\n",
    "exp.optimizer = 'adam'\n",
    "exp.loss_type = \"linear\"\n",
    "\n",
    "exp.debug = True  # Was True\n",
    "\n",
    "exp.preprocess_data(dataset)\n",
    "\n",
    "train_idx, test_idx = list(inst.split(np.arange( SA1DatasetSize )))[i]\n",
    "# print('Before: ', exp.train_idx.shape)\n",
    "# exp.train_idx = np.append(exp.train_idx, np.arange( SA1DatasetSize , len(dataset[-1] )))\n",
    "# exp.test_idx = np.append(exp.test_idx, np.arange( SA1DatasetSize , len(dataset[-1] )))\n",
    "# print('After: ', exp.train_idx.shape)\n",
    "# test_idx, train_idx = list(inst.split(np.arange(len(dataset[-1]))))[i]  # Reversed to get more samples in the test set than the training set\n",
    "\n",
    "\n",
    "exp.create_data(train_idx, test_idx)\n",
    "exp.build_network()\n",
    "results = exp.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
