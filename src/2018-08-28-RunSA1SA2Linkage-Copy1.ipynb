{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/tf-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/paperspace/anaconda3/envs/tf-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# %load runSA1SA2.py\n",
    "import ggcnn.experiment as experiment\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "def load_sa1_dataset():\n",
    "    keys_SA1 = []\n",
    "    features_SA1 = []\n",
    "    labels = []\n",
    "    keys_SA2 = []\n",
    "    features_SA2 = []\n",
    "    \n",
    "    # Load SA1 Node Features\n",
    "    with open('Data/2018-08-24-NSW-SA1Input-Normalised.csv', 'r') as file:\n",
    "        for i, line in enumerate(file):\n",
    "            if i == 0:  # Skip first line (header)\n",
    "                continue\n",
    "            s = line[:-1].split(',')  # Last value in line is \\n\n",
    "            keys_SA1.append(s[0])\n",
    "            features_SA1.extend([float(v) for v in s[1:-1]])  # Last column is the outcome y\n",
    "#             labels.append(np.floor(float(s[-1]) / 10).astype(int))\n",
    "            labels.append(float(s[-1]))\n",
    "    \n",
    "    \n",
    "    # Load SA2 Node Features\n",
    "    with open('Data/2018-08-28-NSW-SA2Input-Normalised.csv', 'r') as file:\n",
    "        for i, line in enumerate(file):\n",
    "            if i == 0:  # Skip first line (header)\n",
    "                continue\n",
    "            s = line[:-1].split(',')  # Last value in line is \\n\n",
    "            keys_SA2.append(s[0])\n",
    "            features_SA2.extend([float(v) for v in s[1:-1]])  # Last column is the outcome y\n",
    "\n",
    "    labels = np.array(labels)\n",
    "    features_SA1 = np.array(features_SA1).reshape((len(keys_SA1), -1))\n",
    "    features_SA2 = np.array(features_SA2).reshape((len(keys_SA2), -1))\n",
    "    \n",
    "    # Load SA1 Link Features\n",
    "    with open('Data/2018-08-25-NSW-NeighbourDistance.csv', 'r') as file:\n",
    "        adj_mat_SA1 = np.zeros((len(keys_SA1), len(keys_SA1)))\n",
    "        for i, line in enumerate(file):\n",
    "            if i == 0:  # Skip first line (header)\n",
    "                continue\n",
    "            s = line[:-1].split(',')\n",
    "            a = keys_SA1.index(s[0])\n",
    "            b = keys_SA1.index(s[1])\n",
    "            adj_mat_SA1[a, b] = 1\n",
    "            adj_mat_SA1[b, a] = 1\n",
    "    \n",
    "\n",
    "    # Load SA2 Link Features\n",
    "    with open('Data/Geography/2018-08-28-NSW-SA2_Neighbouring_Suburbs_With_Bridges-GCC.csv', 'r') as file:\n",
    "        adj_mat_SA2 = np.zeros((len(keys_SA2), len(keys_SA2)))\n",
    "        for i, line in enumerate(file):\n",
    "            if i == 0:  # Skip first line (header)\n",
    "                continue\n",
    "            s = line[:-1].split(',')\n",
    "            a = keys_SA2.index(s[0])\n",
    "            b = keys_SA2.index(s[1])\n",
    "            adj_mat_SA2[a, b] = 1\n",
    "            adj_mat_SA2[b, a] = 1\n",
    "    \n",
    "    \n",
    "    # Load SA1, SA2 Links\n",
    "    with open('Data/SA1SA2Links.csv', 'r') as file:\n",
    "        adj_mat_SA1SA2 = np.zeros((len(keys_SA1), len(keys_SA2)))\n",
    "        for i, line in enumerate(file):\n",
    "            if i == 0:  # Skip first line (header)\n",
    "                continue\n",
    "            s = line[:-1].split(',')\n",
    "            a = keys_SA1.index(s[0])\n",
    "            b = keys_SA2.index(s[1])\n",
    "            adj_mat_SA1SA2[a, b] = 1\n",
    "    \n",
    "    adj_mat_SA2SA1 = np.transpose(adj_mat_SA1SA2)\n",
    "    \n",
    "#     adj_mat_SA1SA2 = adj_mat_SA1SA2 / np.sum(adj_mat_SA1SA2, axis = -1, keepdims = True)\n",
    "#     adj_mat_SA2SA1 = adj_mat_SA2SA1 / np.sum(adj_mat_SA2SA1, axis = -1, keepdims = True)\n",
    "    \n",
    "    return features_SA1, adj_mat_SA1, labels, features_SA2, adj_mat_SA2, adj_mat_SA1SA2, adj_mat_SA2SA1\n",
    "\n",
    "dataset = load_sa1_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-30 06:23:50.067928 Creating training Tensorflow Tensors\n",
      "2018-08-30 06:23:50.068704 Creating training network\n",
      "2018-08-30 06:23:51.088212 Creating loss function and summaries\n",
      "2018-08-30 06:23:51.133157 Training model \"2018-08-28-SA1SA2\"!\n",
      "2018-08-30 06:23:51.133476 Preparing training\n",
      "2018-08-30 06:23:53.618050 Starting threads\n",
      "2018-08-30 06:23:53.618231 Starting training. train_batch_size: 0 test_batch_size: 0\n",
      "2018-08-30 06:23:54.160544 Test Step 0 Finished\n",
      "2018-08-30 06:23:54.160686 Test Step 0 \"min loss\" =  8.370024e+27\n",
      "2018-08-30 06:23:54.160745 Test Step 0 \"loss\" =  8.370024e+27\n",
      "2018-08-30 06:23:55.932717 Training Step 0 Finished Timing (Training: 0.765301, Test: 0.234287) after 2.3144 seconds\n",
      "2018-08-30 06:23:55.932857 Training Step 0 \"min loss\" =  2911.7922\n",
      "2018-08-30 06:23:55.933605 Training Step 0 \"loss\" =  2911.7922\n",
      "2018-08-30 06:23:56.138619 Test Step 5 Finished\n",
      "2018-08-30 06:23:56.138693 Test Step 5 \"min loss\" =  2834.2708\n",
      "2018-08-30 06:23:56.138751 Test Step 5 \"loss\" =  2834.2708\n",
      "2018-08-30 06:23:56.185142 Training Step 5 Finished Timing (Training: 0.916908, Test: 0.0822603) after 0.250904 seconds\n",
      "2018-08-30 06:23:56.185200 Training Step 5 \"min loss\" =  2852.657\n",
      "2018-08-30 06:23:56.185648 Training Step 5 \"loss\" =  2852.657\n",
      "2018-08-30 06:23:56.388930 Test Step 10 Finished\n",
      "2018-08-30 06:23:56.389017 Test Step 10 \"min loss\" =  2804.0894\n",
      "2018-08-30 06:23:56.389549 Test Step 10 \"loss\" =  2804.0894\n",
      "2018-08-30 06:23:56.435119 Training Step 10 Finished Timing (Training: 0.915018, Test: 0.0820396) after 0.249408 seconds\n",
      "2018-08-30 06:23:56.435199 Training Step 10 \"min loss\" =  2795.9492\n",
      "2018-08-30 06:23:56.435256 Training Step 10 \"loss\" =  2795.9492\n",
      "2018-08-30 06:23:56.638675 Test Step 15 Finished\n",
      "2018-08-30 06:23:56.638761 Test Step 15 \"min loss\" =  2753.7153\n",
      "2018-08-30 06:23:56.638818 Test Step 15 \"loss\" =  2753.7153\n",
      "2018-08-30 06:23:56.684548 Training Step 15 Finished Timing (Training: 0.914286, Test: 0.0821891) after 0.248495 seconds\n",
      "2018-08-30 06:23:56.684868 Training Step 15 \"min loss\" =  2741.1562\n",
      "2018-08-30 06:23:56.685117 Training Step 15 \"loss\" =  2741.1562\n",
      "2018-08-30 06:23:56.888542 Test Step 20 Finished\n",
      "2018-08-30 06:23:56.888637 Test Step 20 \"min loss\" =  2666.5068\n",
      "2018-08-30 06:23:56.889168 Test Step 20 \"loss\" =  2666.5068\n",
      "2018-08-30 06:23:56.935029 Training Step 20 Finished Timing (Training: 0.913535, Test: 0.0821521) after 0.249849 seconds\n",
      "2018-08-30 06:23:56.935089 Training Step 20 \"min loss\" =  2691.9102\n",
      "2018-08-30 06:23:56.935654 Training Step 20 \"loss\" =  2691.9102\n",
      "2018-08-30 06:23:57.139062 Test Step 25 Finished\n",
      "2018-08-30 06:23:57.139151 Test Step 25 \"min loss\" =  2533.9368\n",
      "2018-08-30 06:23:57.139201 Test Step 25 \"loss\" =  2533.9368\n",
      "2018-08-30 06:23:57.185050 Training Step 25 Finished Timing (Training: 0.913531, Test: 0.0821281) after 0.249139 seconds\n",
      "2018-08-30 06:23:57.185111 Training Step 25 \"min loss\" =  2647.0024\n",
      "2018-08-30 06:23:57.185601 Training Step 25 \"loss\" =  2647.0024\n",
      "2018-08-30 06:23:57.389039 Test Step 30 Finished\n",
      "2018-08-30 06:23:57.389291 Test Step 30 \"min loss\" =  2438.922\n",
      "2018-08-30 06:23:57.389573 Test Step 30 \"loss\" =  2438.922\n",
      "2018-08-30 06:23:57.435379 Training Step 30 Finished Timing (Training: 0.913367, Test: 0.0822029) after 0.249718 seconds\n",
      "2018-08-30 06:23:57.435437 Training Step 30 \"min loss\" =  2594.8403\n",
      "2018-08-30 06:23:57.435487 Training Step 30 \"loss\" =  2594.8403\n",
      "2018-08-30 06:23:57.639967 Test Step 35 Finished\n",
      "2018-08-30 06:23:57.640030 Test Step 35 \"min loss\" =  2426.7195\n",
      "2018-08-30 06:23:57.640083 Test Step 35 \"loss\" =  2426.7195\n",
      "2018-08-30 06:23:57.686617 Training Step 35 Finished Timing (Training: 0.913338, Test: 0.0822474) after 0.251074 seconds\n",
      "2018-08-30 06:23:57.686683 Training Step 35 \"min loss\" =  2544.7617\n",
      "2018-08-30 06:23:57.687029 Training Step 35 \"loss\" =  2544.7617\n",
      "2018-08-30 06:23:57.890848 Test Step 40 Finished\n",
      "2018-08-30 06:23:57.891225 Test Step 40 \"min loss\" =  2403.5825\n",
      "2018-08-30 06:23:57.891617 Test Step 40 \"loss\" =  2403.5825\n",
      "2018-08-30 06:23:57.937595 Training Step 40 Finished Timing (Training: 0.913061, Test: 0.0822797) after 0.250496 seconds\n",
      "2018-08-30 06:23:57.937682 Training Step 40 \"min loss\" =  2496.3867\n",
      "2018-08-30 06:23:57.937732 Training Step 40 \"loss\" =  2496.3867\n",
      "2018-08-30 06:23:58.141779 Test Step 45 Finished\n",
      "2018-08-30 06:23:58.142048 Test Step 45 \"min loss\" =  2383.4575\n",
      "2018-08-30 06:23:58.142344 Test Step 45 \"loss\" =  2383.4575\n",
      "2018-08-30 06:23:58.188390 Training Step 45 Finished Timing (Training: 0.912792, Test: 0.0822784) after 0.249937 seconds\n",
      "2018-08-30 06:23:58.188467 Training Step 45 \"min loss\" =  2454.4595\n",
      "2018-08-30 06:23:58.188843 Training Step 45 \"loss\" =  2454.4595\n",
      "2018-08-30 06:23:58.392146 Test Step 50 Finished\n",
      "2018-08-30 06:23:58.392235 Test Step 50 \"min loss\" =  2336.5935\n",
      "2018-08-30 06:23:58.392294 Test Step 50 \"loss\" =  2336.5935\n",
      "2018-08-30 06:23:58.438843 Training Step 50 Finished Timing (Training: 0.912625, Test: 0.0822814) after 0.249661 seconds\n",
      "2018-08-30 06:23:58.438918 Training Step 50 \"min loss\" =  2416.5076\n",
      "2018-08-30 06:23:58.438974 Training Step 50 \"loss\" =  2416.5076\n",
      "2018-08-30 06:23:58.642979 Test Step 55 Finished\n",
      "2018-08-30 06:23:58.643394 Test Step 55 \"min loss\" =  2302.667\n",
      "2018-08-30 06:23:58.643460 Test Step 55 \"loss\" =  2302.667\n",
      "2018-08-30 06:23:58.689709 Training Step 55 Finished Timing (Training: 0.91251, Test: 0.0822541) after 0.250104 seconds\n",
      "2018-08-30 06:23:58.689920 Training Step 55 \"min loss\" =  2377.503\n",
      "2018-08-30 06:23:58.690159 Training Step 55 \"loss\" =  2377.503\n",
      "2018-08-30 06:23:58.893432 Test Step 60 Finished\n",
      "2018-08-30 06:23:58.893713 Test Step 60 \"min loss\" =  2232.7603\n",
      "2018-08-30 06:23:58.894008 Test Step 60 \"loss\" =  2232.7603\n",
      "2018-08-30 06:23:58.940154 Training Step 60 Finished Timing (Training: 0.912442, Test: 0.082279) after 0.249934 seconds\n",
      "2018-08-30 06:23:58.940222 Training Step 60 \"min loss\" =  2340.99\n",
      "2018-08-30 06:23:58.940592 Training Step 60 \"loss\" =  2340.99\n",
      "2018-08-30 06:23:59.144097 Test Step 65 Finished\n",
      "2018-08-30 06:23:59.144201 Test Step 65 \"min loss\" =  2192.543\n",
      "2018-08-30 06:23:59.144263 Test Step 65 \"loss\" =  2192.543\n",
      "2018-08-30 06:23:59.190055 Training Step 65 Finished Timing (Training: 0.912413, Test: 0.0824004) after 0.249136 seconds\n",
      "2018-08-30 06:23:59.190125 Training Step 65 \"min loss\" =  2304.272\n",
      "2018-08-30 06:23:59.190186 Training Step 65 \"loss\" =  2304.272\n",
      "2018-08-30 06:23:59.394316 Test Step 70 Finished\n",
      "2018-08-30 06:23:59.394403 Test Step 70 \"min loss\" =  2165.139\n",
      "2018-08-30 06:23:59.394473 Test Step 70 \"loss\" =  2165.139\n",
      "2018-08-30 06:23:59.440904 Training Step 70 Finished Timing (Training: 0.912408, Test: 0.0824413) after 0.249923 seconds\n",
      "2018-08-30 06:23:59.441287 Training Step 70 \"min loss\" =  2269.0398\n",
      "2018-08-30 06:23:59.441761 Training Step 70 \"loss\" =  2269.0398\n",
      "2018-08-30 06:23:59.645751 Test Step 75 Finished\n",
      "2018-08-30 06:23:59.645856 Test Step 75 \"min loss\" =  2125.2256\n",
      "2018-08-30 06:23:59.645915 Test Step 75 \"loss\" =  2125.2256\n",
      "2018-08-30 06:23:59.691668 Training Step 75 Finished Timing (Training: 0.912366, Test: 0.0824059) after 0.249439 seconds\n",
      "2018-08-30 06:23:59.691882 Training Step 75 \"min loss\" =  2230.8757\n",
      "2018-08-30 06:23:59.691944 Training Step 75 \"loss\" =  2230.8757\n",
      "2018-08-30 06:23:59.895518 Test Step 80 Finished\n",
      "2018-08-30 06:23:59.895662 Test Step 80 \"min loss\" =  2071.4302\n",
      "2018-08-30 06:23:59.896495 Test Step 80 \"loss\" =  2071.4302\n",
      "2018-08-30 06:23:59.942782 Training Step 80 Finished Timing (Training: 0.91229, Test: 0.0823889) after 0.250771 seconds\n",
      "2018-08-30 06:23:59.942891 Training Step 80 \"min loss\" =  2193.6655\n",
      "2018-08-30 06:23:59.942951 Training Step 80 \"loss\" =  2193.6655\n",
      "2018-08-30 06:24:00.145887 Test Step 85 Finished\n",
      "2018-08-30 06:24:00.146175 Test Step 85 \"min loss\" =  2025.8507\n",
      "2018-08-30 06:24:00.146236 Test Step 85 \"loss\" =  2025.8507\n",
      "2018-08-30 06:24:00.192514 Training Step 85 Finished Timing (Training: 0.912449, Test: 0.082386) after 0.249501 seconds\n",
      "2018-08-30 06:24:00.192716 Training Step 85 \"min loss\" =  2157.6968\n",
      "2018-08-30 06:24:00.192776 Training Step 85 \"loss\" =  2157.6968\n",
      "2018-08-30 06:24:00.396123 Test Step 90 Finished\n",
      "2018-08-30 06:24:00.396218 Test Step 90 \"min loss\" =  1993.2511\n",
      "2018-08-30 06:24:00.396295 Test Step 90 \"loss\" =  1993.2511\n",
      "2018-08-30 06:24:00.442001 Training Step 90 Finished Timing (Training: 0.912607, Test: 0.082388) after 0.249161 seconds\n",
      "2018-08-30 06:24:00.442247 Training Step 90 \"min loss\" =  2118.3982\n",
      "2018-08-30 06:24:00.442404 Training Step 90 \"loss\" =  2118.3982\n",
      "2018-08-30 06:24:00.648438 Test Step 95 Finished\n",
      "2018-08-30 06:24:00.648564 Test Step 95 \"min loss\" =  1968.8059\n",
      "2018-08-30 06:24:00.648625 Test Step 95 \"loss\" =  1968.8059\n",
      "2018-08-30 06:24:00.695046 Training Step 95 Finished Timing (Training: 0.912728, Test: 0.0823578) after 0.252484 seconds\n",
      "2018-08-30 06:24:00.695319 Training Step 95 \"min loss\" =  2078.507\n",
      "2018-08-30 06:24:00.695381 Training Step 95 \"loss\" =  2078.507\n",
      "2018-08-30 06:24:00.899528 Test Step 100 Finished\n",
      "2018-08-30 06:24:00.900005 Test Step 100 \"min loss\" =  1933.3683\n",
      "2018-08-30 06:24:00.900355 Test Step 100 \"loss\" =  1933.3683\n",
      "2018-08-30 06:24:00.946489 Training Step 100 Finished Timing (Training: 0.912494, Test: 0.0823603) after 0.25048 seconds\n",
      "2018-08-30 06:24:00.946570 Training Step 100 \"min loss\" =  2042.0044\n",
      "2018-08-30 06:24:00.947413 Training Step 100 \"loss\" =  2042.0044\n",
      "2018-08-30 06:24:01.150747 Test Step 105 Finished\n",
      "2018-08-30 06:24:01.151168 Test Step 105 \"min loss\" =  1933.2739\n",
      "2018-08-30 06:24:01.151725 Test Step 105 \"loss\" =  1933.2739\n",
      "2018-08-30 06:24:01.197796 Training Step 105 Finished Timing (Training: 0.912076, Test: 0.0824147) after 0.249855 seconds\n",
      "2018-08-30 06:24:01.198152 Training Step 105 \"min loss\" =  2001.3573\n",
      "2018-08-30 06:24:01.198541 Training Step 105 \"loss\" =  2001.3573\n",
      "2018-08-30 06:24:01.402434 Test Step 110 Finished\n",
      "2018-08-30 06:24:01.402929 Test Step 110 \"min loss\" =  1915.9531\n",
      "2018-08-30 06:24:01.403091 Test Step 110 \"loss\" =  1915.9531\n",
      "2018-08-30 06:24:01.449581 Training Step 110 Finished Timing (Training: 0.910453, Test: 0.0826102) after 0.250457 seconds\n",
      "2018-08-30 06:24:01.449648 Training Step 110 \"min loss\" =  1961.0315\n",
      "2018-08-30 06:24:01.449706 Training Step 110 \"loss\" =  1961.0315\n",
      "2018-08-30 06:24:01.652859 Test Step 115 Finished\n",
      "2018-08-30 06:24:01.652953 Test Step 115 \"min loss\" =  1873.1221\n",
      "2018-08-30 06:24:01.653014 Test Step 115 \"loss\" =  1873.1221\n",
      "2018-08-30 06:24:01.699870 Training Step 115 Finished Timing (Training: 0.911342, Test: 0.0825009) after 0.250044 seconds\n",
      "2018-08-30 06:24:01.700071 Training Step 115 \"min loss\" =  1921.8279\n",
      "2018-08-30 06:24:01.700201 Training Step 115 \"loss\" =  1921.8279\n",
      "2018-08-30 06:24:01.904564 Test Step 120 Finished\n",
      "2018-08-30 06:24:01.904942 Test Step 120 \"min loss\" =  1824.9622\n",
      "2018-08-30 06:24:01.905005 Test Step 120 \"loss\" =  1824.9622\n",
      "2018-08-30 06:24:01.951453 Training Step 120 Finished Timing (Training: 0.912038, Test: 0.0823053) after 0.251128 seconds\n",
      "2018-08-30 06:24:01.951522 Training Step 120 \"min loss\" =  1879.1254\n",
      "2018-08-30 06:24:01.951576 Training Step 120 \"loss\" =  1879.1254\n",
      "2018-08-30 06:24:02.155441 Test Step 125 Finished\n",
      "2018-08-30 06:24:02.155532 Test Step 125 \"min loss\" =  1759.9021\n",
      "2018-08-30 06:24:02.155602 Test Step 125 \"loss\" =  1759.9021\n",
      "2018-08-30 06:24:02.202064 Training Step 125 Finished Timing (Training: 0.913047, Test: 0.0820893) after 0.250431 seconds\n",
      "2018-08-30 06:24:02.202126 Training Step 125 \"min loss\" =  1841.9647\n",
      "2018-08-30 06:24:02.202693 Training Step 125 \"loss\" =  1841.9647\n",
      "2018-08-30 06:24:02.405652 Test Step 130 Finished\n",
      "2018-08-30 06:24:02.405752 Test Step 130 \"min loss\" =  1750.8542\n",
      "2018-08-30 06:24:02.405809 Test Step 130 \"loss\" =  1750.8542\n",
      "2018-08-30 06:24:02.452288 Training Step 130 Finished Timing (Training: 0.913275, Test: 0.0820549) after 0.24953 seconds\n",
      "2018-08-30 06:24:02.452357 Training Step 130 \"min loss\" =  1796.4863\n",
      "2018-08-30 06:24:02.452426 Training Step 130 \"loss\" =  1796.4863\n",
      "2018-08-30 06:24:02.656245 Test Step 135 Finished\n",
      "2018-08-30 06:24:02.656668 Test Step 135 \"min loss\" =  1729.1544\n",
      "2018-08-30 06:24:02.656731 Test Step 135 \"loss\" =  1729.1544\n",
      "2018-08-30 06:24:02.703207 Training Step 135 Finished Timing (Training: 0.913016, Test: 0.0821811) after 0.250701 seconds\n",
      "2018-08-30 06:24:02.703273 Training Step 135 \"min loss\" =  1754.592\n",
      "2018-08-30 06:24:02.703333 Training Step 135 \"loss\" =  1754.592\n",
      "2018-08-30 06:24:02.907183 Test Step 140 Finished\n",
      "2018-08-30 06:24:02.907401 Test Step 140 \"min loss\" =  1625.3335\n",
      "2018-08-30 06:24:02.907994 Test Step 140 \"loss\" =  1625.3335\n",
      "2018-08-30 06:24:02.954676 Training Step 140 Finished Timing (Training: 0.912528, Test: 0.0822095) after 0.250601 seconds\n",
      "2018-08-30 06:24:02.954738 Training Step 140 \"min loss\" =  1712.7379\n",
      "2018-08-30 06:24:02.954803 Training Step 140 \"loss\" =  1712.7379\n",
      "2018-08-30 06:24:03.159876 Test Step 145 Finished\n",
      "2018-08-30 06:24:03.160250 Test Step 145 \"min loss\" =  1579.047\n",
      "2018-08-30 06:24:03.160604 Test Step 145 \"loss\" =  1579.047\n",
      "2018-08-30 06:24:03.206693 Training Step 145 Finished Timing (Training: 0.912583, Test: 0.0821673) after 0.251826 seconds\n",
      "2018-08-30 06:24:03.206753 Training Step 145 \"min loss\" =  1672.7976\n",
      "2018-08-30 06:24:03.206839 Training Step 145 \"loss\" =  1672.7976\n",
      "2018-08-30 06:24:03.410766 Test Step 150 Finished\n",
      "2018-08-30 06:24:03.410929 Test Step 150 \"min loss\" =  1524.2493\n",
      "2018-08-30 06:24:03.410990 Test Step 150 \"loss\" =  1524.2493\n",
      "2018-08-30 06:24:03.457490 Training Step 150 Finished Timing (Training: 0.912863, Test: 0.0822061) after 0.250588 seconds\n",
      "2018-08-30 06:24:03.457552 Training Step 150 \"min loss\" =  1629.557\n",
      "2018-08-30 06:24:03.457613 Training Step 150 \"loss\" =  1629.557\n",
      "2018-08-30 06:24:03.661927 Test Step 155 Finished\n",
      "2018-08-30 06:24:03.662018 Test Step 155 \"min loss\" =  1488.3208\n",
      "2018-08-30 06:24:03.662077 Test Step 155 \"loss\" =  1488.3208\n",
      "2018-08-30 06:24:03.708671 Training Step 155 Finished Timing (Training: 0.913057, Test: 0.0823107) after 0.250993 seconds\n",
      "2018-08-30 06:24:03.708730 Training Step 155 \"min loss\" =  1584.3042\n",
      "2018-08-30 06:24:03.708812 Training Step 155 \"loss\" =  1584.3042\n",
      "2018-08-30 06:24:03.914049 Test Step 160 Finished\n",
      "2018-08-30 06:24:03.914532 Test Step 160 \"min loss\" =  1461.1711\n",
      "2018-08-30 06:24:03.914651 Test Step 160 \"loss\" =  1461.1711\n",
      "2018-08-30 06:24:03.961907 Training Step 160 Finished Timing (Training: 0.912875, Test: 0.0822716) after 0.252177 seconds\n",
      "2018-08-30 06:24:03.962023 Training Step 160 \"min loss\" =  1540.6156\n",
      "2018-08-30 06:24:03.962846 Training Step 160 \"loss\" =  1540.6156\n",
      "2018-08-30 06:24:04.167582 Test Step 165 Finished\n",
      "2018-08-30 06:24:04.167669 Test Step 165 \"min loss\" =  1412.9069\n",
      "2018-08-30 06:24:04.168193 Test Step 165 \"loss\" =  1412.9069\n",
      "2018-08-30 06:24:04.214458 Training Step 165 Finished Timing (Training: 0.912542, Test: 0.0823189) after 0.251086 seconds\n",
      "2018-08-30 06:24:04.214759 Training Step 165 \"min loss\" =  1498.5144\n",
      "2018-08-30 06:24:04.214876 Training Step 165 \"loss\" =  1498.5144\n",
      "2018-08-30 06:24:04.420777 Test Step 170 Finished\n",
      "2018-08-30 06:24:04.420889 Test Step 170 \"min loss\" =  1391.0111\n",
      "2018-08-30 06:24:04.420950 Test Step 170 \"loss\" =  1391.0111\n",
      "2018-08-30 06:24:04.467416 Training Step 170 Finished Timing (Training: 0.912478, Test: 0.082331) after 0.252418 seconds\n",
      "2018-08-30 06:24:04.467483 Training Step 170 \"min loss\" =  1455.4011\n",
      "2018-08-30 06:24:04.467846 Training Step 170 \"loss\" =  1455.4011\n",
      "2018-08-30 06:24:04.671931 Test Step 175 Finished\n",
      "2018-08-30 06:24:04.672380 Test Step 175 \"min loss\" =  1335.7725\n",
      "2018-08-30 06:24:04.672685 Test Step 175 \"loss\" =  1335.7725\n",
      "2018-08-30 06:24:04.718927 Training Step 175 Finished Timing (Training: 0.912448, Test: 0.0822908) after 0.251017 seconds\n",
      "2018-08-30 06:24:04.719003 Training Step 175 \"min loss\" =  1409.6957\n",
      "2018-08-30 06:24:04.719074 Training Step 175 \"loss\" =  1409.6957\n",
      "2018-08-30 06:24:04.923754 Test Step 180 Finished\n",
      "2018-08-30 06:24:04.923855 Test Step 180 \"min loss\" =  1257.9674\n",
      "2018-08-30 06:24:04.924510 Test Step 180 \"loss\" =  1257.9674\n",
      "2018-08-30 06:24:04.970549 Training Step 180 Finished Timing (Training: 0.912469, Test: 0.0822921) after 0.251398 seconds\n",
      "2018-08-30 06:24:04.970609 Training Step 180 \"min loss\" =  1369.042\n",
      "2018-08-30 06:24:04.971056 Training Step 180 \"loss\" =  1369.042\n",
      "2018-08-30 06:24:05.175432 Test Step 185 Finished\n",
      "2018-08-30 06:24:05.175498 Test Step 185 \"min loss\" =  1214.4694\n",
      "2018-08-30 06:24:05.176141 Test Step 185 \"loss\" =  1214.4694\n",
      "2018-08-30 06:24:05.222211 Training Step 185 Finished Timing (Training: 0.912319, Test: 0.0823276) after 0.250819 seconds\n",
      "2018-08-30 06:24:05.222273 Training Step 185 \"min loss\" =  1327.5385\n",
      "2018-08-30 06:24:05.222718 Training Step 185 \"loss\" =  1327.5385\n",
      "2018-08-30 06:24:05.426326 Test Step 190 Finished\n",
      "2018-08-30 06:24:05.426409 Test Step 190 \"min loss\" =  1194.0935\n",
      "2018-08-30 06:24:05.426915 Test Step 190 \"loss\" =  1194.0935\n",
      "2018-08-30 06:24:05.472703 Training Step 190 Finished Timing (Training: 0.912313, Test: 0.0823348) after 0.249821 seconds\n",
      "2018-08-30 06:24:05.472771 Training Step 190 \"min loss\" =  1281.0963\n",
      "2018-08-30 06:24:05.472826 Training Step 190 \"loss\" =  1281.0963\n",
      "2018-08-30 06:24:05.676927 Test Step 195 Finished\n",
      "2018-08-30 06:24:05.677047 Test Step 195 \"min loss\" =  1162.9335\n",
      "2018-08-30 06:24:05.677118 Test Step 195 \"loss\" =  1162.9335\n",
      "2018-08-30 06:24:05.723881 Training Step 195 Finished Timing (Training: 0.912448, Test: 0.082381) after 0.250971 seconds\n",
      "2018-08-30 06:24:05.724023 Training Step 195 \"min loss\" =  1240.2952\n",
      "2018-08-30 06:24:05.724141 Training Step 195 \"loss\" =  1240.2952\n",
      "2018-08-30 06:24:05.929142 Test Step 200 Finished\n",
      "2018-08-30 06:24:05.929286 Test Step 200 \"min loss\" =  1151.0009\n",
      "2018-08-30 06:24:05.929361 Test Step 200 \"loss\" =  1151.0009\n",
      "2018-08-30 06:24:05.976990 Training Step 200 Finished Timing (Training: 0.912428, Test: 0.0823827) after 0.252777 seconds\n",
      "2018-08-30 06:24:05.977124 Training Step 200 \"min loss\" =  1198.6642\n",
      "2018-08-30 06:24:05.977201 Training Step 200 \"loss\" =  1198.6642\n",
      "2018-08-30 06:24:06.182628 Test Step 205 Finished\n",
      "2018-08-30 06:24:06.182716 Test Step 205 \"min loss\" =  1077.6746\n",
      "2018-08-30 06:24:06.182771 Test Step 205 \"loss\" =  1077.6746\n",
      "2018-08-30 06:24:06.229512 Training Step 205 Finished Timing (Training: 0.909339, Test: 0.0868458) after 0.252242 seconds\n",
      "2018-08-30 06:24:06.229578 Training Step 205 \"min loss\" =  1159.4978\n",
      "2018-08-30 06:24:06.229619 Training Step 205 \"loss\" =  1159.4978\n",
      "2018-08-30 06:24:06.433763 Test Step 210 Finished\n",
      "2018-08-30 06:24:06.433849 Test Step 210 \"min loss\" =  1034.4791\n",
      "2018-08-30 06:24:06.433906 Test Step 210 \"loss\" =  1034.4791\n",
      "2018-08-30 06:24:06.480414 Training Step 210 Finished Timing (Training: 0.911311, Test: 0.0846922) after 0.250726 seconds\n",
      "2018-08-30 06:24:06.480489 Training Step 210 \"min loss\" =  1119.366\n",
      "2018-08-30 06:24:06.480544 Training Step 210 \"loss\" =  1119.366\n",
      "2018-08-30 06:24:06.684355 Test Step 215 Finished\n",
      "2018-08-30 06:24:06.684439 Test Step 215 \"min loss\" =  994.22\n",
      "2018-08-30 06:24:06.684889 Test Step 215 \"loss\" =  994.22\n",
      "2018-08-30 06:24:06.731193 Training Step 215 Finished Timing (Training: 0.911704, Test: 0.0838614) after 0.250029 seconds\n",
      "2018-08-30 06:24:06.731361 Training Step 215 \"min loss\" =  1073.7167\n",
      "2018-08-30 06:24:06.731441 Training Step 215 \"loss\" =  1073.7167\n",
      "2018-08-30 06:24:06.936190 Test Step 220 Finished\n",
      "2018-08-30 06:24:06.936622 Test Step 220 \"min loss\" =  987.2436\n",
      "2018-08-30 06:24:06.936865 Test Step 220 \"loss\" =  987.2436\n",
      "2018-08-30 06:24:06.983110 Training Step 220 Finished Timing (Training: 0.91199, Test: 0.0833475) after 0.25159 seconds\n",
      "2018-08-30 06:24:06.983174 Training Step 220 \"min loss\" =  1035.4202\n",
      "2018-08-30 06:24:06.983521 Training Step 220 \"loss\" =  1035.4202\n",
      "2018-08-30 06:24:07.187228 Test Step 225 Finished\n",
      "2018-08-30 06:24:07.187308 Test Step 225 \"min loss\" =  924.4633\n",
      "2018-08-30 06:24:07.187378 Test Step 225 \"loss\" =  924.4633\n",
      "2018-08-30 06:24:07.234025 Training Step 225 Finished Timing (Training: 0.911785, Test: 0.0831297) after 0.250196 seconds\n",
      "2018-08-30 06:24:07.234084 Training Step 225 \"min loss\" =  997.0783\n",
      "2018-08-30 06:24:07.234416 Training Step 225 \"loss\" =  997.0783\n",
      "2018-08-30 06:24:07.438849 Test Step 230 Finished\n",
      "2018-08-30 06:24:07.439228 Test Step 230 \"min loss\" =  847.39136\n",
      "2018-08-30 06:24:07.439285 Test Step 230 \"loss\" =  847.39136\n",
      "2018-08-30 06:24:07.485536 Training Step 230 Finished Timing (Training: 0.911591, Test: 0.0831231) after 0.250772 seconds\n",
      "2018-08-30 06:24:07.485613 Training Step 230 \"min loss\" =  959.03107\n",
      "2018-08-30 06:24:07.485669 Training Step 230 \"loss\" =  959.03107\n",
      "2018-08-30 06:24:07.690155 Test Step 235 Finished\n",
      "2018-08-30 06:24:07.690244 Test Step 235 \"min loss\" =  847.39136\n",
      "2018-08-30 06:24:07.690681 Test Step 235 \"loss\" =  869.4535\n",
      "2018-08-30 06:24:07.736884 Training Step 235 Finished Timing (Training: 0.911603, Test: 0.0829608) after 0.250616 seconds\n",
      "2018-08-30 06:24:07.737064 Training Step 235 \"min loss\" =  919.464\n",
      "2018-08-30 06:24:07.737311 Training Step 235 \"loss\" =  919.464\n",
      "2018-08-30 06:24:07.941399 Test Step 240 Finished\n",
      "2018-08-30 06:24:07.941817 Test Step 240 \"min loss\" =  831.82446\n",
      "2018-08-30 06:24:07.941878 Test Step 240 \"loss\" =  831.82446\n",
      "2018-08-30 06:24:07.987923 Training Step 240 Finished Timing (Training: 0.911572, Test: 0.0828661) after 0.250303 seconds\n",
      "2018-08-30 06:24:07.987985 Training Step 240 \"min loss\" =  882.39325\n",
      "2018-08-30 06:24:07.988355 Training Step 240 \"loss\" =  882.39325\n",
      "2018-08-30 06:24:08.192162 Test Step 245 Finished\n",
      "2018-08-30 06:24:08.192491 Test Step 245 \"min loss\" =  760.17053\n",
      "2018-08-30 06:24:08.192727 Test Step 245 \"loss\" =  760.17053\n",
      "2018-08-30 06:24:08.238841 Training Step 245 Finished Timing (Training: 0.911542, Test: 0.082778) after 0.250145 seconds\n",
      "2018-08-30 06:24:08.238906 Training Step 245 \"min loss\" =  846.4141\n",
      "2018-08-30 06:24:08.239261 Training Step 245 \"loss\" =  846.4141\n",
      "2018-08-30 06:24:08.442488 Test Step 250 Finished\n",
      "2018-08-30 06:24:08.442572 Test Step 250 \"min loss\" =  739.233\n",
      "2018-08-30 06:24:08.443024 Test Step 250 \"loss\" =  739.233\n",
      "2018-08-30 06:24:08.489436 Training Step 250 Finished Timing (Training: 0.911546, Test: 0.0827054) after 0.249865 seconds\n",
      "2018-08-30 06:24:08.489513 Training Step 250 \"min loss\" =  810.1536\n",
      "2018-08-30 06:24:08.489567 Training Step 250 \"loss\" =  810.1536\n",
      "2018-08-30 06:24:08.693732 Test Step 255 Finished\n",
      "2018-08-30 06:24:08.693812 Test Step 255 \"min loss\" =  707.6317\n",
      "2018-08-30 06:24:08.694278 Test Step 255 \"loss\" =  707.6317\n",
      "2018-08-30 06:24:08.740374 Training Step 255 Finished Timing (Training: 0.911529, Test: 0.0826494) after 0.250182 seconds\n",
      "2018-08-30 06:24:08.740572 Training Step 255 \"min loss\" =  775.9666\n",
      "2018-08-30 06:24:08.740818 Training Step 255 \"loss\" =  775.9666\n",
      "2018-08-30 06:24:08.944825 Test Step 260 Finished\n",
      "2018-08-30 06:24:08.944948 Test Step 260 \"min loss\" =  663.53937\n",
      "2018-08-30 06:24:08.945456 Test Step 260 \"loss\" =  663.53937\n",
      "2018-08-30 06:24:08.991996 Training Step 260 Finished Timing (Training: 0.911511, Test: 0.0826593) after 0.250853 seconds\n",
      "2018-08-30 06:24:08.992286 Training Step 260 \"min loss\" =  739.3784\n",
      "2018-08-30 06:24:08.992515 Training Step 260 \"loss\" =  739.3784\n",
      "2018-08-30 06:24:09.197231 Test Step 265 Finished\n",
      "2018-08-30 06:24:09.197330 Test Step 265 \"min loss\" =  644.66565\n",
      "2018-08-30 06:24:09.197388 Test Step 265 \"loss\" =  644.66565\n",
      "2018-08-30 06:24:09.244157 Training Step 265 Finished Timing (Training: 0.911458, Test: 0.0826465) after 0.251329 seconds\n",
      "2018-08-30 06:24:09.244238 Training Step 265 \"min loss\" =  709.09827\n",
      "2018-08-30 06:24:09.244312 Training Step 265 \"loss\" =  709.09827\n",
      "2018-08-30 06:24:09.449137 Test Step 270 Finished\n",
      "2018-08-30 06:24:09.449238 Test Step 270 \"min loss\" =  585.9917\n",
      "2018-08-30 06:24:09.449301 Test Step 270 \"loss\" =  585.9917\n",
      "2018-08-30 06:24:09.495694 Training Step 270 Finished Timing (Training: 0.911411, Test: 0.0826483) after 0.250776 seconds\n",
      "2018-08-30 06:24:09.495992 Training Step 270 \"min loss\" =  675.09467\n",
      "2018-08-30 06:24:09.496055 Training Step 270 \"loss\" =  675.09467\n",
      "2018-08-30 06:24:09.700188 Test Step 275 Finished\n",
      "2018-08-30 06:24:09.700339 Test Step 275 \"min loss\" =  576.47644\n",
      "2018-08-30 06:24:09.700440 Test Step 275 \"loss\" =  576.47644\n",
      "2018-08-30 06:24:09.746878 Training Step 275 Finished Timing (Training: 0.911299, Test: 0.082707) after 0.250428 seconds\n",
      "2018-08-30 06:24:09.747155 Training Step 275 \"min loss\" =  645.44037\n",
      "2018-08-30 06:24:09.747215 Training Step 275 \"loss\" =  645.44037\n",
      "2018-08-30 06:24:09.951653 Test Step 280 Finished\n",
      "2018-08-30 06:24:09.951973 Test Step 280 \"min loss\" =  576.47644\n",
      "2018-08-30 06:24:09.952228 Test Step 280 \"loss\" =  577.386\n",
      "2018-08-30 06:24:09.998205 Training Step 280 Finished Timing (Training: 0.911292, Test: 0.0826687) after 0.25054 seconds\n",
      "2018-08-30 06:24:09.998466 Training Step 280 \"min loss\" =  612.9502\n",
      "2018-08-30 06:24:09.998661 Training Step 280 \"loss\" =  612.9502\n",
      "2018-08-30 06:24:10.203389 Test Step 285 Finished\n",
      "2018-08-30 06:24:10.203491 Test Step 285 \"min loss\" =  558.54755\n",
      "2018-08-30 06:24:10.203912 Test Step 285 \"loss\" =  558.54755\n",
      "2018-08-30 06:24:10.250049 Training Step 285 Finished Timing (Training: 0.911233, Test: 0.0827034) after 0.251077 seconds\n",
      "2018-08-30 06:24:10.250313 Training Step 285 \"min loss\" =  587.24286\n",
      "2018-08-30 06:24:10.250566 Training Step 285 \"loss\" =  587.24286\n",
      "2018-08-30 06:24:10.455122 Test Step 290 Finished\n",
      "2018-08-30 06:24:10.455270 Test Step 290 \"min loss\" =  551.44684\n",
      "2018-08-30 06:24:10.455323 Test Step 290 \"loss\" =  551.44684\n",
      "2018-08-30 06:24:10.501775 Training Step 290 Finished Timing (Training: 0.911211, Test: 0.0826974) after 0.250932 seconds\n",
      "2018-08-30 06:24:10.502162 Training Step 290 \"min loss\" =  555.4072\n",
      "2018-08-30 06:24:10.502227 Training Step 290 \"loss\" =  555.4072\n",
      "2018-08-30 06:24:10.708180 Test Step 295 Finished\n",
      "2018-08-30 06:24:10.708340 Test Step 295 \"min loss\" =  470.07187\n",
      "2018-08-30 06:24:10.708450 Test Step 295 \"loss\" =  470.07187\n",
      "2018-08-30 06:24:10.755008 Training Step 295 Finished Timing (Training: 0.911139, Test: 0.0826945) after 0.252341 seconds\n",
      "2018-08-30 06:24:10.755208 Training Step 295 \"min loss\" =  528.88055\n",
      "2018-08-30 06:24:10.755441 Training Step 295 \"loss\" =  528.88055\n",
      "2018-08-30 06:24:10.960193 Test Step 300 Finished\n",
      "2018-08-30 06:24:10.960275 Test Step 300 \"min loss\" =  467.16992\n",
      "2018-08-30 06:24:10.960723 Test Step 300 \"loss\" =  467.16992\n",
      "2018-08-30 06:24:11.006888 Training Step 300 Finished Timing (Training: 0.911101, Test: 0.0827236) after 0.251135 seconds\n",
      "2018-08-30 06:24:11.007121 Training Step 300 \"min loss\" =  499.5889\n",
      "2018-08-30 06:24:11.007366 Training Step 300 \"loss\" =  499.5889\n",
      "2018-08-30 06:24:11.212908 Test Step 305 Finished\n",
      "2018-08-30 06:24:11.213160 Test Step 305 \"min loss\" =  448.2723\n",
      "2018-08-30 06:24:11.213456 Test Step 305 \"loss\" =  448.2723\n",
      "2018-08-30 06:24:11.259540 Training Step 305 Finished Timing (Training: 0.913397, Test: 0.0830573) after 0.251847 seconds\n",
      "2018-08-30 06:24:11.259606 Training Step 305 \"min loss\" =  480.018\n",
      "2018-08-30 06:24:11.259974 Training Step 305 \"loss\" =  480.41666\n",
      "2018-08-30 06:24:11.464181 Test Step 310 Finished\n",
      "2018-08-30 06:24:11.464611 Test Step 310 \"min loss\" =  434.4665\n",
      "2018-08-30 06:24:11.464696 Test Step 310 \"loss\" =  434.4665\n",
      "2018-08-30 06:24:11.511068 Training Step 310 Finished Timing (Training: 0.912391, Test: 0.0830365) after 0.250735 seconds\n",
      "2018-08-30 06:24:11.511127 Training Step 310 \"min loss\" =  454.02032\n",
      "2018-08-30 06:24:11.511553 Training Step 310 \"loss\" =  454.02032\n",
      "2018-08-30 06:24:11.715747 Test Step 315 Finished\n",
      "2018-08-30 06:24:11.716027 Test Step 315 \"min loss\" =  408.17917\n",
      "2018-08-30 06:24:11.716085 Test Step 315 \"loss\" =  408.17917\n",
      "2018-08-30 06:24:11.762489 Training Step 315 Finished Timing (Training: 0.912854, Test: 0.082816) after 0.250867 seconds\n",
      "2018-08-30 06:24:11.762549 Training Step 315 \"min loss\" =  428.16367\n",
      "2018-08-30 06:24:11.762590 Training Step 315 \"loss\" =  428.16367\n",
      "2018-08-30 06:24:11.966631 Test Step 320 Finished\n",
      "2018-08-30 06:24:11.966821 Test Step 320 \"min loss\" =  400.44153\n",
      "2018-08-30 06:24:11.967420 Test Step 320 \"loss\" =  400.44153\n",
      "2018-08-30 06:24:12.013474 Training Step 320 Finished Timing (Training: 0.912987, Test: 0.082625) after 0.250791 seconds\n",
      "2018-08-30 06:24:12.013545 Training Step 320 \"min loss\" =  405.32782\n",
      "2018-08-30 06:24:12.013599 Training Step 320 \"loss\" =  405.32782\n",
      "2018-08-30 06:24:12.218411 Test Step 325 Finished\n",
      "2018-08-30 06:24:12.218749 Test Step 325 \"min loss\" =  379.91742\n",
      "2018-08-30 06:24:12.219260 Test Step 325 \"loss\" =  379.91742\n",
      "2018-08-30 06:24:12.265465 Training Step 325 Finished Timing (Training: 0.912321, Test: 0.0827683) after 0.251188 seconds\n",
      "2018-08-30 06:24:12.265532 Training Step 325 \"min loss\" =  383.60007\n",
      "2018-08-30 06:24:12.265764 Training Step 325 \"loss\" =  383.60007\n",
      "2018-08-30 06:24:12.469611 Test Step 330 Finished\n",
      "2018-08-30 06:24:12.469710 Test Step 330 \"min loss\" =  358.037\n",
      "2018-08-30 06:24:12.469774 Test Step 330 \"loss\" =  358.037\n",
      "2018-08-30 06:24:12.516338 Training Step 330 Finished Timing (Training: 0.912779, Test: 0.0827078) after 0.250504 seconds\n",
      "2018-08-30 06:24:12.516406 Training Step 330 \"min loss\" =  359.77692\n",
      "2018-08-30 06:24:12.517104 Training Step 330 \"loss\" =  359.77692\n",
      "2018-08-30 06:24:12.720956 Test Step 335 Finished\n",
      "2018-08-30 06:24:12.721071 Test Step 335 \"min loss\" =  337.72195\n",
      "2018-08-30 06:24:12.721134 Test Step 335 \"loss\" =  337.72195\n",
      "2018-08-30 06:24:12.767052 Training Step 335 Finished Timing (Training: 0.91282, Test: 0.0826777) after 0.249876 seconds\n",
      "2018-08-30 06:24:12.767125 Training Step 335 \"min loss\" =  339.5954\n",
      "2018-08-30 06:24:12.767725 Training Step 335 \"loss\" =  339.5954\n",
      "2018-08-30 06:24:12.972226 Test Step 340 Finished\n",
      "2018-08-30 06:24:12.972313 Test Step 340 \"min loss\" =  302.3409\n",
      "2018-08-30 06:24:12.972377 Test Step 340 \"loss\" =  302.3409\n",
      "2018-08-30 06:24:13.018345 Training Step 340 Finished Timing (Training: 0.912857, Test: 0.082695) after 0.250542 seconds\n",
      "2018-08-30 06:24:13.018416 Training Step 340 \"min loss\" =  321.734\n",
      "2018-08-30 06:24:13.018498 Training Step 340 \"loss\" =  321.8653\n",
      "2018-08-30 06:24:13.222804 Test Step 345 Finished\n",
      "2018-08-30 06:24:13.222924 Test Step 345 \"min loss\" =  298.4251\n",
      "2018-08-30 06:24:13.223404 Test Step 345 \"loss\" =  298.4251\n",
      "2018-08-30 06:24:13.269510 Training Step 345 Finished Timing (Training: 0.912864, Test: 0.0826614) after 0.250947 seconds\n",
      "2018-08-30 06:24:13.269590 Training Step 345 \"min loss\" =  302.40988\n",
      "2018-08-30 06:24:13.270147 Training Step 345 \"loss\" =  302.40988\n",
      "2018-08-30 06:24:13.475141 Test Step 350 Finished\n",
      "2018-08-30 06:24:13.475231 Test Step 350 \"min loss\" =  296.6098\n",
      "2018-08-30 06:24:13.475288 Test Step 350 \"loss\" =  296.6098\n",
      "2018-08-30 06:24:13.521286 Training Step 350 Finished Timing (Training: 0.912971, Test: 0.0826276) after 0.251049 seconds\n",
      "2018-08-30 06:24:13.521370 Training Step 350 \"min loss\" =  282.34537\n",
      "2018-08-30 06:24:13.521791 Training Step 350 \"loss\" =  282.34537\n",
      "2018-08-30 06:24:13.726363 Test Step 355 Finished\n",
      "2018-08-30 06:24:13.726488 Test Step 355 \"min loss\" =  285.97946\n",
      "2018-08-30 06:24:13.726578 Test Step 355 \"loss\" =  285.97946\n",
      "2018-08-30 06:24:13.772613 Training Step 355 Finished Timing (Training: 0.912968, Test: 0.0825877) after 0.250439 seconds\n",
      "2018-08-30 06:24:13.772915 Training Step 355 \"min loss\" =  268.25385\n",
      "2018-08-30 06:24:13.772976 Training Step 355 \"loss\" =  268.25385\n",
      "2018-08-30 06:24:13.977614 Test Step 360 Finished\n",
      "2018-08-30 06:24:13.977926 Test Step 360 \"min loss\" =  251.18137\n",
      "2018-08-30 06:24:13.978173 Test Step 360 \"loss\" =  251.18137\n",
      "2018-08-30 06:24:14.024449 Training Step 360 Finished Timing (Training: 0.912859, Test: 0.0826255) after 0.251416 seconds\n",
      "2018-08-30 06:24:14.024515 Training Step 360 \"min loss\" =  248.69849\n",
      "2018-08-30 06:24:14.024893 Training Step 360 \"loss\" =  248.69849\n",
      "2018-08-30 06:24:14.228873 Test Step 365 Finished\n",
      "2018-08-30 06:24:14.229176 Test Step 365 \"min loss\" =  237.30919\n",
      "2018-08-30 06:24:14.229255 Test Step 365 \"loss\" =  237.30919\n",
      "2018-08-30 06:24:14.275530 Training Step 365 Finished Timing (Training: 0.912738, Test: 0.0825819) after 0.250302 seconds\n",
      "2018-08-30 06:24:14.275712 Training Step 365 \"min loss\" =  232.70972\n",
      "2018-08-30 06:24:14.275976 Training Step 365 \"loss\" =  232.70972\n",
      "2018-08-30 06:24:14.480792 Test Step 370 Finished\n",
      "2018-08-30 06:24:14.481180 Test Step 370 \"min loss\" =  237.30919\n",
      "2018-08-30 06:24:14.481241 Test Step 370 \"loss\" =  249.97739\n",
      "2018-08-30 06:24:14.527824 Training Step 370 Finished Timing (Training: 0.912577, Test: 0.0826052) after 0.251497 seconds\n",
      "2018-08-30 06:24:14.527915 Training Step 370 \"min loss\" =  220.01689\n",
      "2018-08-30 06:24:14.527989 Training Step 370 \"loss\" =  220.01689\n",
      "2018-08-30 06:24:14.732745 Test Step 375 Finished\n",
      "2018-08-30 06:24:14.732830 Test Step 375 \"min loss\" =  214.34659\n",
      "2018-08-30 06:24:14.733435 Test Step 375 \"loss\" =  214.34659\n",
      "2018-08-30 06:24:14.779463 Training Step 375 Finished Timing (Training: 0.912433, Test: 0.0826106) after 0.250825 seconds\n",
      "2018-08-30 06:24:14.779526 Training Step 375 \"min loss\" =  203.43967\n",
      "2018-08-30 06:24:14.779868 Training Step 375 \"loss\" =  203.43967\n",
      "2018-08-30 06:24:14.984369 Test Step 380 Finished\n",
      "2018-08-30 06:24:14.984655 Test Step 380 \"min loss\" =  191.7918\n",
      "2018-08-30 06:24:14.984946 Test Step 380 \"loss\" =  191.7918\n",
      "2018-08-30 06:24:15.031209 Training Step 380 Finished Timing (Training: 0.912318, Test: 0.0825817) after 0.251012 seconds\n",
      "2018-08-30 06:24:15.031285 Training Step 380 \"min loss\" =  190.97787\n",
      "2018-08-30 06:24:15.031341 Training Step 380 \"loss\" =  190.97787\n",
      "2018-08-30 06:24:15.236240 Test Step 385 Finished\n",
      "2018-08-30 06:24:15.236526 Test Step 385 \"min loss\" =  186.71501\n",
      "2018-08-30 06:24:15.236810 Test Step 385 \"loss\" =  186.71501\n",
      "2018-08-30 06:24:15.283264 Training Step 385 Finished Timing (Training: 0.912271, Test: 0.0825452) after 0.251307 seconds\n",
      "2018-08-30 06:24:15.283407 Training Step 385 \"min loss\" =  180.26427\n",
      "2018-08-30 06:24:15.283462 Training Step 385 \"loss\" =  180.26427\n",
      "2018-08-30 06:24:15.488051 Test Step 390 Finished\n",
      "2018-08-30 06:24:15.488318 Test Step 390 \"min loss\" =  181.10678\n",
      "2018-08-30 06:24:15.488597 Test Step 390 \"loss\" =  181.10678\n",
      "2018-08-30 06:24:15.535037 Training Step 390 Finished Timing (Training: 0.91223, Test: 0.0824998) after 0.25095 seconds\n",
      "2018-08-30 06:24:15.535192 Training Step 390 \"min loss\" =  167.7391\n",
      "2018-08-30 06:24:15.535298 Training Step 390 \"loss\" =  167.7391\n",
      "2018-08-30 06:24:15.739775 Test Step 395 Finished\n",
      "2018-08-30 06:24:15.740050 Test Step 395 \"min loss\" =  179.24095\n",
      "2018-08-30 06:24:15.740329 Test Step 395 \"loss\" =  179.24095\n",
      "2018-08-30 06:24:15.786576 Training Step 395 Finished Timing (Training: 0.912169, Test: 0.0824631) after 0.250639 seconds\n",
      "2018-08-30 06:24:15.786652 Training Step 395 \"min loss\" =  155.23688\n",
      "2018-08-30 06:24:15.786708 Training Step 395 \"loss\" =  155.23688\n",
      "2018-08-30 06:24:15.991746 Test Step 400 Finished\n",
      "2018-08-30 06:24:15.992012 Test Step 400 \"min loss\" =  179.24095\n",
      "2018-08-30 06:24:15.992319 Test Step 400 \"loss\" =  183.55061\n",
      "2018-08-30 06:24:16.038948 Training Step 400 Finished Timing (Training: 0.912013, Test: 0.0825473) after 0.251595 seconds\n",
      "2018-08-30 06:24:16.039024 Training Step 400 \"min loss\" =  146.29663\n",
      "2018-08-30 06:24:16.039079 Training Step 400 \"loss\" =  146.29663\n",
      "2018-08-30 06:24:16.244709 Test Step 405 Finished\n",
      "2018-08-30 06:24:16.244786 Test Step 405 \"min loss\" =  165.77344\n",
      "2018-08-30 06:24:16.244839 Test Step 405 \"loss\" =  165.77344\n",
      "2018-08-30 06:24:16.291554 Training Step 405 Finished Timing (Training: 0.915432, Test: 0.0837275) after 0.251866 seconds\n",
      "2018-08-30 06:24:16.291623 Training Step 405 \"min loss\" =  134.0197\n",
      "2018-08-30 06:24:16.292101 Training Step 405 \"loss\" =  134.0197\n",
      "2018-08-30 06:24:16.496440 Test Step 410 Finished\n",
      "2018-08-30 06:24:16.496527 Test Step 410 \"min loss\" =  139.5357\n",
      "2018-08-30 06:24:16.496586 Test Step 410 \"loss\" =  139.5357\n",
      "2018-08-30 06:24:16.542498 Training Step 410 Finished Timing (Training: 0.914478, Test: 0.0834147) after 0.250329 seconds\n",
      "2018-08-30 06:24:16.542571 Training Step 410 \"min loss\" =  125.797295\n",
      "2018-08-30 06:24:16.542630 Training Step 410 \"loss\" =  125.797295\n",
      "2018-08-30 06:24:16.747036 Test Step 415 Finished\n",
      "2018-08-30 06:24:16.747117 Test Step 415 \"min loss\" =  135.79898\n",
      "2018-08-30 06:24:16.747592 Test Step 415 \"loss\" =  135.79898\n",
      "2018-08-30 06:24:16.793824 Training Step 415 Finished Timing (Training: 0.913979, Test: 0.0831783) after 0.25113 seconds\n",
      "2018-08-30 06:24:16.794025 Training Step 415 \"min loss\" =  118.93359\n",
      "2018-08-30 06:24:16.794272 Training Step 415 \"loss\" =  119.56897\n",
      "2018-08-30 06:24:16.998911 Test Step 420 Finished\n",
      "2018-08-30 06:24:16.999209 Test Step 420 \"min loss\" =  131.06516\n",
      "2018-08-30 06:24:16.999515 Test Step 420 \"loss\" =  131.06516\n",
      "2018-08-30 06:24:17.045523 Training Step 420 Finished Timing (Training: 0.91313, Test: 0.0830397) after 0.250926 seconds\n",
      "2018-08-30 06:24:17.045601 Training Step 420 \"min loss\" =  109.471756\n",
      "2018-08-30 06:24:17.045978 Training Step 420 \"loss\" =  109.471756\n",
      "2018-08-30 06:24:17.250224 Test Step 425 Finished\n",
      "2018-08-30 06:24:17.250312 Test Step 425 \"min loss\" =  131.06516\n",
      "2018-08-30 06:24:17.250775 Test Step 425 \"loss\" =  135.228\n",
      "2018-08-30 06:24:17.296958 Training Step 425 Finished Timing (Training: 0.912632, Test: 0.0829645) after 0.25065 seconds\n",
      "2018-08-30 06:24:17.297027 Training Step 425 \"min loss\" =  104.55517\n",
      "2018-08-30 06:24:17.297414 Training Step 425 \"loss\" =  104.55517\n",
      "2018-08-30 06:24:17.503233 Test Step 430 Finished\n",
      "2018-08-30 06:24:17.503525 Test Step 430 \"min loss\" =  130.4116\n",
      "2018-08-30 06:24:17.503842 Test Step 430 \"loss\" =  130.4116\n",
      "2018-08-30 06:24:17.550129 Training Step 430 Finished Timing (Training: 0.91236, Test: 0.0828255) after 0.252398 seconds\n",
      "2018-08-30 06:24:17.550404 Training Step 430 \"min loss\" =  93.58064\n",
      "2018-08-30 06:24:17.550595 Training Step 430 \"loss\" =  93.58064\n",
      "2018-08-30 06:24:17.754717 Test Step 435 Finished\n",
      "2018-08-30 06:24:17.755002 Test Step 435 \"min loss\" =  107.293335\n",
      "2018-08-30 06:24:17.755299 Test Step 435 \"loss\" =  107.293335\n",
      "2018-08-30 06:24:17.801584 Training Step 435 Finished Timing (Training: 0.912068, Test: 0.0828242) after 0.250652 seconds\n",
      "2018-08-30 06:24:17.801958 Training Step 435 \"min loss\" =  89.37108\n",
      "2018-08-30 06:24:17.802020 Training Step 435 \"loss\" =  89.37108\n",
      "2018-08-30 06:24:18.006526 Test Step 440 Finished\n",
      "2018-08-30 06:24:18.006624 Test Step 440 \"min loss\" =  107.293335\n",
      "2018-08-30 06:24:18.007159 Test Step 440 \"loss\" =  117.535484\n",
      "2018-08-30 06:24:18.053268 Training Step 440 Finished Timing (Training: 0.911832, Test: 0.0827476) after 0.250858 seconds\n",
      "2018-08-30 06:24:18.053493 Training Step 440 \"min loss\" =  83.46487\n",
      "2018-08-30 06:24:18.053725 Training Step 440 \"loss\" =  83.46487\n",
      "2018-08-30 06:24:18.265812 Test Step 445 Finished\n",
      "2018-08-30 06:24:18.266162 Test Step 445 \"min loss\" =  107.293335\n",
      "2018-08-30 06:24:18.266370 Test Step 445 \"loss\" =  107.80487\n",
      "2018-08-30 06:24:18.312660 Training Step 445 Finished Timing (Training: 0.912064, Test: 0.0823998) after 0.258625 seconds\n",
      "2018-08-30 06:24:18.312941 Training Step 445 \"min loss\" =  76.85496\n",
      "2018-08-30 06:24:18.313205 Training Step 445 \"loss\" =  76.85496\n",
      "2018-08-30 06:24:18.525213 Test Step 450 Finished\n",
      "2018-08-30 06:24:18.525305 Test Step 450 \"min loss\" =  98.549194\n",
      "2018-08-30 06:24:18.525772 Test Step 450 \"loss\" =  98.549194\n",
      "2018-08-30 06:24:18.571784 Training Step 450 Finished Timing (Training: 0.908898, Test: 0.0853708) after 0.258178 seconds\n",
      "2018-08-30 06:24:18.571860 Training Step 450 \"min loss\" =  72.39919\n",
      "2018-08-30 06:24:18.571916 Training Step 450 \"loss\" =  73.27097\n",
      "2018-08-30 06:24:18.776554 Test Step 455 Finished\n",
      "2018-08-30 06:24:18.776978 Test Step 455 \"min loss\" =  92.3169\n",
      "2018-08-30 06:24:18.777113 Test Step 455 \"loss\" =  92.3169\n",
      "2018-08-30 06:24:18.823533 Training Step 455 Finished Timing (Training: 0.909194, Test: 0.085064) after 0.251011 seconds\n",
      "2018-08-30 06:24:18.823736 Training Step 455 \"min loss\" =  68.820305\n",
      "2018-08-30 06:24:18.823984 Training Step 455 \"loss\" =  69.21519\n",
      "2018-08-30 06:24:19.028310 Test Step 460 Finished\n",
      "2018-08-30 06:24:19.028581 Test Step 460 \"min loss\" =  82.47249\n",
      "2018-08-30 06:24:19.028946 Test Step 460 \"loss\" =  82.47249\n",
      "2018-08-30 06:24:19.075174 Training Step 460 Finished Timing (Training: 0.909348, Test: 0.084877) after 0.250867 seconds\n",
      "2018-08-30 06:24:19.075238 Training Step 460 \"min loss\" =  65.02468\n",
      "2018-08-30 06:24:19.075583 Training Step 460 \"loss\" =  66.13021\n",
      "2018-08-30 06:24:19.279868 Test Step 465 Finished\n",
      "2018-08-30 06:24:19.280162 Test Step 465 \"min loss\" =  79.476295\n",
      "2018-08-30 06:24:19.280468 Test Step 465 \"loss\" =  79.476295\n",
      "2018-08-30 06:24:19.326614 Training Step 465 Finished Timing (Training: 0.909474, Test: 0.0846921) after 0.250719 seconds\n",
      "2018-08-30 06:24:19.326679 Training Step 465 \"min loss\" =  59.803844\n",
      "2018-08-30 06:24:19.327057 Training Step 465 \"loss\" =  61.399105\n",
      "2018-08-30 06:24:19.531351 Test Step 470 Finished\n",
      "2018-08-30 06:24:19.531710 Test Step 470 \"min loss\" =  75.03223\n",
      "2018-08-30 06:24:19.531837 Test Step 470 \"loss\" =  75.03223\n",
      "2018-08-30 06:24:19.578662 Training Step 470 Finished Timing (Training: 0.909629, Test: 0.0845611) after 0.251288 seconds\n",
      "2018-08-30 06:24:19.578727 Training Step 470 \"min loss\" =  55.36621\n",
      "2018-08-30 06:24:19.579092 Training Step 470 \"loss\" =  56.6238\n",
      "2018-08-30 06:24:19.783298 Test Step 475 Finished\n",
      "2018-08-30 06:24:19.783385 Test Step 475 \"min loss\" =  75.03223\n",
      "2018-08-30 06:24:19.783859 Test Step 475 \"loss\" =  78.71749\n",
      "2018-08-30 06:24:19.829983 Training Step 475 Finished Timing (Training: 0.909736, Test: 0.0844025) after 0.250575 seconds\n",
      "2018-08-30 06:24:19.830194 Training Step 475 \"min loss\" =  50.431976\n",
      "2018-08-30 06:24:19.830601 Training Step 475 \"loss\" =  50.431976\n",
      "2018-08-30 06:24:20.034757 Test Step 480 Finished\n",
      "2018-08-30 06:24:20.035089 Test Step 480 \"min loss\" =  65.92155\n",
      "2018-08-30 06:24:20.035327 Test Step 480 \"loss\" =  65.92155\n",
      "2018-08-30 06:24:20.081519 Training Step 480 Finished Timing (Training: 0.909802, Test: 0.0842468) after 0.250595 seconds\n",
      "2018-08-30 06:24:20.081585 Training Step 480 \"min loss\" =  47.29136\n",
      "2018-08-30 06:24:20.081640 Training Step 480 \"loss\" =  47.642567\n",
      "2018-08-30 06:24:20.286495 Test Step 485 Finished\n",
      "2018-08-30 06:24:20.286887 Test Step 485 \"min loss\" =  65.92155\n",
      "2018-08-30 06:24:20.287082 Test Step 485 \"loss\" =  66.48708\n",
      "2018-08-30 06:24:20.333685 Training Step 485 Finished Timing (Training: 0.909857, Test: 0.0841606) after 0.251444 seconds\n",
      "2018-08-30 06:24:20.333746 Training Step 485 \"min loss\" =  42.623787\n",
      "2018-08-30 06:24:20.334109 Training Step 485 \"loss\" =  42.623787\n",
      "2018-08-30 06:24:20.538235 Test Step 490 Finished\n",
      "2018-08-30 06:24:20.538700 Test Step 490 \"min loss\" =  63.347073\n",
      "2018-08-30 06:24:20.538938 Test Step 490 \"loss\" =  63.347073\n",
      "2018-08-30 06:24:20.585113 Training Step 490 Finished Timing (Training: 0.909941, Test: 0.0840355) after 0.250689 seconds\n",
      "2018-08-30 06:24:20.585185 Training Step 490 \"min loss\" =  40.747936\n",
      "2018-08-30 06:24:20.585557 Training Step 490 \"loss\" =  40.747936\n",
      "2018-08-30 06:24:20.789566 Test Step 495 Finished\n",
      "2018-08-30 06:24:20.789652 Test Step 495 \"min loss\" =  60.52748\n",
      "2018-08-30 06:24:20.789710 Test Step 495 \"loss\" =  60.52748\n",
      "2018-08-30 06:24:20.836596 Training Step 495 Finished Timing (Training: 0.910008, Test: 0.0839513) after 0.250728 seconds\n",
      "2018-08-30 06:24:20.836865 Training Step 495 \"min loss\" =  38.83631\n",
      "2018-08-30 06:24:20.837060 Training Step 495 \"loss\" =  39.905994\n",
      "2018-08-30 06:24:21.041487 Test Step 500 Finished\n",
      "2018-08-30 06:24:21.041581 Test Step 500 \"min loss\" =  50.862488\n",
      "2018-08-30 06:24:21.041662 Test Step 500 \"loss\" =  50.862488\n",
      "2018-08-30 06:24:21.088261 Training Step 500 Finished Timing (Training: 0.910061, Test: 0.0838712) after 0.250857 seconds\n",
      "2018-08-30 06:24:21.088351 Training Step 500 \"min loss\" =  35.301308\n",
      "2018-08-30 06:24:21.088808 Training Step 500 \"loss\" =  35.301308\n",
      "2018-08-30 06:24:21.293157 Test Step 505 Finished\n",
      "2018-08-30 06:24:21.293269 Test Step 505 \"min loss\" =  50.862488\n",
      "2018-08-30 06:24:21.293715 Test Step 505 \"loss\" =  53.46543\n",
      "2018-08-30 06:24:21.339770 Training Step 505 Finished Timing (Training: 0.913874, Test: 0.0825444) after 0.250728 seconds\n",
      "2018-08-30 06:24:21.339847 Training Step 505 \"min loss\" =  34.70085\n",
      "2018-08-30 06:24:21.339904 Training Step 505 \"loss\" =  35.91115\n",
      "2018-08-30 06:24:21.544028 Test Step 510 Finished\n",
      "2018-08-30 06:24:21.544142 Test Step 510 \"min loss\" =  50.862488\n",
      "2018-08-30 06:24:21.544203 Test Step 510 \"loss\" =  54.3505\n",
      "2018-08-30 06:24:21.590961 Training Step 510 Finished Timing (Training: 0.913802, Test: 0.082362) after 0.250435 seconds\n",
      "2018-08-30 06:24:21.591022 Training Step 510 \"min loss\" =  32.928707\n",
      "2018-08-30 06:24:21.591421 Training Step 510 \"loss\" =  32.928707\n",
      "2018-08-30 06:24:21.795816 Test Step 515 Finished\n",
      "2018-08-30 06:24:21.795895 Test Step 515 \"min loss\" =  45.033382\n",
      "2018-08-30 06:24:21.795948 Test Step 515 \"loss\" =  45.033382\n",
      "2018-08-30 06:24:21.842594 Training Step 515 Finished Timing (Training: 0.913601, Test: 0.0828486) after 0.251105 seconds\n",
      "2018-08-30 06:24:21.842658 Training Step 515 \"min loss\" =  31.311655\n",
      "2018-08-30 06:24:21.842697 Training Step 515 \"loss\" =  32.66239\n",
      "2018-08-30 06:24:22.048345 Test Step 520 Finished\n",
      "2018-08-30 06:24:22.048419 Test Step 520 \"min loss\" =  41.975906\n",
      "2018-08-30 06:24:22.048479 Test Step 520 \"loss\" =  41.975906\n",
      "2018-08-30 06:24:22.094833 Training Step 520 Finished Timing (Training: 0.91392, Test: 0.0830239) after 0.252064 seconds\n",
      "2018-08-30 06:24:22.094899 Training Step 520 \"min loss\" =  28.95095\n",
      "2018-08-30 06:24:22.094940 Training Step 520 \"loss\" =  28.95095\n",
      "2018-08-30 06:24:22.299328 Test Step 525 Finished\n",
      "2018-08-30 06:24:22.299447 Test Step 525 \"min loss\" =  40.298885\n",
      "2018-08-30 06:24:22.299555 Test Step 525 \"loss\" =  40.298885\n",
      "2018-08-30 06:24:22.345763 Training Step 525 Finished Timing (Training: 0.914305, Test: 0.082873) after 0.250768 seconds\n",
      "2018-08-30 06:24:22.345828 Training Step 525 \"min loss\" =  27.21822\n",
      "2018-08-30 06:24:22.345867 Training Step 525 \"loss\" =  27.687824\n",
      "2018-08-30 06:24:22.550923 Test Step 530 Finished\n",
      "2018-08-30 06:24:22.550999 Test Step 530 \"min loss\" =  35.588905\n",
      "2018-08-30 06:24:22.551545 Test Step 530 \"loss\" =  35.588905\n",
      "2018-08-30 06:24:22.597638 Training Step 530 Finished Timing (Training: 0.913941, Test: 0.0826688) after 0.251023 seconds\n",
      "2018-08-30 06:24:22.597697 Training Step 530 \"min loss\" =  25.627348\n",
      "2018-08-30 06:24:22.598212 Training Step 530 \"loss\" =  26.090155\n",
      "2018-08-30 06:24:22.802473 Test Step 535 Finished\n",
      "2018-08-30 06:24:22.802556 Test Step 535 \"min loss\" =  35.26998\n",
      "2018-08-30 06:24:22.803157 Test Step 535 \"loss\" =  35.26998\n",
      "2018-08-30 06:24:22.849212 Training Step 535 Finished Timing (Training: 0.913572, Test: 0.0827191) after 0.250932 seconds\n",
      "2018-08-30 06:24:22.849284 Training Step 535 \"min loss\" =  24.93626\n",
      "2018-08-30 06:24:22.849704 Training Step 535 \"loss\" =  24.93626\n",
      "2018-08-30 06:24:23.053867 Test Step 540 Finished\n",
      "2018-08-30 06:24:23.054192 Test Step 540 \"min loss\" =  35.26998\n",
      "2018-08-30 06:24:23.054387 Test Step 540 \"loss\" =  38.80629\n",
      "2018-08-30 06:24:23.100466 Training Step 540 Finished Timing (Training: 0.913318, Test: 0.0826538) after 0.250525 seconds\n",
      "2018-08-30 06:24:23.100532 Training Step 540 \"min loss\" =  24.063879\n",
      "2018-08-30 06:24:23.100891 Training Step 540 \"loss\" =  24.654922\n",
      "2018-08-30 06:24:23.306375 Test Step 545 Finished\n",
      "2018-08-30 06:24:23.306637 Test Step 545 \"min loss\" =  35.26998\n",
      "2018-08-30 06:24:23.306951 Test Step 545 \"loss\" =  35.393192\n",
      "2018-08-30 06:24:23.353620 Training Step 545 Finished Timing (Training: 0.91293, Test: 0.0827496) after 0.252412 seconds\n",
      "2018-08-30 06:24:23.353819 Training Step 545 \"min loss\" =  22.836823\n",
      "2018-08-30 06:24:23.354065 Training Step 545 \"loss\" =  23.723017\n",
      "2018-08-30 06:24:23.558365 Test Step 550 Finished\n",
      "2018-08-30 06:24:23.558592 Test Step 550 \"min loss\" =  34.643917\n",
      "2018-08-30 06:24:23.558873 Test Step 550 \"loss\" =  34.643917\n",
      "2018-08-30 06:24:23.605140 Training Step 550 Finished Timing (Training: 0.912831, Test: 0.0826419) after 0.250751 seconds\n",
      "2018-08-30 06:24:23.605380 Training Step 550 \"min loss\" =  21.461353\n",
      "2018-08-30 06:24:23.605621 Training Step 550 \"loss\" =  22.710632\n",
      "2018-08-30 06:24:23.809638 Test Step 555 Finished\n",
      "2018-08-30 06:24:23.809992 Test Step 555 \"min loss\" =  31.368298\n",
      "2018-08-30 06:24:23.810199 Test Step 555 \"loss\" =  31.368298\n",
      "2018-08-30 06:24:23.856553 Training Step 555 Finished Timing (Training: 0.912702, Test: 0.0825511) after 0.250568 seconds\n",
      "2018-08-30 06:24:23.856630 Training Step 555 \"min loss\" =  19.5814\n",
      "2018-08-30 06:24:23.856692 Training Step 555 \"loss\" =  19.5814\n",
      "2018-08-30 06:24:24.060705 Test Step 560 Finished\n",
      "2018-08-30 06:24:24.060992 Test Step 560 \"min loss\" =  29.451155\n",
      "2018-08-30 06:24:24.061312 Test Step 560 \"loss\" =  29.451155\n",
      "2018-08-30 06:24:24.107457 Training Step 560 Finished Timing (Training: 0.912707, Test: 0.0825502) after 0.2507 seconds\n",
      "2018-08-30 06:24:24.107517 Training Step 560 \"min loss\" =  19.5814\n",
      "2018-08-30 06:24:24.107566 Training Step 560 \"loss\" =  20.74368\n",
      "2018-08-30 06:24:24.311979 Test Step 565 Finished\n",
      "2018-08-30 06:24:24.312068 Test Step 565 \"min loss\" =  29.451155\n",
      "2018-08-30 06:24:24.312506 Test Step 565 \"loss\" =  34.441254\n",
      "2018-08-30 06:24:24.358879 Training Step 565 Finished Timing (Training: 0.912598, Test: 0.082542) after 0.250707 seconds\n",
      "2018-08-30 06:24:24.358935 Training Step 565 \"min loss\" =  19.5814\n",
      "2018-08-30 06:24:24.358984 Training Step 565 \"loss\" =  20.726175\n",
      "2018-08-30 06:24:24.564554 Test Step 570 Finished\n",
      "2018-08-30 06:24:24.564676 Test Step 570 \"min loss\" =  29.451155\n",
      "2018-08-30 06:24:24.565178 Test Step 570 \"loss\" =  33.090813\n",
      "2018-08-30 06:24:24.611263 Training Step 570 Finished Timing (Training: 0.912451, Test: 0.0826988) after 0.25222 seconds\n",
      "2018-08-30 06:24:24.611337 Training Step 570 \"min loss\" =  19.475395\n",
      "2018-08-30 06:24:24.611689 Training Step 570 \"loss\" =  19.94259\n",
      "2018-08-30 06:24:24.823620 Test Step 575 Finished\n",
      "2018-08-30 06:24:24.823914 Test Step 575 \"min loss\" =  29.451155\n",
      "2018-08-30 06:24:24.824191 Test Step 575 \"loss\" =  31.821629\n",
      "2018-08-30 06:24:24.870460 Training Step 575 Finished Timing (Training: 0.912531, Test: 0.0825167) after 0.258461 seconds\n",
      "2018-08-30 06:24:24.870535 Training Step 575 \"min loss\" =  18.150726\n",
      "2018-08-30 06:24:24.870591 Training Step 575 \"loss\" =  19.163141\n",
      "2018-08-30 06:24:25.075419 Test Step 580 Finished\n",
      "2018-08-30 06:24:25.075548 Test Step 580 \"min loss\" =  28.746834\n",
      "2018-08-30 06:24:25.075625 Test Step 580 \"loss\" =  28.746834\n",
      "2018-08-30 06:24:25.121338 Training Step 580 Finished Timing (Training: 0.912628, Test: 0.0824934) after 0.250228 seconds\n",
      "2018-08-30 06:24:25.121404 Training Step 580 \"min loss\" =  17.939154\n",
      "2018-08-30 06:24:25.121452 Training Step 580 \"loss\" =  19.56044\n",
      "2018-08-30 06:24:25.324724 Test Step 585 Finished\n",
      "2018-08-30 06:24:25.325127 Test Step 585 \"min loss\" =  24.50587\n",
      "2018-08-30 06:24:25.325387 Test Step 585 \"loss\" =  24.50587\n",
      "2018-08-30 06:24:25.371618 Training Step 585 Finished Timing (Training: 0.91269, Test: 0.0824929) after 0.250063 seconds\n",
      "2018-08-30 06:24:25.371679 Training Step 585 \"min loss\" =  16.982458\n",
      "2018-08-30 06:24:25.372465 Training Step 585 \"loss\" =  19.6669\n",
      "2018-08-30 06:24:25.576339 Test Step 590 Finished\n",
      "2018-08-30 06:24:25.576837 Test Step 590 \"min loss\" =  21.9046\n",
      "2018-08-30 06:24:25.576902 Test Step 590 \"loss\" =  21.9046\n",
      "2018-08-30 06:24:25.623175 Training Step 590 Finished Timing (Training: 0.912544, Test: 0.0825254) after 0.250485 seconds\n",
      "2018-08-30 06:24:25.623251 Training Step 590 \"min loss\" =  16.34824\n",
      "2018-08-30 06:24:25.623310 Training Step 590 \"loss\" =  16.34824\n",
      "2018-08-30 06:24:25.827829 Test Step 595 Finished\n",
      "2018-08-30 06:24:25.828233 Test Step 595 \"min loss\" =  21.574575\n",
      "2018-08-30 06:24:25.828303 Test Step 595 \"loss\" =  21.574575\n",
      "2018-08-30 06:24:25.874533 Training Step 595 Finished Timing (Training: 0.912676, Test: 0.0824935) after 0.251159 seconds\n",
      "2018-08-30 06:24:25.874603 Training Step 595 \"min loss\" =  16.34824\n",
      "2018-08-30 06:24:25.874661 Training Step 595 \"loss\" =  18.841536\n",
      "2018-08-30 06:24:26.079502 Test Step 600 Finished\n",
      "2018-08-30 06:24:26.079678 Test Step 600 \"min loss\" =  21.574575\n",
      "2018-08-30 06:24:26.079741 Test Step 600 \"loss\" =  21.70305\n",
      "2018-08-30 06:24:26.126428 Training Step 600 Finished Timing (Training: 0.912747, Test: 0.0825599) after 0.251703 seconds\n",
      "2018-08-30 06:24:26.126496 Training Step 600 \"min loss\" =  15.710667\n",
      "2018-08-30 06:24:26.126556 Training Step 600 \"loss\" =  17.290718\n",
      "2018-08-30 06:24:26.330907 Test Step 605 Finished\n",
      "2018-08-30 06:24:26.331037 Test Step 605 \"min loss\" =  21.44005\n",
      "2018-08-30 06:24:26.331096 Test Step 605 \"loss\" =  21.44005\n",
      "2018-08-30 06:24:26.376936 Training Step 605 Finished Timing (Training: 0.915796, Test: 0.0830982) after 0.250316 seconds\n",
      "2018-08-30 06:24:26.377012 Training Step 605 \"min loss\" =  15.710667\n",
      "2018-08-30 06:24:26.377092 Training Step 605 \"loss\" =  16.488829\n",
      "2018-08-30 06:24:26.582050 Test Step 610 Finished\n",
      "2018-08-30 06:24:26.582151 Test Step 610 \"min loss\" =  21.242104\n",
      "2018-08-30 06:24:26.582227 Test Step 610 \"loss\" =  21.242104\n",
      "2018-08-30 06:24:26.628858 Training Step 610 Finished Timing (Training: 0.915926, Test: 0.0825578) after 0.251694 seconds\n",
      "2018-08-30 06:24:26.629021 Training Step 610 \"min loss\" =  15.527054\n",
      "2018-08-30 06:24:26.629469 Training Step 610 \"loss\" =  15.527054\n",
      "2018-08-30 06:24:26.833534 Test Step 615 Finished\n",
      "2018-08-30 06:24:26.833618 Test Step 615 \"min loss\" =  18.64206\n",
      "2018-08-30 06:24:26.834091 Test Step 615 \"loss\" =  18.64206\n",
      "2018-08-30 06:24:26.880352 Training Step 615 Finished Timing (Training: 0.914426, Test: 0.0824756) after 0.250817 seconds\n",
      "2018-08-30 06:24:26.880421 Training Step 615 \"min loss\" =  15.41078\n",
      "2018-08-30 06:24:26.880810 Training Step 615 \"loss\" =  15.412675\n",
      "2018-08-30 06:24:27.085048 Test Step 620 Finished\n",
      "2018-08-30 06:24:27.085163 Test Step 620 \"min loss\" =  18.64206\n",
      "2018-08-30 06:24:27.085767 Test Step 620 \"loss\" =  19.417206\n",
      "2018-08-30 06:24:27.132263 Training Step 620 Finished Timing (Training: 0.913005, Test: 0.0824772) after 0.251141 seconds\n",
      "2018-08-30 06:24:27.132627 Training Step 620 \"min loss\" =  13.630226\n",
      "2018-08-30 06:24:27.132976 Training Step 620 \"loss\" =  15.898038\n",
      "2018-08-30 06:24:27.337553 Test Step 625 Finished\n",
      "2018-08-30 06:24:27.337674 Test Step 625 \"min loss\" =  18.64206\n",
      "2018-08-30 06:24:27.338539 Test Step 625 \"loss\" =  19.37111\n",
      "2018-08-30 06:24:27.384678 Training Step 625 Finished Timing (Training: 0.911882, Test: 0.0823922) after 0.251103 seconds\n",
      "2018-08-30 06:24:27.385027 Training Step 625 \"min loss\" =  13.630226\n",
      "2018-08-30 06:24:27.385494 Training Step 625 \"loss\" =  14.811497\n",
      "2018-08-30 06:24:27.589307 Test Step 630 Finished\n",
      "2018-08-30 06:24:27.589817 Test Step 630 \"min loss\" =  17.483894\n",
      "2018-08-30 06:24:27.590348 Test Step 630 \"loss\" =  17.483894\n",
      "2018-08-30 06:24:27.636482 Training Step 630 Finished Timing (Training: 0.911316, Test: 0.0823306) after 0.250882 seconds\n",
      "2018-08-30 06:24:27.636541 Training Step 630 \"min loss\" =  13.630226\n",
      "2018-08-30 06:24:27.636580 Training Step 630 \"loss\" =  14.283084\n",
      "2018-08-30 06:24:27.841053 Test Step 635 Finished\n",
      "2018-08-30 06:24:27.841156 Test Step 635 \"min loss\" =  16.806648\n",
      "2018-08-30 06:24:27.841808 Test Step 635 \"loss\" =  16.806648\n",
      "2018-08-30 06:24:27.887999 Training Step 635 Finished Timing (Training: 0.911708, Test: 0.082272) after 0.25135 seconds\n",
      "2018-08-30 06:24:27.888058 Training Step 635 \"min loss\" =  13.630226\n",
      "2018-08-30 06:24:27.888558 Training Step 635 \"loss\" =  14.869188\n",
      "2018-08-30 06:24:28.092670 Test Step 640 Finished\n",
      "2018-08-30 06:24:28.093096 Test Step 640 \"min loss\" =  16.806648\n",
      "2018-08-30 06:24:28.093158 Test Step 640 \"loss\" =  17.922\n",
      "2018-08-30 06:24:28.138976 Training Step 640 Finished Timing (Training: 0.911864, Test: 0.0822728) after 0.250351 seconds\n",
      "2018-08-30 06:24:28.139042 Training Step 640 \"min loss\" =  13.630226\n",
      "2018-08-30 06:24:28.139590 Training Step 640 \"loss\" =  14.724405\n",
      "2018-08-30 06:24:28.343396 Test Step 645 Finished\n",
      "2018-08-30 06:24:28.343737 Test Step 645 \"min loss\" =  16.806648\n",
      "2018-08-30 06:24:28.343797 Test Step 645 \"loss\" =  20.564623\n",
      "2018-08-30 06:24:28.390194 Training Step 645 Finished Timing (Training: 0.911989, Test: 0.0822135) after 0.250377 seconds\n",
      "2018-08-30 06:24:28.390521 Training Step 645 \"min loss\" =  13.630226\n",
      "2018-08-30 06:24:28.390745 Training Step 645 \"loss\" =  14.325665\n",
      "2018-08-30 06:24:28.594489 Test Step 650 Finished\n",
      "2018-08-30 06:24:28.594906 Test Step 650 \"min loss\" =  16.806648\n",
      "2018-08-30 06:24:28.594975 Test Step 650 \"loss\" =  18.244413\n",
      "2018-08-30 06:24:28.641174 Training Step 650 Finished Timing (Training: 0.91212, Test: 0.0821873) after 0.250361 seconds\n",
      "2018-08-30 06:24:28.641537 Training Step 650 \"min loss\" =  12.979209\n",
      "2018-08-30 06:24:28.641622 Training Step 650 \"loss\" =  12.979209\n",
      "2018-08-30 06:24:28.846161 Test Step 655 Finished\n",
      "2018-08-30 06:24:28.846454 Test Step 655 \"min loss\" =  16.806648\n",
      "2018-08-30 06:24:28.846784 Test Step 655 \"loss\" =  18.57091\n",
      "2018-08-30 06:24:28.893052 Training Step 655 Finished Timing (Training: 0.912206, Test: 0.0821848) after 0.251366 seconds\n",
      "2018-08-30 06:24:28.893350 Training Step 655 \"min loss\" =  12.979209\n",
      "2018-08-30 06:24:28.893415 Training Step 655 \"loss\" =  13.075078\n",
      "2018-08-30 06:24:29.098066 Test Step 660 Finished\n",
      "2018-08-30 06:24:29.098356 Test Step 660 \"min loss\" =  16.806648\n",
      "2018-08-30 06:24:29.098788 Test Step 660 \"loss\" =  17.417482\n",
      "2018-08-30 06:24:29.144597 Training Step 660 Finished Timing (Training: 0.912089, Test: 0.0821872) after 0.250603 seconds\n",
      "2018-08-30 06:24:29.144679 Training Step 660 \"min loss\" =  12.824628\n",
      "2018-08-30 06:24:29.145061 Training Step 660 \"loss\" =  13.55389\n",
      "2018-08-30 06:24:29.349098 Test Step 665 Finished\n",
      "2018-08-30 06:24:29.349362 Test Step 665 \"min loss\" =  16.082481\n",
      "2018-08-30 06:24:29.349421 Test Step 665 \"loss\" =  16.082481\n",
      "2018-08-30 06:24:29.395641 Training Step 665 Finished Timing (Training: 0.912053, Test: 0.0821991) after 0.250515 seconds\n",
      "2018-08-30 06:24:29.395950 Training Step 665 \"min loss\" =  12.824628\n",
      "2018-08-30 06:24:29.396286 Training Step 665 \"loss\" =  13.034189\n",
      "2018-08-30 06:24:29.600128 Test Step 670 Finished\n",
      "2018-08-30 06:24:29.600433 Test Step 670 \"min loss\" =  16.082481\n",
      "2018-08-30 06:24:29.600922 Test Step 670 \"loss\" =  16.724598\n",
      "2018-08-30 06:24:29.647027 Training Step 670 Finished Timing (Training: 0.911908, Test: 0.0822445) after 0.250487 seconds\n",
      "2018-08-30 06:24:29.647258 Training Step 670 \"min loss\" =  12.824628\n",
      "2018-08-30 06:24:29.647813 Training Step 670 \"loss\" =  13.448236\n",
      "2018-08-30 06:24:29.851824 Test Step 675 Finished\n",
      "2018-08-30 06:24:29.852104 Test Step 675 \"min loss\" =  16.082481\n",
      "2018-08-30 06:24:29.852534 Test Step 675 \"loss\" =  18.535637\n",
      "2018-08-30 06:24:29.898629 Training Step 675 Finished Timing (Training: 0.911837, Test: 0.0822672) after 0.250747 seconds\n",
      "2018-08-30 06:24:29.898982 Training Step 675 \"min loss\" =  12.819578\n",
      "2018-08-30 06:24:29.899385 Training Step 675 \"loss\" =  13.181934\n",
      "2018-08-30 06:24:30.103056 Test Step 680 Finished\n",
      "2018-08-30 06:24:30.103331 Test Step 680 \"min loss\" =  15.709722\n",
      "2018-08-30 06:24:30.103395 Test Step 680 \"loss\" =  15.709722\n",
      "2018-08-30 06:24:30.149190 Training Step 680 Finished Timing (Training: 0.911799, Test: 0.0822962) after 0.249471 seconds\n",
      "2018-08-30 06:24:30.149558 Training Step 680 \"min loss\" =  12.819578\n",
      "2018-08-30 06:24:30.149622 Training Step 680 \"loss\" =  12.87091\n",
      "2018-08-30 06:24:30.353876 Test Step 685 Finished\n",
      "2018-08-30 06:24:30.353962 Test Step 685 \"min loss\" =  15.709722\n",
      "2018-08-30 06:24:30.354018 Test Step 685 \"loss\" =  16.472982\n",
      "2018-08-30 06:24:30.400256 Training Step 685 Finished Timing (Training: 0.911727, Test: 0.0823224) after 0.250226 seconds\n",
      "2018-08-30 06:24:30.400334 Training Step 685 \"min loss\" =  11.754513\n",
      "2018-08-30 06:24:30.400390 Training Step 685 \"loss\" =  11.828736\n",
      "2018-08-30 06:24:30.604876 Test Step 690 Finished\n",
      "2018-08-30 06:24:30.604973 Test Step 690 \"min loss\" =  15.666191\n",
      "2018-08-30 06:24:30.605522 Test Step 690 \"loss\" =  15.666191\n",
      "2018-08-30 06:24:30.651903 Training Step 690 Finished Timing (Training: 0.911588, Test: 0.0823916) after 0.250903 seconds\n",
      "2018-08-30 06:24:30.652003 Training Step 690 \"min loss\" =  11.754513\n",
      "2018-08-30 06:24:30.652394 Training Step 690 \"loss\" =  12.792074\n",
      "2018-08-30 06:24:30.856561 Test Step 695 Finished\n",
      "2018-08-30 06:24:30.856642 Test Step 695 \"min loss\" =  15.666191\n",
      "2018-08-30 06:24:30.857080 Test Step 695 \"loss\" =  16.484848\n",
      "2018-08-30 06:24:30.903211 Training Step 695 Finished Timing (Training: 0.911522, Test: 0.0824291) after 0.250539 seconds\n",
      "2018-08-30 06:24:30.903287 Training Step 695 \"min loss\" =  11.754513\n",
      "2018-08-30 06:24:30.903674 Training Step 695 \"loss\" =  12.257219\n",
      "2018-08-30 06:24:31.107872 Test Step 700 Finished\n",
      "2018-08-30 06:24:31.107998 Test Step 700 \"min loss\" =  12.666007\n",
      "2018-08-30 06:24:31.108701 Test Step 700 \"loss\" =  12.666007\n",
      "2018-08-30 06:24:31.154840 Training Step 700 Finished Timing (Training: 0.911425, Test: 0.0824293) after 0.250828 seconds\n",
      "2018-08-30 06:24:31.154926 Training Step 700 \"min loss\" =  11.429984\n",
      "2018-08-30 06:24:31.155326 Training Step 700 \"loss\" =  13.465843\n",
      "2018-08-30 06:24:31.359093 Test Step 705 Finished\n",
      "2018-08-30 06:24:31.359486 Test Step 705 \"min loss\" =  11.4629135\n",
      "2018-08-30 06:24:31.359704 Test Step 705 \"loss\" =  11.4629135\n",
      "2018-08-30 06:24:31.405947 Training Step 705 Finished Timing (Training: 0.913699, Test: 0.0820766) after 0.250179 seconds\n",
      "2018-08-30 06:24:31.406156 Training Step 705 \"min loss\" =  11.429984\n",
      "2018-08-30 06:24:31.406549 Training Step 705 \"loss\" =  12.244136\n",
      "2018-08-30 06:24:31.610613 Test Step 710 Finished\n",
      "2018-08-30 06:24:31.611035 Test Step 710 \"min loss\" =  11.4629135\n",
      "2018-08-30 06:24:31.611269 Test Step 710 \"loss\" =  13.184087\n",
      "2018-08-30 06:24:31.657358 Training Step 710 Finished Timing (Training: 0.91181, Test: 0.0825163) after 0.250601 seconds\n",
      "2018-08-30 06:24:31.657557 Training Step 710 \"min loss\" =  11.429984\n",
      "2018-08-30 06:24:31.657864 Training Step 710 \"loss\" =  13.915301\n",
      "2018-08-30 06:24:31.861467 Test Step 715 Finished\n",
      "2018-08-30 06:24:31.861749 Test Step 715 \"min loss\" =  11.4629135\n",
      "2018-08-30 06:24:31.862048 Test Step 715 \"loss\" =  11.631392\n",
      "2018-08-30 06:24:31.908291 Training Step 715 Finished Timing (Training: 0.911128, Test: 0.0825433) after 0.250046 seconds\n",
      "2018-08-30 06:24:31.908413 Training Step 715 \"min loss\" =  11.429984\n",
      "2018-08-30 06:24:31.908557 Training Step 715 \"loss\" =  12.548668\n",
      "2018-08-30 06:24:32.112899 Test Step 720 Finished\n",
      "2018-08-30 06:24:32.113177 Test Step 720 \"min loss\" =  11.4629135\n",
      "2018-08-30 06:24:32.113232 Test Step 720 \"loss\" =  11.996854\n",
      "2018-08-30 06:24:32.159664 Training Step 720 Finished Timing (Training: 0.911071, Test: 0.0823668) after 0.250471 seconds\n",
      "2018-08-30 06:24:32.159747 Training Step 720 \"min loss\" =  11.429984\n",
      "2018-08-30 06:24:32.159801 Training Step 720 \"loss\" =  12.560635\n",
      "2018-08-30 06:24:32.364528 Test Step 725 Finished\n",
      "2018-08-30 06:24:32.364628 Test Step 725 \"min loss\" =  11.4629135\n",
      "2018-08-30 06:24:32.365126 Test Step 725 \"loss\" =  12.399737\n",
      "2018-08-30 06:24:32.411665 Training Step 725 Finished Timing (Training: 0.910736, Test: 0.0823961) after 0.251169 seconds\n",
      "2018-08-30 06:24:32.411920 Training Step 725 \"min loss\" =  11.429984\n",
      "2018-08-30 06:24:32.412575 Training Step 725 \"loss\" =  11.729508\n",
      "2018-08-30 06:24:32.616815 Test Step 730 Finished\n",
      "2018-08-30 06:24:32.616904 Test Step 730 \"min loss\" =  11.299878\n",
      "2018-08-30 06:24:32.617400 Test Step 730 \"loss\" =  11.299878\n",
      "2018-08-30 06:24:32.664019 Training Step 730 Finished Timing (Training: 0.910502, Test: 0.0823619) after 0.251226 seconds\n",
      "2018-08-30 06:24:32.664132 Training Step 730 \"min loss\" =  11.172965\n",
      "2018-08-30 06:24:32.664687 Training Step 730 \"loss\" =  13.058775\n",
      "2018-08-30 06:24:32.869448 Test Step 735 Finished\n",
      "2018-08-30 06:24:32.869533 Test Step 735 \"min loss\" =  10.987143\n",
      "2018-08-30 06:24:32.870006 Test Step 735 \"loss\" =  10.987143\n",
      "2018-08-30 06:24:32.916585 Training Step 735 Finished Timing (Training: 0.910488, Test: 0.0822625) after 0.251472 seconds\n",
      "2018-08-30 06:24:32.916811 Training Step 735 \"min loss\" =  11.172965\n",
      "2018-08-30 06:24:32.917120 Training Step 735 \"loss\" =  12.84172\n",
      "2018-08-30 06:24:33.121451 Test Step 740 Finished\n",
      "2018-08-30 06:24:33.121715 Test Step 740 \"min loss\" =  10.987143\n",
      "2018-08-30 06:24:33.122027 Test Step 740 \"loss\" =  11.313465\n",
      "2018-08-30 06:24:33.168218 Training Step 740 Finished Timing (Training: 0.91053, Test: 0.0822397) after 0.250788 seconds\n",
      "2018-08-30 06:24:33.168331 Training Step 740 \"min loss\" =  11.172965\n",
      "2018-08-30 06:24:33.168788 Training Step 740 \"loss\" =  12.3055935\n",
      "2018-08-30 06:24:33.373101 Test Step 745 Finished\n",
      "2018-08-30 06:24:33.373435 Test Step 745 \"min loss\" =  10.718158\n",
      "2018-08-30 06:24:33.373492 Test Step 745 \"loss\" =  10.718158\n",
      "2018-08-30 06:24:33.420086 Training Step 745 Finished Timing (Training: 0.910456, Test: 0.0821809) after 0.25088 seconds\n",
      "2018-08-30 06:24:33.420294 Training Step 745 \"min loss\" =  10.860955\n",
      "2018-08-30 06:24:33.420363 Training Step 745 \"loss\" =  12.44083\n",
      "2018-08-30 06:24:33.624604 Test Step 750 Finished\n",
      "2018-08-30 06:24:33.624685 Test Step 750 \"min loss\" =  10.718158\n",
      "2018-08-30 06:24:33.625186 Test Step 750 \"loss\" =  10.977982\n",
      "2018-08-30 06:24:33.671379 Training Step 750 Finished Timing (Training: 0.910493, Test: 0.0821887) after 0.25051 seconds\n",
      "2018-08-30 06:24:33.671485 Training Step 750 \"min loss\" =  10.860955\n",
      "2018-08-30 06:24:33.671613 Training Step 750 \"loss\" =  12.440329\n",
      "2018-08-30 06:24:33.876443 Test Step 755 Finished\n",
      "2018-08-30 06:24:33.876706 Test Step 755 \"min loss\" =  10.718158\n",
      "2018-08-30 06:24:33.877001 Test Step 755 \"loss\" =  10.730757\n",
      "2018-08-30 06:24:33.923273 Training Step 755 Finished Timing (Training: 0.910678, Test: 0.0822118) after 0.251557 seconds\n",
      "2018-08-30 06:24:33.923486 Training Step 755 \"min loss\" =  10.860955\n",
      "2018-08-30 06:24:33.923730 Training Step 755 \"loss\" =  11.778933\n",
      "2018-08-30 06:24:34.127496 Test Step 760 Finished\n",
      "2018-08-30 06:24:34.127579 Test Step 760 \"min loss\" =  10.537068\n",
      "2018-08-30 06:24:34.128049 Test Step 760 \"loss\" =  10.537068\n",
      "2018-08-30 06:24:34.174211 Training Step 760 Finished Timing (Training: 0.910678, Test: 0.0822442) after 0.250154 seconds\n",
      "2018-08-30 06:24:34.174292 Training Step 760 \"min loss\" =  10.817483\n",
      "2018-08-30 06:24:34.174686 Training Step 760 \"loss\" =  12.465591\n",
      "2018-08-30 06:24:34.378330 Test Step 765 Finished\n",
      "2018-08-30 06:24:34.378594 Test Step 765 \"min loss\" =  10.537068\n",
      "2018-08-30 06:24:34.378872 Test Step 765 \"loss\" =  11.169743\n",
      "2018-08-30 06:24:34.424887 Training Step 765 Finished Timing (Training: 0.910712, Test: 0.0822183) after 0.249796 seconds\n",
      "2018-08-30 06:24:34.425203 Training Step 765 \"min loss\" =  10.16532\n",
      "2018-08-30 06:24:34.425437 Training Step 765 \"loss\" =  12.337202\n",
      "2018-08-30 06:24:34.629247 Test Step 770 Finished\n",
      "2018-08-30 06:24:34.629346 Test Step 770 \"min loss\" =  10.166645\n",
      "2018-08-30 06:24:34.629406 Test Step 770 \"loss\" =  10.166645\n",
      "2018-08-30 06:24:34.675193 Training Step 770 Finished Timing (Training: 0.910871, Test: 0.0822659) after 0.249519 seconds\n",
      "2018-08-30 06:24:34.675271 Training Step 770 \"min loss\" =  10.16532\n",
      "2018-08-30 06:24:34.675858 Training Step 770 \"loss\" =  11.184737\n",
      "2018-08-30 06:24:34.879626 Test Step 775 Finished\n",
      "2018-08-30 06:24:34.879727 Test Step 775 \"min loss\" =  10.166645\n",
      "2018-08-30 06:24:34.879789 Test Step 775 \"loss\" =  10.709185\n",
      "2018-08-30 06:24:34.925798 Training Step 775 Finished Timing (Training: 0.910948, Test: 0.0823437) after 0.249695 seconds\n",
      "2018-08-30 06:24:34.926138 Training Step 775 \"min loss\" =  10.16532\n",
      "2018-08-30 06:24:34.926356 Training Step 775 \"loss\" =  11.620868\n",
      "2018-08-30 06:24:35.130371 Test Step 780 Finished\n",
      "2018-08-30 06:24:35.130458 Test Step 780 \"min loss\" =  10.120875\n",
      "2018-08-30 06:24:35.130519 Test Step 780 \"loss\" =  10.120875\n",
      "2018-08-30 06:24:35.176522 Training Step 780 Finished Timing (Training: 0.911163, Test: 0.0823293) after 0.250104 seconds\n",
      "2018-08-30 06:24:35.176590 Training Step 780 \"min loss\" =  10.16532\n",
      "2018-08-30 06:24:35.176968 Training Step 780 \"loss\" =  10.324216\n",
      "2018-08-30 06:24:35.380704 Test Step 785 Finished\n",
      "2018-08-30 06:24:35.380791 Test Step 785 \"min loss\" =  10.120875\n",
      "2018-08-30 06:24:35.380852 Test Step 785 \"loss\" =  10.321601\n",
      "2018-08-30 06:24:35.427527 Training Step 785 Finished Timing (Training: 0.91141, Test: 0.0822849) after 0.250491 seconds\n",
      "2018-08-30 06:24:35.427597 Training Step 785 \"min loss\" =  10.16532\n",
      "2018-08-30 06:24:35.427657 Training Step 785 \"loss\" =  10.470643\n",
      "2018-08-30 06:24:35.632389 Test Step 790 Finished\n",
      "2018-08-30 06:24:35.632871 Test Step 790 \"min loss\" =  9.880913\n",
      "2018-08-30 06:24:35.632931 Test Step 790 \"loss\" =  9.880913\n",
      "2018-08-30 06:24:35.679362 Training Step 790 Finished Timing (Training: 0.911272, Test: 0.0823061) after 0.250907 seconds\n",
      "2018-08-30 06:24:35.679681 Training Step 790 \"min loss\" =  9.870895\n",
      "2018-08-30 06:24:35.680007 Training Step 790 \"loss\" =  10.3437395\n",
      "2018-08-30 06:24:35.883703 Test Step 795 Finished\n",
      "2018-08-30 06:24:35.883803 Test Step 795 \"min loss\" =  9.880913\n",
      "2018-08-30 06:24:35.883865 Test Step 795 \"loss\" =  9.948292\n",
      "2018-08-30 06:24:35.930431 Training Step 795 Finished Timing (Training: 0.911382, Test: 0.0822672) after 0.250037 seconds\n",
      "2018-08-30 06:24:35.930739 Training Step 795 \"min loss\" =  9.870895\n",
      "2018-08-30 06:24:35.930965 Training Step 795 \"loss\" =  11.193414\n",
      "2018-08-30 06:24:36.134564 Test Step 800 Finished\n",
      "2018-08-30 06:24:36.134996 Test Step 800 \"min loss\" =  9.880913\n",
      "2018-08-30 06:24:36.135266 Test Step 800 \"loss\" =  10.302255\n",
      "2018-08-30 06:24:36.181328 Training Step 800 Finished Timing (Training: 0.911416, Test: 0.0822703) after 0.250292 seconds\n",
      "2018-08-30 06:24:36.181395 Training Step 800 \"min loss\" =  9.870895\n",
      "2018-08-30 06:24:36.181483 Training Step 800 \"loss\" =  11.502181\n",
      "2018-08-30 06:24:36.385571 Test Step 805 Finished\n",
      "2018-08-30 06:24:36.385664 Test Step 805 \"min loss\" =  9.880913\n",
      "2018-08-30 06:24:36.385727 Test Step 805 \"loss\" =  10.643892\n",
      "2018-08-30 06:24:36.431493 Training Step 805 Finished Timing (Training: 0.916544, Test: 0.0822612) after 0.249184 seconds\n",
      "2018-08-30 06:24:36.431558 Training Step 805 \"min loss\" =  9.870895\n",
      "2018-08-30 06:24:36.431635 Training Step 805 \"loss\" =  10.891466\n",
      "2018-08-30 06:24:36.635801 Test Step 810 Finished\n",
      "2018-08-30 06:24:36.635887 Test Step 810 \"min loss\" =  9.880913\n",
      "2018-08-30 06:24:36.635947 Test Step 810 \"loss\" =  10.401461\n",
      "2018-08-30 06:24:36.682499 Training Step 810 Finished Timing (Training: 0.915964, Test: 0.0825093) after 0.250786 seconds\n",
      "2018-08-30 06:24:36.682894 Training Step 810 \"min loss\" =  9.870895\n",
      "2018-08-30 06:24:36.683427 Training Step 810 \"loss\" =  11.611647\n",
      "2018-08-30 06:24:36.887521 Test Step 815 Finished\n",
      "2018-08-30 06:24:36.887610 Test Step 815 \"min loss\" =  9.880913\n",
      "2018-08-30 06:24:36.887669 Test Step 815 \"loss\" =  10.244932\n",
      "2018-08-30 06:24:36.934367 Training Step 815 Finished Timing (Training: 0.913569, Test: 0.0822514) after 0.250593 seconds\n",
      "2018-08-30 06:24:36.934434 Training Step 815 \"min loss\" =  9.870895\n",
      "2018-08-30 06:24:36.934814 Training Step 815 \"loss\" =  10.643424\n",
      "2018-08-30 06:24:37.139239 Test Step 820 Finished\n",
      "2018-08-30 06:24:37.139322 Test Step 820 \"min loss\" =  9.769391\n",
      "2018-08-30 06:24:37.139809 Test Step 820 \"loss\" =  9.769391\n",
      "2018-08-30 06:24:37.186105 Training Step 820 Finished Timing (Training: 0.913196, Test: 0.0821452) after 0.250852 seconds\n",
      "2018-08-30 06:24:37.186451 Training Step 820 \"min loss\" =  9.870895\n",
      "2018-08-30 06:24:37.186703 Training Step 820 \"loss\" =  9.977878\n",
      "2018-08-30 06:24:37.391019 Test Step 825 Finished\n",
      "2018-08-30 06:24:37.391098 Test Step 825 \"min loss\" =  9.31414\n",
      "2018-08-30 06:24:37.391615 Test Step 825 \"loss\" =  9.31414\n",
      "2018-08-30 06:24:37.437761 Training Step 825 Finished Timing (Training: 0.912685, Test: 0.0822632) after 0.250678 seconds\n",
      "2018-08-30 06:24:37.438016 Training Step 825 \"min loss\" =  9.870895\n",
      "2018-08-30 06:24:37.438285 Training Step 825 \"loss\" =  11.3128605\n",
      "2018-08-30 06:24:37.643197 Test Step 830 Finished\n",
      "2018-08-30 06:24:37.643568 Test Step 830 \"min loss\" =  9.31414\n",
      "2018-08-30 06:24:37.643822 Test Step 830 \"loss\" =  10.012746\n",
      "2018-08-30 06:24:37.690094 Training Step 830 Finished Timing (Training: 0.912437, Test: 0.0822326) after 0.251746 seconds\n",
      "2018-08-30 06:24:37.690172 Training Step 830 \"min loss\" =  9.870895\n",
      "2018-08-30 06:24:37.690587 Training Step 830 \"loss\" =  10.797906\n",
      "2018-08-30 06:24:37.894790 Test Step 835 Finished\n",
      "2018-08-30 06:24:37.894898 Test Step 835 \"min loss\" =  9.31414\n",
      "2018-08-30 06:24:37.895385 Test Step 835 \"loss\" =  10.190676\n",
      "2018-08-30 06:24:37.941551 Training Step 835 Finished Timing (Training: 0.91211, Test: 0.0823046) after 0.250612 seconds\n",
      "2018-08-30 06:24:37.941827 Training Step 835 \"min loss\" =  9.391031\n",
      "2018-08-30 06:24:37.942035 Training Step 835 \"loss\" =  11.003707\n",
      "2018-08-30 06:24:38.145967 Test Step 840 Finished\n",
      "2018-08-30 06:24:38.146251 Test Step 840 \"min loss\" =  9.31414\n",
      "2018-08-30 06:24:38.146549 Test Step 840 \"loss\" =  9.980729\n",
      "2018-08-30 06:24:38.192642 Training Step 840 Finished Timing (Training: 0.91206, Test: 0.0823176) after 0.250547 seconds\n",
      "2018-08-30 06:24:38.192894 Training Step 840 \"min loss\" =  9.391031\n",
      "2018-08-30 06:24:38.193162 Training Step 840 \"loss\" =  9.689713\n",
      "2018-08-30 06:24:38.397349 Test Step 845 Finished\n",
      "2018-08-30 06:24:38.397426 Test Step 845 \"min loss\" =  9.31414\n",
      "2018-08-30 06:24:38.397895 Test Step 845 \"loss\" =  9.871044\n",
      "2018-08-30 06:24:38.443903 Training Step 845 Finished Timing (Training: 0.912059, Test: 0.0822936) after 0.25068 seconds\n",
      "2018-08-30 06:24:38.444176 Training Step 845 \"min loss\" =  9.391031\n",
      "2018-08-30 06:24:38.444506 Training Step 845 \"loss\" =  10.291578\n",
      "2018-08-30 06:24:38.648378 Test Step 850 Finished\n",
      "2018-08-30 06:24:38.648646 Test Step 850 \"min loss\" =  9.31414\n",
      "2018-08-30 06:24:38.648944 Test Step 850 \"loss\" =  9.582549\n",
      "2018-08-30 06:24:38.695219 Training Step 850 Finished Timing (Training: 0.911916, Test: 0.0823105) after 0.250506 seconds\n",
      "2018-08-30 06:24:38.695466 Training Step 850 \"min loss\" =  9.391031\n",
      "2018-08-30 06:24:38.695543 Training Step 850 \"loss\" =  10.206741\n",
      "2018-08-30 06:24:38.899529 Test Step 855 Finished\n",
      "2018-08-30 06:24:38.899692 Test Step 855 \"min loss\" =  9.31414\n",
      "2018-08-30 06:24:38.899782 Test Step 855 \"loss\" =  9.767507\n",
      "2018-08-30 06:24:38.946498 Training Step 855 Finished Timing (Training: 0.91177, Test: 0.082301) after 0.250423 seconds\n",
      "2018-08-30 06:24:38.946691 Training Step 855 \"min loss\" =  9.391031\n",
      "2018-08-30 06:24:38.946752 Training Step 855 \"loss\" =  11.365194\n",
      "2018-08-30 06:24:39.151183 Test Step 860 Finished\n",
      "2018-08-30 06:24:39.151270 Test Step 860 \"min loss\" =  9.31414\n",
      "2018-08-30 06:24:39.151345 Test Step 860 \"loss\" =  10.759772\n",
      "2018-08-30 06:24:39.197123 Training Step 860 Finished Timing (Training: 0.912115, Test: 0.0822588) after 0.25029 seconds\n",
      "2018-08-30 06:24:39.197451 Training Step 860 \"min loss\" =  9.391031\n",
      "2018-08-30 06:24:39.197686 Training Step 860 \"loss\" =  9.776163\n",
      "2018-08-30 06:24:39.401702 Test Step 865 Finished\n",
      "2018-08-30 06:24:39.401795 Test Step 865 \"min loss\" =  9.31414\n",
      "2018-08-30 06:24:39.401857 Test Step 865 \"loss\" =  9.56075\n",
      "2018-08-30 06:24:39.448954 Training Step 865 Finished Timing (Training: 0.91229, Test: 0.08224) after 0.251202 seconds\n",
      "2018-08-30 06:24:39.449020 Training Step 865 \"min loss\" =  9.391031\n",
      "2018-08-30 06:24:39.449078 Training Step 865 \"loss\" =  9.899153\n",
      "2018-08-30 06:24:39.654658 Test Step 870 Finished\n",
      "2018-08-30 06:24:39.654753 Test Step 870 \"min loss\" =  9.31414\n",
      "2018-08-30 06:24:39.654815 Test Step 870 \"loss\" =  9.8223715\n",
      "2018-08-30 06:24:39.700731 Training Step 870 Finished Timing (Training: 0.91237, Test: 0.0822192) after 0.250879 seconds\n",
      "2018-08-30 06:24:39.700807 Training Step 870 \"min loss\" =  9.391031\n",
      "2018-08-30 06:24:39.700880 Training Step 870 \"loss\" =  11.310746\n",
      "2018-08-30 06:24:39.905554 Test Step 875 Finished\n",
      "2018-08-30 06:24:39.905654 Test Step 875 \"min loss\" =  9.31414\n",
      "2018-08-30 06:24:39.905711 Test Step 875 \"loss\" =  9.430854\n",
      "2018-08-30 06:24:39.952551 Training Step 875 Finished Timing (Training: 0.912529, Test: 0.0822986) after 0.251592 seconds\n",
      "2018-08-30 06:24:39.952886 Training Step 875 \"min loss\" =  9.391031\n",
      "2018-08-30 06:24:39.952956 Training Step 875 \"loss\" =  10.721213\n",
      "2018-08-30 06:24:40.156679 Test Step 880 Finished\n",
      "2018-08-30 06:24:40.156773 Test Step 880 \"min loss\" =  8.906532\n",
      "2018-08-30 06:24:40.156838 Test Step 880 \"loss\" =  8.906532\n",
      "2018-08-30 06:24:40.203459 Training Step 880 Finished Timing (Training: 0.91249, Test: 0.0823072) after 0.250442 seconds\n",
      "2018-08-30 06:24:40.203531 Training Step 880 \"min loss\" =  9.391031\n",
      "2018-08-30 06:24:40.203591 Training Step 880 \"loss\" =  9.507706\n",
      "2018-08-30 06:24:40.406645 Test Step 885 Finished\n",
      "2018-08-30 06:24:40.406727 Test Step 885 \"min loss\" =  8.906532\n",
      "2018-08-30 06:24:40.406786 Test Step 885 \"loss\" =  9.054763\n",
      "2018-08-30 06:24:40.453512 Training Step 885 Finished Timing (Training: 0.912567, Test: 0.082266) after 0.249858 seconds\n",
      "2018-08-30 06:24:40.453590 Training Step 885 \"min loss\" =  9.391031\n",
      "2018-08-30 06:24:40.453645 Training Step 885 \"loss\" =  10.455316\n",
      "2018-08-30 06:24:40.658370 Test Step 890 Finished\n",
      "2018-08-30 06:24:40.658523 Test Step 890 \"min loss\" =  8.906532\n",
      "2018-08-30 06:24:40.658585 Test Step 890 \"loss\" =  9.362973\n",
      "2018-08-30 06:24:40.704499 Training Step 890 Finished Timing (Training: 0.912606, Test: 0.0822622) after 0.250153 seconds\n",
      "2018-08-30 06:24:40.704674 Training Step 890 \"min loss\" =  9.391031\n",
      "2018-08-30 06:24:40.704733 Training Step 890 \"loss\" =  10.588908\n",
      "2018-08-30 06:24:40.908738 Test Step 895 Finished\n",
      "2018-08-30 06:24:40.909122 Test Step 895 \"min loss\" =  8.784416\n",
      "2018-08-30 06:24:40.909184 Test Step 895 \"loss\" =  8.784416\n",
      "2018-08-30 06:24:40.955481 Training Step 895 Finished Timing (Training: 0.912719, Test: 0.0822403) after 0.250678 seconds\n",
      "2018-08-30 06:24:40.955549 Training Step 895 \"min loss\" =  9.391031\n",
      "2018-08-30 06:24:40.955608 Training Step 895 \"loss\" =  10.56222\n",
      "2018-08-30 06:24:41.159881 Test Step 900 Finished\n",
      "2018-08-30 06:24:41.160273 Test Step 900 \"min loss\" =  8.784416\n",
      "2018-08-30 06:24:41.160334 Test Step 900 \"loss\" =  9.259643\n",
      "2018-08-30 06:24:41.206823 Training Step 900 Finished Timing (Training: 0.912812, Test: 0.0822546) after 0.251151 seconds\n",
      "2018-08-30 06:24:41.207151 Training Step 900 \"min loss\" =  9.391031\n",
      "2018-08-30 06:24:41.207216 Training Step 900 \"loss\" =  10.602942\n",
      "2018-08-30 06:24:41.410360 Test Step 905 Finished\n",
      "2018-08-30 06:24:41.410476 Test Step 905 \"min loss\" =  8.784416\n",
      "2018-08-30 06:24:41.410537 Test Step 905 \"loss\" =  9.412819\n",
      "2018-08-30 06:24:41.456691 Training Step 905 Finished Timing (Training: 0.916358, Test: 0.0825612) after 0.249409 seconds\n",
      "2018-08-30 06:24:41.456985 Training Step 905 \"min loss\" =  9.391031\n",
      "2018-08-30 06:24:41.457055 Training Step 905 \"loss\" =  10.425702\n",
      "2018-08-30 06:24:41.660627 Test Step 910 Finished\n",
      "2018-08-30 06:24:41.660738 Test Step 910 \"min loss\" =  8.784416\n",
      "2018-08-30 06:24:41.661210 Test Step 910 \"loss\" =  9.209275\n",
      "2018-08-30 06:24:41.707444 Training Step 910 Finished Timing (Training: 0.914987, Test: 0.0822302) after 0.250324 seconds\n",
      "2018-08-30 06:24:41.707511 Training Step 910 \"min loss\" =  9.391031\n",
      "2018-08-30 06:24:41.707570 Training Step 910 \"loss\" =  10.308089\n",
      "2018-08-30 06:24:41.911631 Test Step 915 Finished\n",
      "2018-08-30 06:24:41.911717 Test Step 915 \"min loss\" =  8.772758\n",
      "2018-08-30 06:24:41.911780 Test Step 915 \"loss\" =  8.772758\n",
      "2018-08-30 06:24:41.957415 Training Step 915 Finished Timing (Training: 0.915212, Test: 0.0823418) after 0.249764 seconds\n",
      "2018-08-30 06:24:41.957727 Training Step 915 \"min loss\" =  9.391031\n",
      "2018-08-30 06:24:41.958302 Training Step 915 \"loss\" =  9.5234995\n",
      "2018-08-30 06:24:42.161455 Test Step 920 Finished\n",
      "2018-08-30 06:24:42.161560 Test Step 920 \"min loss\" =  8.772758\n",
      "2018-08-30 06:24:42.161619 Test Step 920 \"loss\" =  10.092947\n",
      "2018-08-30 06:24:42.207388 Training Step 920 Finished Timing (Training: 0.914622, Test: 0.0823491) after 0.249017 seconds\n",
      "2018-08-30 06:24:42.207463 Training Step 920 \"min loss\" =  9.391031\n",
      "2018-08-30 06:24:42.207537 Training Step 920 \"loss\" =  10.318784\n",
      "2018-08-30 06:24:42.411663 Test Step 925 Finished\n",
      "2018-08-30 06:24:42.411759 Test Step 925 \"min loss\" =  8.772758\n",
      "2018-08-30 06:24:42.411818 Test Step 925 \"loss\" =  9.166811\n",
      "2018-08-30 06:24:42.457598 Training Step 925 Finished Timing (Training: 0.914793, Test: 0.0824255) after 0.249996 seconds\n",
      "2018-08-30 06:24:42.457696 Training Step 925 \"min loss\" =  9.391031\n",
      "2018-08-30 06:24:42.457772 Training Step 925 \"loss\" =  9.428976\n",
      "2018-08-30 06:24:42.662840 Test Step 930 Finished\n",
      "2018-08-30 06:24:42.662963 Test Step 930 \"min loss\" =  8.772758\n",
      "2018-08-30 06:24:42.663024 Test Step 930 \"loss\" =  9.004905\n",
      "2018-08-30 06:24:42.709818 Training Step 930 Finished Timing (Training: 0.914567, Test: 0.0823522) after 0.251343 seconds\n",
      "2018-08-30 06:24:42.709957 Training Step 930 \"min loss\" =  8.937559\n",
      "2018-08-30 06:24:42.710550 Training Step 930 \"loss\" =  9.776225\n",
      "2018-08-30 06:24:42.916259 Test Step 935 Finished\n",
      "2018-08-30 06:24:42.916354 Test Step 935 \"min loss\" =  8.772758\n",
      "2018-08-30 06:24:42.916415 Test Step 935 \"loss\" =  10.024878\n",
      "2018-08-30 06:24:42.962843 Training Step 935 Finished Timing (Training: 0.913209, Test: 0.0829009) after 0.25189 seconds\n",
      "2018-08-30 06:24:42.962912 Training Step 935 \"min loss\" =  8.937559\n",
      "2018-08-30 06:24:42.962971 Training Step 935 \"loss\" =  9.833641\n",
      "2018-08-30 06:24:43.167618 Test Step 940 Finished\n",
      "2018-08-30 06:24:43.167726 Test Step 940 \"min loss\" =  8.772758\n",
      "2018-08-30 06:24:43.167804 Test Step 940 \"loss\" =  9.184684\n",
      "2018-08-30 06:24:43.214475 Training Step 940 Finished Timing (Training: 0.913482, Test: 0.0828779) after 0.251426 seconds\n",
      "2018-08-30 06:24:43.214549 Training Step 940 \"min loss\" =  8.937559\n",
      "2018-08-30 06:24:43.215041 Training Step 940 \"loss\" =  9.771198\n",
      "2018-08-30 06:24:43.418620 Test Step 945 Finished\n",
      "2018-08-30 06:24:43.418704 Test Step 945 \"min loss\" =  8.772758\n",
      "2018-08-30 06:24:43.418762 Test Step 945 \"loss\" =  9.434596\n",
      "2018-08-30 06:24:43.464531 Training Step 945 Finished Timing (Training: 0.913528, Test: 0.0828563) after 0.249422 seconds\n",
      "2018-08-30 06:24:43.464594 Training Step 945 \"min loss\" =  8.937559\n",
      "2018-08-30 06:24:43.464634 Training Step 945 \"loss\" =  9.739855\n",
      "2018-08-30 06:24:43.670144 Test Step 950 Finished\n",
      "2018-08-30 06:24:43.670259 Test Step 950 \"min loss\" =  8.772758\n",
      "2018-08-30 06:24:43.670315 Test Step 950 \"loss\" =  9.4862585\n",
      "2018-08-30 06:24:43.716877 Training Step 950 Finished Timing (Training: 0.913615, Test: 0.0829613) after 0.252166 seconds\n",
      "2018-08-30 06:24:43.717153 Training Step 950 \"min loss\" =  8.937559\n",
      "2018-08-30 06:24:43.717215 Training Step 950 \"loss\" =  10.279756\n",
      "2018-08-30 06:24:43.921299 Test Step 955 Finished\n",
      "2018-08-30 06:24:43.921382 Test Step 955 \"min loss\" =  8.772758\n",
      "2018-08-30 06:24:43.921440 Test Step 955 \"loss\" =  9.30998\n",
      "2018-08-30 06:24:43.967259 Training Step 955 Finished Timing (Training: 0.913739, Test: 0.0829179) after 0.249968 seconds\n",
      "2018-08-30 06:24:43.967321 Training Step 955 \"min loss\" =  8.937559\n",
      "2018-08-30 06:24:43.967379 Training Step 955 \"loss\" =  9.322614\n",
      "2018-08-30 06:24:44.170731 Test Step 960 Finished\n",
      "2018-08-30 06:24:44.170830 Test Step 960 \"min loss\" =  8.772758\n",
      "2018-08-30 06:24:44.170886 Test Step 960 \"loss\" =  10.0172825\n",
      "2018-08-30 06:24:44.216614 Training Step 960 Finished Timing (Training: 0.913909, Test: 0.0828872) after 0.249171 seconds\n",
      "2018-08-30 06:24:44.216686 Training Step 960 \"min loss\" =  8.937559\n",
      "2018-08-30 06:24:44.216762 Training Step 960 \"loss\" =  11.526058\n",
      "2018-08-30 06:24:44.421056 Test Step 965 Finished\n",
      "2018-08-30 06:24:44.421303 Test Step 965 \"min loss\" =  8.772758\n",
      "2018-08-30 06:24:44.421395 Test Step 965 \"loss\" =  10.199443\n",
      "2018-08-30 06:24:44.467144 Training Step 965 Finished Timing (Training: 0.913826, Test: 0.0828542) after 0.249779 seconds\n",
      "2018-08-30 06:24:44.467206 Training Step 965 \"min loss\" =  8.937559\n",
      "2018-08-30 06:24:44.467264 Training Step 965 \"loss\" =  10.890936\n",
      "2018-08-30 06:24:44.671681 Test Step 970 Finished\n",
      "2018-08-30 06:24:44.671777 Test Step 970 \"min loss\" =  8.772758\n",
      "2018-08-30 06:24:44.671835 Test Step 970 \"loss\" =  9.27229\n",
      "2018-08-30 06:24:44.718410 Training Step 970 Finished Timing (Training: 0.913757, Test: 0.082888) after 0.251071 seconds\n",
      "2018-08-30 06:24:44.718688 Training Step 970 \"min loss\" =  8.937559\n",
      "2018-08-30 06:24:44.718752 Training Step 970 \"loss\" =  9.390845\n",
      "2018-08-30 06:24:44.922378 Test Step 975 Finished\n",
      "2018-08-30 06:24:44.922764 Test Step 975 \"min loss\" =  8.772758\n",
      "2018-08-30 06:24:44.922826 Test Step 975 \"loss\" =  9.667459\n",
      "2018-08-30 06:24:44.969099 Training Step 975 Finished Timing (Training: 0.913639, Test: 0.0828629) after 0.249835 seconds\n",
      "2018-08-30 06:24:44.969164 Training Step 975 \"min loss\" =  8.937559\n",
      "2018-08-30 06:24:44.969293 Training Step 975 \"loss\" =  10.7845\n",
      "2018-08-30 06:24:45.173402 Test Step 980 Finished\n",
      "2018-08-30 06:24:45.173488 Test Step 980 \"min loss\" =  8.772758\n",
      "2018-08-30 06:24:45.173549 Test Step 980 \"loss\" =  8.925885\n",
      "2018-08-30 06:24:45.220037 Training Step 980 Finished Timing (Training: 0.913684, Test: 0.0829127) after 0.250687 seconds\n",
      "2018-08-30 06:24:45.220107 Training Step 980 \"min loss\" =  8.937559\n",
      "2018-08-30 06:24:45.220726 Training Step 980 \"loss\" =  9.941427\n",
      "2018-08-30 06:24:45.425323 Test Step 985 Finished\n",
      "2018-08-30 06:24:45.425442 Test Step 985 \"min loss\" =  8.772758\n",
      "2018-08-30 06:24:45.426143 Test Step 985 \"loss\" =  8.865807\n",
      "2018-08-30 06:24:45.472296 Training Step 985 Finished Timing (Training: 0.91346, Test: 0.0829032) after 0.251302 seconds\n",
      "2018-08-30 06:24:45.472360 Training Step 985 \"min loss\" =  8.937559\n",
      "2018-08-30 06:24:45.472938 Training Step 985 \"loss\" =  9.941477\n",
      "2018-08-30 06:24:45.677204 Test Step 990 Finished\n",
      "2018-08-30 06:24:45.677623 Test Step 990 \"min loss\" =  8.772758\n",
      "2018-08-30 06:24:45.677684 Test Step 990 \"loss\" =  9.433814\n",
      "2018-08-30 06:24:45.723978 Training Step 990 Finished Timing (Training: 0.91332, Test: 0.08285) after 0.250976 seconds\n",
      "2018-08-30 06:24:45.724257 Training Step 990 \"min loss\" =  8.937559\n",
      "2018-08-30 06:24:45.724320 Training Step 990 \"loss\" =  10.12423\n",
      "2018-08-30 06:24:45.928858 Test Step 995 Finished\n",
      "2018-08-30 06:24:45.929055 Test Step 995 \"min loss\" =  8.772758\n",
      "2018-08-30 06:24:45.929112 Test Step 995 \"loss\" =  8.935969\n",
      "2018-08-30 06:24:45.975467 Training Step 995 Finished Timing (Training: 0.913318, Test: 0.0828984) after 0.251086 seconds\n",
      "2018-08-30 06:24:45.975529 Training Step 995 \"min loss\" =  8.937559\n",
      "2018-08-30 06:24:45.975579 Training Step 995 \"loss\" =  9.689456\n",
      "2018-08-30 06:24:46.179221 Test Step 1000 Finished\n",
      "2018-08-30 06:24:46.179316 Test Step 1000 \"min loss\" =  8.772758\n",
      "2018-08-30 06:24:46.179391 Test Step 1000 \"loss\" =  9.066996\n",
      "2018-08-30 06:24:46.226035 Training Step 1000 Finished Timing (Training: 0.913429, Test: 0.0828945) after 0.250401 seconds\n",
      "2018-08-30 06:24:46.226113 Training Step 1000 \"min loss\" =  8.689297\n",
      "2018-08-30 06:24:46.226188 Training Step 1000 \"loss\" =  9.594373\n",
      "2018-08-30 06:24:46.430812 Test Step 1005 Finished\n",
      "2018-08-30 06:24:46.430893 Test Step 1005 \"min loss\" =  8.772758\n",
      "2018-08-30 06:24:46.430952 Test Step 1005 \"loss\" =  8.968671\n",
      "2018-08-30 06:24:46.477738 Training Step 1005 Finished Timing (Training: 0.914935, Test: 0.0841904) after 0.251472 seconds\n",
      "2018-08-30 06:24:46.477817 Training Step 1005 \"min loss\" =  8.689297\n",
      "2018-08-30 06:24:46.478275 Training Step 1005 \"loss\" =  9.666388\n",
      "2018-08-30 06:24:46.683120 Test Step 1010 Finished\n",
      "2018-08-30 06:24:46.683221 Test Step 1010 \"min loss\" =  8.772758\n",
      "2018-08-30 06:24:46.683280 Test Step 1010 \"loss\" =  8.928114\n",
      "2018-08-30 06:24:46.729157 Training Step 1010 Finished Timing (Training: 0.914268, Test: 0.0836171) after 0.250813 seconds\n",
      "2018-08-30 06:24:46.729270 Training Step 1010 \"min loss\" =  8.689297\n",
      "2018-08-30 06:24:46.729347 Training Step 1010 \"loss\" =  9.743226\n",
      "2018-08-30 06:24:46.933814 Test Step 1015 Finished\n",
      "2018-08-30 06:24:46.934008 Test Step 1015 \"min loss\" =  8.336771\n",
      "2018-08-30 06:24:46.934083 Test Step 1015 \"loss\" =  8.336771\n",
      "2018-08-30 06:24:46.980647 Training Step 1015 Finished Timing (Training: 0.9143, Test: 0.0834817) after 0.251229 seconds\n",
      "2018-08-30 06:24:46.980818 Training Step 1015 \"min loss\" =  8.689297\n",
      "2018-08-30 06:24:46.980876 Training Step 1015 \"loss\" =  9.370179\n",
      "2018-08-30 06:24:47.185546 Test Step 1020 Finished\n",
      "2018-08-30 06:24:47.185624 Test Step 1020 \"min loss\" =  8.336771\n",
      "2018-08-30 06:24:47.185683 Test Step 1020 \"loss\" =  9.161904\n",
      "2018-08-30 06:24:47.232406 Training Step 1020 Finished Timing (Training: 0.91391, Test: 0.0832339) after 0.250781 seconds\n",
      "2018-08-30 06:24:47.232569 Training Step 1020 \"min loss\" =  8.689297\n",
      "2018-08-30 06:24:47.232647 Training Step 1020 \"loss\" =  9.784369\n",
      "2018-08-30 06:24:47.436595 Test Step 1025 Finished\n",
      "2018-08-30 06:24:47.436683 Test Step 1025 \"min loss\" =  8.336771\n",
      "2018-08-30 06:24:47.436745 Test Step 1025 \"loss\" =  9.3743515\n",
      "2018-08-30 06:24:47.483202 Training Step 1025 Finished Timing (Training: 0.913958, Test: 0.0833219) after 0.250488 seconds\n",
      "2018-08-30 06:24:47.483268 Training Step 1025 \"min loss\" =  8.689297\n",
      "2018-08-30 06:24:47.483313 Training Step 1025 \"loss\" =  11.221501\n",
      "2018-08-30 06:24:47.688076 Test Step 1030 Finished\n",
      "2018-08-30 06:24:47.688480 Test Step 1030 \"min loss\" =  8.336771\n",
      "2018-08-30 06:24:47.688542 Test Step 1030 \"loss\" =  9.101033\n",
      "2018-08-30 06:24:47.734457 Training Step 1030 Finished Timing (Training: 0.913963, Test: 0.0832796) after 0.251064 seconds\n",
      "2018-08-30 06:24:47.734784 Training Step 1030 \"min loss\" =  8.654852\n",
      "2018-08-30 06:24:47.735048 Training Step 1030 \"loss\" =  9.502932\n",
      "2018-08-30 06:24:47.939856 Test Step 1035 Finished\n",
      "2018-08-30 06:24:47.939984 Test Step 1035 \"min loss\" =  8.336771\n",
      "2018-08-30 06:24:47.940047 Test Step 1035 \"loss\" =  8.57744\n",
      "2018-08-30 06:24:47.986669 Training Step 1035 Finished Timing (Training: 0.914028, Test: 0.0830711) after 0.251554 seconds\n",
      "2018-08-30 06:24:47.986740 Training Step 1035 \"min loss\" =  8.41099\n",
      "2018-08-30 06:24:47.986848 Training Step 1035 \"loss\" =  8.41099\n",
      "2018-08-30 06:24:48.190724 Test Step 1040 Finished\n",
      "2018-08-30 06:24:48.190811 Test Step 1040 \"min loss\" =  8.336771\n",
      "2018-08-30 06:24:48.191508 Test Step 1040 \"loss\" =  8.372981\n",
      "2018-08-30 06:24:48.237582 Training Step 1040 Finished Timing (Training: 0.91384, Test: 0.0829712) after 0.250679 seconds\n",
      "2018-08-30 06:24:48.237654 Training Step 1040 \"min loss\" =  8.41099\n",
      "2018-08-30 06:24:48.237729 Training Step 1040 \"loss\" =  9.710228\n",
      "2018-08-30 06:24:48.441980 Test Step 1045 Finished\n",
      "2018-08-30 06:24:48.442072 Test Step 1045 \"min loss\" =  8.336771\n",
      "2018-08-30 06:24:48.442149 Test Step 1045 \"loss\" =  8.396592\n",
      "2018-08-30 06:24:48.488563 Training Step 1045 Finished Timing (Training: 0.914063, Test: 0.0828995) after 0.250769 seconds\n",
      "2018-08-30 06:24:48.488624 Training Step 1045 \"min loss\" =  8.41099\n",
      "2018-08-30 06:24:48.489039 Training Step 1045 \"loss\" =  8.814173\n",
      "2018-08-30 06:24:48.694219 Test Step 1050 Finished\n",
      "2018-08-30 06:24:48.694330 Test Step 1050 \"min loss\" =  8.336771\n",
      "2018-08-30 06:24:48.694405 Test Step 1050 \"loss\" =  8.628672\n",
      "2018-08-30 06:24:48.740915 Training Step 1050 Finished Timing (Training: 0.914119, Test: 0.0828271) after 0.251808 seconds\n",
      "2018-08-30 06:24:48.740989 Training Step 1050 \"min loss\" =  8.41099\n",
      "2018-08-30 06:24:48.741050 Training Step 1050 \"loss\" =  9.076325\n",
      "2018-08-30 06:24:48.945419 Test Step 1055 Finished\n",
      "2018-08-30 06:24:48.945504 Test Step 1055 \"min loss\" =  8.336771\n",
      "2018-08-30 06:24:48.945565 Test Step 1055 \"loss\" =  8.452136\n",
      "2018-08-30 06:24:48.992095 Training Step 1055 Finished Timing (Training: 0.914199, Test: 0.0827949) after 0.250787 seconds\n",
      "2018-08-30 06:24:48.992376 Training Step 1055 \"min loss\" =  8.41099\n",
      "2018-08-30 06:24:48.992439 Training Step 1055 \"loss\" =  8.933096\n",
      "2018-08-30 06:24:49.196826 Test Step 1060 Finished\n",
      "2018-08-30 06:24:49.196913 Test Step 1060 \"min loss\" =  8.336771\n",
      "2018-08-30 06:24:49.196990 Test Step 1060 \"loss\" =  8.473067\n",
      "2018-08-30 06:24:49.243533 Training Step 1060 Finished Timing (Training: 0.914277, Test: 0.0827486) after 0.251032 seconds\n",
      "2018-08-30 06:24:49.243606 Training Step 1060 \"min loss\" =  8.41099\n",
      "2018-08-30 06:24:49.243668 Training Step 1060 \"loss\" =  9.466593\n",
      "2018-08-30 06:24:49.447681 Test Step 1065 Finished\n",
      "2018-08-30 06:24:49.447803 Test Step 1065 \"min loss\" =  8.336771\n",
      "2018-08-30 06:24:49.448410 Test Step 1065 \"loss\" =  8.383662\n",
      "2018-08-30 06:24:49.494352 Training Step 1065 Finished Timing (Training: 0.914153, Test: 0.0827339) after 0.250589 seconds\n",
      "2018-08-30 06:24:49.494422 Training Step 1065 \"min loss\" =  8.41099\n",
      "2018-08-30 06:24:49.494485 Training Step 1065 \"loss\" =  8.997855\n",
      "2018-08-30 06:24:49.698722 Test Step 1070 Finished\n",
      "2018-08-30 06:24:49.698862 Test Step 1070 \"min loss\" =  8.336771\n",
      "2018-08-30 06:24:49.698941 Test Step 1070 \"loss\" =  8.620676\n",
      "2018-08-30 06:24:49.745461 Training Step 1070 Finished Timing (Training: 0.914262, Test: 0.0826963) after 0.250878 seconds\n",
      "2018-08-30 06:24:49.745536 Training Step 1070 \"min loss\" =  8.41099\n",
      "2018-08-30 06:24:49.745613 Training Step 1070 \"loss\" =  8.748029\n",
      "2018-08-30 06:24:49.951206 Test Step 1075 Finished\n",
      "2018-08-30 06:24:49.951287 Test Step 1075 \"min loss\" =  8.336771\n",
      "2018-08-30 06:24:49.951346 Test Step 1075 \"loss\" =  9.038578\n",
      "2018-08-30 06:24:49.997901 Training Step 1075 Finished Timing (Training: 0.914359, Test: 0.0826798) after 0.252196 seconds\n",
      "2018-08-30 06:24:49.997981 Training Step 1075 \"min loss\" =  8.180962\n",
      "2018-08-30 06:24:49.998704 Training Step 1075 \"loss\" =  8.391995\n",
      "2018-08-30 06:24:50.203562 Test Step 1080 Finished\n",
      "2018-08-30 06:24:50.203838 Test Step 1080 \"min loss\" =  8.336771\n",
      "2018-08-30 06:24:50.204120 Test Step 1080 \"loss\" =  8.478485\n",
      "2018-08-30 06:24:50.250261 Training Step 1080 Finished Timing (Training: 0.914051, Test: 0.0826067) after 0.250967 seconds\n",
      "2018-08-30 06:24:50.250542 Training Step 1080 \"min loss\" =  8.180962\n",
      "2018-08-30 06:24:50.250601 Training Step 1080 \"loss\" =  9.08389\n",
      "2018-08-30 06:24:50.454273 Test Step 1085 Finished\n",
      "2018-08-30 06:24:50.454528 Test Step 1085 \"min loss\" =  8.336771\n",
      "2018-08-30 06:24:50.454806 Test Step 1085 \"loss\" =  8.488233\n",
      "2018-08-30 06:24:50.500874 Training Step 1085 Finished Timing (Training: 0.913957, Test: 0.082602) after 0.250215 seconds\n",
      "2018-08-30 06:24:50.500953 Training Step 1085 \"min loss\" =  8.180962\n",
      "2018-08-30 06:24:50.501526 Training Step 1085 \"loss\" =  9.419655\n",
      "2018-08-30 06:24:50.706400 Test Step 1090 Finished\n",
      "2018-08-30 06:24:50.706520 Test Step 1090 \"min loss\" =  8.336771\n",
      "2018-08-30 06:24:50.706583 Test Step 1090 \"loss\" =  8.582399\n",
      "2018-08-30 06:24:50.752700 Training Step 1090 Finished Timing (Training: 0.9139, Test: 0.0826268) after 0.251085 seconds\n",
      "2018-08-30 06:24:50.752928 Training Step 1090 \"min loss\" =  8.180962\n",
      "2018-08-30 06:24:50.752991 Training Step 1090 \"loss\" =  8.646518\n",
      "2018-08-30 06:24:50.957688 Test Step 1095 Finished\n",
      "2018-08-30 06:24:50.957774 Test Step 1095 \"min loss\" =  8.336771\n",
      "2018-08-30 06:24:50.957834 Test Step 1095 \"loss\" =  8.719794\n",
      "2018-08-30 06:24:51.004629 Training Step 1095 Finished Timing (Training: 0.913954, Test: 0.0826329) after 0.251571 seconds\n",
      "2018-08-30 06:24:51.004708 Training Step 1095 \"min loss\" =  8.180962\n",
      "2018-08-30 06:24:51.004784 Training Step 1095 \"loss\" =  9.372471\n",
      "2018-08-30 06:24:51.210392 Test Step 1100 Finished\n",
      "2018-08-30 06:24:51.210505 Test Step 1100 \"min loss\" =  8.336771\n",
      "2018-08-30 06:24:51.210574 Test Step 1100 \"loss\" =  8.704626\n",
      "2018-08-30 06:24:51.257323 Training Step 1100 Finished Timing (Training: 0.914012, Test: 0.0826476) after 0.252449 seconds\n",
      "2018-08-30 06:24:51.257410 Training Step 1100 \"min loss\" =  8.180962\n",
      "2018-08-30 06:24:51.257759 Training Step 1100 \"loss\" =  8.966532\n",
      "2018-08-30 06:24:51.461796 Test Step 1105 Finished\n",
      "2018-08-30 06:24:51.462063 Test Step 1105 \"min loss\" =  8.315109\n",
      "2018-08-30 06:24:51.462344 Test Step 1105 \"loss\" =  8.315109\n",
      "2018-08-30 06:24:51.508689 Training Step 1105 Finished Timing (Training: 0.913723, Test: 0.0827896) after 0.250613 seconds\n",
      "2018-08-30 06:24:51.508755 Training Step 1105 \"min loss\" =  8.180962\n",
      "2018-08-30 06:24:51.509160 Training Step 1105 \"loss\" =  8.639183\n",
      "2018-08-30 06:24:51.713413 Test Step 1110 Finished\n",
      "2018-08-30 06:24:51.713686 Test Step 1110 \"min loss\" =  8.315109\n",
      "2018-08-30 06:24:51.713966 Test Step 1110 \"loss\" =  8.385326\n",
      "2018-08-30 06:24:51.759978 Training Step 1110 Finished Timing (Training: 0.912366, Test: 0.0825011) after 0.250468 seconds\n",
      "2018-08-30 06:24:51.760169 Training Step 1110 \"min loss\" =  8.180962\n",
      "2018-08-30 06:24:51.760402 Training Step 1110 \"loss\" =  8.865763\n",
      "2018-08-30 06:24:51.965033 Test Step 1115 Finished\n",
      "2018-08-30 06:24:51.965288 Test Step 1115 \"min loss\" =  8.315109\n",
      "2018-08-30 06:24:51.965571 Test Step 1115 \"loss\" =  9.091562\n",
      "2018-08-30 06:24:52.011640 Training Step 1115 Finished Timing (Training: 0.912047, Test: 0.0824059) after 0.25093 seconds\n",
      "2018-08-30 06:24:52.011697 Training Step 1115 \"min loss\" =  8.180962\n",
      "2018-08-30 06:24:52.012229 Training Step 1115 \"loss\" =  8.726832\n",
      "2018-08-30 06:24:52.216154 Test Step 1120 Finished\n",
      "2018-08-30 06:24:52.216278 Test Step 1120 \"min loss\" =  8.315109\n",
      "2018-08-30 06:24:52.217169 Test Step 1120 \"loss\" =  8.504408\n",
      "2018-08-30 06:24:52.263497 Training Step 1120 Finished Timing (Training: 0.911145, Test: 0.0822953) after 0.250928 seconds\n",
      "2018-08-30 06:24:52.264021 Training Step 1120 \"min loss\" =  8.180962\n",
      "2018-08-30 06:24:52.264487 Training Step 1120 \"loss\" =  8.962981\n",
      "2018-08-30 06:24:52.468117 Test Step 1125 Finished\n",
      "2018-08-30 06:24:52.468575 Test Step 1125 \"min loss\" =  8.184696\n",
      "2018-08-30 06:24:52.469106 Test Step 1125 \"loss\" =  8.184696\n",
      "2018-08-30 06:24:52.515417 Training Step 1125 Finished Timing (Training: 0.910564, Test: 0.0822092) after 0.25083 seconds\n",
      "2018-08-30 06:24:52.515502 Training Step 1125 \"min loss\" =  8.180962\n",
      "2018-08-30 06:24:52.516235 Training Step 1125 \"loss\" =  8.954806\n",
      "2018-08-30 06:24:52.720465 Test Step 1130 Finished\n",
      "2018-08-30 06:24:52.720886 Test Step 1130 \"min loss\" =  8.184696\n",
      "2018-08-30 06:24:52.721432 Test Step 1130 \"loss\" =  8.35377\n",
      "2018-08-30 06:24:52.767614 Training Step 1130 Finished Timing (Training: 0.910091, Test: 0.0822327) after 0.251029 seconds\n",
      "2018-08-30 06:24:52.767972 Training Step 1130 \"min loss\" =  8.180962\n",
      "2018-08-30 06:24:52.768087 Training Step 1130 \"loss\" =  8.362689\n",
      "2018-08-30 06:24:52.972695 Test Step 1135 Finished\n",
      "2018-08-30 06:24:52.973110 Test Step 1135 \"min loss\" =  8.184696\n",
      "2018-08-30 06:24:52.973415 Test Step 1135 \"loss\" =  8.723948\n",
      "2018-08-30 06:24:53.019970 Training Step 1135 Finished Timing (Training: 0.91017, Test: 0.0821569) after 0.251267 seconds\n",
      "2018-08-30 06:24:53.020046 Training Step 1135 \"min loss\" =  8.180962\n",
      "2018-08-30 06:24:53.020667 Training Step 1135 \"loss\" =  8.462776\n",
      "2018-08-30 06:24:53.232582 Test Step 1140 Finished\n",
      "2018-08-30 06:24:53.232878 Test Step 1140 \"min loss\" =  8.184696\n",
      "2018-08-30 06:24:53.233174 Test Step 1140 \"loss\" =  9.222262\n",
      "2018-08-30 06:24:53.279332 Training Step 1140 Finished Timing (Training: 0.910566, Test: 0.0818909) after 0.258307 seconds\n",
      "2018-08-30 06:24:53.279409 Training Step 1140 \"min loss\" =  8.156004\n",
      "2018-08-30 06:24:53.279465 Training Step 1140 \"loss\" =  8.40537\n",
      "2018-08-30 06:24:53.484509 Test Step 1145 Finished\n",
      "2018-08-30 06:24:53.484781 Test Step 1145 \"min loss\" =  8.184696\n",
      "2018-08-30 06:24:53.485079 Test Step 1145 \"loss\" =  8.642528\n",
      "2018-08-30 06:24:53.531396 Training Step 1145 Finished Timing (Training: 0.910561, Test: 0.0819716) after 0.251269 seconds\n",
      "2018-08-30 06:24:53.531463 Training Step 1145 \"min loss\" =  8.156004\n",
      "2018-08-30 06:24:53.531523 Training Step 1145 \"loss\" =  8.690025\n",
      "2018-08-30 06:24:53.734962 Test Step 1150 Finished\n",
      "2018-08-30 06:24:53.735053 Test Step 1150 \"min loss\" =  8.184696\n",
      "2018-08-30 06:24:53.735544 Test Step 1150 \"loss\" =  8.906192\n",
      "2018-08-30 06:24:53.781616 Training Step 1150 Finished Timing (Training: 0.910769, Test: 0.0820518) after 0.250015 seconds\n",
      "2018-08-30 06:24:53.781854 Training Step 1150 \"min loss\" =  8.156004\n",
      "2018-08-30 06:24:53.782165 Training Step 1150 \"loss\" =  8.469147\n",
      "2018-08-30 06:24:53.986712 Test Step 1155 Finished\n",
      "2018-08-30 06:24:53.986812 Test Step 1155 \"min loss\" =  8.184696\n",
      "2018-08-30 06:24:53.987350 Test Step 1155 \"loss\" =  8.323052\n",
      "2018-08-30 06:24:54.033532 Training Step 1155 Finished Timing (Training: 0.910673, Test: 0.0820911) after 0.250937 seconds\n",
      "2018-08-30 06:24:54.033770 Training Step 1155 \"min loss\" =  8.156004\n",
      "2018-08-30 06:24:54.034025 Training Step 1155 \"loss\" =  8.234342\n",
      "2018-08-30 06:24:54.237905 Test Step 1160 Finished\n",
      "2018-08-30 06:24:54.238180 Test Step 1160 \"min loss\" =  8.184696\n",
      "2018-08-30 06:24:54.238474 Test Step 1160 \"loss\" =  8.551618\n",
      "2018-08-30 06:24:54.284759 Training Step 1160 Finished Timing (Training: 0.910666, Test: 0.0821191) after 0.250401 seconds\n",
      "2018-08-30 06:24:54.284854 Training Step 1160 \"min loss\" =  8.141263\n",
      "2018-08-30 06:24:54.285244 Training Step 1160 \"loss\" =  8.343085\n",
      "2018-08-30 06:24:54.489473 Test Step 1165 Finished\n",
      "2018-08-30 06:24:54.489555 Test Step 1165 \"min loss\" =  8.184696\n",
      "2018-08-30 06:24:54.489612 Test Step 1165 \"loss\" =  8.501343\n",
      "2018-08-30 06:24:54.536194 Training Step 1165 Finished Timing (Training: 0.910634, Test: 0.0821404) after 0.250616 seconds\n",
      "2018-08-30 06:24:54.536468 Training Step 1165 \"min loss\" =  7.9876246\n",
      "2018-08-30 06:24:54.536531 Training Step 1165 \"loss\" =  8.480075\n",
      "2018-08-30 06:24:54.740589 Test Step 1170 Finished\n",
      "2018-08-30 06:24:54.740966 Test Step 1170 \"min loss\" =  8.138953\n",
      "2018-08-30 06:24:54.741161 Test Step 1170 \"loss\" =  8.138953\n",
      "2018-08-30 06:24:54.787327 Training Step 1170 Finished Timing (Training: 0.910695, Test: 0.0822203) after 0.250731 seconds\n",
      "2018-08-30 06:24:54.787541 Training Step 1170 \"min loss\" =  7.9107194\n",
      "2018-08-30 06:24:54.787774 Training Step 1170 \"loss\" =  8.7823925\n",
      "2018-08-30 06:24:54.991786 Test Step 1175 Finished\n",
      "2018-08-30 06:24:54.992063 Test Step 1175 \"min loss\" =  8.00214\n",
      "2018-08-30 06:24:54.992540 Test Step 1175 \"loss\" =  8.00214\n",
      "2018-08-30 06:24:55.038664 Training Step 1175 Finished Timing (Training: 0.910664, Test: 0.0822647) after 0.250584 seconds\n",
      "2018-08-30 06:24:55.038728 Training Step 1175 \"min loss\" =  7.9107194\n",
      "2018-08-30 06:24:55.039092 Training Step 1175 \"loss\" =  9.131933\n",
      "2018-08-30 06:24:55.242641 Test Step 1180 Finished\n",
      "2018-08-30 06:24:55.242742 Test Step 1180 \"min loss\" =  8.00214\n",
      "2018-08-30 06:24:55.242818 Test Step 1180 \"loss\" =  8.153805\n",
      "2018-08-30 06:24:55.289349 Training Step 1180 Finished Timing (Training: 0.910896, Test: 0.0822872) after 0.250195 seconds\n",
      "2018-08-30 06:24:55.289443 Training Step 1180 \"min loss\" =  7.9107194\n",
      "2018-08-30 06:24:55.289519 Training Step 1180 \"loss\" =  8.63013\n",
      "2018-08-30 06:24:55.494074 Test Step 1185 Finished\n",
      "2018-08-30 06:24:55.494166 Test Step 1185 \"min loss\" =  8.00214\n",
      "2018-08-30 06:24:55.494226 Test Step 1185 \"loss\" =  8.491316\n",
      "2018-08-30 06:24:55.540711 Training Step 1185 Finished Timing (Training: 0.9112, Test: 0.0822746) after 0.251129 seconds\n",
      "2018-08-30 06:24:55.540772 Training Step 1185 \"min loss\" =  7.9107194\n",
      "2018-08-30 06:24:55.541215 Training Step 1185 \"loss\" =  9.15698\n",
      "2018-08-30 06:24:55.745987 Test Step 1190 Finished\n",
      "2018-08-30 06:24:55.746105 Test Step 1190 \"min loss\" =  8.00214\n",
      "2018-08-30 06:24:55.746166 Test Step 1190 \"loss\" =  8.649378\n",
      "2018-08-30 06:24:55.793177 Training Step 1190 Finished Timing (Training: 0.911299, Test: 0.0822667) after 0.251558 seconds\n",
      "2018-08-30 06:24:55.793258 Training Step 1190 \"min loss\" =  7.9107194\n",
      "2018-08-30 06:24:55.793310 Training Step 1190 \"loss\" =  8.752439\n",
      "2018-08-30 06:24:55.997408 Test Step 1195 Finished\n",
      "2018-08-30 06:24:55.997599 Test Step 1195 \"min loss\" =  8.00214\n",
      "2018-08-30 06:24:55.997658 Test Step 1195 \"loss\" =  8.493038\n",
      "2018-08-30 06:24:56.044182 Training Step 1195 Finished Timing (Training: 0.911392, Test: 0.0823963) after 0.250802 seconds\n",
      "2018-08-30 06:24:56.044248 Training Step 1195 \"min loss\" =  7.9107194\n",
      "2018-08-30 06:24:56.044660 Training Step 1195 \"loss\" =  8.652146\n",
      "2018-08-30 06:24:56.248643 Test Step 1200 Finished\n",
      "2018-08-30 06:24:56.248755 Test Step 1200 \"min loss\" =  7.92752\n",
      "2018-08-30 06:24:56.248815 Test Step 1200 \"loss\" =  7.92752\n",
      "2018-08-30 06:24:56.294647 Training Step 1200 Finished Timing (Training: 0.911506, Test: 0.0824328) after 0.24992 seconds\n",
      "2018-08-30 06:24:56.294718 Training Step 1200 \"min loss\" =  7.9107194\n",
      "2018-08-30 06:24:56.295197 Training Step 1200 \"loss\" =  8.427956\n",
      "2018-08-30 06:24:56.499672 Test Step 1205 Finished\n",
      "2018-08-30 06:24:56.500060 Test Step 1205 \"min loss\" =  7.92752\n",
      "2018-08-30 06:24:56.500122 Test Step 1205 \"loss\" =  7.937508\n",
      "2018-08-30 06:24:56.546457 Training Step 1205 Finished Timing (Training: 0.915371, Test: 0.0825345) after 0.250998 seconds\n",
      "2018-08-30 06:24:56.546568 Training Step 1205 \"min loss\" =  7.7826424\n",
      "2018-08-30 06:24:56.546639 Training Step 1205 \"loss\" =  8.4411955\n",
      "2018-08-30 06:24:56.750652 Test Step 1210 Finished\n",
      "2018-08-30 06:24:56.750757 Test Step 1210 \"min loss\" =  7.92752\n",
      "2018-08-30 06:24:56.751277 Test Step 1210 \"loss\" =  8.056288\n",
      "2018-08-30 06:24:56.797495 Training Step 1210 Finished Timing (Training: 0.913962, Test: 0.0825756) after 0.250801 seconds\n",
      "2018-08-30 06:24:56.797740 Training Step 1210 \"min loss\" =  7.7826424\n",
      "2018-08-30 06:24:56.797808 Training Step 1210 \"loss\" =  8.477959\n",
      "2018-08-30 06:24:57.002268 Test Step 1215 Finished\n",
      "2018-08-30 06:24:57.002349 Test Step 1215 \"min loss\" =  7.92752\n",
      "2018-08-30 06:24:57.002787 Test Step 1215 \"loss\" =  8.028006\n",
      "2018-08-30 06:24:57.048976 Training Step 1215 Finished Timing (Training: 0.912425, Test: 0.0830831) after 0.250695 seconds\n",
      "2018-08-30 06:24:57.049053 Training Step 1215 \"min loss\" =  7.7826424\n",
      "2018-08-30 06:24:57.049112 Training Step 1215 \"loss\" =  8.227231\n",
      "2018-08-30 06:24:57.254259 Test Step 1220 Finished\n",
      "2018-08-30 06:24:57.254700 Test Step 1220 \"min loss\" =  7.92752\n",
      "2018-08-30 06:24:57.254967 Test Step 1220 \"loss\" =  8.409349\n",
      "2018-08-30 06:24:57.301173 Training Step 1220 Finished Timing (Training: 0.912125, Test: 0.0829358) after 0.251413 seconds\n",
      "2018-08-30 06:24:57.301255 Training Step 1220 \"min loss\" =  7.7826424\n",
      "2018-08-30 06:24:57.301314 Training Step 1220 \"loss\" =  8.71559\n",
      "2018-08-30 06:24:57.506361 Test Step 1225 Finished\n",
      "2018-08-30 06:24:57.506450 Test Step 1225 \"min loss\" =  7.92752\n",
      "2018-08-30 06:24:57.507089 Test Step 1225 \"loss\" =  8.191208\n",
      "2018-08-30 06:24:57.553448 Training Step 1225 Finished Timing (Training: 0.912171, Test: 0.0829289) after 0.25206 seconds\n",
      "2018-08-30 06:24:57.553541 Training Step 1225 \"min loss\" =  7.716234\n",
      "2018-08-30 06:24:57.553599 Training Step 1225 \"loss\" =  8.41523\n",
      "2018-08-30 06:24:57.758323 Test Step 1230 Finished\n",
      "2018-08-30 06:24:57.758406 Test Step 1230 \"min loss\" =  7.92752\n",
      "2018-08-30 06:24:57.758845 Test Step 1230 \"loss\" =  7.964502\n",
      "2018-08-30 06:24:57.804931 Training Step 1230 Finished Timing (Training: 0.912274, Test: 0.0829283) after 0.251269 seconds\n",
      "2018-08-30 06:24:57.805222 Training Step 1230 \"min loss\" =  7.716234\n",
      "2018-08-30 06:24:57.805277 Training Step 1230 \"loss\" =  8.440418\n",
      "2018-08-30 06:24:58.009857 Test Step 1235 Finished\n",
      "2018-08-30 06:24:58.010308 Test Step 1235 \"min loss\" =  7.92752\n",
      "2018-08-30 06:24:58.010371 Test Step 1235 \"loss\" =  8.121809\n",
      "2018-08-30 06:24:58.056765 Training Step 1235 Finished Timing (Training: 0.912243, Test: 0.0828649) after 0.25106 seconds\n",
      "2018-08-30 06:24:58.056851 Training Step 1235 \"min loss\" =  7.6533985\n",
      "2018-08-30 06:24:58.057270 Training Step 1235 \"loss\" =  8.126681\n",
      "2018-08-30 06:24:58.261260 Test Step 1240 Finished\n",
      "2018-08-30 06:24:58.261373 Test Step 1240 \"min loss\" =  7.747969\n",
      "2018-08-30 06:24:58.261426 Test Step 1240 \"loss\" =  7.747969\n",
      "2018-08-30 06:24:58.308108 Training Step 1240 Finished Timing (Training: 0.911983, Test: 0.0827764) after 0.250522 seconds\n",
      "2018-08-30 06:24:58.308176 Training Step 1240 \"min loss\" =  7.5678687\n",
      "2018-08-30 06:24:58.308565 Training Step 1240 \"loss\" =  7.5678687\n",
      "2018-08-30 06:24:58.513522 Test Step 1245 Finished\n",
      "2018-08-30 06:24:58.513765 Test Step 1245 \"min loss\" =  7.747969\n",
      "2018-08-30 06:24:58.514041 Test Step 1245 \"loss\" =  7.9889183\n",
      "2018-08-30 06:24:58.560151 Training Step 1245 Finished Timing (Training: 0.911834, Test: 0.0827956) after 0.251274 seconds\n",
      "2018-08-30 06:24:58.560410 Training Step 1245 \"min loss\" =  7.5678687\n",
      "2018-08-30 06:24:58.560605 Training Step 1245 \"loss\" =  8.741158\n",
      "2018-08-30 06:24:58.765397 Test Step 1250 Finished\n",
      "2018-08-30 06:24:58.765663 Test Step 1250 \"min loss\" =  7.747969\n",
      "2018-08-30 06:24:58.766246 Test Step 1250 \"loss\" =  7.950573\n",
      "2018-08-30 06:24:58.812453 Training Step 1250 Finished Timing (Training: 0.911576, Test: 0.0827174) after 0.251536 seconds\n",
      "2018-08-30 06:24:58.812524 Training Step 1250 \"min loss\" =  7.4870605\n",
      "2018-08-30 06:24:58.812906 Training Step 1250 \"loss\" =  8.130582\n",
      "2018-08-30 06:24:59.017086 Test Step 1255 Finished\n",
      "2018-08-30 06:24:59.017376 Test Step 1255 \"min loss\" =  7.747969\n",
      "2018-08-30 06:24:59.017659 Test Step 1255 \"loss\" =  8.694457\n",
      "2018-08-30 06:24:59.064515 Training Step 1255 Finished Timing (Training: 0.91152, Test: 0.0826811) after 0.251283 seconds\n",
      "2018-08-30 06:24:59.064646 Training Step 1255 \"min loss\" =  7.4870605\n",
      "2018-08-30 06:24:59.064707 Training Step 1255 \"loss\" =  8.242563\n",
      "2018-08-30 06:24:59.269559 Test Step 1260 Finished\n",
      "2018-08-30 06:24:59.269730 Test Step 1260 \"min loss\" =  7.747969\n",
      "2018-08-30 06:24:59.269812 Test Step 1260 \"loss\" =  8.091535\n",
      "2018-08-30 06:24:59.316496 Training Step 1260 Finished Timing (Training: 0.911482, Test: 0.0826886) after 0.251723 seconds\n",
      "2018-08-30 06:24:59.316572 Training Step 1260 \"min loss\" =  7.4870605\n",
      "2018-08-30 06:24:59.316649 Training Step 1260 \"loss\" =  7.723435\n",
      "2018-08-30 06:24:59.521604 Test Step 1265 Finished\n",
      "2018-08-30 06:24:59.521694 Test Step 1265 \"min loss\" =  7.747969\n",
      "2018-08-30 06:24:59.521754 Test Step 1265 \"loss\" =  7.8992257\n",
      "2018-08-30 06:24:59.568285 Training Step 1265 Finished Timing (Training: 0.911392, Test: 0.0826817) after 0.25101 seconds\n",
      "2018-08-30 06:24:59.568358 Training Step 1265 \"min loss\" =  7.4870605\n",
      "2018-08-30 06:24:59.568434 Training Step 1265 \"loss\" =  8.426713\n",
      "2018-08-30 06:24:59.773079 Test Step 1270 Finished\n",
      "2018-08-30 06:24:59.773237 Test Step 1270 \"min loss\" =  7.747969\n",
      "2018-08-30 06:24:59.773297 Test Step 1270 \"loss\" =  8.088128\n",
      "2018-08-30 06:24:59.819107 Training Step 1270 Finished Timing (Training: 0.911357, Test: 0.0827567) after 0.24981 seconds\n",
      "2018-08-30 06:24:59.819199 Training Step 1270 \"min loss\" =  7.4870605\n",
      "2018-08-30 06:24:59.819253 Training Step 1270 \"loss\" =  8.474192\n",
      "2018-08-30 06:25:00.024461 Test Step 1275 Finished\n",
      "2018-08-30 06:25:00.024561 Test Step 1275 \"min loss\" =  7.747969\n",
      "2018-08-30 06:25:00.024620 Test Step 1275 \"loss\" =  7.907884\n",
      "2018-08-30 06:25:00.070370 Training Step 1275 Finished Timing (Training: 0.911382, Test: 0.0827921) after 0.250247 seconds\n",
      "2018-08-30 06:25:00.070444 Training Step 1275 \"min loss\" =  7.4870605\n",
      "2018-08-30 06:25:00.070520 Training Step 1275 \"loss\" =  8.376235\n",
      "2018-08-30 06:25:00.274974 Test Step 1280 Finished\n",
      "2018-08-30 06:25:00.275100 Test Step 1280 \"min loss\" =  7.747969\n",
      "2018-08-30 06:25:00.275925 Test Step 1280 \"loss\" =  7.8423953\n",
      "2018-08-30 06:25:00.322012 Training Step 1280 Finished Timing (Training: 0.911225, Test: 0.082803) after 0.250839 seconds\n",
      "2018-08-30 06:25:00.322090 Training Step 1280 \"min loss\" =  7.4870605\n",
      "2018-08-30 06:25:00.322145 Training Step 1280 \"loss\" =  9.043472\n",
      "2018-08-30 06:25:00.527157 Test Step 1285 Finished\n",
      "2018-08-30 06:25:00.527237 Test Step 1285 \"min loss\" =  7.747969\n",
      "2018-08-30 06:25:00.527765 Test Step 1285 \"loss\" =  8.090794\n",
      "2018-08-30 06:25:00.573806 Training Step 1285 Finished Timing (Training: 0.911143, Test: 0.0828217) after 0.250985 seconds\n",
      "2018-08-30 06:25:00.573879 Training Step 1285 \"min loss\" =  7.4870605\n",
      "2018-08-30 06:25:00.573934 Training Step 1285 \"loss\" =  8.496915\n",
      "2018-08-30 06:25:00.779212 Test Step 1290 Finished\n",
      "2018-08-30 06:25:00.779607 Test Step 1290 \"min loss\" =  7.747969\n",
      "2018-08-30 06:25:00.779675 Test Step 1290 \"loss\" =  8.327998\n",
      "2018-08-30 06:25:00.825727 Training Step 1290 Finished Timing (Training: 0.91115, Test: 0.0828628) after 0.251188 seconds\n",
      "2018-08-30 06:25:00.825804 Training Step 1290 \"min loss\" =  7.4870605\n",
      "2018-08-30 06:25:00.826350 Training Step 1290 \"loss\" =  8.376776\n",
      "2018-08-30 06:25:01.031638 Test Step 1295 Finished\n",
      "2018-08-30 06:25:01.032052 Test Step 1295 \"min loss\" =  7.747969\n",
      "2018-08-30 06:25:01.032405 Test Step 1295 \"loss\" =  8.1953\n",
      "2018-08-30 06:25:01.078628 Training Step 1295 Finished Timing (Training: 0.911025, Test: 0.0829668) after 0.252143 seconds\n",
      "2018-08-30 06:25:01.078932 Training Step 1295 \"min loss\" =  7.4870605\n",
      "2018-08-30 06:25:01.079173 Training Step 1295 \"loss\" =  8.22039\n",
      "2018-08-30 06:25:01.283272 Test Step 1300 Finished\n",
      "2018-08-30 06:25:01.283759 Test Step 1300 \"min loss\" =  7.747969\n",
      "2018-08-30 06:25:01.284228 Test Step 1300 \"loss\" =  7.896381\n",
      "2018-08-30 06:25:01.330169 Training Step 1300 Finished Timing (Training: 0.910924, Test: 0.0829764) after 0.250613 seconds\n",
      "2018-08-30 06:25:01.330251 Training Step 1300 \"min loss\" =  7.4870605\n",
      "2018-08-30 06:25:01.330351 Training Step 1300 \"loss\" =  8.031002\n",
      "2018-08-30 06:25:01.538153 Test Step 1305 Finished\n",
      "2018-08-30 06:25:01.538281 Test Step 1305 \"min loss\" =  7.747969\n",
      "2018-08-30 06:25:01.539063 Test Step 1305 \"loss\" =  8.12227\n",
      "2018-08-30 06:25:01.585462 Training Step 1305 Finished Timing (Training: 0.910699, Test: 0.084256) after 0.254107 seconds\n",
      "2018-08-30 06:25:01.585690 Training Step 1305 \"min loss\" =  7.4870605\n",
      "2018-08-30 06:25:01.586117 Training Step 1305 \"loss\" =  7.831962\n",
      "2018-08-30 06:25:01.791024 Test Step 1310 Finished\n",
      "2018-08-30 06:25:01.791159 Test Step 1310 \"min loss\" =  7.747969\n",
      "2018-08-30 06:25:01.791782 Test Step 1310 \"loss\" =  8.256672\n",
      "2018-08-30 06:25:01.837679 Training Step 1310 Finished Timing (Training: 0.910378, Test: 0.0833674) after 0.251205 seconds\n",
      "2018-08-30 06:25:01.837787 Training Step 1310 \"min loss\" =  7.4870605\n",
      "2018-08-30 06:25:01.837863 Training Step 1310 \"loss\" =  7.620621\n",
      "2018-08-30 06:25:02.042473 Test Step 1315 Finished\n",
      "2018-08-30 06:25:02.042871 Test Step 1315 \"min loss\" =  7.747969\n",
      "2018-08-30 06:25:02.042938 Test Step 1315 \"loss\" =  8.490822\n",
      "2018-08-30 06:25:02.088715 Training Step 1315 Finished Timing (Training: 0.91165, Test: 0.0830882) after 0.250778 seconds\n",
      "2018-08-30 06:25:02.088795 Training Step 1315 \"min loss\" =  7.4870605\n",
      "2018-08-30 06:25:02.088855 Training Step 1315 \"loss\" =  7.543858\n",
      "2018-08-30 06:25:02.293338 Test Step 1320 Finished\n",
      "2018-08-30 06:25:02.293444 Test Step 1320 \"min loss\" =  7.747969\n",
      "2018-08-30 06:25:02.294162 Test Step 1320 \"loss\" =  8.304853\n",
      "2018-08-30 06:25:02.340520 Training Step 1320 Finished Timing (Training: 0.91149, Test: 0.0831115) after 0.251588 seconds\n",
      "2018-08-30 06:25:02.340821 Training Step 1320 \"min loss\" =  7.1456933\n",
      "2018-08-30 06:25:02.341146 Training Step 1320 \"loss\" =  7.228804\n",
      "2018-08-30 06:25:02.545736 Test Step 1325 Finished\n",
      "2018-08-30 06:25:02.545886 Test Step 1325 \"min loss\" =  7.747969\n",
      "2018-08-30 06:25:02.545950 Test Step 1325 \"loss\" =  8.10187\n",
      "2018-08-30 06:25:02.592785 Training Step 1325 Finished Timing (Training: 0.910849, Test: 0.0830363) after 0.251132 seconds\n",
      "2018-08-30 06:25:02.592856 Training Step 1325 \"min loss\" =  7.1456933\n",
      "2018-08-30 06:25:02.593204 Training Step 1325 \"loss\" =  7.289932\n",
      "2018-08-30 06:25:02.797417 Test Step 1330 Finished\n",
      "2018-08-30 06:25:02.797939 Test Step 1330 \"min loss\" =  7.747969\n",
      "2018-08-30 06:25:02.798266 Test Step 1330 \"loss\" =  8.2975855\n",
      "2018-08-30 06:25:02.844689 Training Step 1330 Finished Timing (Training: 0.910814, Test: 0.0829269) after 0.251414 seconds\n",
      "2018-08-30 06:25:02.844805 Training Step 1330 \"min loss\" =  7.1456933\n",
      "2018-08-30 06:25:02.845556 Training Step 1330 \"loss\" =  7.865345\n",
      "2018-08-30 06:25:03.050575 Test Step 1335 Finished\n",
      "2018-08-30 06:25:03.050675 Test Step 1335 \"min loss\" =  7.747969\n",
      "2018-08-30 06:25:03.051014 Test Step 1335 \"loss\" =  8.090446\n",
      "2018-08-30 06:25:03.097528 Training Step 1335 Finished Timing (Training: 0.910568, Test: 0.0828296) after 0.251709 seconds\n",
      "2018-08-30 06:25:03.097809 Training Step 1335 \"min loss\" =  7.1456933\n",
      "2018-08-30 06:25:03.098291 Training Step 1335 \"loss\" =  7.681816\n",
      "2018-08-30 06:25:03.303939 Test Step 1340 Finished\n",
      "2018-08-30 06:25:03.304061 Test Step 1340 \"min loss\" =  7.747969\n",
      "2018-08-30 06:25:03.304133 Test Step 1340 \"loss\" =  8.478214\n",
      "2018-08-30 06:25:03.350039 Training Step 1340 Finished Timing (Training: 0.910661, Test: 0.0828523) after 0.251363 seconds\n",
      "2018-08-30 06:25:03.350117 Training Step 1340 \"min loss\" =  7.1456933\n",
      "2018-08-30 06:25:03.350173 Training Step 1340 \"loss\" =  8.901647\n",
      "2018-08-30 06:25:03.554527 Test Step 1345 Finished\n",
      "2018-08-30 06:25:03.554860 Test Step 1345 \"min loss\" =  7.747969\n",
      "2018-08-30 06:25:03.555246 Test Step 1345 \"loss\" =  8.007218\n",
      "2018-08-30 06:25:03.601643 Training Step 1345 Finished Timing (Training: 0.910936, Test: 0.0828525) after 0.251406 seconds\n",
      "2018-08-30 06:25:03.601715 Training Step 1345 \"min loss\" =  7.1456933\n",
      "2018-08-30 06:25:03.601761 Training Step 1345 \"loss\" =  7.65048\n",
      "2018-08-30 06:25:03.807535 Test Step 1350 Finished\n",
      "2018-08-30 06:25:03.807957 Test Step 1350 \"min loss\" =  7.747969\n",
      "2018-08-30 06:25:03.808051 Test Step 1350 \"loss\" =  8.335343\n",
      "2018-08-30 06:25:03.854806 Training Step 1350 Finished Timing (Training: 0.910865, Test: 0.0828761) after 0.252064 seconds\n",
      "2018-08-30 06:25:03.854887 Training Step 1350 \"min loss\" =  7.1456933\n",
      "2018-08-30 06:25:03.854944 Training Step 1350 \"loss\" =  7.226698\n",
      "2018-08-30 06:25:04.060581 Test Step 1355 Finished\n",
      "2018-08-30 06:25:04.060703 Test Step 1355 \"min loss\" =  7.747969\n",
      "2018-08-30 06:25:04.061432 Test Step 1355 \"loss\" =  8.248518\n",
      "2018-08-30 06:25:04.107944 Training Step 1355 Finished Timing (Training: 0.910967, Test: 0.0828003) after 0.25289 seconds\n",
      "2018-08-30 06:25:04.108016 Training Step 1355 \"min loss\" =  7.1456933\n",
      "2018-08-30 06:25:04.108090 Training Step 1355 \"loss\" =  7.7903113\n",
      "2018-08-30 06:25:04.313065 Test Step 1360 Finished\n",
      "2018-08-30 06:25:04.313181 Test Step 1360 \"min loss\" =  7.747969\n",
      "2018-08-30 06:25:04.313278 Test Step 1360 \"loss\" =  8.08768\n",
      "2018-08-30 06:25:04.359668 Training Step 1360 Finished Timing (Training: 0.911296, Test: 0.0828149) after 0.251511 seconds\n",
      "2018-08-30 06:25:04.359761 Training Step 1360 \"min loss\" =  7.1456933\n",
      "2018-08-30 06:25:04.359817 Training Step 1360 \"loss\" =  7.4430294\n",
      "2018-08-30 06:25:04.566881 Test Step 1365 Finished\n",
      "2018-08-30 06:25:04.567004 Test Step 1365 \"min loss\" =  7.747969\n",
      "2018-08-30 06:25:04.567069 Test Step 1365 \"loss\" =  8.367874\n",
      "2018-08-30 06:25:04.613969 Training Step 1365 Finished Timing (Training: 0.911109, Test: 0.0830002) after 0.25307 seconds\n",
      "2018-08-30 06:25:04.614365 Training Step 1365 \"min loss\" =  6.9823585\n",
      "2018-08-30 06:25:04.614811 Training Step 1365 \"loss\" =  7.49161\n",
      "2018-08-30 06:25:04.819479 Test Step 1370 Finished\n",
      "2018-08-30 06:25:04.819791 Test Step 1370 \"min loss\" =  7.747969\n",
      "2018-08-30 06:25:04.820384 Test Step 1370 \"loss\" =  8.002414\n",
      "2018-08-30 06:25:04.866137 Training Step 1370 Finished Timing (Training: 0.910928, Test: 0.0829607) after 0.250887 seconds\n",
      "2018-08-30 06:25:04.866432 Training Step 1370 \"min loss\" =  6.9823585\n",
      "2018-08-30 06:25:04.866879 Training Step 1370 \"loss\" =  8.378324\n",
      "2018-08-30 06:25:05.071833 Test Step 1375 Finished\n",
      "2018-08-30 06:25:05.071960 Test Step 1375 \"min loss\" =  7.747969\n",
      "2018-08-30 06:25:05.072031 Test Step 1375 \"loss\" =  8.289773\n",
      "2018-08-30 06:25:05.118983 Training Step 1375 Finished Timing (Training: 0.911039, Test: 0.0829684) after 0.252038 seconds\n",
      "2018-08-30 06:25:05.119057 Training Step 1375 \"min loss\" =  6.9823585\n",
      "2018-08-30 06:25:05.119678 Training Step 1375 \"loss\" =  8.539014\n",
      "2018-08-30 06:25:05.324078 Test Step 1380 Finished\n",
      "2018-08-30 06:25:05.324199 Test Step 1380 \"min loss\" =  7.747969\n",
      "2018-08-30 06:25:05.324254 Test Step 1380 \"loss\" =  7.9502096\n",
      "2018-08-30 06:25:05.370869 Training Step 1380 Finished Timing (Training: 0.911192, Test: 0.0829336) after 0.251115 seconds\n",
      "2018-08-30 06:25:05.371172 Training Step 1380 \"min loss\" =  6.9823585\n",
      "2018-08-30 06:25:05.371246 Training Step 1380 \"loss\" =  8.031156\n",
      "2018-08-30 06:25:05.575402 Test Step 1385 Finished\n",
      "2018-08-30 06:25:05.575521 Test Step 1385 \"min loss\" =  7.747969\n",
      "2018-08-30 06:25:05.576026 Test Step 1385 \"loss\" =  8.491649\n",
      "2018-08-30 06:25:05.622399 Training Step 1385 Finished Timing (Training: 0.911169, Test: 0.0829164) after 0.251089 seconds\n",
      "2018-08-30 06:25:05.622483 Training Step 1385 \"min loss\" =  6.9823585\n",
      "2018-08-30 06:25:05.622568 Training Step 1385 \"loss\" =  7.933683\n",
      "2018-08-30 06:25:05.828291 Test Step 1390 Finished\n",
      "2018-08-30 06:25:05.828465 Test Step 1390 \"min loss\" =  7.747969\n",
      "2018-08-30 06:25:05.828623 Test Step 1390 \"loss\" =  8.17659\n",
      "2018-08-30 06:25:05.875597 Training Step 1390 Finished Timing (Training: 0.911053, Test: 0.0828994) after 0.252348 seconds\n",
      "2018-08-30 06:25:05.875719 Training Step 1390 \"min loss\" =  6.9823585\n",
      "2018-08-30 06:25:05.875786 Training Step 1390 \"loss\" =  7.685642\n",
      "2018-08-30 06:25:06.082346 Test Step 1395 Finished\n",
      "2018-08-30 06:25:06.082462 Test Step 1395 \"min loss\" =  7.747969\n",
      "2018-08-30 06:25:06.083007 Test Step 1395 \"loss\" =  9.01582\n",
      "2018-08-30 06:25:06.128811 Training Step 1395 Finished Timing (Training: 0.911091, Test: 0.082969) after 0.252958 seconds\n",
      "2018-08-30 06:25:06.129325 Training Step 1395 \"min loss\" =  6.840047\n",
      "2018-08-30 06:25:06.129396 Training Step 1395 \"loss\" =  7.2923913\n",
      "2018-08-30 06:25:06.333697 Test Step 1400 Finished\n",
      "2018-08-30 06:25:06.333855 Test Step 1400 \"min loss\" =  7.747969\n",
      "2018-08-30 06:25:06.333941 Test Step 1400 \"loss\" =  8.181194\n",
      "2018-08-30 06:25:06.380158 Training Step 1400 Finished Timing (Training: 0.911179, Test: 0.0829818) after 0.250698 seconds\n",
      "2018-08-30 06:25:06.380242 Training Step 1400 \"min loss\" =  6.840047\n",
      "2018-08-30 06:25:06.380302 Training Step 1400 \"loss\" =  7.5457563\n",
      "2018-08-30 06:25:06.584505 Test Step 1405 Finished\n",
      "2018-08-30 06:25:06.584593 Test Step 1405 \"min loss\" =  7.747969\n",
      "2018-08-30 06:25:06.584653 Test Step 1405 \"loss\" =  8.027593\n",
      "2018-08-30 06:25:06.631386 Training Step 1405 Finished Timing (Training: 0.917071, Test: 0.0820334) after 0.251022 seconds\n",
      "2018-08-30 06:25:06.631627 Training Step 1405 \"min loss\" =  6.840047\n",
      "2018-08-30 06:25:06.631690 Training Step 1405 \"loss\" =  7.9968395\n",
      "2018-08-30 06:25:06.835712 Test Step 1410 Finished\n",
      "2018-08-30 06:25:06.836208 Test Step 1410 \"min loss\" =  7.747969\n",
      "2018-08-30 06:25:06.836342 Test Step 1410 \"loss\" =  8.059885\n",
      "2018-08-30 06:25:06.882243 Training Step 1410 Finished Timing (Training: 0.915056, Test: 0.0823064) after 0.250481 seconds\n",
      "2018-08-30 06:25:06.882351 Training Step 1410 \"min loss\" =  6.840047\n",
      "2018-08-30 06:25:06.882444 Training Step 1410 \"loss\" =  7.332361\n",
      "2018-08-30 06:25:07.087905 Test Step 1415 Finished\n",
      "2018-08-30 06:25:07.088255 Test Step 1415 \"min loss\" =  7.747969\n",
      "2018-08-30 06:25:07.088322 Test Step 1415 \"loss\" =  8.051301\n",
      "2018-08-30 06:25:07.134160 Training Step 1415 Finished Timing (Training: 0.914919, Test: 0.0821959) after 0.251602 seconds\n",
      "2018-08-30 06:25:07.134405 Training Step 1415 \"min loss\" =  6.840047\n",
      "2018-08-30 06:25:07.134812 Training Step 1415 \"loss\" =  7.3197856\n",
      "2018-08-30 06:25:07.346478 Test Step 1420 Finished\n",
      "2018-08-30 06:25:07.346952 Test Step 1420 \"min loss\" =  7.747969\n",
      "2018-08-30 06:25:07.347012 Test Step 1420 \"loss\" =  8.292811\n",
      "2018-08-30 06:25:07.392936 Training Step 1420 Finished Timing (Training: 0.907566, Test: 0.088817) after 0.257906 seconds\n",
      "2018-08-30 06:25:07.393039 Training Step 1420 \"min loss\" =  6.5159492\n",
      "2018-08-30 06:25:07.393096 Training Step 1420 \"loss\" =  7.848015\n",
      "2018-08-30 06:25:07.596902 Test Step 1425 Finished\n",
      "2018-08-30 06:25:07.597233 Test Step 1425 \"min loss\" =  7.747969\n",
      "2018-08-30 06:25:07.597754 Test Step 1425 \"loss\" =  7.9782248\n",
      "2018-08-30 06:25:07.643802 Training Step 1425 Finished Timing (Training: 0.908444, Test: 0.0875753) after 0.25063 seconds\n",
      "2018-08-30 06:25:07.644204 Training Step 1425 \"min loss\" =  6.5159492\n",
      "2018-08-30 06:25:07.644661 Training Step 1425 \"loss\" =  6.8197837\n",
      "2018-08-30 06:25:07.848227 Test Step 1430 Finished\n",
      "2018-08-30 06:25:07.848317 Test Step 1430 \"min loss\" =  7.673839\n",
      "2018-08-30 06:25:07.848373 Test Step 1430 \"loss\" =  7.673839\n",
      "2018-08-30 06:25:07.894274 Training Step 1430 Finished Timing (Training: 0.909215, Test: 0.0866943) after 0.249542 seconds\n",
      "2018-08-30 06:25:07.894380 Training Step 1430 \"min loss\" =  6.5159492\n",
      "2018-08-30 06:25:07.894893 Training Step 1430 \"loss\" =  7.6841297\n",
      "2018-08-30 06:25:08.098943 Test Step 1435 Finished\n",
      "2018-08-30 06:25:08.099074 Test Step 1435 \"min loss\" =  7.673839\n",
      "2018-08-30 06:25:08.099715 Test Step 1435 \"loss\" =  7.8820877\n",
      "2018-08-30 06:25:08.146095 Training Step 1435 Finished Timing (Training: 0.909402, Test: 0.0861067) after 0.250946 seconds\n",
      "2018-08-30 06:25:08.146181 Training Step 1435 \"min loss\" =  6.5159492\n",
      "2018-08-30 06:25:08.146985 Training Step 1435 \"loss\" =  7.1173377\n",
      "2018-08-30 06:25:08.351605 Test Step 1440 Finished\n",
      "2018-08-30 06:25:08.351698 Test Step 1440 \"min loss\" =  7.673839\n",
      "2018-08-30 06:25:08.351756 Test Step 1440 \"loss\" =  7.7471538\n",
      "2018-08-30 06:25:08.398332 Training Step 1440 Finished Timing (Training: 0.90955, Test: 0.0856034) after 0.251276 seconds\n",
      "2018-08-30 06:25:08.398404 Training Step 1440 \"min loss\" =  6.5159492\n",
      "2018-08-30 06:25:08.398497 Training Step 1440 \"loss\" =  7.203023\n",
      "2018-08-30 06:25:08.602192 Test Step 1445 Finished\n",
      "2018-08-30 06:25:08.602282 Test Step 1445 \"min loss\" =  7.673839\n",
      "2018-08-30 06:25:08.602896 Test Step 1445 \"loss\" =  7.8158426\n",
      "2018-08-30 06:25:08.648922 Training Step 1445 Finished Timing (Training: 0.909916, Test: 0.0852601) after 0.250362 seconds\n",
      "2018-08-30 06:25:08.649028 Training Step 1445 \"min loss\" =  6.5159492\n",
      "2018-08-30 06:25:08.649599 Training Step 1445 \"loss\" =  6.6584215\n",
      "2018-08-30 06:25:08.853877 Test Step 1450 Finished\n",
      "2018-08-30 06:25:08.854131 Test Step 1450 \"min loss\" =  7.673839\n",
      "2018-08-30 06:25:08.854189 Test Step 1450 \"loss\" =  7.7296605\n",
      "2018-08-30 06:25:08.901155 Training Step 1450 Finished Timing (Training: 0.909817, Test: 0.0851389) after 0.25133 seconds\n",
      "2018-08-30 06:25:08.901485 Training Step 1450 \"min loss\" =  6.5159492\n",
      "2018-08-30 06:25:08.901548 Training Step 1450 \"loss\" =  7.6365404\n",
      "2018-08-30 06:25:09.106218 Test Step 1455 Finished\n",
      "2018-08-30 06:25:09.106299 Test Step 1455 \"min loss\" =  7.586621\n",
      "2018-08-30 06:25:09.106835 Test Step 1455 \"loss\" =  7.586621\n",
      "2018-08-30 06:25:09.152988 Training Step 1455 Finished Timing (Training: 0.909974, Test: 0.0849011) after 0.25103 seconds\n",
      "2018-08-30 06:25:09.153330 Training Step 1455 \"min loss\" =  6.5159492\n",
      "2018-08-30 06:25:09.153678 Training Step 1455 \"loss\" =  7.6417437\n",
      "2018-08-30 06:25:09.358216 Test Step 1460 Finished\n",
      "2018-08-30 06:25:09.358535 Test Step 1460 \"min loss\" =  7.586621\n",
      "2018-08-30 06:25:09.358730 Test Step 1460 \"loss\" =  7.6325297\n",
      "2018-08-30 06:25:09.404988 Training Step 1460 Finished Timing (Training: 0.910065, Test: 0.0846992) after 0.251225 seconds\n",
      "2018-08-30 06:25:09.405257 Training Step 1460 \"min loss\" =  6.5159492\n",
      "2018-08-30 06:25:09.405536 Training Step 1460 \"loss\" =  7.1320505\n",
      "2018-08-30 06:25:09.609902 Test Step 1465 Finished\n",
      "2018-08-30 06:25:09.609989 Test Step 1465 \"min loss\" =  7.586621\n",
      "2018-08-30 06:25:09.610441 Test Step 1465 \"loss\" =  8.058726\n",
      "2018-08-30 06:25:09.656632 Training Step 1465 Finished Timing (Training: 0.910098, Test: 0.0845626) after 0.250857 seconds\n",
      "2018-08-30 06:25:09.656710 Training Step 1465 \"min loss\" =  6.5159492\n",
      "2018-08-30 06:25:09.656769 Training Step 1465 \"loss\" =  7.2907944\n",
      "2018-08-30 06:25:09.861291 Test Step 1470 Finished\n",
      "2018-08-30 06:25:09.861372 Test Step 1470 \"min loss\" =  7.586621\n",
      "2018-08-30 06:25:09.861821 Test Step 1470 \"loss\" =  7.7528663\n",
      "2018-08-30 06:25:09.908091 Training Step 1470 Finished Timing (Training: 0.910234, Test: 0.0843357) after 0.250653 seconds\n",
      "2018-08-30 06:25:09.908173 Training Step 1470 \"min loss\" =  6.5159492\n",
      "2018-08-30 06:25:09.908231 Training Step 1470 \"loss\" =  6.632756\n",
      "2018-08-30 06:25:10.113115 Test Step 1475 Finished\n",
      "2018-08-30 06:25:10.113404 Test Step 1475 \"min loss\" =  7.586621\n",
      "2018-08-30 06:25:10.113687 Test Step 1475 \"loss\" =  7.5995474\n",
      "2018-08-30 06:25:10.160286 Training Step 1475 Finished Timing (Training: 0.910272, Test: 0.0842139) after 0.251426 seconds\n",
      "2018-08-30 06:25:10.160365 Training Step 1475 \"min loss\" =  6.5159492\n",
      "2018-08-30 06:25:10.160424 Training Step 1475 \"loss\" =  7.0247455\n",
      "2018-08-30 06:25:10.366091 Test Step 1480 Finished\n",
      "2018-08-30 06:25:10.366185 Test Step 1480 \"min loss\" =  7.4191127\n",
      "2018-08-30 06:25:10.366623 Test Step 1480 \"loss\" =  7.4191127\n",
      "2018-08-30 06:25:10.412761 Training Step 1480 Finished Timing (Training: 0.910344, Test: 0.0840736) after 0.251689 seconds\n",
      "2018-08-30 06:25:10.412831 Training Step 1480 \"min loss\" =  6.5159492\n",
      "2018-08-30 06:25:10.412886 Training Step 1480 \"loss\" =  6.7463946\n",
      "2018-08-30 06:25:10.617078 Test Step 1485 Finished\n",
      "2018-08-30 06:25:10.617496 Test Step 1485 \"min loss\" =  7.4191127\n",
      "2018-08-30 06:25:10.617732 Test Step 1485 \"loss\" =  7.4988294\n",
      "2018-08-30 06:25:10.663827 Training Step 1485 Finished Timing (Training: 0.910384, Test: 0.0839606) after 0.250249 seconds\n",
      "2018-08-30 06:25:10.663943 Training Step 1485 \"min loss\" =  6.5159492\n",
      "2018-08-30 06:25:10.664008 Training Step 1485 \"loss\" =  7.5288253\n",
      "2018-08-30 06:25:10.868570 Test Step 1490 Finished\n",
      "2018-08-30 06:25:10.869013 Test Step 1490 \"min loss\" =  7.4191127\n",
      "2018-08-30 06:25:10.869549 Test Step 1490 \"loss\" =  7.890158\n",
      "2018-08-30 06:25:10.915408 Training Step 1490 Finished Timing (Training: 0.910344, Test: 0.0838277) after 0.250476 seconds\n",
      "2018-08-30 06:25:10.915783 Training Step 1490 \"min loss\" =  6.5159492\n",
      "2018-08-30 06:25:10.916125 Training Step 1490 \"loss\" =  8.495791\n",
      "2018-08-30 06:25:11.120378 Test Step 1495 Finished\n",
      "2018-08-30 06:25:11.120808 Test Step 1495 \"min loss\" =  7.4191127\n",
      "2018-08-30 06:25:11.121116 Test Step 1495 \"loss\" =  8.0969925\n",
      "2018-08-30 06:25:11.167313 Training Step 1495 Finished Timing (Training: 0.910156, Test: 0.0837935) after 0.250607 seconds\n",
      "2018-08-30 06:25:11.167402 Training Step 1495 \"min loss\" =  6.5159492\n",
      "2018-08-30 06:25:11.168178 Training Step 1495 \"loss\" =  7.338666\n",
      "2018-08-30 06:25:11.372020 Test Step 1500 Finished\n",
      "2018-08-30 06:25:11.372452 Test Step 1500 \"min loss\" =  7.4191127\n",
      "2018-08-30 06:25:11.372983 Test Step 1500 \"loss\" =  7.967848\n",
      "2018-08-30 06:25:11.419016 Training Step 1500 Finished Timing (Training: 0.910045, Test: 0.0836719) after 0.250343 seconds\n",
      "2018-08-30 06:25:11.419356 Training Step 1500 \"min loss\" =  6.5159492\n",
      "2018-08-30 06:25:11.419698 Training Step 1500 \"loss\" =  7.1087894\n",
      "2018-08-30 06:25:11.623779 Test Step 1505 Finished\n",
      "2018-08-30 06:25:11.623881 Test Step 1505 \"min loss\" =  7.4191127\n",
      "2018-08-30 06:25:11.624482 Test Step 1505 \"loss\" =  7.8261743\n",
      "2018-08-30 06:25:11.670824 Training Step 1505 Finished Timing (Training: 0.912663, Test: 0.0816709) after 0.250786 seconds\n",
      "2018-08-30 06:25:11.671097 Training Step 1505 \"min loss\" =  6.5159492\n",
      "2018-08-30 06:25:11.671199 Training Step 1505 \"loss\" =  7.064068\n",
      "2018-08-30 06:25:11.875576 Test Step 1510 Finished\n",
      "2018-08-30 06:25:11.875681 Test Step 1510 \"min loss\" =  7.4191127\n",
      "2018-08-30 06:25:11.876556 Test Step 1510 \"loss\" =  8.023353\n",
      "2018-08-30 06:25:11.922652 Training Step 1510 Finished Timing (Training: 0.911387, Test: 0.081878) after 0.251346 seconds\n",
      "2018-08-30 06:25:11.922745 Training Step 1510 \"min loss\" =  6.5159492\n",
      "2018-08-30 06:25:11.922868 Training Step 1510 \"loss\" =  7.340667\n",
      "2018-08-30 06:25:12.127833 Test Step 1515 Finished\n",
      "2018-08-30 06:25:12.127951 Test Step 1515 \"min loss\" =  7.4191127\n",
      "2018-08-30 06:25:12.128662 Test Step 1515 \"loss\" =  7.8173122\n",
      "2018-08-30 06:25:12.175136 Training Step 1515 Finished Timing (Training: 0.911656, Test: 0.0815228) after 0.252149 seconds\n",
      "2018-08-30 06:25:12.175239 Training Step 1515 \"min loss\" =  6.5159492\n",
      "2018-08-30 06:25:12.175349 Training Step 1515 \"loss\" =  7.133287\n",
      "2018-08-30 06:25:12.380188 Test Step 1520 Finished\n",
      "2018-08-30 06:25:12.380638 Test Step 1520 \"min loss\" =  7.4191127\n",
      "2018-08-30 06:25:12.381167 Test Step 1520 \"loss\" =  7.8821588\n",
      "2018-08-30 06:25:12.427521 Training Step 1520 Finished Timing (Training: 0.910804, Test: 0.0816424) after 0.25128 seconds\n",
      "2018-08-30 06:25:12.427596 Training Step 1520 \"min loss\" =  6.5159492\n",
      "2018-08-30 06:25:12.428321 Training Step 1520 \"loss\" =  6.7944846\n",
      "2018-08-30 06:25:12.631952 Test Step 1525 Finished\n",
      "2018-08-30 06:25:12.632068 Test Step 1525 \"min loss\" =  7.4191127\n",
      "2018-08-30 06:25:12.632896 Test Step 1525 \"loss\" =  7.979733\n",
      "2018-08-30 06:25:12.678857 Training Step 1525 Finished Timing (Training: 0.910176, Test: 0.0818248) after 0.250185 seconds\n",
      "2018-08-30 06:25:12.678941 Training Step 1525 \"min loss\" =  6.5159492\n",
      "2018-08-30 06:25:12.679709 Training Step 1525 \"loss\" =  6.8836637\n",
      "2018-08-30 06:25:12.883517 Test Step 1530 Finished\n",
      "2018-08-30 06:25:12.883931 Test Step 1530 \"min loss\" =  7.4191127\n",
      "2018-08-30 06:25:12.884450 Test Step 1530 \"loss\" =  8.05526\n",
      "2018-08-30 06:25:12.930450 Training Step 1530 Finished Timing (Training: 0.909819, Test: 0.0818613) after 0.250395 seconds\n",
      "2018-08-30 06:25:12.930524 Training Step 1530 \"min loss\" =  6.5159492\n",
      "2018-08-30 06:25:12.931122 Training Step 1530 \"loss\" =  6.881216\n",
      "2018-08-30 06:25:13.134718 Test Step 1535 Finished\n",
      "2018-08-30 06:25:13.135178 Test Step 1535 \"min loss\" =  7.4191127\n",
      "2018-08-30 06:25:13.135774 Test Step 1535 \"loss\" =  7.9939303\n",
      "2018-08-30 06:25:13.182021 Training Step 1535 Finished Timing (Training: 0.909466, Test: 0.0818719) after 0.250298 seconds\n",
      "2018-08-30 06:25:13.182145 Training Step 1535 \"min loss\" =  6.5159492\n",
      "2018-08-30 06:25:13.182937 Training Step 1535 \"loss\" =  7.4133325\n",
      "2018-08-30 06:25:13.386855 Test Step 1540 Finished\n",
      "2018-08-30 06:25:13.386972 Test Step 1540 \"min loss\" =  7.4191127\n",
      "2018-08-30 06:25:13.387823 Test Step 1540 \"loss\" =  8.064249\n",
      "2018-08-30 06:25:13.433837 Training Step 1540 Finished Timing (Training: 0.909149, Test: 0.0819765) after 0.250551 seconds\n",
      "2018-08-30 06:25:13.433920 Training Step 1540 \"min loss\" =  6.5159492\n",
      "2018-08-30 06:25:13.434669 Training Step 1540 \"loss\" =  6.7203846\n",
      "2018-08-30 06:25:13.638458 Test Step 1545 Finished\n",
      "2018-08-30 06:25:13.638891 Test Step 1545 \"min loss\" =  7.4191127\n",
      "2018-08-30 06:25:13.639417 Test Step 1545 \"loss\" =  7.785907\n",
      "2018-08-30 06:25:13.685386 Training Step 1545 Finished Timing (Training: 0.909038, Test: 0.0819683) after 0.250371 seconds\n",
      "2018-08-30 06:25:13.685465 Training Step 1545 \"min loss\" =  6.5159492\n",
      "2018-08-30 06:25:13.686210 Training Step 1545 \"loss\" =  7.147384\n",
      "2018-08-30 06:25:13.889690 Test Step 1550 Finished\n",
      "2018-08-30 06:25:13.889762 Test Step 1550 \"min loss\" =  7.4191127\n",
      "2018-08-30 06:25:13.890499 Test Step 1550 \"loss\" =  7.8015814\n",
      "2018-08-30 06:25:13.936712 Training Step 1550 Finished Timing (Training: 0.909218, Test: 0.0819658) after 0.250407 seconds\n",
      "2018-08-30 06:25:13.936775 Training Step 1550 \"min loss\" =  6.4213576\n",
      "2018-08-30 06:25:13.937210 Training Step 1550 \"loss\" =  7.4844255\n",
      "2018-08-30 06:25:14.141555 Test Step 1555 Finished\n",
      "2018-08-30 06:25:14.141630 Test Step 1555 \"min loss\" =  7.4191127\n",
      "2018-08-30 06:25:14.142265 Test Step 1555 \"loss\" =  8.336655\n",
      "2018-08-30 06:25:14.188396 Training Step 1555 Finished Timing (Training: 0.909453, Test: 0.0819127) after 0.250767 seconds\n",
      "2018-08-30 06:25:14.188460 Training Step 1555 \"min loss\" =  6.4213576\n",
      "2018-08-30 06:25:14.189009 Training Step 1555 \"loss\" =  6.863282\n",
      "2018-08-30 06:25:14.392545 Test Step 1560 Finished\n",
      "2018-08-30 06:25:14.393006 Test Step 1560 \"min loss\" =  7.4191127\n",
      "2018-08-30 06:25:14.393426 Test Step 1560 \"loss\" =  7.9507866\n",
      "2018-08-30 06:25:14.439596 Training Step 1560 Finished Timing (Training: 0.909465, Test: 0.0819306) after 0.250495 seconds\n",
      "2018-08-30 06:25:14.439676 Training Step 1560 \"min loss\" =  6.4213576\n",
      "2018-08-30 06:25:14.440425 Training Step 1560 \"loss\" =  7.4328423\n",
      "2018-08-30 06:25:14.644437 Test Step 1565 Finished\n",
      "2018-08-30 06:25:14.644880 Test Step 1565 \"min loss\" =  7.4191127\n",
      "2018-08-30 06:25:14.645186 Test Step 1565 \"loss\" =  7.79466\n",
      "2018-08-30 06:25:14.691645 Training Step 1565 Finished Timing (Training: 0.909348, Test: 0.0819713) after 0.251122 seconds\n",
      "2018-08-30 06:25:14.691732 Training Step 1565 \"min loss\" =  6.140988\n",
      "2018-08-30 06:25:14.692494 Training Step 1565 \"loss\" =  6.140988\n",
      "2018-08-30 06:25:14.896524 Test Step 1570 Finished\n",
      "2018-08-30 06:25:14.897007 Test Step 1570 \"min loss\" =  7.4191127\n",
      "2018-08-30 06:25:14.897429 Test Step 1570 \"loss\" =  7.6027937\n",
      "2018-08-30 06:25:14.943587 Training Step 1570 Finished Timing (Training: 0.909272, Test: 0.0819622) after 0.250742 seconds\n",
      "2018-08-30 06:25:14.943668 Training Step 1570 \"min loss\" =  6.140988\n",
      "2018-08-30 06:25:14.944408 Training Step 1570 \"loss\" =  6.9972215\n",
      "2018-08-30 06:25:15.148652 Test Step 1575 Finished\n",
      "2018-08-30 06:25:15.149160 Test Step 1575 \"min loss\" =  7.4191127\n",
      "2018-08-30 06:25:15.149617 Test Step 1575 \"loss\" =  7.549201\n",
      "2018-08-30 06:25:15.196204 Training Step 1575 Finished Timing (Training: 0.909196, Test: 0.0819667) after 0.251668 seconds\n",
      "2018-08-30 06:25:15.196347 Training Step 1575 \"min loss\" =  6.140988\n",
      "2018-08-30 06:25:15.197009 Training Step 1575 \"loss\" =  7.366975\n",
      "2018-08-30 06:25:15.400886 Test Step 1580 Finished\n",
      "2018-08-30 06:25:15.400989 Test Step 1580 \"min loss\" =  7.4191127\n",
      "2018-08-30 06:25:15.401865 Test Step 1580 \"loss\" =  8.02766\n",
      "2018-08-30 06:25:15.448149 Training Step 1580 Finished Timing (Training: 0.909032, Test: 0.0819838) after 0.250595 seconds\n",
      "2018-08-30 06:25:15.448566 Training Step 1580 \"min loss\" =  6.140988\n",
      "2018-08-30 06:25:15.449067 Training Step 1580 \"loss\" =  6.5655866\n",
      "2018-08-30 06:25:15.653713 Test Step 1585 Finished\n",
      "2018-08-30 06:25:15.653828 Test Step 1585 \"min loss\" =  7.4191127\n",
      "2018-08-30 06:25:15.654679 Test Step 1585 \"loss\" =  8.360261\n",
      "2018-08-30 06:25:15.700798 Training Step 1585 Finished Timing (Training: 0.908929, Test: 0.0819697) after 0.251221 seconds\n",
      "2018-08-30 06:25:15.700882 Training Step 1585 \"min loss\" =  6.140988\n",
      "2018-08-30 06:25:15.701647 Training Step 1585 \"loss\" =  6.5875626\n",
      "2018-08-30 06:25:15.906502 Test Step 1590 Finished\n",
      "2018-08-30 06:25:15.906942 Test Step 1590 \"min loss\" =  7.4191127\n",
      "2018-08-30 06:25:15.907475 Test Step 1590 \"loss\" =  7.8222485\n",
      "2018-08-30 06:25:15.953666 Training Step 1590 Finished Timing (Training: 0.908811, Test: 0.081983) after 0.251553 seconds\n",
      "2018-08-30 06:25:15.954042 Training Step 1590 \"min loss\" =  6.140988\n",
      "2018-08-30 06:25:15.954575 Training Step 1590 \"loss\" =  6.772476\n",
      "2018-08-30 06:25:16.158610 Test Step 1595 Finished\n",
      "2018-08-30 06:25:16.159075 Test Step 1595 \"min loss\" =  7.4191127\n",
      "2018-08-30 06:25:16.159605 Test Step 1595 \"loss\" =  7.6957254\n",
      "2018-08-30 06:25:16.205888 Training Step 1595 Finished Timing (Training: 0.908788, Test: 0.0819959) after 0.251214 seconds\n",
      "2018-08-30 06:25:16.205974 Training Step 1595 \"min loss\" =  6.140988\n",
      "2018-08-30 06:25:16.206784 Training Step 1595 \"loss\" =  7.139836\n",
      "2018-08-30 06:25:16.411236 Test Step 1600 Finished\n",
      "2018-08-30 06:25:16.411346 Test Step 1600 \"min loss\" =  7.4191127\n",
      "2018-08-30 06:25:16.412092 Test Step 1600 \"loss\" =  7.48716\n",
      "2018-08-30 06:25:16.458302 Training Step 1600 Finished Timing (Training: 0.908715, Test: 0.0819932) after 0.251059 seconds\n",
      "2018-08-30 06:25:16.458386 Training Step 1600 \"min loss\" =  6.140988\n",
      "2018-08-30 06:25:16.458481 Training Step 1600 \"loss\" =  7.7886057\n",
      "2018-08-30 06:25:16.661925 Test Step 1605 Finished\n",
      "2018-08-30 06:25:16.662403 Test Step 1605 \"min loss\" =  7.4191127\n",
      "2018-08-30 06:25:16.662499 Test Step 1605 \"loss\" =  7.475132\n",
      "2018-08-30 06:25:16.708890 Training Step 1605 Finished Timing (Training: 0.913056, Test: 0.0820196) after 0.250306 seconds\n",
      "2018-08-30 06:25:16.708982 Training Step 1605 \"min loss\" =  6.140988\n",
      "2018-08-30 06:25:16.709111 Training Step 1605 \"loss\" =  6.795364\n",
      "2018-08-30 06:25:16.913720 Test Step 1610 Finished\n",
      "2018-08-30 06:25:16.914196 Test Step 1610 \"min loss\" =  7.4191127\n",
      "2018-08-30 06:25:16.914724 Test Step 1610 \"loss\" =  7.542316\n",
      "2018-08-30 06:25:16.960893 Training Step 1610 Finished Timing (Training: 0.909832, Test: 0.0819544) after 0.25061 seconds\n",
      "2018-08-30 06:25:16.960980 Training Step 1610 \"min loss\" =  6.140988\n",
      "2018-08-30 06:25:16.961721 Training Step 1610 \"loss\" =  6.8457055\n",
      "2018-08-30 06:25:17.166203 Test Step 1615 Finished\n",
      "2018-08-30 06:25:17.166295 Test Step 1615 \"min loss\" =  7.4191127\n",
      "2018-08-30 06:25:17.166411 Test Step 1615 \"loss\" =  7.7366614\n",
      "2018-08-30 06:25:17.213371 Training Step 1615 Finished Timing (Training: 0.909139, Test: 0.0820712) after 0.251306 seconds\n",
      "2018-08-30 06:25:17.213452 Training Step 1615 \"min loss\" =  6.140988\n",
      "2018-08-30 06:25:17.214202 Training Step 1615 \"loss\" =  7.4990005\n",
      "2018-08-30 06:25:17.418487 Test Step 1620 Finished\n",
      "2018-08-30 06:25:17.418615 Test Step 1620 \"min loss\" =  7.4191127\n",
      "2018-08-30 06:25:17.419462 Test Step 1620 \"loss\" =  8.195872\n",
      "2018-08-30 06:25:17.465586 Training Step 1620 Finished Timing (Training: 0.908852, Test: 0.082056) after 0.251036 seconds\n",
      "2018-08-30 06:25:17.465664 Training Step 1620 \"min loss\" =  6.140988\n",
      "2018-08-30 06:25:17.466162 Training Step 1620 \"loss\" =  6.748017\n",
      "2018-08-30 06:25:17.670257 Test Step 1625 Finished\n",
      "2018-08-30 06:25:17.670689 Test Step 1625 \"min loss\" =  7.4191127\n",
      "2018-08-30 06:25:17.670974 Test Step 1625 \"loss\" =  7.866171\n",
      "2018-08-30 06:25:17.717727 Training Step 1625 Finished Timing (Training: 0.908719, Test: 0.0818569) after 0.250862 seconds\n",
      "2018-08-30 06:25:17.718100 Training Step 1625 \"min loss\" =  6.140988\n",
      "2018-08-30 06:25:17.718447 Training Step 1625 \"loss\" =  7.226081\n",
      "2018-08-30 06:25:17.924220 Test Step 1630 Finished\n",
      "2018-08-30 06:25:17.924577 Test Step 1630 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:17.924642 Test Step 1630 \"loss\" =  7.2904453\n",
      "2018-08-30 06:25:17.970438 Training Step 1630 Finished Timing (Training: 0.90907, Test: 0.0818825) after 0.251409 seconds\n",
      "2018-08-30 06:25:17.970715 Training Step 1630 \"min loss\" =  6.140988\n",
      "2018-08-30 06:25:17.970778 Training Step 1630 \"loss\" =  7.0738106\n",
      "2018-08-30 06:25:18.176199 Test Step 1635 Finished\n",
      "2018-08-30 06:25:18.176290 Test Step 1635 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:18.176353 Test Step 1635 \"loss\" =  7.430648\n",
      "2018-08-30 06:25:18.223069 Training Step 1635 Finished Timing (Training: 0.909331, Test: 0.0822777) after 0.25176 seconds\n",
      "2018-08-30 06:25:18.223159 Training Step 1635 \"min loss\" =  6.140988\n",
      "2018-08-30 06:25:18.223234 Training Step 1635 \"loss\" =  7.048192\n",
      "2018-08-30 06:25:18.427930 Test Step 1640 Finished\n",
      "2018-08-30 06:25:18.428179 Test Step 1640 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:18.428465 Test Step 1640 \"loss\" =  7.7432175\n",
      "2018-08-30 06:25:18.475016 Training Step 1640 Finished Timing (Training: 0.909679, Test: 0.082344) after 0.251716 seconds\n",
      "2018-08-30 06:25:18.475307 Training Step 1640 \"min loss\" =  6.140988\n",
      "2018-08-30 06:25:18.475369 Training Step 1640 \"loss\" =  7.047655\n",
      "2018-08-30 06:25:18.679642 Test Step 1645 Finished\n",
      "2018-08-30 06:25:18.679872 Test Step 1645 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:18.680331 Test Step 1645 \"loss\" =  8.416289\n",
      "2018-08-30 06:25:18.726453 Training Step 1645 Finished Timing (Training: 0.909593, Test: 0.0824359) after 0.250492 seconds\n",
      "2018-08-30 06:25:18.726576 Training Step 1645 \"min loss\" =  6.140988\n",
      "2018-08-30 06:25:18.726635 Training Step 1645 \"loss\" =  6.9617753\n",
      "2018-08-30 06:25:18.930435 Test Step 1650 Finished\n",
      "2018-08-30 06:25:18.930536 Test Step 1650 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:18.930595 Test Step 1650 \"loss\" =  7.6132708\n",
      "2018-08-30 06:25:18.977049 Training Step 1650 Finished Timing (Training: 0.910223, Test: 0.0824007) after 0.250347 seconds\n",
      "2018-08-30 06:25:18.977113 Training Step 1650 \"min loss\" =  6.140988\n",
      "2018-08-30 06:25:18.977173 Training Step 1650 \"loss\" =  6.937404\n",
      "2018-08-30 06:25:19.182437 Test Step 1655 Finished\n",
      "2018-08-30 06:25:19.182830 Test Step 1655 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:19.182895 Test Step 1655 \"loss\" =  7.5379486\n",
      "2018-08-30 06:25:19.229161 Training Step 1655 Finished Timing (Training: 0.910573, Test: 0.082451) after 0.251902 seconds\n",
      "2018-08-30 06:25:19.229252 Training Step 1655 \"min loss\" =  6.140988\n",
      "2018-08-30 06:25:19.229316 Training Step 1655 \"loss\" =  6.2974806\n",
      "2018-08-30 06:25:19.434786 Test Step 1660 Finished\n",
      "2018-08-30 06:25:19.434865 Test Step 1660 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:19.435284 Test Step 1660 \"loss\" =  7.5506077\n",
      "2018-08-30 06:25:19.481455 Training Step 1660 Finished Timing (Training: 0.910716, Test: 0.082544) after 0.252071 seconds\n",
      "2018-08-30 06:25:19.481518 Training Step 1660 \"min loss\" =  6.140988\n",
      "2018-08-30 06:25:19.481845 Training Step 1660 \"loss\" =  6.714063\n",
      "2018-08-30 06:25:19.686203 Test Step 1665 Finished\n",
      "2018-08-30 06:25:19.686288 Test Step 1665 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:19.686945 Test Step 1665 \"loss\" =  8.187905\n",
      "2018-08-30 06:25:19.733027 Training Step 1665 Finished Timing (Training: 0.910556, Test: 0.0826517) after 0.250706 seconds\n",
      "2018-08-30 06:25:19.733155 Training Step 1665 \"min loss\" =  6.140988\n",
      "2018-08-30 06:25:19.733284 Training Step 1665 \"loss\" =  6.4825625\n",
      "2018-08-30 06:25:19.937278 Test Step 1670 Finished\n",
      "2018-08-30 06:25:19.937418 Test Step 1670 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:19.937482 Test Step 1670 \"loss\" =  8.120915\n",
      "2018-08-30 06:25:19.984418 Training Step 1670 Finished Timing (Training: 0.910802, Test: 0.0826974) after 0.251014 seconds\n",
      "2018-08-30 06:25:19.984497 Training Step 1670 \"min loss\" =  6.140988\n",
      "2018-08-30 06:25:19.984550 Training Step 1670 \"loss\" =  6.5412827\n",
      "2018-08-30 06:25:20.188498 Test Step 1675 Finished\n",
      "2018-08-30 06:25:20.188615 Test Step 1675 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:20.188675 Test Step 1675 \"loss\" =  7.6550345\n",
      "2018-08-30 06:25:20.234406 Training Step 1675 Finished Timing (Training: 0.911077, Test: 0.0827304) after 0.24979 seconds\n",
      "2018-08-30 06:25:20.234477 Training Step 1675 \"min loss\" =  5.866295\n",
      "2018-08-30 06:25:20.235065 Training Step 1675 \"loss\" =  7.6750503\n",
      "2018-08-30 06:25:20.438843 Test Step 1680 Finished\n",
      "2018-08-30 06:25:20.439263 Test Step 1680 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:20.439789 Test Step 1680 \"loss\" =  7.8749075\n",
      "2018-08-30 06:25:20.486248 Training Step 1680 Finished Timing (Training: 0.910978, Test: 0.0827125) after 0.251117 seconds\n",
      "2018-08-30 06:25:20.486337 Training Step 1680 \"min loss\" =  5.866295\n",
      "2018-08-30 06:25:20.486991 Training Step 1680 \"loss\" =  6.282084\n",
      "2018-08-30 06:25:20.691377 Test Step 1685 Finished\n",
      "2018-08-30 06:25:20.691632 Test Step 1685 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:20.691926 Test Step 1685 \"loss\" =  7.444276\n",
      "2018-08-30 06:25:20.738156 Training Step 1685 Finished Timing (Training: 0.910696, Test: 0.0828092) after 0.250573 seconds\n",
      "2018-08-30 06:25:20.738236 Training Step 1685 \"min loss\" =  5.866295\n",
      "2018-08-30 06:25:20.738793 Training Step 1685 \"loss\" =  7.082145\n",
      "2018-08-30 06:25:20.942402 Test Step 1690 Finished\n",
      "2018-08-30 06:25:20.942672 Test Step 1690 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:20.942952 Test Step 1690 \"loss\" =  7.6968527\n",
      "2018-08-30 06:25:20.989062 Training Step 1690 Finished Timing (Training: 0.910743, Test: 0.0827599) after 0.250197 seconds\n",
      "2018-08-30 06:25:20.989158 Training Step 1690 \"min loss\" =  5.866295\n",
      "2018-08-30 06:25:20.989704 Training Step 1690 \"loss\" =  6.3627276\n",
      "2018-08-30 06:25:21.202673 Test Step 1695 Finished\n",
      "2018-08-30 06:25:21.202763 Test Step 1695 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:21.203231 Test Step 1695 \"loss\" =  7.82157\n",
      "2018-08-30 06:25:21.249361 Training Step 1695 Finished Timing (Training: 0.909248, Test: 0.0842431) after 0.25945 seconds\n",
      "2018-08-30 06:25:21.249438 Training Step 1695 \"min loss\" =  5.866295\n",
      "2018-08-30 06:25:21.249493 Training Step 1695 \"loss\" =  6.86803\n",
      "2018-08-30 06:25:21.453919 Test Step 1700 Finished\n",
      "2018-08-30 06:25:21.454188 Test Step 1700 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:21.454483 Test Step 1700 \"loss\" =  7.921883\n",
      "2018-08-30 06:25:21.500608 Training Step 1700 Finished Timing (Training: 0.909362, Test: 0.0841289) after 0.250517 seconds\n",
      "2018-08-30 06:25:21.500686 Training Step 1700 \"min loss\" =  5.866295\n",
      "2018-08-30 06:25:21.500745 Training Step 1700 \"loss\" =  6.6513762\n",
      "2018-08-30 06:25:21.704749 Test Step 1705 Finished\n",
      "2018-08-30 06:25:21.704830 Test Step 1705 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:21.705274 Test Step 1705 \"loss\" =  7.78189\n",
      "2018-08-30 06:25:21.751547 Training Step 1705 Finished Timing (Training: 0.914359, Test: 0.0822459) after 0.250159 seconds\n",
      "2018-08-30 06:25:21.751623 Training Step 1705 \"min loss\" =  5.746875\n",
      "2018-08-30 06:25:21.751678 Training Step 1705 \"loss\" =  6.578938\n",
      "2018-08-30 06:25:21.955789 Test Step 1710 Finished\n",
      "2018-08-30 06:25:21.956054 Test Step 1710 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:21.956363 Test Step 1710 \"loss\" =  7.8953156\n",
      "2018-08-30 06:25:22.002781 Training Step 1710 Finished Timing (Training: 0.912611, Test: 0.0823327) after 0.250479 seconds\n",
      "2018-08-30 06:25:22.002864 Training Step 1710 \"min loss\" =  5.746875\n",
      "2018-08-30 06:25:22.003340 Training Step 1710 \"loss\" =  6.692955\n",
      "2018-08-30 06:25:22.206756 Test Step 1715 Finished\n",
      "2018-08-30 06:25:22.206852 Test Step 1715 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:22.206911 Test Step 1715 \"loss\" =  7.6074753\n",
      "2018-08-30 06:25:22.253447 Training Step 1715 Finished Timing (Training: 0.912797, Test: 0.0823067) after 0.249777 seconds\n",
      "2018-08-30 06:25:22.253509 Training Step 1715 \"min loss\" =  5.746875\n",
      "2018-08-30 06:25:22.253969 Training Step 1715 \"loss\" =  7.2940617\n",
      "2018-08-30 06:25:22.457407 Test Step 1720 Finished\n",
      "2018-08-30 06:25:22.457489 Test Step 1720 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:22.458014 Test Step 1720 \"loss\" =  7.5980954\n",
      "2018-08-30 06:25:22.504013 Training Step 1720 Finished Timing (Training: 0.912802, Test: 0.0822524) after 0.249977 seconds\n",
      "2018-08-30 06:25:22.504074 Training Step 1720 \"min loss\" =  5.746875\n",
      "2018-08-30 06:25:22.504612 Training Step 1720 \"loss\" =  6.728554\n",
      "2018-08-30 06:25:22.708301 Test Step 1725 Finished\n",
      "2018-08-30 06:25:22.708389 Test Step 1725 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:22.708468 Test Step 1725 \"loss\" =  7.582328\n",
      "2018-08-30 06:25:22.755355 Training Step 1725 Finished Timing (Training: 0.912507, Test: 0.0822146) after 0.25066 seconds\n",
      "2018-08-30 06:25:22.755416 Training Step 1725 \"min loss\" =  5.746875\n",
      "2018-08-30 06:25:22.755482 Training Step 1725 \"loss\" =  6.2450385\n",
      "2018-08-30 06:25:22.958457 Test Step 1730 Finished\n",
      "2018-08-30 06:25:22.958558 Test Step 1730 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:22.958620 Test Step 1730 \"loss\" =  7.65862\n",
      "2018-08-30 06:25:23.004345 Training Step 1730 Finished Timing (Training: 0.913007, Test: 0.0822471) after 0.248735 seconds\n",
      "2018-08-30 06:25:23.004408 Training Step 1730 \"min loss\" =  5.746875\n",
      "2018-08-30 06:25:23.004474 Training Step 1730 \"loss\" =  6.644851\n",
      "2018-08-30 06:25:23.207645 Test Step 1735 Finished\n",
      "2018-08-30 06:25:23.207729 Test Step 1735 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:23.207818 Test Step 1735 \"loss\" =  7.5341196\n",
      "2018-08-30 06:25:23.253603 Training Step 1735 Finished Timing (Training: 0.913329, Test: 0.0823398) after 0.249074 seconds\n",
      "2018-08-30 06:25:23.253664 Training Step 1735 \"min loss\" =  5.746875\n",
      "2018-08-30 06:25:23.253719 Training Step 1735 \"loss\" =  6.2316303\n",
      "2018-08-30 06:25:23.457247 Test Step 1740 Finished\n",
      "2018-08-30 06:25:23.457343 Test Step 1740 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:23.457385 Test Step 1740 \"loss\" =  7.61221\n",
      "2018-08-30 06:25:23.503256 Training Step 1740 Finished Timing (Training: 0.913593, Test: 0.0824125) after 0.249475 seconds\n",
      "2018-08-30 06:25:23.503324 Training Step 1740 \"min loss\" =  5.746875\n",
      "2018-08-30 06:25:23.503384 Training Step 1740 \"loss\" =  6.0620112\n",
      "2018-08-30 06:25:23.707517 Test Step 1745 Finished\n",
      "2018-08-30 06:25:23.707598 Test Step 1745 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:23.707638 Test Step 1745 \"loss\" =  7.6291475\n",
      "2018-08-30 06:25:23.753506 Training Step 1745 Finished Timing (Training: 0.913736, Test: 0.082533) after 0.250059 seconds\n",
      "2018-08-30 06:25:23.753573 Training Step 1745 \"min loss\" =  5.746875\n",
      "2018-08-30 06:25:23.753637 Training Step 1745 \"loss\" =  6.875272\n",
      "2018-08-30 06:25:23.957418 Test Step 1750 Finished\n",
      "2018-08-30 06:25:23.957505 Test Step 1750 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:23.958237 Test Step 1750 \"loss\" =  7.867106\n",
      "2018-08-30 06:25:24.004293 Training Step 1750 Finished Timing (Training: 0.913385, Test: 0.0825195) after 0.249846 seconds\n",
      "2018-08-30 06:25:24.004354 Training Step 1750 \"min loss\" =  5.746875\n",
      "2018-08-30 06:25:24.004436 Training Step 1750 \"loss\" =  7.0543427\n",
      "2018-08-30 06:25:24.209428 Test Step 1755 Finished\n",
      "2018-08-30 06:25:24.209520 Test Step 1755 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:24.210142 Test Step 1755 \"loss\" =  7.4699306\n",
      "2018-08-30 06:25:24.255843 Training Step 1755 Finished Timing (Training: 0.913082, Test: 0.0825784) after 0.250645 seconds\n",
      "2018-08-30 06:25:24.255903 Training Step 1755 \"min loss\" =  5.746875\n",
      "2018-08-30 06:25:24.255956 Training Step 1755 \"loss\" =  6.2819433\n",
      "2018-08-30 06:25:24.459685 Test Step 1760 Finished\n",
      "2018-08-30 06:25:24.459782 Test Step 1760 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:24.460242 Test Step 1760 \"loss\" =  7.507272\n",
      "2018-08-30 06:25:24.506422 Training Step 1760 Finished Timing (Training: 0.912959, Test: 0.0825234) after 0.249689 seconds\n",
      "2018-08-30 06:25:24.506491 Training Step 1760 \"min loss\" =  5.746875\n",
      "2018-08-30 06:25:24.506555 Training Step 1760 \"loss\" =  6.569632\n",
      "2018-08-30 06:25:24.710911 Test Step 1765 Finished\n",
      "2018-08-30 06:25:24.711038 Test Step 1765 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:24.711623 Test Step 1765 \"loss\" =  7.5880046\n",
      "2018-08-30 06:25:24.757349 Training Step 1765 Finished Timing (Training: 0.912753, Test: 0.0825706) after 0.250061 seconds\n",
      "2018-08-30 06:25:24.757425 Training Step 1765 \"min loss\" =  5.746875\n",
      "2018-08-30 06:25:24.757469 Training Step 1765 \"loss\" =  6.5485835\n",
      "2018-08-30 06:25:24.962150 Test Step 1770 Finished\n",
      "2018-08-30 06:25:24.962269 Test Step 1770 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:24.962341 Test Step 1770 \"loss\" =  7.716812\n",
      "2018-08-30 06:25:25.009101 Training Step 1770 Finished Timing (Training: 0.912652, Test: 0.082611) after 0.251546 seconds\n",
      "2018-08-30 06:25:25.009160 Training Step 1770 \"min loss\" =  5.746875\n",
      "2018-08-30 06:25:25.009230 Training Step 1770 \"loss\" =  6.500742\n",
      "2018-08-30 06:25:25.213627 Test Step 1775 Finished\n",
      "2018-08-30 06:25:25.213722 Test Step 1775 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:25.213775 Test Step 1775 \"loss\" =  7.878365\n",
      "2018-08-30 06:25:25.259580 Training Step 1775 Finished Timing (Training: 0.912755, Test: 0.0827077) after 0.250281 seconds\n",
      "2018-08-30 06:25:25.259646 Training Step 1775 \"min loss\" =  5.746875\n",
      "2018-08-30 06:25:25.259691 Training Step 1775 \"loss\" =  7.2205334\n",
      "2018-08-30 06:25:25.464160 Test Step 1780 Finished\n",
      "2018-08-30 06:25:25.464246 Test Step 1780 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:25.464299 Test Step 1780 \"loss\" =  7.411514\n",
      "2018-08-30 06:25:25.510878 Training Step 1780 Finished Timing (Training: 0.913012, Test: 0.0826374) after 0.251122 seconds\n",
      "2018-08-30 06:25:25.510940 Training Step 1780 \"min loss\" =  5.746875\n",
      "2018-08-30 06:25:25.511396 Training Step 1780 \"loss\" =  6.035793\n",
      "2018-08-30 06:25:25.715336 Test Step 1785 Finished\n",
      "2018-08-30 06:25:25.715430 Test Step 1785 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:25.716038 Test Step 1785 \"loss\" =  7.452079\n",
      "2018-08-30 06:25:25.762199 Training Step 1785 Finished Timing (Training: 0.912773, Test: 0.0826268) after 0.250329 seconds\n",
      "2018-08-30 06:25:25.762277 Training Step 1785 \"min loss\" =  5.746875\n",
      "2018-08-30 06:25:25.762833 Training Step 1785 \"loss\" =  6.5212097\n",
      "2018-08-30 06:25:25.966725 Test Step 1790 Finished\n",
      "2018-08-30 06:25:25.966819 Test Step 1790 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:25.967359 Test Step 1790 \"loss\" =  7.8964148\n",
      "2018-08-30 06:25:26.013462 Training Step 1790 Finished Timing (Training: 0.912714, Test: 0.0826193) after 0.250536 seconds\n",
      "2018-08-30 06:25:26.013523 Training Step 1790 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:26.013585 Training Step 1790 \"loss\" =  6.127101\n",
      "2018-08-30 06:25:26.217491 Test Step 1795 Finished\n",
      "2018-08-30 06:25:26.217578 Test Step 1795 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:26.217625 Test Step 1795 \"loss\" =  7.592514\n",
      "2018-08-30 06:25:26.263546 Training Step 1795 Finished Timing (Training: 0.912861, Test: 0.0826172) after 0.249884 seconds\n",
      "2018-08-30 06:25:26.263635 Training Step 1795 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:26.263708 Training Step 1795 \"loss\" =  6.465012\n",
      "2018-08-30 06:25:26.467908 Test Step 1800 Finished\n",
      "2018-08-30 06:25:26.468015 Test Step 1800 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:26.468077 Test Step 1800 \"loss\" =  7.4560075\n",
      "2018-08-30 06:25:26.514487 Training Step 1800 Finished Timing (Training: 0.912906, Test: 0.0825764) after 0.25072 seconds\n",
      "2018-08-30 06:25:26.514790 Training Step 1800 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:26.514858 Training Step 1800 \"loss\" =  6.233418\n",
      "2018-08-30 06:25:26.719526 Test Step 1805 Finished\n",
      "2018-08-30 06:25:26.719604 Test Step 1805 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:26.719664 Test Step 1805 \"loss\" =  7.558524\n",
      "2018-08-30 06:25:26.766091 Training Step 1805 Finished Timing (Training: 0.913254, Test: 0.0830282) after 0.251174 seconds\n",
      "2018-08-30 06:25:26.766157 Training Step 1805 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:26.766707 Training Step 1805 \"loss\" =  6.242382\n",
      "2018-08-30 06:25:26.970564 Test Step 1810 Finished\n",
      "2018-08-30 06:25:26.971032 Test Step 1810 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:26.971480 Test Step 1810 \"loss\" =  8.091848\n",
      "2018-08-30 06:25:27.017570 Training Step 1810 Finished Timing (Training: 0.911412, Test: 0.0828983) after 0.250555 seconds\n",
      "2018-08-30 06:25:27.017633 Training Step 1810 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:27.017689 Training Step 1810 \"loss\" =  6.4913297\n",
      "2018-08-30 06:25:27.222227 Test Step 1815 Finished\n",
      "2018-08-30 06:25:27.222325 Test Step 1815 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:27.222407 Test Step 1815 \"loss\" =  8.144446\n",
      "2018-08-30 06:25:27.268903 Training Step 1815 Finished Timing (Training: 0.912025, Test: 0.0827653) after 0.250533 seconds\n",
      "2018-08-30 06:25:27.268973 Training Step 1815 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:27.269032 Training Step 1815 \"loss\" =  5.965708\n",
      "2018-08-30 06:25:27.472198 Test Step 1820 Finished\n",
      "2018-08-30 06:25:27.472291 Test Step 1820 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:27.472844 Test Step 1820 \"loss\" =  7.7039404\n",
      "2018-08-30 06:25:27.518958 Training Step 1820 Finished Timing (Training: 0.912487, Test: 0.0826914) after 0.249866 seconds\n",
      "2018-08-30 06:25:27.519022 Training Step 1820 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:27.519075 Training Step 1820 \"loss\" =  6.9027066\n",
      "2018-08-30 06:25:27.722716 Test Step 1825 Finished\n",
      "2018-08-30 06:25:27.723069 Test Step 1825 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:27.723131 Test Step 1825 \"loss\" =  7.5450068\n",
      "2018-08-30 06:25:27.769375 Training Step 1825 Finished Timing (Training: 0.912138, Test: 0.0825353) after 0.249588 seconds\n",
      "2018-08-30 06:25:27.769668 Training Step 1825 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:27.769734 Training Step 1825 \"loss\" =  6.8103805\n",
      "2018-08-30 06:25:27.974266 Test Step 1830 Finished\n",
      "2018-08-30 06:25:27.974369 Test Step 1830 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:27.974430 Test Step 1830 \"loss\" =  7.880226\n",
      "2018-08-30 06:25:28.020978 Training Step 1830 Finished Timing (Training: 0.912538, Test: 0.0825718) after 0.251179 seconds\n",
      "2018-08-30 06:25:28.021048 Training Step 1830 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:28.021119 Training Step 1830 \"loss\" =  6.771996\n",
      "2018-08-30 06:25:28.225911 Test Step 1835 Finished\n",
      "2018-08-30 06:25:28.225999 Test Step 1835 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:28.226061 Test Step 1835 \"loss\" =  7.573839\n",
      "2018-08-30 06:25:28.272640 Training Step 1835 Finished Timing (Training: 0.911892, Test: 0.0827008) after 0.250629 seconds\n",
      "2018-08-30 06:25:28.272919 Training Step 1835 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:28.272981 Training Step 1835 \"loss\" =  6.0178776\n",
      "2018-08-30 06:25:28.477593 Test Step 1840 Finished\n",
      "2018-08-30 06:25:28.477709 Test Step 1840 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:28.477773 Test Step 1840 \"loss\" =  7.529677\n",
      "2018-08-30 06:25:28.524596 Training Step 1840 Finished Timing (Training: 0.912126, Test: 0.0828068) after 0.25155 seconds\n",
      "2018-08-30 06:25:28.524671 Training Step 1840 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:28.524747 Training Step 1840 \"loss\" =  6.078654\n",
      "2018-08-30 06:25:28.729602 Test Step 1845 Finished\n",
      "2018-08-30 06:25:28.729684 Test Step 1845 \"min loss\" =  7.2904453\n",
      "2018-08-30 06:25:28.729741 Test Step 1845 \"loss\" =  7.5537176\n",
      "2018-08-30 06:25:28.775780 Training Step 1845 Finished Timing (Training: 0.912482, Test: 0.0828002) after 0.250919 seconds\n",
      "2018-08-30 06:25:28.775894 Training Step 1845 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:28.775970 Training Step 1845 \"loss\" =  6.228218\n",
      "2018-08-30 06:25:28.978833 Test Step 1850 Finished\n",
      "2018-08-30 06:25:28.978918 Test Step 1850 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:28.978967 Test Step 1850 \"loss\" =  7.2893496\n",
      "2018-08-30 06:25:29.025922 Training Step 1850 Finished Timing (Training: 0.912529, Test: 0.0827411) after 0.249887 seconds\n",
      "2018-08-30 06:25:29.025982 Training Step 1850 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:29.026037 Training Step 1850 \"loss\" =  5.7977877\n",
      "2018-08-30 06:25:29.230556 Test Step 1855 Finished\n",
      "2018-08-30 06:25:29.230624 Test Step 1855 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:29.230683 Test Step 1855 \"loss\" =  7.46117\n",
      "2018-08-30 06:25:29.277427 Training Step 1855 Finished Timing (Training: 0.912629, Test: 0.0826591) after 0.251333 seconds\n",
      "2018-08-30 06:25:29.277489 Training Step 1855 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:29.278256 Training Step 1855 \"loss\" =  6.628923\n",
      "2018-08-30 06:25:29.482662 Test Step 1860 Finished\n",
      "2018-08-30 06:25:29.482816 Test Step 1860 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:29.482876 Test Step 1860 \"loss\" =  7.4867306\n",
      "2018-08-30 06:25:29.529787 Training Step 1860 Finished Timing (Training: 0.912467, Test: 0.082622) after 0.251461 seconds\n",
      "2018-08-30 06:25:29.529848 Training Step 1860 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:29.530175 Training Step 1860 \"loss\" =  5.8360643\n",
      "2018-08-30 06:25:29.735183 Test Step 1865 Finished\n",
      "2018-08-30 06:25:29.735276 Test Step 1865 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:29.735334 Test Step 1865 \"loss\" =  7.7729206\n",
      "2018-08-30 06:25:29.781863 Training Step 1865 Finished Timing (Training: 0.912372, Test: 0.0826202) after 0.251374 seconds\n",
      "2018-08-30 06:25:29.781955 Training Step 1865 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:29.782011 Training Step 1865 \"loss\" =  6.083152\n",
      "2018-08-30 06:25:29.986275 Test Step 1870 Finished\n",
      "2018-08-30 06:25:29.986362 Test Step 1870 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:29.986419 Test Step 1870 \"loss\" =  7.937985\n",
      "2018-08-30 06:25:30.032927 Training Step 1870 Finished Timing (Training: 0.912311, Test: 0.0825786) after 0.250293 seconds\n",
      "2018-08-30 06:25:30.033002 Training Step 1870 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:30.033057 Training Step 1870 \"loss\" =  6.1297684\n",
      "2018-08-30 06:25:30.237864 Test Step 1875 Finished\n",
      "2018-08-30 06:25:30.237956 Test Step 1875 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:30.238018 Test Step 1875 \"loss\" =  8.2858305\n",
      "2018-08-30 06:25:30.284611 Training Step 1875 Finished Timing (Training: 0.912138, Test: 0.0825795) after 0.250864 seconds\n",
      "2018-08-30 06:25:30.284689 Training Step 1875 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:30.284748 Training Step 1875 \"loss\" =  6.52429\n",
      "2018-08-30 06:25:30.489578 Test Step 1880 Finished\n",
      "2018-08-30 06:25:30.489668 Test Step 1880 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:30.490046 Test Step 1880 \"loss\" =  7.7831545\n",
      "2018-08-30 06:25:30.536198 Training Step 1880 Finished Timing (Training: 0.912084, Test: 0.0825598) after 0.250803 seconds\n",
      "2018-08-30 06:25:30.536259 Training Step 1880 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:30.536728 Training Step 1880 \"loss\" =  6.1046166\n",
      "2018-08-30 06:25:30.744023 Test Step 1885 Finished\n",
      "2018-08-30 06:25:30.744107 Test Step 1885 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:30.744164 Test Step 1885 \"loss\" =  7.9067235\n",
      "2018-08-30 06:25:30.790824 Training Step 1885 Finished Timing (Training: 0.912001, Test: 0.0825996) after 0.253892 seconds\n",
      "2018-08-30 06:25:30.790920 Training Step 1885 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:30.791321 Training Step 1885 \"loss\" =  5.833556\n",
      "2018-08-30 06:25:30.995158 Test Step 1890 Finished\n",
      "2018-08-30 06:25:30.995247 Test Step 1890 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:30.995311 Test Step 1890 \"loss\" =  7.5450406\n",
      "2018-08-30 06:25:31.042034 Training Step 1890 Finished Timing (Training: 0.911953, Test: 0.0825743) after 0.250386 seconds\n",
      "2018-08-30 06:25:31.042097 Training Step 1890 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:31.042433 Training Step 1890 \"loss\" =  6.168927\n",
      "2018-08-30 06:25:31.247253 Test Step 1895 Finished\n",
      "2018-08-30 06:25:31.247344 Test Step 1895 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:31.247406 Test Step 1895 \"loss\" =  7.9839478\n",
      "2018-08-30 06:25:31.293998 Training Step 1895 Finished Timing (Training: 0.911874, Test: 0.0825804) after 0.251255 seconds\n",
      "2018-08-30 06:25:31.294069 Training Step 1895 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:31.294417 Training Step 1895 \"loss\" =  6.3346424\n",
      "2018-08-30 06:25:31.498770 Test Step 1900 Finished\n",
      "2018-08-30 06:25:31.498836 Test Step 1900 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:31.498886 Test Step 1900 \"loss\" =  8.019068\n",
      "2018-08-30 06:25:31.545384 Training Step 1900 Finished Timing (Training: 0.911839, Test: 0.0825917) after 0.25066 seconds\n",
      "2018-08-30 06:25:31.545457 Training Step 1900 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:31.545511 Training Step 1900 \"loss\" =  6.2048903\n",
      "2018-08-30 06:25:31.749745 Test Step 1905 Finished\n",
      "2018-08-30 06:25:31.749813 Test Step 1905 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:31.750235 Test Step 1905 \"loss\" =  7.6150427\n",
      "2018-08-30 06:25:31.796319 Training Step 1905 Finished Timing (Training: 0.913913, Test: 0.0828121) after 0.250205 seconds\n",
      "2018-08-30 06:25:31.796394 Training Step 1905 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:31.796884 Training Step 1905 \"loss\" =  5.8449106\n",
      "2018-08-30 06:25:32.000998 Test Step 1910 Finished\n",
      "2018-08-30 06:25:32.001456 Test Step 1910 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:32.001713 Test Step 1910 \"loss\" =  7.826665\n",
      "2018-08-30 06:25:32.047767 Training Step 1910 Finished Timing (Training: 0.91239, Test: 0.0822447) after 0.250684 seconds\n",
      "2018-08-30 06:25:32.047823 Training Step 1910 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:32.048173 Training Step 1910 \"loss\" =  5.8933616\n",
      "2018-08-30 06:25:32.252764 Test Step 1915 Finished\n",
      "2018-08-30 06:25:32.252850 Test Step 1915 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:32.252909 Test Step 1915 \"loss\" =  7.7767487\n",
      "2018-08-30 06:25:32.299632 Training Step 1915 Finished Timing (Training: 0.912318, Test: 0.0820078) after 0.251138 seconds\n",
      "2018-08-30 06:25:32.299763 Training Step 1915 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:32.300162 Training Step 1915 \"loss\" =  5.9288588\n",
      "2018-08-30 06:25:32.504299 Test Step 1920 Finished\n",
      "2018-08-30 06:25:32.504778 Test Step 1920 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:32.504854 Test Step 1920 \"loss\" =  8.516618\n",
      "2018-08-30 06:25:32.551309 Training Step 1920 Finished Timing (Training: 0.911541, Test: 0.0819538) after 0.250799 seconds\n",
      "2018-08-30 06:25:32.551373 Training Step 1920 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:32.551785 Training Step 1920 \"loss\" =  6.1655755\n",
      "2018-08-30 06:25:32.755876 Test Step 1925 Finished\n",
      "2018-08-30 06:25:32.755975 Test Step 1925 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:32.756032 Test Step 1925 \"loss\" =  7.948646\n",
      "2018-08-30 06:25:32.802552 Training Step 1925 Finished Timing (Training: 0.911418, Test: 0.0819973) after 0.250338 seconds\n",
      "2018-08-30 06:25:32.802744 Training Step 1925 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:32.802984 Training Step 1925 \"loss\" =  6.1113505\n",
      "2018-08-30 06:25:33.006452 Test Step 1930 Finished\n",
      "2018-08-30 06:25:33.007015 Test Step 1930 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:33.007078 Test Step 1930 \"loss\" =  7.877843\n",
      "2018-08-30 06:25:33.052756 Training Step 1930 Finished Timing (Training: 0.911559, Test: 0.0819833) after 0.249451 seconds\n",
      "2018-08-30 06:25:33.053036 Training Step 1930 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:33.053233 Training Step 1930 \"loss\" =  5.803276\n",
      "2018-08-30 06:25:33.256491 Test Step 1935 Finished\n",
      "2018-08-30 06:25:33.256579 Test Step 1935 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:33.256639 Test Step 1935 \"loss\" =  7.5108247\n",
      "2018-08-30 06:25:33.303051 Training Step 1935 Finished Timing (Training: 0.911833, Test: 0.082035) after 0.249506 seconds\n",
      "2018-08-30 06:25:33.303302 Training Step 1935 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:33.303516 Training Step 1935 \"loss\" =  6.323199\n",
      "2018-08-30 06:25:33.515335 Test Step 1940 Finished\n",
      "2018-08-30 06:25:33.515421 Test Step 1940 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:33.515882 Test Step 1940 \"loss\" =  7.442983\n",
      "2018-08-30 06:25:33.562077 Training Step 1940 Finished Timing (Training: 0.908212, Test: 0.0856182) after 0.258253 seconds\n",
      "2018-08-30 06:25:33.562145 Training Step 1940 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:33.562203 Training Step 1940 \"loss\" =  5.917271\n",
      "2018-08-30 06:25:33.767219 Test Step 1945 Finished\n",
      "2018-08-30 06:25:33.767302 Test Step 1945 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:33.767764 Test Step 1945 \"loss\" =  7.491102\n",
      "2018-08-30 06:25:33.814204 Training Step 1945 Finished Timing (Training: 0.908562, Test: 0.0852317) after 0.251366 seconds\n",
      "2018-08-30 06:25:33.814268 Training Step 1945 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:33.814633 Training Step 1945 \"loss\" =  6.522508\n",
      "2018-08-30 06:25:34.018265 Test Step 1950 Finished\n",
      "2018-08-30 06:25:34.018370 Test Step 1950 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:34.018427 Test Step 1950 \"loss\" =  7.652213\n",
      "2018-08-30 06:25:34.065217 Training Step 1950 Finished Timing (Training: 0.908882, Test: 0.0848922) after 0.250273 seconds\n",
      "2018-08-30 06:25:34.065310 Training Step 1950 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:34.065369 Training Step 1950 \"loss\" =  5.665019\n",
      "2018-08-30 06:25:34.269866 Test Step 1955 Finished\n",
      "2018-08-30 06:25:34.269967 Test Step 1955 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:34.270401 Test Step 1955 \"loss\" =  7.5117908\n",
      "2018-08-30 06:25:34.316742 Training Step 1955 Finished Timing (Training: 0.909122, Test: 0.0846217) after 0.250746 seconds\n",
      "2018-08-30 06:25:34.316931 Training Step 1955 \"min loss\" =  5.528102\n",
      "2018-08-30 06:25:34.317175 Training Step 1955 \"loss\" =  6.084103\n",
      "2018-08-30 06:25:34.521650 Test Step 1960 Finished\n",
      "2018-08-30 06:25:34.521778 Test Step 1960 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:34.522110 Test Step 1960 \"loss\" =  7.744431\n",
      "2018-08-30 06:25:34.567986 Training Step 1960 Finished Timing (Training: 0.90934, Test: 0.0844899) after 0.250485 seconds\n",
      "2018-08-30 06:25:34.568063 Training Step 1960 \"min loss\" =  5.4139915\n",
      "2018-08-30 06:25:34.568542 Training Step 1960 \"loss\" =  6.388487\n",
      "2018-08-30 06:25:34.772923 Test Step 1965 Finished\n",
      "2018-08-30 06:25:34.773010 Test Step 1965 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:34.773064 Test Step 1965 \"loss\" =  7.7967463\n",
      "2018-08-30 06:25:34.819790 Training Step 1965 Finished Timing (Training: 0.90971, Test: 0.0843384) after 0.251179 seconds\n",
      "2018-08-30 06:25:34.820201 Training Step 1965 \"min loss\" =  5.4139915\n",
      "2018-08-30 06:25:34.820272 Training Step 1965 \"loss\" =  5.867905\n",
      "2018-08-30 06:25:35.025424 Test Step 1970 Finished\n",
      "2018-08-30 06:25:35.025529 Test Step 1970 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:35.025583 Test Step 1970 \"loss\" =  7.862434\n",
      "2018-08-30 06:25:35.072175 Training Step 1970 Finished Timing (Training: 0.909648, Test: 0.0842287) after 0.251334 seconds\n",
      "2018-08-30 06:25:35.072236 Training Step 1970 \"min loss\" =  5.4139915\n",
      "2018-08-30 06:25:35.072288 Training Step 1970 \"loss\" =  6.4479904\n",
      "2018-08-30 06:25:35.276688 Test Step 1975 Finished\n",
      "2018-08-30 06:25:35.277077 Test Step 1975 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:35.277139 Test Step 1975 \"loss\" =  7.4583144\n",
      "2018-08-30 06:25:35.323002 Training Step 1975 Finished Timing (Training: 0.909991, Test: 0.0841061) after 0.250659 seconds\n",
      "2018-08-30 06:25:35.323072 Training Step 1975 \"min loss\" =  5.4139915\n",
      "2018-08-30 06:25:35.323132 Training Step 1975 \"loss\" =  5.9366016\n",
      "2018-08-30 06:25:35.527797 Test Step 1980 Finished\n",
      "2018-08-30 06:25:35.527900 Test Step 1980 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:35.527959 Test Step 1980 \"loss\" =  7.5477986\n",
      "2018-08-30 06:25:35.574517 Training Step 1980 Finished Timing (Training: 0.910197, Test: 0.0839634) after 0.251304 seconds\n",
      "2018-08-30 06:25:35.574584 Training Step 1980 \"min loss\" =  5.4139915\n",
      "2018-08-30 06:25:35.574642 Training Step 1980 \"loss\" =  5.8251395\n",
      "2018-08-30 06:25:35.779142 Test Step 1985 Finished\n",
      "2018-08-30 06:25:35.779237 Test Step 1985 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:35.779311 Test Step 1985 \"loss\" =  7.66871\n",
      "2018-08-30 06:25:35.826240 Training Step 1985 Finished Timing (Training: 0.910342, Test: 0.0838582) after 0.251529 seconds\n",
      "2018-08-30 06:25:35.826333 Training Step 1985 \"min loss\" =  5.4139915\n",
      "2018-08-30 06:25:35.826743 Training Step 1985 \"loss\" =  6.037047\n",
      "2018-08-30 06:25:36.039641 Test Step 1990 Finished\n",
      "2018-08-30 06:25:36.039915 Test Step 1990 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:36.040197 Test Step 1990 \"loss\" =  7.6507716\n",
      "2018-08-30 06:25:36.086250 Training Step 1990 Finished Timing (Training: 0.908754, Test: 0.0853986) after 0.259181 seconds\n",
      "2018-08-30 06:25:36.086315 Training Step 1990 \"min loss\" =  5.4139915\n",
      "2018-08-30 06:25:36.086691 Training Step 1990 \"loss\" =  5.8711166\n",
      "2018-08-30 06:25:36.292422 Test Step 1995 Finished\n",
      "2018-08-30 06:25:36.292607 Test Step 1995 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:36.292723 Test Step 1995 \"loss\" =  7.956396\n",
      "2018-08-30 06:25:36.339584 Training Step 1995 Finished Timing (Training: 0.908893, Test: 0.0853145) after 0.252567 seconds\n",
      "2018-08-30 06:25:36.339957 Training Step 1995 \"min loss\" =  5.4139915\n",
      "2018-08-30 06:25:36.340222 Training Step 1995 \"loss\" =  5.5781817\n",
      "2018-08-30 06:25:36.544677 Test Step 2000 Finished\n",
      "2018-08-30 06:25:36.545102 Test Step 2000 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:36.545381 Test Step 2000 \"loss\" =  7.419037\n",
      "2018-08-30 06:25:36.591596 Training Step 2000 Finished Timing (Training: 0.908978, Test: 0.0851774) after 0.251313 seconds\n",
      "2018-08-30 06:25:36.591802 Training Step 2000 \"min loss\" =  5.4139915\n",
      "2018-08-30 06:25:36.592103 Training Step 2000 \"loss\" =  5.8174577\n",
      "2018-08-30 06:25:36.797161 Test Step 2005 Finished\n",
      "2018-08-30 06:25:36.797446 Test Step 2005 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:36.797759 Test Step 2005 \"loss\" =  7.7378907\n",
      "2018-08-30 06:25:36.844036 Training Step 2005 Finished Timing (Training: 0.911695, Test: 0.0844952) after 0.251513 seconds\n",
      "2018-08-30 06:25:36.844099 Training Step 2005 \"min loss\" =  5.4139915\n",
      "2018-08-30 06:25:36.844153 Training Step 2005 \"loss\" =  5.7596765\n",
      "2018-08-30 06:25:37.049017 Test Step 2010 Finished\n",
      "2018-08-30 06:25:37.049111 Test Step 2010 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:37.049734 Test Step 2010 \"loss\" =  7.689644\n",
      "2018-08-30 06:25:37.095800 Training Step 2010 Finished Timing (Training: 0.911626, Test: 0.0833336) after 0.250972 seconds\n",
      "2018-08-30 06:25:37.095934 Training Step 2010 \"min loss\" =  5.4139915\n",
      "2018-08-30 06:25:37.095978 Training Step 2010 \"loss\" =  6.1686454\n",
      "2018-08-30 06:25:37.299715 Test Step 2015 Finished\n",
      "2018-08-30 06:25:37.299820 Test Step 2015 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:37.299881 Test Step 2015 \"loss\" =  7.369604\n",
      "2018-08-30 06:25:37.346484 Training Step 2015 Finished Timing (Training: 0.913042, Test: 0.0828784) after 0.250425 seconds\n",
      "2018-08-30 06:25:37.346550 Training Step 2015 \"min loss\" =  5.4139915\n",
      "2018-08-30 06:25:37.347051 Training Step 2015 \"loss\" =  5.7243967\n",
      "2018-08-30 06:25:37.551215 Test Step 2020 Finished\n",
      "2018-08-30 06:25:37.551355 Test Step 2020 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:37.551420 Test Step 2020 \"loss\" =  7.5220623\n",
      "2018-08-30 06:25:37.598539 Training Step 2020 Finished Timing (Training: 0.912762, Test: 0.0829696) after 0.251131 seconds\n",
      "2018-08-30 06:25:37.598598 Training Step 2020 \"min loss\" =  5.4139915\n",
      "2018-08-30 06:25:37.598656 Training Step 2020 \"loss\" =  5.8350554\n",
      "2018-08-30 06:25:37.803932 Test Step 2025 Finished\n",
      "2018-08-30 06:25:37.804152 Test Step 2025 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:37.804213 Test Step 2025 \"loss\" =  7.892691\n",
      "2018-08-30 06:25:37.850815 Training Step 2025 Finished Timing (Training: 0.912782, Test: 0.0828558) after 0.251454 seconds\n",
      "2018-08-30 06:25:37.850881 Training Step 2025 \"min loss\" =  5.4139915\n",
      "2018-08-30 06:25:37.850951 Training Step 2025 \"loss\" =  6.218746\n",
      "2018-08-30 06:25:38.054945 Test Step 2030 Finished\n",
      "2018-08-30 06:25:38.055043 Test Step 2030 \"min loss\" =  7.2893496\n",
      "2018-08-30 06:25:38.055591 Test Step 2030 \"loss\" =  7.4636\n",
      "2018-08-30 06:25:38.101921 Training Step 2030 Finished Timing (Training: 0.912595, Test: 0.0827094) after 0.25024 seconds\n",
      "2018-08-30 06:25:38.101979 Training Step 2030 \"min loss\" =  5.4139915\n",
      "2018-08-30 06:25:38.102024 Training Step 2030 \"loss\" =  5.876925\n",
      "2018-08-30 06:25:38.308290 Test Step 2035 Finished\n",
      "2018-08-30 06:25:38.308368 Test Step 2035 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:38.308773 Test Step 2035 \"loss\" =  7.2666607\n",
      "2018-08-30 06:25:38.355393 Training Step 2035 Finished Timing (Training: 0.912561, Test: 0.082741) after 0.253311 seconds\n",
      "2018-08-30 06:25:38.355451 Training Step 2035 \"min loss\" =  5.4139915\n",
      "2018-08-30 06:25:38.355489 Training Step 2035 \"loss\" =  5.4891944\n",
      "2018-08-30 06:25:38.560931 Test Step 2040 Finished\n",
      "2018-08-30 06:25:38.561268 Test Step 2040 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:38.561329 Test Step 2040 \"loss\" =  7.291263\n",
      "2018-08-30 06:25:38.607801 Training Step 2040 Finished Timing (Training: 0.912573, Test: 0.0828057) after 0.252232 seconds\n",
      "2018-08-30 06:25:38.607988 Training Step 2040 \"min loss\" =  5.4139915\n",
      "2018-08-30 06:25:38.608045 Training Step 2040 \"loss\" =  5.7437234\n",
      "2018-08-30 06:25:38.813578 Test Step 2045 Finished\n",
      "2018-08-30 06:25:38.813679 Test Step 2045 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:38.814319 Test Step 2045 \"loss\" =  7.718186\n",
      "2018-08-30 06:25:38.860560 Training Step 2045 Finished Timing (Training: 0.912228, Test: 0.0827968) after 0.251882 seconds\n",
      "2018-08-30 06:25:38.860797 Training Step 2045 \"min loss\" =  5.4139915\n",
      "2018-08-30 06:25:38.861224 Training Step 2045 \"loss\" =  6.166382\n",
      "2018-08-30 06:25:39.065937 Test Step 2050 Finished\n",
      "2018-08-30 06:25:39.066206 Test Step 2050 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:39.066666 Test Step 2050 \"loss\" =  7.7295465\n",
      "2018-08-30 06:25:39.112766 Training Step 2050 Finished Timing (Training: 0.912116, Test: 0.0827911) after 0.251473 seconds\n",
      "2018-08-30 06:25:39.112850 Training Step 2050 \"min loss\" =  5.4000545\n",
      "2018-08-30 06:25:39.113236 Training Step 2050 \"loss\" =  5.857238\n",
      "2018-08-30 06:25:39.318104 Test Step 2055 Finished\n",
      "2018-08-30 06:25:39.318189 Test Step 2055 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:39.318817 Test Step 2055 \"loss\" =  8.028952\n",
      "2018-08-30 06:25:39.364777 Training Step 2055 Finished Timing (Training: 0.912096, Test: 0.0827916) after 0.251469 seconds\n",
      "2018-08-30 06:25:39.364856 Training Step 2055 \"min loss\" =  5.4000545\n",
      "2018-08-30 06:25:39.364926 Training Step 2055 \"loss\" =  6.2263436\n",
      "2018-08-30 06:25:39.571488 Test Step 2060 Finished\n",
      "2018-08-30 06:25:39.571609 Test Step 2060 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:39.571670 Test Step 2060 \"loss\" =  7.510442\n",
      "2018-08-30 06:25:39.617780 Training Step 2060 Finished Timing (Training: 0.912304, Test: 0.0828396) after 0.252759 seconds\n",
      "2018-08-30 06:25:39.617846 Training Step 2060 \"min loss\" =  5.4000545\n",
      "2018-08-30 06:25:39.617895 Training Step 2060 \"loss\" =  5.6410975\n",
      "2018-08-30 06:25:39.823138 Test Step 2065 Finished\n",
      "2018-08-30 06:25:39.823241 Test Step 2065 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:39.823312 Test Step 2065 \"loss\" =  7.9240503\n",
      "2018-08-30 06:25:39.869390 Training Step 2065 Finished Timing (Training: 0.912542, Test: 0.0828445) after 0.25144 seconds\n",
      "2018-08-30 06:25:39.869718 Training Step 2065 \"min loss\" =  5.4000545\n",
      "2018-08-30 06:25:39.869781 Training Step 2065 \"loss\" =  5.4735\n",
      "2018-08-30 06:25:40.075333 Test Step 2070 Finished\n",
      "2018-08-30 06:25:40.075631 Test Step 2070 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:40.075878 Test Step 2070 \"loss\" =  7.425274\n",
      "2018-08-30 06:25:40.122297 Training Step 2070 Finished Timing (Training: 0.912439, Test: 0.0828459) after 0.252452 seconds\n",
      "2018-08-30 06:25:40.122606 Training Step 2070 \"min loss\" =  5.4000545\n",
      "2018-08-30 06:25:40.122671 Training Step 2070 \"loss\" =  6.17319\n",
      "2018-08-30 06:25:40.327650 Test Step 2075 Finished\n",
      "2018-08-30 06:25:40.327728 Test Step 2075 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:40.328180 Test Step 2075 \"loss\" =  7.653971\n",
      "2018-08-30 06:25:40.374599 Training Step 2075 Finished Timing (Training: 0.912256, Test: 0.0828114) after 0.251363 seconds\n",
      "2018-08-30 06:25:40.374686 Training Step 2075 \"min loss\" =  5.4000545\n",
      "2018-08-30 06:25:40.375115 Training Step 2075 \"loss\" =  6.061301\n",
      "2018-08-30 06:25:40.580157 Test Step 2080 Finished\n",
      "2018-08-30 06:25:40.580499 Test Step 2080 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:40.580715 Test Step 2080 \"loss\" =  7.5289364\n",
      "2018-08-30 06:25:40.627063 Training Step 2080 Finished Timing (Training: 0.912034, Test: 0.0828404) after 0.251537 seconds\n",
      "2018-08-30 06:25:40.627148 Training Step 2080 \"min loss\" =  5.4000545\n",
      "2018-08-30 06:25:40.627553 Training Step 2080 \"loss\" =  5.636455\n",
      "2018-08-30 06:25:40.832646 Test Step 2085 Finished\n",
      "2018-08-30 06:25:40.833056 Test Step 2085 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:40.833443 Test Step 2085 \"loss\" =  7.9348254\n",
      "2018-08-30 06:25:40.879719 Training Step 2085 Finished Timing (Training: 0.911985, Test: 0.0828538) after 0.252099 seconds\n",
      "2018-08-30 06:25:40.879951 Training Step 2085 \"min loss\" =  5.3441963\n",
      "2018-08-30 06:25:40.880371 Training Step 2085 \"loss\" =  5.515343\n",
      "2018-08-30 06:25:41.085823 Test Step 2090 Finished\n",
      "2018-08-30 06:25:41.086097 Test Step 2090 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:41.086164 Test Step 2090 \"loss\" =  7.3885884\n",
      "2018-08-30 06:25:41.133128 Training Step 2090 Finished Timing (Training: 0.91191, Test: 0.0827941) after 0.252512 seconds\n",
      "2018-08-30 06:25:41.133207 Training Step 2090 \"min loss\" =  5.3441963\n",
      "2018-08-30 06:25:41.133786 Training Step 2090 \"loss\" =  5.6753316\n",
      "2018-08-30 06:25:41.338720 Test Step 2095 Finished\n",
      "2018-08-30 06:25:41.338992 Test Step 2095 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:41.339321 Test Step 2095 \"loss\" =  7.437208\n",
      "2018-08-30 06:25:41.385790 Training Step 2095 Finished Timing (Training: 0.911845, Test: 0.0827506) after 0.251934 seconds\n",
      "2018-08-30 06:25:41.386019 Training Step 2095 \"min loss\" =  5.2766337\n",
      "2018-08-30 06:25:41.386077 Training Step 2095 \"loss\" =  5.2766337\n",
      "2018-08-30 06:25:41.591823 Test Step 2100 Finished\n",
      "2018-08-30 06:25:41.592197 Test Step 2100 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:41.592261 Test Step 2100 \"loss\" =  7.4181843\n",
      "2018-08-30 06:25:41.638750 Training Step 2100 Finished Timing (Training: 0.911784, Test: 0.0827151) after 0.252018 seconds\n",
      "2018-08-30 06:25:41.638990 Training Step 2100 \"min loss\" =  5.2766337\n",
      "2018-08-30 06:25:41.639405 Training Step 2100 \"loss\" =  5.950536\n",
      "2018-08-30 06:25:41.844064 Test Step 2105 Finished\n",
      "2018-08-30 06:25:41.844427 Test Step 2105 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:41.844638 Test Step 2105 \"loss\" =  7.8561463\n",
      "2018-08-30 06:25:41.891069 Training Step 2105 Finished Timing (Training: 0.912593, Test: 0.0830328) after 0.251331 seconds\n",
      "2018-08-30 06:25:41.891154 Training Step 2105 \"min loss\" =  5.2766337\n",
      "2018-08-30 06:25:41.891251 Training Step 2105 \"loss\" =  6.0715284\n",
      "2018-08-30 06:25:42.096738 Test Step 2110 Finished\n",
      "2018-08-30 06:25:42.096837 Test Step 2110 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:42.097308 Test Step 2110 \"loss\" =  7.3110256\n",
      "2018-08-30 06:25:42.143780 Training Step 2110 Finished Timing (Training: 0.911965, Test: 0.083464) after 0.252434 seconds\n",
      "2018-08-30 06:25:42.143852 Training Step 2110 \"min loss\" =  5.2464566\n",
      "2018-08-30 06:25:42.144230 Training Step 2110 \"loss\" =  5.7357435\n",
      "2018-08-30 06:25:42.349072 Test Step 2115 Finished\n",
      "2018-08-30 06:25:42.349177 Test Step 2115 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:42.349856 Test Step 2115 \"loss\" =  7.577881\n",
      "2018-08-30 06:25:42.396037 Training Step 2115 Finished Timing (Training: 0.911208, Test: 0.0829972) after 0.251316 seconds\n",
      "2018-08-30 06:25:42.396258 Training Step 2115 \"min loss\" =  5.0452065\n",
      "2018-08-30 06:25:42.396677 Training Step 2115 \"loss\" =  6.12293\n",
      "2018-08-30 06:25:42.601800 Test Step 2120 Finished\n",
      "2018-08-30 06:25:42.602173 Test Step 2120 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:42.602236 Test Step 2120 \"loss\" =  7.9294424\n",
      "2018-08-30 06:25:42.648695 Training Step 2120 Finished Timing (Training: 0.911067, Test: 0.0829788) after 0.25195 seconds\n",
      "2018-08-30 06:25:42.648961 Training Step 2120 \"min loss\" =  5.0452065\n",
      "2018-08-30 06:25:42.649306 Training Step 2120 \"loss\" =  6.075566\n",
      "2018-08-30 06:25:42.854405 Test Step 2125 Finished\n",
      "2018-08-30 06:25:42.854504 Test Step 2125 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:42.855116 Test Step 2125 \"loss\" =  7.618903\n",
      "2018-08-30 06:25:42.901421 Training Step 2125 Finished Timing (Training: 0.911086, Test: 0.0829828) after 0.252044 seconds\n",
      "2018-08-30 06:25:42.901510 Training Step 2125 \"min loss\" =  5.0452065\n",
      "2018-08-30 06:25:42.901884 Training Step 2125 \"loss\" =  5.677246\n",
      "2018-08-30 06:25:43.107263 Test Step 2130 Finished\n",
      "2018-08-30 06:25:43.107603 Test Step 2130 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:43.108015 Test Step 2130 \"loss\" =  7.829347\n",
      "2018-08-30 06:25:43.154198 Training Step 2130 Finished Timing (Training: 0.910881, Test: 0.0828825) after 0.251848 seconds\n",
      "2018-08-30 06:25:43.154479 Training Step 2130 \"min loss\" =  5.0452065\n",
      "2018-08-30 06:25:43.154546 Training Step 2130 \"loss\" =  5.847506\n",
      "2018-08-30 06:25:43.359358 Test Step 2135 Finished\n",
      "2018-08-30 06:25:43.359438 Test Step 2135 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:43.359887 Test Step 2135 \"loss\" =  7.8141203\n",
      "2018-08-30 06:25:43.406692 Training Step 2135 Finished Timing (Training: 0.910754, Test: 0.0828328) after 0.251647 seconds\n",
      "2018-08-30 06:25:43.406766 Training Step 2135 \"min loss\" =  5.0452065\n",
      "2018-08-30 06:25:43.407149 Training Step 2135 \"loss\" =  6.0352693\n",
      "2018-08-30 06:25:43.613134 Test Step 2140 Finished\n",
      "2018-08-30 06:25:43.613451 Test Step 2140 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:43.613691 Test Step 2140 \"loss\" =  7.8946857\n",
      "2018-08-30 06:25:43.660381 Training Step 2140 Finished Timing (Training: 0.910737, Test: 0.0827467) after 0.252743 seconds\n",
      "2018-08-30 06:25:43.660681 Training Step 2140 \"min loss\" =  5.0452065\n",
      "2018-08-30 06:25:43.660741 Training Step 2140 \"loss\" =  5.5980973\n",
      "2018-08-30 06:25:43.866870 Test Step 2145 Finished\n",
      "2018-08-30 06:25:43.866978 Test Step 2145 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:43.867037 Test Step 2145 \"loss\" =  7.511978\n",
      "2018-08-30 06:25:43.913726 Training Step 2145 Finished Timing (Training: 0.910872, Test: 0.0827729) after 0.252927 seconds\n",
      "2018-08-30 06:25:43.913801 Training Step 2145 \"min loss\" =  5.0452065\n",
      "2018-08-30 06:25:43.913857 Training Step 2145 \"loss\" =  5.4167128\n",
      "2018-08-30 06:25:44.119471 Test Step 2150 Finished\n",
      "2018-08-30 06:25:44.119779 Test Step 2150 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:44.120021 Test Step 2150 \"loss\" =  7.3884563\n",
      "2018-08-30 06:25:44.166377 Training Step 2150 Finished Timing (Training: 0.910877, Test: 0.0827556) after 0.251897 seconds\n",
      "2018-08-30 06:25:44.166652 Training Step 2150 \"min loss\" =  5.0452065\n",
      "2018-08-30 06:25:44.166969 Training Step 2150 \"loss\" =  5.7456594\n",
      "2018-08-30 06:25:44.372499 Test Step 2155 Finished\n",
      "2018-08-30 06:25:44.372572 Test Step 2155 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:44.373011 Test Step 2155 \"loss\" =  7.7986116\n",
      "2018-08-30 06:25:44.419174 Training Step 2155 Finished Timing (Training: 0.910765, Test: 0.0828534) after 0.252007 seconds\n",
      "2018-08-30 06:25:44.419419 Training Step 2155 \"min loss\" =  5.0452065\n",
      "2018-08-30 06:25:44.419476 Training Step 2155 \"loss\" =  5.469835\n",
      "2018-08-30 06:25:44.625015 Test Step 2160 Finished\n",
      "2018-08-30 06:25:44.625087 Test Step 2160 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:44.625568 Test Step 2160 \"loss\" =  7.7555366\n",
      "2018-08-30 06:25:44.671987 Training Step 2160 Finished Timing (Training: 0.910822, Test: 0.0828022) after 0.252125 seconds\n",
      "2018-08-30 06:25:44.672060 Training Step 2160 \"min loss\" =  5.0452065\n",
      "2018-08-30 06:25:44.672116 Training Step 2160 \"loss\" =  6.698281\n",
      "2018-08-30 06:25:44.878608 Test Step 2165 Finished\n",
      "2018-08-30 06:25:44.878711 Test Step 2165 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:44.879163 Test Step 2165 \"loss\" =  7.690516\n",
      "2018-08-30 06:25:44.925545 Training Step 2165 Finished Timing (Training: 0.910736, Test: 0.0828621) after 0.252746 seconds\n",
      "2018-08-30 06:25:44.925599 Training Step 2165 \"min loss\" =  5.0452065\n",
      "2018-08-30 06:25:44.925929 Training Step 2165 \"loss\" =  5.71801\n",
      "2018-08-30 06:25:45.131723 Test Step 2170 Finished\n",
      "2018-08-30 06:25:45.131844 Test Step 2170 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:45.132372 Test Step 2170 \"loss\" =  7.975211\n",
      "2018-08-30 06:25:45.178813 Training Step 2170 Finished Timing (Training: 0.910814, Test: 0.0828177) after 0.252513 seconds\n",
      "2018-08-30 06:25:45.178876 Training Step 2170 \"min loss\" =  5.0452065\n",
      "2018-08-30 06:25:45.178918 Training Step 2170 \"loss\" =  5.4305034\n",
      "2018-08-30 06:25:45.383291 Test Step 2175 Finished\n",
      "2018-08-30 06:25:45.383379 Test Step 2175 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:45.383483 Test Step 2175 \"loss\" =  7.884967\n",
      "2018-08-30 06:25:45.429546 Training Step 2175 Finished Timing (Training: 0.911157, Test: 0.0827666) after 0.250533 seconds\n",
      "2018-08-30 06:25:45.429818 Training Step 2175 \"min loss\" =  5.0452065\n",
      "2018-08-30 06:25:45.429881 Training Step 2175 \"loss\" =  5.690534\n",
      "2018-08-30 06:25:45.635969 Test Step 2180 Finished\n",
      "2018-08-30 06:25:45.636070 Test Step 2180 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:45.636705 Test Step 2180 \"loss\" =  7.951969\n",
      "2018-08-30 06:25:45.683018 Training Step 2180 Finished Timing (Training: 0.911246, Test: 0.0827557) after 0.253071 seconds\n",
      "2018-08-30 06:25:45.683092 Training Step 2180 \"min loss\" =  5.0244017\n",
      "2018-08-30 06:25:45.683188 Training Step 2180 \"loss\" =  5.3327436\n",
      "2018-08-30 06:25:45.888941 Test Step 2185 Finished\n",
      "2018-08-30 06:25:45.889027 Test Step 2185 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:45.889088 Test Step 2185 \"loss\" =  7.857491\n",
      "2018-08-30 06:25:45.936357 Training Step 2185 Finished Timing (Training: 0.911519, Test: 0.082726) after 0.253118 seconds\n",
      "2018-08-30 06:25:45.936450 Training Step 2185 \"min loss\" =  5.0244017\n",
      "2018-08-30 06:25:45.936510 Training Step 2185 \"loss\" =  5.4382396\n",
      "2018-08-30 06:25:46.142124 Test Step 2190 Finished\n",
      "2018-08-30 06:25:46.142207 Test Step 2190 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:46.142270 Test Step 2190 \"loss\" =  8.204775\n",
      "2018-08-30 06:25:46.188395 Training Step 2190 Finished Timing (Training: 0.911715, Test: 0.0827497) after 0.251804 seconds\n",
      "2018-08-30 06:25:46.188460 Training Step 2190 \"min loss\" =  5.0244017\n",
      "2018-08-30 06:25:46.188500 Training Step 2190 \"loss\" =  6.176441\n",
      "2018-08-30 06:25:46.393766 Test Step 2195 Finished\n",
      "2018-08-30 06:25:46.393843 Test Step 2195 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:46.393892 Test Step 2195 \"loss\" =  7.717195\n",
      "2018-08-30 06:25:46.440745 Training Step 2195 Finished Timing (Training: 0.911799, Test: 0.0827132) after 0.252166 seconds\n",
      "2018-08-30 06:25:46.440810 Training Step 2195 \"min loss\" =  5.0244017\n",
      "2018-08-30 06:25:46.440869 Training Step 2195 \"loss\" =  5.825209\n",
      "2018-08-30 06:25:46.646349 Test Step 2200 Finished\n",
      "2018-08-30 06:25:46.646768 Test Step 2200 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:46.646857 Test Step 2200 \"loss\" =  7.7582555\n",
      "2018-08-30 06:25:46.693435 Training Step 2200 Finished Timing (Training: 0.911908, Test: 0.0827215) after 0.252483 seconds\n",
      "2018-08-30 06:25:46.693765 Training Step 2200 \"min loss\" =  5.0244017\n",
      "2018-08-30 06:25:46.693827 Training Step 2200 \"loss\" =  5.566389\n",
      "2018-08-30 06:25:46.899549 Test Step 2205 Finished\n",
      "2018-08-30 06:25:46.899661 Test Step 2205 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:46.900189 Test Step 2205 \"loss\" =  7.355301\n",
      "2018-08-30 06:25:46.946605 Training Step 2205 Finished Timing (Training: 0.915329, Test: 0.0817998) after 0.252713 seconds\n",
      "2018-08-30 06:25:46.946881 Training Step 2205 \"min loss\" =  5.0244017\n",
      "2018-08-30 06:25:46.946945 Training Step 2205 \"loss\" =  5.547468\n",
      "2018-08-30 06:25:47.152341 Test Step 2210 Finished\n",
      "2018-08-30 06:25:47.152437 Test Step 2210 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:47.152512 Test Step 2210 \"loss\" =  7.6516175\n",
      "2018-08-30 06:25:47.199241 Training Step 2210 Finished Timing (Training: 0.91377, Test: 0.0818094) after 0.252076 seconds\n",
      "2018-08-30 06:25:47.199306 Training Step 2210 \"min loss\" =  5.0244017\n",
      "2018-08-30 06:25:47.199368 Training Step 2210 \"loss\" =  5.8772693\n",
      "2018-08-30 06:25:47.404303 Test Step 2215 Finished\n",
      "2018-08-30 06:25:47.404382 Test Step 2215 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:47.404447 Test Step 2215 \"loss\" =  7.888058\n",
      "2018-08-30 06:25:47.451228 Training Step 2215 Finished Timing (Training: 0.914449, Test: 0.0820236) after 0.251781 seconds\n",
      "2018-08-30 06:25:47.451294 Training Step 2215 \"min loss\" =  5.0244017\n",
      "2018-08-30 06:25:47.451914 Training Step 2215 \"loss\" =  5.5689745\n",
      "2018-08-30 06:25:47.656715 Test Step 2220 Finished\n",
      "2018-08-30 06:25:47.656789 Test Step 2220 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:47.657490 Test Step 2220 \"loss\" =  7.5359645\n",
      "2018-08-30 06:25:47.704076 Training Step 2220 Finished Timing (Training: 0.913249, Test: 0.08212) after 0.251794 seconds\n",
      "2018-08-30 06:25:47.704150 Training Step 2220 \"min loss\" =  5.0244017\n",
      "2018-08-30 06:25:47.704197 Training Step 2220 \"loss\" =  5.4429903\n",
      "2018-08-30 06:25:47.911096 Test Step 2225 Finished\n",
      "2018-08-30 06:25:47.911592 Test Step 2225 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:47.911759 Test Step 2225 \"loss\" =  7.638994\n",
      "2018-08-30 06:25:47.958470 Training Step 2225 Finished Timing (Training: 0.912582, Test: 0.0821703) after 0.253293 seconds\n",
      "2018-08-30 06:25:47.958530 Training Step 2225 \"min loss\" =  5.0244017\n",
      "2018-08-30 06:25:47.958602 Training Step 2225 \"loss\" =  6.081504\n",
      "2018-08-30 06:25:48.164895 Test Step 2230 Finished\n",
      "2018-08-30 06:25:48.165226 Test Step 2230 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:48.165585 Test Step 2230 \"loss\" =  7.6482472\n",
      "2018-08-30 06:25:48.212172 Training Step 2230 Finished Timing (Training: 0.911887, Test: 0.0823706) after 0.25273 seconds\n",
      "2018-08-30 06:25:48.212509 Training Step 2230 \"min loss\" =  5.0244017\n",
      "2018-08-30 06:25:48.212578 Training Step 2230 \"loss\" =  5.237168\n",
      "2018-08-30 06:25:48.418192 Test Step 2235 Finished\n",
      "2018-08-30 06:25:48.418267 Test Step 2235 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:48.418327 Test Step 2235 \"loss\" =  7.7069244\n",
      "2018-08-30 06:25:48.465145 Training Step 2235 Finished Timing (Training: 0.91159, Test: 0.0824064) after 0.252031 seconds\n",
      "2018-08-30 06:25:48.465206 Training Step 2235 \"min loss\" =  5.0244017\n",
      "2018-08-30 06:25:48.465767 Training Step 2235 \"loss\" =  5.5335298\n",
      "2018-08-30 06:25:48.670793 Test Step 2240 Finished\n",
      "2018-08-30 06:25:48.670887 Test Step 2240 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:48.670928 Test Step 2240 \"loss\" =  7.767753\n",
      "2018-08-30 06:25:48.716990 Training Step 2240 Finished Timing (Training: 0.911942, Test: 0.0823479) after 0.251129 seconds\n",
      "2018-08-30 06:25:48.717061 Training Step 2240 \"min loss\" =  5.0244017\n",
      "2018-08-30 06:25:48.717666 Training Step 2240 \"loss\" =  5.7631135\n",
      "2018-08-30 06:25:48.923441 Test Step 2245 Finished\n",
      "2018-08-30 06:25:48.923552 Test Step 2245 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:48.923614 Test Step 2245 \"loss\" =  7.5668187\n",
      "2018-08-30 06:25:48.970457 Training Step 2245 Finished Timing (Training: 0.912072, Test: 0.0824038) after 0.252714 seconds\n",
      "2018-08-30 06:25:48.970520 Training Step 2245 \"min loss\" =  5.0244017\n",
      "2018-08-30 06:25:48.970562 Training Step 2245 \"loss\" =  5.9004335\n",
      "2018-08-30 06:25:49.176102 Test Step 2250 Finished\n",
      "2018-08-30 06:25:49.176177 Test Step 2250 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:49.176815 Test Step 2250 \"loss\" =  7.5158453\n",
      "2018-08-30 06:25:49.223231 Training Step 2250 Finished Timing (Training: 0.911882, Test: 0.0823841) after 0.251985 seconds\n",
      "2018-08-30 06:25:49.223292 Training Step 2250 \"min loss\" =  5.0244017\n",
      "2018-08-30 06:25:49.223330 Training Step 2250 \"loss\" =  5.5299425\n",
      "2018-08-30 06:25:49.428935 Test Step 2255 Finished\n",
      "2018-08-30 06:25:49.429011 Test Step 2255 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:49.429503 Test Step 2255 \"loss\" =  7.510667\n",
      "2018-08-30 06:25:49.475857 Training Step 2255 Finished Timing (Training: 0.911845, Test: 0.0824002) after 0.251768 seconds\n",
      "2018-08-30 06:25:49.475915 Training Step 2255 \"min loss\" =  5.0244017\n",
      "2018-08-30 06:25:49.475964 Training Step 2255 \"loss\" =  6.3205276\n",
      "2018-08-30 06:25:49.681856 Test Step 2260 Finished\n",
      "2018-08-30 06:25:49.681930 Test Step 2260 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:49.682613 Test Step 2260 \"loss\" =  7.905861\n",
      "2018-08-30 06:25:49.729053 Training Step 2260 Finished Timing (Training: 0.911635, Test: 0.0824696) after 0.252308 seconds\n",
      "2018-08-30 06:25:49.729115 Training Step 2260 \"min loss\" =  5.0244017\n",
      "2018-08-30 06:25:49.729694 Training Step 2260 \"loss\" =  5.6904573\n",
      "2018-08-30 06:25:49.935671 Test Step 2265 Finished\n",
      "2018-08-30 06:25:49.935779 Test Step 2265 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:49.936313 Test Step 2265 \"loss\" =  7.711202\n",
      "2018-08-30 06:25:49.982311 Training Step 2265 Finished Timing (Training: 0.911671, Test: 0.0824477) after 0.252547 seconds\n",
      "2018-08-30 06:25:49.982383 Training Step 2265 \"min loss\" =  5.0244017\n",
      "2018-08-30 06:25:49.982441 Training Step 2265 \"loss\" =  5.5113144\n",
      "2018-08-30 06:25:50.187729 Test Step 2270 Finished\n",
      "2018-08-30 06:25:50.188094 Test Step 2270 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:50.188153 Test Step 2270 \"loss\" =  7.598047\n",
      "2018-08-30 06:25:50.234647 Training Step 2270 Finished Timing (Training: 0.911791, Test: 0.0824516) after 0.252123 seconds\n",
      "2018-08-30 06:25:50.234926 Training Step 2270 \"min loss\" =  5.0244017\n",
      "2018-08-30 06:25:50.235159 Training Step 2270 \"loss\" =  5.5385065\n",
      "2018-08-30 06:25:50.439955 Test Step 2275 Finished\n",
      "2018-08-30 06:25:50.440042 Test Step 2275 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:50.440664 Test Step 2275 \"loss\" =  7.7606363\n",
      "2018-08-30 06:25:50.486861 Training Step 2275 Finished Timing (Training: 0.911848, Test: 0.0824186) after 0.251645 seconds\n",
      "2018-08-30 06:25:50.486920 Training Step 2275 \"min loss\" =  5.0244017\n",
      "2018-08-30 06:25:50.487386 Training Step 2275 \"loss\" =  5.0462465\n",
      "2018-08-30 06:25:50.692746 Test Step 2280 Finished\n",
      "2018-08-30 06:25:50.693153 Test Step 2280 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:50.693377 Test Step 2280 \"loss\" =  8.166595\n",
      "2018-08-30 06:25:50.739946 Training Step 2280 Finished Timing (Training: 0.911802, Test: 0.0824024) after 0.252362 seconds\n",
      "2018-08-30 06:25:50.740011 Training Step 2280 \"min loss\" =  5.0244017\n",
      "2018-08-30 06:25:50.740378 Training Step 2280 \"loss\" =  5.7577257\n",
      "2018-08-30 06:25:50.946458 Test Step 2285 Finished\n",
      "2018-08-30 06:25:50.946600 Test Step 2285 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:50.946655 Test Step 2285 \"loss\" =  8.017966\n",
      "2018-08-30 06:25:50.993371 Training Step 2285 Finished Timing (Training: 0.911717, Test: 0.0824422) after 0.25267 seconds\n",
      "2018-08-30 06:25:50.993444 Training Step 2285 \"min loss\" =  5.0244017\n",
      "2018-08-30 06:25:50.993499 Training Step 2285 \"loss\" =  5.447871\n",
      "2018-08-30 06:25:51.199396 Test Step 2290 Finished\n",
      "2018-08-30 06:25:51.199786 Test Step 2290 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:51.200111 Test Step 2290 \"loss\" =  7.4446545\n",
      "2018-08-30 06:25:51.246458 Training Step 2290 Finished Timing (Training: 0.911563, Test: 0.0825261) after 0.252333 seconds\n",
      "2018-08-30 06:25:51.246585 Training Step 2290 \"min loss\" =  5.0244017\n",
      "2018-08-30 06:25:51.246642 Training Step 2290 \"loss\" =  5.613719\n",
      "2018-08-30 06:25:51.453162 Test Step 2295 Finished\n",
      "2018-08-30 06:25:51.453550 Test Step 2295 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:51.453614 Test Step 2295 \"loss\" =  7.453515\n",
      "2018-08-30 06:25:51.500053 Training Step 2295 Finished Timing (Training: 0.911525, Test: 0.0825117) after 0.252798 seconds\n",
      "2018-08-30 06:25:51.500115 Training Step 2295 \"min loss\" =  5.0244017\n",
      "2018-08-30 06:25:51.500495 Training Step 2295 \"loss\" =  5.4708548\n",
      "2018-08-30 06:25:51.705778 Test Step 2300 Finished\n",
      "2018-08-30 06:25:51.705865 Test Step 2300 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:51.705924 Test Step 2300 \"loss\" =  7.834332\n",
      "2018-08-30 06:25:51.752625 Training Step 2300 Finished Timing (Training: 0.911446, Test: 0.0825077) after 0.251638 seconds\n",
      "2018-08-30 06:25:51.752686 Training Step 2300 \"min loss\" =  4.9516716\n",
      "2018-08-30 06:25:51.752740 Training Step 2300 \"loss\" =  5.371097\n",
      "2018-08-30 06:25:51.958919 Test Step 2305 Finished\n",
      "2018-08-30 06:25:51.959003 Test Step 2305 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:51.959460 Test Step 2305 \"loss\" =  7.664051\n",
      "2018-08-30 06:25:52.005879 Training Step 2305 Finished Timing (Training: 0.912575, Test: 0.0836602) after 0.252516 seconds\n",
      "2018-08-30 06:25:52.006090 Training Step 2305 \"min loss\" =  4.9516716\n",
      "2018-08-30 06:25:52.006479 Training Step 2305 \"loss\" =  5.548533\n",
      "2018-08-30 06:25:52.211342 Test Step 2310 Finished\n",
      "2018-08-30 06:25:52.211431 Test Step 2310 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:52.211490 Test Step 2310 \"loss\" =  7.7483544\n",
      "2018-08-30 06:25:52.258587 Training Step 2310 Finished Timing (Training: 0.911494, Test: 0.0830958) after 0.251766 seconds\n",
      "2018-08-30 06:25:52.258663 Training Step 2310 \"min loss\" =  4.9484234\n",
      "2018-08-30 06:25:52.258719 Training Step 2310 \"loss\" =  5.3212323\n",
      "2018-08-30 06:25:52.464678 Test Step 2315 Finished\n",
      "2018-08-30 06:25:52.465103 Test Step 2315 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:52.465174 Test Step 2315 \"loss\" =  7.267754\n",
      "2018-08-30 06:25:52.511808 Training Step 2315 Finished Timing (Training: 0.911455, Test: 0.0829876) after 0.252337 seconds\n",
      "2018-08-30 06:25:52.512090 Training Step 2315 \"min loss\" =  4.9484234\n",
      "2018-08-30 06:25:52.512156 Training Step 2315 \"loss\" =  5.593496\n",
      "2018-08-30 06:25:52.717660 Test Step 2320 Finished\n",
      "2018-08-30 06:25:52.717764 Test Step 2320 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:52.717853 Test Step 2320 \"loss\" =  7.45423\n",
      "2018-08-30 06:25:52.764391 Training Step 2320 Finished Timing (Training: 0.91166, Test: 0.0829348) after 0.251614 seconds\n",
      "2018-08-30 06:25:52.764469 Training Step 2320 \"min loss\" =  4.9484234\n",
      "2018-08-30 06:25:52.764843 Training Step 2320 \"loss\" =  5.648459\n",
      "2018-08-30 06:25:52.969926 Test Step 2325 Finished\n",
      "2018-08-30 06:25:52.970224 Test Step 2325 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:52.970672 Test Step 2325 \"loss\" =  7.503363\n",
      "2018-08-30 06:25:53.016993 Training Step 2325 Finished Timing (Training: 0.911504, Test: 0.0828791) after 0.251807 seconds\n",
      "2018-08-30 06:25:53.017089 Training Step 2325 \"min loss\" =  4.9484234\n",
      "2018-08-30 06:25:53.017548 Training Step 2325 \"loss\" =  5.0147624\n",
      "2018-08-30 06:25:53.223209 Test Step 2330 Finished\n",
      "2018-08-30 06:25:53.223373 Test Step 2330 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:53.223435 Test Step 2330 \"loss\" =  7.6271315\n",
      "2018-08-30 06:25:53.269565 Training Step 2330 Finished Timing (Training: 0.911595, Test: 0.0828907) after 0.251647 seconds\n",
      "2018-08-30 06:25:53.269637 Training Step 2330 \"min loss\" =  4.9484234\n",
      "2018-08-30 06:25:53.270073 Training Step 2330 \"loss\" =  5.5857563\n",
      "2018-08-30 06:25:53.475034 Test Step 2335 Finished\n",
      "2018-08-30 06:25:53.475386 Test Step 2335 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:53.475449 Test Step 2335 \"loss\" =  7.540252\n",
      "2018-08-30 06:25:53.521390 Training Step 2335 Finished Timing (Training: 0.911695, Test: 0.0829585) after 0.251246 seconds\n",
      "2018-08-30 06:25:53.521461 Training Step 2335 \"min loss\" =  4.9484234\n",
      "2018-08-30 06:25:53.521518 Training Step 2335 \"loss\" =  5.517292\n",
      "2018-08-30 06:25:53.725667 Test Step 2340 Finished\n",
      "2018-08-30 06:25:53.725784 Test Step 2340 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:53.725847 Test Step 2340 \"loss\" =  7.8340807\n",
      "2018-08-30 06:25:53.772630 Training Step 2340 Finished Timing (Training: 0.911878, Test: 0.0828891) after 0.251044 seconds\n",
      "2018-08-30 06:25:53.772690 Training Step 2340 \"min loss\" =  4.9484234\n",
      "2018-08-30 06:25:53.772741 Training Step 2340 \"loss\" =  5.130621\n",
      "2018-08-30 06:25:53.978087 Test Step 2345 Finished\n",
      "2018-08-30 06:25:53.978186 Test Step 2345 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:53.978778 Test Step 2345 \"loss\" =  7.533811\n",
      "2018-08-30 06:25:54.025423 Training Step 2345 Finished Timing (Training: 0.911757, Test: 0.0827705) after 0.251981 seconds\n",
      "2018-08-30 06:25:54.025491 Training Step 2345 \"min loss\" =  4.9172134\n",
      "2018-08-30 06:25:54.025551 Training Step 2345 \"loss\" =  5.7867327\n",
      "2018-08-30 06:25:54.231271 Test Step 2350 Finished\n",
      "2018-08-30 06:25:54.231355 Test Step 2350 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:54.231416 Test Step 2350 \"loss\" =  7.9173813\n",
      "2018-08-30 06:25:54.278279 Training Step 2350 Finished Timing (Training: 0.912186, Test: 0.0827096) after 0.25266 seconds\n",
      "2018-08-30 06:25:54.278353 Training Step 2350 \"min loss\" =  4.9172134\n",
      "2018-08-30 06:25:54.278864 Training Step 2350 \"loss\" =  5.757814\n",
      "2018-08-30 06:25:54.483609 Test Step 2355 Finished\n",
      "2018-08-30 06:25:54.483723 Test Step 2355 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:54.483804 Test Step 2355 \"loss\" =  7.383456\n",
      "2018-08-30 06:25:54.530516 Training Step 2355 Finished Timing (Training: 0.912364, Test: 0.082654) after 0.25158 seconds\n",
      "2018-08-30 06:25:54.530589 Training Step 2355 \"min loss\" =  4.9172134\n",
      "2018-08-30 06:25:54.530671 Training Step 2355 \"loss\" =  5.2527328\n",
      "2018-08-30 06:25:54.736672 Test Step 2360 Finished\n",
      "2018-08-30 06:25:54.737087 Test Step 2360 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:54.737155 Test Step 2360 \"loss\" =  7.7996025\n",
      "2018-08-30 06:25:54.783875 Training Step 2360 Finished Timing (Training: 0.912302, Test: 0.0826451) after 0.252453 seconds\n",
      "2018-08-30 06:25:54.783943 Training Step 2360 \"min loss\" =  4.9172134\n",
      "2018-08-30 06:25:54.784020 Training Step 2360 \"loss\" =  5.387806\n",
      "2018-08-30 06:25:54.988913 Test Step 2365 Finished\n",
      "2018-08-30 06:25:54.989030 Test Step 2365 \"min loss\" =  7.2666607\n",
      "2018-08-30 06:25:54.989104 Test Step 2365 \"loss\" =  7.353295\n",
      "2018-08-30 06:25:55.035936 Training Step 2365 Finished Timing (Training: 0.912531, Test: 0.0826512) after 0.251852 seconds\n",
      "2018-08-30 06:25:55.036000 Training Step 2365 \"min loss\" =  4.9172134\n",
      "2018-08-30 06:25:55.036057 Training Step 2365 \"loss\" =  5.23513\n",
      "2018-08-30 06:25:55.240683 Test Step 2370 Finished\n",
      "2018-08-30 06:25:55.240765 Test Step 2370 \"min loss\" =  7.2476244\n",
      "2018-08-30 06:25:55.240841 Test Step 2370 \"loss\" =  7.2476244\n",
      "2018-08-30 06:25:55.286735 Training Step 2370 Finished Timing (Training: 0.912776, Test: 0.0826256) after 0.250611 seconds\n",
      "2018-08-30 06:25:55.287004 Training Step 2370 \"min loss\" =  4.9172134\n",
      "2018-08-30 06:25:55.287073 Training Step 2370 \"loss\" =  5.2383366\n",
      "2018-08-30 06:25:55.491862 Test Step 2375 Finished\n",
      "2018-08-30 06:25:55.491941 Test Step 2375 \"min loss\" =  7.1734414\n",
      "2018-08-30 06:25:55.492709 Test Step 2375 \"loss\" =  7.1734414\n",
      "2018-08-30 06:25:55.538756 Training Step 2375 Finished Timing (Training: 0.912679, Test: 0.0825657) after 0.251201 seconds\n",
      "2018-08-30 06:25:55.538833 Training Step 2375 \"min loss\" =  4.9172134\n",
      "2018-08-30 06:25:55.538896 Training Step 2375 \"loss\" =  5.468523\n",
      "2018-08-30 06:25:55.744224 Test Step 2380 Finished\n",
      "2018-08-30 06:25:55.744304 Test Step 2380 \"min loss\" =  7.1734414\n",
      "2018-08-30 06:25:55.744357 Test Step 2380 \"loss\" =  7.677244\n",
      "2018-08-30 06:25:55.790375 Training Step 2380 Finished Timing (Training: 0.912886, Test: 0.0825421) after 0.251385 seconds\n",
      "2018-08-30 06:25:55.790447 Training Step 2380 \"min loss\" =  4.9172134\n",
      "2018-08-30 06:25:55.790513 Training Step 2380 \"loss\" =  6.439006\n",
      "2018-08-30 06:25:55.995433 Test Step 2385 Finished\n",
      "2018-08-30 06:25:55.995551 Test Step 2385 \"min loss\" =  7.009744\n",
      "2018-08-30 06:25:55.996138 Test Step 2385 \"loss\" =  7.009744\n",
      "2018-08-30 06:25:56.042526 Training Step 2385 Finished Timing (Training: 0.912938, Test: 0.0825208) after 0.251929 seconds\n",
      "2018-08-30 06:25:56.042606 Training Step 2385 \"min loss\" =  4.904055\n",
      "2018-08-30 06:25:56.042665 Training Step 2385 \"loss\" =  5.344672\n",
      "2018-08-30 06:25:56.247807 Test Step 2390 Finished\n",
      "2018-08-30 06:25:56.247908 Test Step 2390 \"min loss\" =  7.009744\n",
      "2018-08-30 06:25:56.247984 Test Step 2390 \"loss\" =  7.2361107\n",
      "2018-08-30 06:25:56.294878 Training Step 2390 Finished Timing (Training: 0.912968, Test: 0.0824763) after 0.252109 seconds\n",
      "2018-08-30 06:25:56.294953 Training Step 2390 \"min loss\" =  4.904055\n",
      "2018-08-30 06:25:56.295044 Training Step 2390 \"loss\" =  5.1183786\n",
      "2018-08-30 06:25:56.499859 Test Step 2395 Finished\n",
      "2018-08-30 06:25:56.499944 Test Step 2395 \"min loss\" =  7.009744\n",
      "2018-08-30 06:25:56.500612 Test Step 2395 \"loss\" =  7.1857305\n",
      "2018-08-30 06:25:56.547006 Training Step 2395 Finished Timing (Training: 0.913011, Test: 0.082449) after 0.25189 seconds\n",
      "2018-08-30 06:25:56.547068 Training Step 2395 \"min loss\" =  4.7222357\n",
      "2018-08-30 06:25:56.547120 Training Step 2395 \"loss\" =  5.5061884\n",
      "2018-08-30 06:25:56.753682 Test Step 2400 Finished\n",
      "2018-08-30 06:25:56.753782 Test Step 2400 \"min loss\" =  7.009744\n",
      "2018-08-30 06:25:56.753854 Test Step 2400 \"loss\" =  7.2983046\n",
      "2018-08-30 06:25:56.800590 Training Step 2400 Finished Timing (Training: 0.913092, Test: 0.0825092) after 0.253411 seconds\n",
      "2018-08-30 06:25:56.800655 Training Step 2400 \"min loss\" =  4.7222357\n",
      "2018-08-30 06:25:56.800706 Training Step 2400 \"loss\" =  5.0046678\n",
      "2018-08-30 06:25:57.006927 Test Step 2405 Finished\n",
      "2018-08-30 06:25:57.007007 Test Step 2405 \"min loss\" =  7.009744\n",
      "2018-08-30 06:25:57.007088 Test Step 2405 \"loss\" =  7.2139792\n",
      "2018-08-30 06:25:57.053796 Training Step 2405 Finished Timing (Training: 0.914395, Test: 0.0845979) after 0.252336 seconds\n",
      "2018-08-30 06:25:57.053857 Training Step 2405 \"min loss\" =  4.7222357\n",
      "2018-08-30 06:25:57.053909 Training Step 2405 \"loss\" =  5.1007624\n",
      "2018-08-30 06:25:57.259367 Test Step 2410 Finished\n",
      "2018-08-30 06:25:57.259756 Test Step 2410 \"min loss\" =  7.009744\n",
      "2018-08-30 06:25:57.259827 Test Step 2410 \"loss\" =  7.4512625\n",
      "2018-08-30 06:25:57.306433 Training Step 2410 Finished Timing (Training: 0.913723, Test: 0.0833503) after 0.252447 seconds\n",
      "2018-08-30 06:25:57.306494 Training Step 2410 \"min loss\" =  4.7222357\n",
      "2018-08-30 06:25:57.306545 Training Step 2410 \"loss\" =  6.205998\n",
      "2018-08-30 06:25:57.511102 Test Step 2415 Finished\n",
      "2018-08-30 06:25:57.511191 Test Step 2415 \"min loss\" =  7.009744\n",
      "2018-08-30 06:25:57.511249 Test Step 2415 \"loss\" =  7.343303\n",
      "2018-08-30 06:25:57.558438 Training Step 2415 Finished Timing (Training: 0.913679, Test: 0.0828047) after 0.251832 seconds\n",
      "2018-08-30 06:25:57.558510 Training Step 2415 \"min loss\" =  4.7222357\n",
      "2018-08-30 06:25:57.558871 Training Step 2415 \"loss\" =  4.8991847\n",
      "2018-08-30 06:25:57.764111 Test Step 2420 Finished\n",
      "2018-08-30 06:25:57.764178 Test Step 2420 \"min loss\" =  7.009744\n",
      "2018-08-30 06:25:57.764229 Test Step 2420 \"loss\" =  7.8725677\n",
      "2018-08-30 06:25:57.810940 Training Step 2420 Finished Timing (Training: 0.913237, Test: 0.0825787) after 0.251734 seconds\n",
      "2018-08-30 06:25:57.810999 Training Step 2420 \"min loss\" =  4.7222357\n",
      "2018-08-30 06:25:57.811329 Training Step 2420 \"loss\" =  5.3016005\n",
      "2018-08-30 06:25:58.016618 Test Step 2425 Finished\n",
      "2018-08-30 06:25:58.017168 Test Step 2425 \"min loss\" =  7.009744\n",
      "2018-08-30 06:25:58.017539 Test Step 2425 \"loss\" =  7.13709\n",
      "2018-08-30 06:25:58.064625 Training Step 2425 Finished Timing (Training: 0.912748, Test: 0.0822861) after 0.252983 seconds\n",
      "2018-08-30 06:25:58.064688 Training Step 2425 \"min loss\" =  4.7222357\n",
      "2018-08-30 06:25:58.065082 Training Step 2425 \"loss\" =  5.434443\n",
      "2018-08-30 06:25:58.270275 Test Step 2430 Finished\n",
      "2018-08-30 06:25:58.270341 Test Step 2430 \"min loss\" =  7.009744\n",
      "2018-08-30 06:25:58.270853 Test Step 2430 \"loss\" =  7.347105\n",
      "2018-08-30 06:25:58.317417 Training Step 2430 Finished Timing (Training: 0.91286, Test: 0.0822296) after 0.252277 seconds\n",
      "2018-08-30 06:25:58.317482 Training Step 2430 \"min loss\" =  4.7222357\n",
      "2018-08-30 06:25:58.317810 Training Step 2430 \"loss\" =  5.3909492\n",
      "2018-08-30 06:25:58.522969 Test Step 2435 Finished\n",
      "2018-08-30 06:25:58.523050 Test Step 2435 \"min loss\" =  7.009744\n",
      "2018-08-30 06:25:58.523504 Test Step 2435 \"loss\" =  7.2161064\n",
      "2018-08-30 06:25:58.569910 Training Step 2435 Finished Timing (Training: 0.912686, Test: 0.0821991) after 0.251789 seconds\n",
      "2018-08-30 06:25:58.570128 Training Step 2435 \"min loss\" =  4.7222357\n",
      "2018-08-30 06:25:58.570323 Training Step 2435 \"loss\" =  5.4526324\n",
      "2018-08-30 06:25:58.775812 Test Step 2440 Finished\n",
      "2018-08-30 06:25:58.775876 Test Step 2440 \"min loss\" =  7.009744\n",
      "2018-08-30 06:25:58.776448 Test Step 2440 \"loss\" =  7.753199\n",
      "2018-08-30 06:25:58.822788 Training Step 2440 Finished Timing (Training: 0.912533, Test: 0.0821822) after 0.252152 seconds\n",
      "2018-08-30 06:25:58.822844 Training Step 2440 \"min loss\" =  4.7222357\n",
      "2018-08-30 06:25:58.823179 Training Step 2440 \"loss\" =  5.6164536\n",
      "2018-08-30 06:25:59.028701 Test Step 2445 Finished\n",
      "2018-08-30 06:25:59.028786 Test Step 2445 \"min loss\" =  7.009744\n",
      "2018-08-30 06:25:59.029273 Test Step 2445 \"loss\" =  7.651719\n",
      "2018-08-30 06:25:59.075668 Training Step 2445 Finished Timing (Training: 0.912292, Test: 0.0822845) after 0.252179 seconds\n",
      "2018-08-30 06:25:59.075728 Training Step 2445 \"min loss\" =  4.7222357\n",
      "2018-08-30 06:25:59.076077 Training Step 2445 \"loss\" =  5.3399286\n",
      "2018-08-30 06:25:59.281844 Test Step 2450 Finished\n",
      "2018-08-30 06:25:59.281946 Test Step 2450 \"min loss\" =  7.009744\n",
      "2018-08-30 06:25:59.282013 Test Step 2450 \"loss\" =  7.6662006\n",
      "2018-08-30 06:25:59.328888 Training Step 2450 Finished Timing (Training: 0.912214, Test: 0.0822636) after 0.252495 seconds\n",
      "2018-08-30 06:25:59.328949 Training Step 2450 \"min loss\" =  4.7222357\n",
      "2018-08-30 06:25:59.329434 Training Step 2450 \"loss\" =  5.135592\n",
      "2018-08-30 06:25:59.534491 Test Step 2455 Finished\n",
      "2018-08-30 06:25:59.534585 Test Step 2455 \"min loss\" =  7.009744\n",
      "2018-08-30 06:25:59.535049 Test Step 2455 \"loss\" =  7.220836\n",
      "2018-08-30 06:25:59.581473 Training Step 2455 Finished Timing (Training: 0.912158, Test: 0.0822295) after 0.251843 seconds\n",
      "2018-08-30 06:25:59.581531 Training Step 2455 \"min loss\" =  4.7222357\n",
      "2018-08-30 06:25:59.581882 Training Step 2455 \"loss\" =  5.7311954\n",
      "2018-08-30 06:25:59.786888 Test Step 2460 Finished\n",
      "2018-08-30 06:25:59.786958 Test Step 2460 \"min loss\" =  7.009744\n",
      "2018-08-30 06:25:59.787384 Test Step 2460 \"loss\" =  7.2827506\n",
      "2018-08-30 06:25:59.833641 Training Step 2460 Finished Timing (Training: 0.912079, Test: 0.0822653) after 0.251451 seconds\n",
      "2018-08-30 06:25:59.833703 Training Step 2460 \"min loss\" =  4.7222357\n",
      "2018-08-30 06:25:59.834096 Training Step 2460 \"loss\" =  5.0624332\n",
      "2018-08-30 06:26:00.039432 Test Step 2465 Finished\n",
      "2018-08-30 06:26:00.039785 Test Step 2465 \"min loss\" =  7.009744\n",
      "2018-08-30 06:26:00.039994 Test Step 2465 \"loss\" =  7.3440075\n",
      "2018-08-30 06:26:00.086534 Training Step 2465 Finished Timing (Training: 0.912016, Test: 0.0822567) after 0.252162 seconds\n",
      "2018-08-30 06:26:00.086760 Training Step 2465 \"min loss\" =  4.7222357\n",
      "2018-08-30 06:26:00.086954 Training Step 2465 \"loss\" =  5.2374005\n",
      "2018-08-30 06:26:00.292228 Test Step 2470 Finished\n",
      "2018-08-30 06:26:00.292319 Test Step 2470 \"min loss\" =  7.009744\n",
      "2018-08-30 06:26:00.292381 Test Step 2470 \"loss\" =  7.7211213\n",
      "2018-08-30 06:26:00.339208 Training Step 2470 Finished Timing (Training: 0.911986, Test: 0.0822453) after 0.251943 seconds\n",
      "2018-08-30 06:26:00.339270 Training Step 2470 \"min loss\" =  4.7222357\n",
      "2018-08-30 06:26:00.339740 Training Step 2470 \"loss\" =  5.662767\n",
      "2018-08-30 06:26:00.546183 Test Step 2475 Finished\n",
      "2018-08-30 06:26:00.546306 Test Step 2475 \"min loss\" =  7.009744\n",
      "2018-08-30 06:26:00.546919 Test Step 2475 \"loss\" =  7.6704626\n",
      "2018-08-30 06:26:00.593326 Training Step 2475 Finished Timing (Training: 0.911856, Test: 0.0823365) after 0.253333 seconds\n",
      "2018-08-30 06:26:00.593398 Training Step 2475 \"min loss\" =  4.7222357\n",
      "2018-08-30 06:26:00.593472 Training Step 2475 \"loss\" =  6.3654165\n",
      "2018-08-30 06:26:00.798244 Test Step 2480 Finished\n",
      "2018-08-30 06:26:00.798323 Test Step 2480 \"min loss\" =  7.009744\n",
      "2018-08-30 06:26:00.798366 Test Step 2480 \"loss\" =  7.224883\n",
      "2018-08-30 06:26:00.844364 Training Step 2480 Finished Timing (Training: 0.912055, Test: 0.0823895) after 0.250789 seconds\n",
      "2018-08-30 06:26:00.844432 Training Step 2480 \"min loss\" =  4.7222357\n",
      "2018-08-30 06:26:00.844954 Training Step 2480 \"loss\" =  5.147471\n",
      "2018-08-30 06:26:01.049976 Test Step 2485 Finished\n",
      "2018-08-30 06:26:01.050074 Test Step 2485 \"min loss\" =  7.009744\n",
      "2018-08-30 06:26:01.050178 Test Step 2485 \"loss\" =  7.4847016\n",
      "2018-08-30 06:26:01.097088 Training Step 2485 Finished Timing (Training: 0.911896, Test: 0.0824455) after 0.252067 seconds\n",
      "2018-08-30 06:26:01.097149 Training Step 2485 \"min loss\" =  4.7222357\n",
      "2018-08-30 06:26:01.097189 Training Step 2485 \"loss\" =  4.8114223\n",
      "2018-08-30 06:26:01.302204 Test Step 2490 Finished\n",
      "2018-08-30 06:26:01.302282 Test Step 2490 \"min loss\" =  7.009744\n",
      "2018-08-30 06:26:01.302348 Test Step 2490 \"loss\" =  7.4247\n",
      "2018-08-30 06:26:01.349073 Training Step 2490 Finished Timing (Training: 0.911959, Test: 0.0824343) after 0.251808 seconds\n",
      "2018-08-30 06:26:01.349136 Training Step 2490 \"min loss\" =  4.7222357\n",
      "2018-08-30 06:26:01.349181 Training Step 2490 \"loss\" =  5.540798\n",
      "2018-08-30 06:26:01.554414 Test Step 2495 Finished\n",
      "2018-08-30 06:26:01.554843 Test Step 2495 \"min loss\" =  7.009744\n",
      "2018-08-30 06:26:01.554906 Test Step 2495 \"loss\" =  7.057781\n",
      "2018-08-30 06:26:01.601416 Training Step 2495 Finished Timing (Training: 0.911976, Test: 0.0824238) after 0.252134 seconds\n",
      "2018-08-30 06:26:01.601474 Training Step 2495 \"min loss\" =  4.7222357\n",
      "2018-08-30 06:26:01.601769 Training Step 2495 \"loss\" =  5.1489177\n",
      "2018-08-30 06:26:01.807787 Test Step 2500 Finished\n",
      "2018-08-30 06:26:01.807905 Test Step 2500 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:01.807977 Test Step 2500 \"loss\" =  6.9635506\n",
      "2018-08-30 06:26:01.854704 Training Step 2500 Finished Timing (Training: 0.911895, Test: 0.0824521) after 0.252732 seconds\n",
      "2018-08-30 06:26:01.854775 Training Step 2500 \"min loss\" =  4.635459\n",
      "2018-08-30 06:26:01.854825 Training Step 2500 \"loss\" =  4.878745\n",
      "2018-08-30 06:26:02.059778 Test Step 2505 Finished\n",
      "2018-08-30 06:26:02.059874 Test Step 2505 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:02.060004 Test Step 2505 \"loss\" =  7.3982205\n",
      "2018-08-30 06:26:02.107088 Training Step 2505 Finished Timing (Training: 0.912878, Test: 0.0822753) after 0.252192 seconds\n",
      "2018-08-30 06:26:02.107159 Training Step 2505 \"min loss\" =  4.635459\n",
      "2018-08-30 06:26:02.107201 Training Step 2505 \"loss\" =  5.2078476\n",
      "2018-08-30 06:26:02.312754 Test Step 2510 Finished\n",
      "2018-08-30 06:26:02.312851 Test Step 2510 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:02.312969 Test Step 2510 \"loss\" =  7.490494\n",
      "2018-08-30 06:26:02.359816 Training Step 2510 Finished Timing (Training: 0.913641, Test: 0.0817354) after 0.251907 seconds\n",
      "2018-08-30 06:26:02.359886 Training Step 2510 \"min loss\" =  4.5336504\n",
      "2018-08-30 06:26:02.359928 Training Step 2510 \"loss\" =  5.484974\n",
      "2018-08-30 06:26:02.565525 Test Step 2515 Finished\n",
      "2018-08-30 06:26:02.565916 Test Step 2515 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:02.565977 Test Step 2515 \"loss\" =  7.5456433\n",
      "2018-08-30 06:26:02.612581 Training Step 2515 Finished Timing (Training: 0.913756, Test: 0.0821756) after 0.252558 seconds\n",
      "2018-08-30 06:26:02.612649 Training Step 2515 \"min loss\" =  4.5336504\n",
      "2018-08-30 06:26:02.612708 Training Step 2515 \"loss\" =  5.9294176\n",
      "2018-08-30 06:26:02.817665 Test Step 2520 Finished\n",
      "2018-08-30 06:26:02.817745 Test Step 2520 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:02.818255 Test Step 2520 \"loss\" =  8.520012\n",
      "2018-08-30 06:26:02.864456 Training Step 2520 Finished Timing (Training: 0.913089, Test: 0.0823514) after 0.251028 seconds\n",
      "2018-08-30 06:26:02.864520 Training Step 2520 \"min loss\" =  4.5336504\n",
      "2018-08-30 06:26:02.864888 Training Step 2520 \"loss\" =  5.3855605\n",
      "2018-08-30 06:26:03.069960 Test Step 2525 Finished\n",
      "2018-08-30 06:26:03.070038 Test Step 2525 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:03.070491 Test Step 2525 \"loss\" =  8.038798\n",
      "2018-08-30 06:26:03.116897 Training Step 2525 Finished Timing (Training: 0.912841, Test: 0.0823475) after 0.251941 seconds\n",
      "2018-08-30 06:26:03.116960 Training Step 2525 \"min loss\" =  4.5336504\n",
      "2018-08-30 06:26:03.117001 Training Step 2525 \"loss\" =  5.4069657\n",
      "2018-08-30 06:26:03.323429 Test Step 2530 Finished\n",
      "2018-08-30 06:26:03.323500 Test Step 2530 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:03.323566 Test Step 2530 \"loss\" =  7.6731944\n",
      "2018-08-30 06:26:03.370842 Training Step 2530 Finished Timing (Training: 0.91283, Test: 0.0824526) after 0.253081 seconds\n",
      "2018-08-30 06:26:03.370937 Training Step 2530 \"min loss\" =  4.5336504\n",
      "2018-08-30 06:26:03.371029 Training Step 2530 \"loss\" =  5.2451735\n",
      "2018-08-30 06:26:03.576625 Test Step 2535 Finished\n",
      "2018-08-30 06:26:03.576748 Test Step 2535 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:03.576830 Test Step 2535 \"loss\" =  7.5072846\n",
      "2018-08-30 06:26:03.623597 Training Step 2535 Finished Timing (Training: 0.912252, Test: 0.0825177) after 0.251684 seconds\n",
      "2018-08-30 06:26:03.623664 Training Step 2535 \"min loss\" =  4.5336504\n",
      "2018-08-30 06:26:03.623718 Training Step 2535 \"loss\" =  5.2679977\n",
      "2018-08-30 06:26:03.828876 Test Step 2540 Finished\n",
      "2018-08-30 06:26:03.828980 Test Step 2540 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:03.829538 Test Step 2540 \"loss\" =  7.9274306\n",
      "2018-08-30 06:26:03.875946 Training Step 2540 Finished Timing (Training: 0.9125, Test: 0.0824594) after 0.252161 seconds\n",
      "2018-08-30 06:26:03.876247 Training Step 2540 \"min loss\" =  4.5336504\n",
      "2018-08-30 06:26:03.876514 Training Step 2540 \"loss\" =  5.324506\n",
      "2018-08-30 06:26:04.081294 Test Step 2545 Finished\n",
      "2018-08-30 06:26:04.081395 Test Step 2545 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:04.081522 Test Step 2545 \"loss\" =  7.2771535\n",
      "2018-08-30 06:26:04.127577 Training Step 2545 Finished Timing (Training: 0.912609, Test: 0.0824885) after 0.250992 seconds\n",
      "2018-08-30 06:26:04.127658 Training Step 2545 \"min loss\" =  4.5145736\n",
      "2018-08-30 06:26:04.127715 Training Step 2545 \"loss\" =  4.9198327\n",
      "2018-08-30 06:26:04.333677 Test Step 2550 Finished\n",
      "2018-08-30 06:26:04.333805 Test Step 2550 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:04.333872 Test Step 2550 \"loss\" =  7.788097\n",
      "2018-08-30 06:26:04.380756 Training Step 2550 Finished Timing (Training: 0.912928, Test: 0.0824662) after 0.252975 seconds\n",
      "2018-08-30 06:26:04.380825 Training Step 2550 \"min loss\" =  4.5145736\n",
      "2018-08-30 06:26:04.380882 Training Step 2550 \"loss\" =  5.4207244\n",
      "2018-08-30 06:26:04.585858 Test Step 2555 Finished\n",
      "2018-08-30 06:26:04.586246 Test Step 2555 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:04.586310 Test Step 2555 \"loss\" =  7.57982\n",
      "2018-08-30 06:26:04.632890 Training Step 2555 Finished Timing (Training: 0.913067, Test: 0.0824885) after 0.25195 seconds\n",
      "2018-08-30 06:26:04.632957 Training Step 2555 \"min loss\" =  4.5145736\n",
      "2018-08-30 06:26:04.633388 Training Step 2555 \"loss\" =  5.048396\n",
      "2018-08-30 06:26:04.838441 Test Step 2560 Finished\n",
      "2018-08-30 06:26:04.838723 Test Step 2560 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:04.838785 Test Step 2560 \"loss\" =  7.6813817\n",
      "2018-08-30 06:26:04.885461 Training Step 2560 Finished Timing (Training: 0.912951, Test: 0.082449) after 0.252007 seconds\n",
      "2018-08-30 06:26:04.885536 Training Step 2560 \"min loss\" =  4.5145736\n",
      "2018-08-30 06:26:04.885597 Training Step 2560 \"loss\" =  5.012938\n",
      "2018-08-30 06:26:05.091692 Test Step 2565 Finished\n",
      "2018-08-30 06:26:05.092079 Test Step 2565 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:05.092168 Test Step 2565 \"loss\" =  7.2853007\n",
      "2018-08-30 06:26:05.138728 Training Step 2565 Finished Timing (Training: 0.912879, Test: 0.0824683) after 0.252505 seconds\n",
      "2018-08-30 06:26:05.139028 Training Step 2565 \"min loss\" =  4.511668\n",
      "2018-08-30 06:26:05.139089 Training Step 2565 \"loss\" =  4.838159\n",
      "2018-08-30 06:26:05.344070 Test Step 2570 Finished\n",
      "2018-08-30 06:26:05.344152 Test Step 2570 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:05.344197 Test Step 2570 \"loss\" =  7.475419\n",
      "2018-08-30 06:26:05.390104 Training Step 2570 Finished Timing (Training: 0.912916, Test: 0.0824834) after 0.250608 seconds\n",
      "2018-08-30 06:26:05.390173 Training Step 2570 \"min loss\" =  4.511668\n",
      "2018-08-30 06:26:05.390533 Training Step 2570 \"loss\" =  4.8489594\n",
      "2018-08-30 06:26:05.595720 Test Step 2575 Finished\n",
      "2018-08-30 06:26:05.595802 Test Step 2575 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:05.595854 Test Step 2575 \"loss\" =  7.53106\n",
      "2018-08-30 06:26:05.643187 Training Step 2575 Finished Timing (Training: 0.912819, Test: 0.0824344) after 0.252584 seconds\n",
      "2018-08-30 06:26:05.643275 Training Step 2575 \"min loss\" =  4.511668\n",
      "2018-08-30 06:26:05.643361 Training Step 2575 \"loss\" =  5.1546073\n",
      "2018-08-30 06:26:05.848800 Test Step 2580 Finished\n",
      "2018-08-30 06:26:05.848872 Test Step 2580 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:05.849462 Test Step 2580 \"loss\" =  7.9483128\n",
      "2018-08-30 06:26:05.895667 Training Step 2580 Finished Timing (Training: 0.912683, Test: 0.0824903) after 0.2517 seconds\n",
      "2018-08-30 06:26:05.895763 Training Step 2580 \"min loss\" =  4.511668\n",
      "2018-08-30 06:26:05.895816 Training Step 2580 \"loss\" =  5.037484\n",
      "2018-08-30 06:26:06.101760 Test Step 2585 Finished\n",
      "2018-08-30 06:26:06.102040 Test Step 2585 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:06.102324 Test Step 2585 \"loss\" =  7.729846\n",
      "2018-08-30 06:26:06.148935 Training Step 2585 Finished Timing (Training: 0.912579, Test: 0.0824889) after 0.252493 seconds\n",
      "2018-08-30 06:26:06.149011 Training Step 2585 \"min loss\" =  4.511668\n",
      "2018-08-30 06:26:06.149493 Training Step 2585 \"loss\" =  5.108862\n",
      "2018-08-30 06:26:06.355201 Test Step 2590 Finished\n",
      "2018-08-30 06:26:06.355270 Test Step 2590 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:06.355664 Test Step 2590 \"loss\" =  7.58133\n",
      "2018-08-30 06:26:06.401958 Training Step 2590 Finished Timing (Training: 0.912433, Test: 0.0825285) after 0.252128 seconds\n",
      "2018-08-30 06:26:06.402037 Training Step 2590 \"min loss\" =  4.511668\n",
      "2018-08-30 06:26:06.402092 Training Step 2590 \"loss\" =  5.0343337\n",
      "2018-08-30 06:26:06.607766 Test Step 2595 Finished\n",
      "2018-08-30 06:26:06.607834 Test Step 2595 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:06.608219 Test Step 2595 \"loss\" =  7.430887\n",
      "2018-08-30 06:26:06.654685 Training Step 2595 Finished Timing (Training: 0.912322, Test: 0.0825749) after 0.251991 seconds\n",
      "2018-08-30 06:26:06.654758 Training Step 2595 \"min loss\" =  4.511668\n",
      "2018-08-30 06:26:06.654822 Training Step 2595 \"loss\" =  5.2203727\n",
      "2018-08-30 06:26:06.860497 Test Step 2600 Finished\n",
      "2018-08-30 06:26:06.860765 Test Step 2600 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:06.861050 Test Step 2600 \"loss\" =  7.632312\n",
      "2018-08-30 06:26:06.907517 Training Step 2600 Finished Timing (Training: 0.912343, Test: 0.0825876) after 0.252618 seconds\n",
      "2018-08-30 06:26:06.907782 Training Step 2600 \"min loss\" =  4.511668\n",
      "2018-08-30 06:26:06.907977 Training Step 2600 \"loss\" =  4.937196\n",
      "2018-08-30 06:26:07.113169 Test Step 2605 Finished\n",
      "2018-08-30 06:26:07.113278 Test Step 2605 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:07.113765 Test Step 2605 \"loss\" =  7.4881315\n",
      "2018-08-30 06:26:07.160189 Training Step 2605 Finished Timing (Training: 0.914277, Test: 0.0819243) after 0.251901 seconds\n",
      "2018-08-30 06:26:07.160253 Training Step 2605 \"min loss\" =  4.511668\n",
      "2018-08-30 06:26:07.160625 Training Step 2605 \"loss\" =  4.8482003\n",
      "2018-08-30 06:26:07.365727 Test Step 2610 Finished\n",
      "2018-08-30 06:26:07.365821 Test Step 2610 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:07.365878 Test Step 2610 \"loss\" =  7.594199\n",
      "2018-08-30 06:26:07.412461 Training Step 2610 Finished Timing (Training: 0.912366, Test: 0.0825644) after 0.251524 seconds\n",
      "2018-08-30 06:26:07.412769 Training Step 2610 \"min loss\" =  4.511668\n",
      "2018-08-30 06:26:07.412828 Training Step 2610 \"loss\" =  5.2533965\n",
      "2018-08-30 06:26:07.617432 Test Step 2615 Finished\n",
      "2018-08-30 06:26:07.617508 Test Step 2615 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:07.617971 Test Step 2615 \"loss\" =  8.360639\n",
      "2018-08-30 06:26:07.664404 Training Step 2615 Finished Timing (Training: 0.91274, Test: 0.082501) after 0.251519 seconds\n",
      "2018-08-30 06:26:07.664491 Training Step 2615 \"min loss\" =  4.511668\n",
      "2018-08-30 06:26:07.664561 Training Step 2615 \"loss\" =  5.1133413\n",
      "2018-08-30 06:26:07.869633 Test Step 2620 Finished\n",
      "2018-08-30 06:26:07.869716 Test Step 2620 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:07.869771 Test Step 2620 \"loss\" =  7.649289\n",
      "2018-08-30 06:26:07.916311 Training Step 2620 Finished Timing (Training: 0.91245, Test: 0.0824387) after 0.251162 seconds\n",
      "2018-08-30 06:26:07.916388 Training Step 2620 \"min loss\" =  4.511668\n",
      "2018-08-30 06:26:07.916764 Training Step 2620 \"loss\" =  5.2646194\n",
      "2018-08-30 06:26:08.121914 Test Step 2625 Finished\n",
      "2018-08-30 06:26:08.122037 Test Step 2625 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:08.122491 Test Step 2625 \"loss\" =  7.275898\n",
      "2018-08-30 06:26:08.168698 Training Step 2625 Finished Timing (Training: 0.912377, Test: 0.0824006) after 0.251623 seconds\n",
      "2018-08-30 06:26:08.168760 Training Step 2625 \"min loss\" =  4.511668\n",
      "2018-08-30 06:26:08.168810 Training Step 2625 \"loss\" =  4.9939194\n",
      "2018-08-30 06:26:08.375754 Test Step 2630 Finished\n",
      "2018-08-30 06:26:08.375822 Test Step 2630 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:08.376266 Test Step 2630 \"loss\" =  7.353519\n",
      "2018-08-30 06:26:08.422878 Training Step 2630 Finished Timing (Training: 0.91207, Test: 0.0828123) after 0.25401 seconds\n",
      "2018-08-30 06:26:08.422940 Training Step 2630 \"min loss\" =  4.511668\n",
      "2018-08-30 06:26:08.423380 Training Step 2630 \"loss\" =  4.8864346\n",
      "2018-08-30 06:26:08.628758 Test Step 2635 Finished\n",
      "2018-08-30 06:26:08.628839 Test Step 2635 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:08.628904 Test Step 2635 \"loss\" =  7.3329973\n",
      "2018-08-30 06:26:08.675633 Training Step 2635 Finished Timing (Training: 0.912154, Test: 0.0827982) after 0.25182 seconds\n",
      "2018-08-30 06:26:08.675711 Training Step 2635 \"min loss\" =  4.511668\n",
      "2018-08-30 06:26:08.675766 Training Step 2635 \"loss\" =  5.351065\n",
      "2018-08-30 06:26:08.881572 Test Step 2640 Finished\n",
      "2018-08-30 06:26:08.881967 Test Step 2640 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:08.882190 Test Step 2640 \"loss\" =  7.519146\n",
      "2018-08-30 06:26:08.928514 Training Step 2640 Finished Timing (Training: 0.912092, Test: 0.0826724) after 0.25193 seconds\n",
      "2018-08-30 06:26:08.928575 Training Step 2640 \"min loss\" =  4.511668\n",
      "2018-08-30 06:26:08.928631 Training Step 2640 \"loss\" =  4.800294\n",
      "2018-08-30 06:26:09.133794 Test Step 2645 Finished\n",
      "2018-08-30 06:26:09.133870 Test Step 2645 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:09.134663 Test Step 2645 \"loss\" =  7.0365987\n",
      "2018-08-30 06:26:09.180701 Training Step 2645 Finished Timing (Training: 0.912192, Test: 0.0826496) after 0.252002 seconds\n",
      "2018-08-30 06:26:09.180765 Training Step 2645 \"min loss\" =  4.511668\n",
      "2018-08-30 06:26:09.180802 Training Step 2645 \"loss\" =  4.949477\n",
      "2018-08-30 06:26:09.385932 Test Step 2650 Finished\n",
      "2018-08-30 06:26:09.386026 Test Step 2650 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:09.386559 Test Step 2650 \"loss\" =  7.1961594\n",
      "2018-08-30 06:26:09.432983 Training Step 2650 Finished Timing (Training: 0.912257, Test: 0.0827446) after 0.252102 seconds\n",
      "2018-08-30 06:26:09.433047 Training Step 2650 \"min loss\" =  4.511668\n",
      "2018-08-30 06:26:09.433122 Training Step 2650 \"loss\" =  5.141163\n",
      "2018-08-30 06:26:09.639333 Test Step 2655 Finished\n",
      "2018-08-30 06:26:09.639409 Test Step 2655 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:09.639473 Test Step 2655 \"loss\" =  6.9769936\n",
      "2018-08-30 06:26:09.685615 Training Step 2655 Finished Timing (Training: 0.912461, Test: 0.0826575) after 0.251933 seconds\n",
      "2018-08-30 06:26:09.685679 Training Step 2655 \"min loss\" =  4.511668\n",
      "2018-08-30 06:26:09.686036 Training Step 2655 \"loss\" =  5.233016\n",
      "2018-08-30 06:26:09.890864 Test Step 2660 Finished\n",
      "2018-08-30 06:26:09.890934 Test Step 2660 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:09.890986 Test Step 2660 \"loss\" =  7.0102854\n",
      "2018-08-30 06:26:09.936918 Training Step 2660 Finished Timing (Training: 0.912627, Test: 0.08267) after 0.250815 seconds\n",
      "2018-08-30 06:26:09.936984 Training Step 2660 \"min loss\" =  4.511668\n",
      "2018-08-30 06:26:09.937023 Training Step 2660 \"loss\" =  4.743988\n",
      "2018-08-30 06:26:10.143265 Test Step 2665 Finished\n",
      "2018-08-30 06:26:10.143350 Test Step 2665 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:10.143393 Test Step 2665 \"loss\" =  6.975391\n",
      "2018-08-30 06:26:10.189457 Training Step 2665 Finished Timing (Training: 0.912414, Test: 0.0831269) after 0.252365 seconds\n",
      "2018-08-30 06:26:10.189540 Training Step 2665 \"min loss\" =  4.511668\n",
      "2018-08-30 06:26:10.189652 Training Step 2665 \"loss\" =  4.8232827\n",
      "2018-08-30 06:26:10.395721 Test Step 2670 Finished\n",
      "2018-08-30 06:26:10.395813 Test Step 2670 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:10.395887 Test Step 2670 \"loss\" =  7.0453877\n",
      "2018-08-30 06:26:10.442899 Training Step 2670 Finished Timing (Training: 0.912395, Test: 0.0830852) after 0.252987 seconds\n",
      "2018-08-30 06:26:10.443026 Training Step 2670 \"min loss\" =  4.511668\n",
      "2018-08-30 06:26:10.443096 Training Step 2670 \"loss\" =  4.893063\n",
      "2018-08-30 06:26:10.649004 Test Step 2675 Finished\n",
      "2018-08-30 06:26:10.649151 Test Step 2675 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:10.649775 Test Step 2675 \"loss\" =  7.192379\n",
      "2018-08-30 06:26:10.696126 Training Step 2675 Finished Timing (Training: 0.912406, Test: 0.0830328) after 0.252965 seconds\n",
      "2018-08-30 06:26:10.696262 Training Step 2675 \"min loss\" =  4.4236813\n",
      "2018-08-30 06:26:10.696397 Training Step 2675 \"loss\" =  4.949347\n",
      "2018-08-30 06:26:10.901521 Test Step 2680 Finished\n",
      "2018-08-30 06:26:10.901608 Test Step 2680 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:10.901678 Test Step 2680 \"loss\" =  7.3297725\n",
      "2018-08-30 06:26:10.948526 Training Step 2680 Finished Timing (Training: 0.912326, Test: 0.0829625) after 0.251523 seconds\n",
      "2018-08-30 06:26:10.948658 Training Step 2680 \"min loss\" =  4.4236813\n",
      "2018-08-30 06:26:10.948716 Training Step 2680 \"loss\" =  4.674614\n",
      "2018-08-30 06:26:11.154614 Test Step 2685 Finished\n",
      "2018-08-30 06:26:11.154706 Test Step 2685 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:11.155182 Test Step 2685 \"loss\" =  7.547218\n",
      "2018-08-30 06:26:11.201672 Training Step 2685 Finished Timing (Training: 0.912204, Test: 0.082942) after 0.252266 seconds\n",
      "2018-08-30 06:26:11.201750 Training Step 2685 \"min loss\" =  4.4236813\n",
      "2018-08-30 06:26:11.201805 Training Step 2685 \"loss\" =  4.873018\n",
      "2018-08-30 06:26:11.407131 Test Step 2690 Finished\n",
      "2018-08-30 06:26:11.407211 Test Step 2690 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:11.407271 Test Step 2690 \"loss\" =  7.2919626\n",
      "2018-08-30 06:26:11.454343 Training Step 2690 Finished Timing (Training: 0.912168, Test: 0.0828778) after 0.251912 seconds\n",
      "2018-08-30 06:26:11.454498 Training Step 2690 \"min loss\" =  4.37589\n",
      "2018-08-30 06:26:11.454555 Training Step 2690 \"loss\" =  4.70822\n",
      "2018-08-30 06:26:11.661440 Test Step 2695 Finished\n",
      "2018-08-30 06:26:11.661591 Test Step 2695 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:11.662083 Test Step 2695 \"loss\" =  7.2494006\n",
      "2018-08-30 06:26:11.708525 Training Step 2695 Finished Timing (Training: 0.911972, Test: 0.0829493) after 0.253344 seconds\n",
      "2018-08-30 06:26:11.708598 Training Step 2695 \"min loss\" =  4.37589\n",
      "2018-08-30 06:26:11.708653 Training Step 2695 \"loss\" =  4.854496\n",
      "2018-08-30 06:26:11.915147 Test Step 2700 Finished\n",
      "2018-08-30 06:26:11.915231 Test Step 2700 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:11.915686 Test Step 2700 \"loss\" =  7.269933\n",
      "2018-08-30 06:26:11.962277 Training Step 2700 Finished Timing (Training: 0.911983, Test: 0.0829277) after 0.25302 seconds\n",
      "2018-08-30 06:26:11.962337 Training Step 2700 \"min loss\" =  4.315056\n",
      "2018-08-30 06:26:11.962758 Training Step 2700 \"loss\" =  4.654504\n",
      "2018-08-30 06:26:12.167983 Test Step 2705 Finished\n",
      "2018-08-30 06:26:12.168071 Test Step 2705 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:12.168156 Test Step 2705 \"loss\" =  7.4862914\n",
      "2018-08-30 06:26:12.215469 Training Step 2705 Finished Timing (Training: 0.913791, Test: 0.0825838) after 0.252473 seconds\n",
      "2018-08-30 06:26:12.215526 Training Step 2705 \"min loss\" =  4.315056\n",
      "2018-08-30 06:26:12.215881 Training Step 2705 \"loss\" =  4.9694386\n",
      "2018-08-30 06:26:12.421688 Test Step 2710 Finished\n",
      "2018-08-30 06:26:12.421775 Test Step 2710 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:12.421835 Test Step 2710 \"loss\" =  7.504608\n",
      "2018-08-30 06:26:12.468564 Training Step 2710 Finished Timing (Training: 0.912361, Test: 0.082566) after 0.252348 seconds\n",
      "2018-08-30 06:26:12.468644 Training Step 2710 \"min loss\" =  4.315056\n",
      "2018-08-30 06:26:12.468698 Training Step 2710 \"loss\" =  4.7060003\n",
      "2018-08-30 06:26:12.674641 Test Step 2715 Finished\n",
      "2018-08-30 06:26:12.674725 Test Step 2715 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:12.674783 Test Step 2715 \"loss\" =  7.1962547\n",
      "2018-08-30 06:26:12.721781 Training Step 2715 Finished Timing (Training: 0.912281, Test: 0.0822202) after 0.252432 seconds\n",
      "2018-08-30 06:26:12.721843 Training Step 2715 \"min loss\" =  4.315056\n",
      "2018-08-30 06:26:12.722229 Training Step 2715 \"loss\" =  4.676803\n",
      "2018-08-30 06:26:12.927514 Test Step 2720 Finished\n",
      "2018-08-30 06:26:12.927677 Test Step 2720 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:12.927732 Test Step 2720 \"loss\" =  7.245085\n",
      "2018-08-30 06:26:12.974480 Training Step 2720 Finished Timing (Training: 0.911981, Test: 0.0822418) after 0.251934 seconds\n",
      "2018-08-30 06:26:12.974535 Training Step 2720 \"min loss\" =  4.315056\n",
      "2018-08-30 06:26:12.974886 Training Step 2720 \"loss\" =  4.5310044\n",
      "2018-08-30 06:26:13.179911 Test Step 2725 Finished\n",
      "2018-08-30 06:26:13.180004 Test Step 2725 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:13.180465 Test Step 2725 \"loss\" =  7.14091\n",
      "2018-08-30 06:26:13.226921 Training Step 2725 Finished Timing (Training: 0.912022, Test: 0.0822883) after 0.251722 seconds\n",
      "2018-08-30 06:26:13.227002 Training Step 2725 \"min loss\" =  4.315056\n",
      "2018-08-30 06:26:13.227061 Training Step 2725 \"loss\" =  4.6679506\n",
      "2018-08-30 06:26:13.432258 Test Step 2730 Finished\n",
      "2018-08-30 06:26:13.432351 Test Step 2730 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:13.432412 Test Step 2730 \"loss\" =  7.112488\n",
      "2018-08-30 06:26:13.478448 Training Step 2730 Finished Timing (Training: 0.91215, Test: 0.0824411) after 0.250753 seconds\n",
      "2018-08-30 06:26:13.478536 Training Step 2730 \"min loss\" =  4.315056\n",
      "2018-08-30 06:26:13.478594 Training Step 2730 \"loss\" =  4.9610825\n",
      "2018-08-30 06:26:13.686051 Test Step 2735 Finished\n",
      "2018-08-30 06:26:13.686138 Test Step 2735 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:13.686213 Test Step 2735 \"loss\" =  7.3658857\n",
      "2018-08-30 06:26:13.733214 Training Step 2735 Finished Timing (Training: 0.911855, Test: 0.08256) after 0.253953 seconds\n",
      "2018-08-30 06:26:13.733306 Training Step 2735 \"min loss\" =  4.315056\n",
      "2018-08-30 06:26:13.733361 Training Step 2735 \"loss\" =  4.4075093\n",
      "2018-08-30 06:26:13.938933 Test Step 2740 Finished\n",
      "2018-08-30 06:26:13.939332 Test Step 2740 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:13.939393 Test Step 2740 \"loss\" =  7.496259\n",
      "2018-08-30 06:26:13.985721 Training Step 2740 Finished Timing (Training: 0.91172, Test: 0.0825715) after 0.25173 seconds\n",
      "2018-08-30 06:26:13.985784 Training Step 2740 \"min loss\" =  4.315056\n",
      "2018-08-30 06:26:13.986140 Training Step 2740 \"loss\" =  4.7788687\n",
      "2018-08-30 06:26:14.191211 Test Step 2745 Finished\n",
      "2018-08-30 06:26:14.191362 Test Step 2745 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:14.191491 Test Step 2745 \"loss\" =  7.033337\n",
      "2018-08-30 06:26:14.238296 Training Step 2745 Finished Timing (Training: 0.911568, Test: 0.0825951) after 0.251831 seconds\n",
      "2018-08-30 06:26:14.238357 Training Step 2745 \"min loss\" =  4.315056\n",
      "2018-08-30 06:26:14.238701 Training Step 2745 \"loss\" =  4.560533\n",
      "2018-08-30 06:26:14.444294 Test Step 2750 Finished\n",
      "2018-08-30 06:26:14.444384 Test Step 2750 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:14.444446 Test Step 2750 \"loss\" =  7.265374\n",
      "2018-08-30 06:26:14.491648 Training Step 2750 Finished Timing (Training: 0.911545, Test: 0.0825685) after 0.252619 seconds\n",
      "2018-08-30 06:26:14.491713 Training Step 2750 \"min loss\" =  4.315056\n",
      "2018-08-30 06:26:14.492041 Training Step 2750 \"loss\" =  4.653754\n",
      "2018-08-30 06:26:14.696791 Test Step 2755 Finished\n",
      "2018-08-30 06:26:14.697082 Test Step 2755 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:14.697362 Test Step 2755 \"loss\" =  7.091016\n",
      "2018-08-30 06:26:14.744055 Training Step 2755 Finished Timing (Training: 0.911519, Test: 0.0825431) after 0.2517 seconds\n",
      "2018-08-30 06:26:14.744122 Training Step 2755 \"min loss\" =  4.315056\n",
      "2018-08-30 06:26:14.744622 Training Step 2755 \"loss\" =  5.00405\n",
      "2018-08-30 06:26:14.956507 Test Step 2760 Finished\n",
      "2018-08-30 06:26:14.956600 Test Step 2760 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:14.957062 Test Step 2760 \"loss\" =  7.626116\n",
      "2018-08-30 06:26:15.003491 Training Step 2760 Finished Timing (Training: 0.911638, Test: 0.0823561) after 0.258594 seconds\n",
      "2018-08-30 06:26:15.003555 Training Step 2760 \"min loss\" =  4.2278557\n",
      "2018-08-30 06:26:15.003929 Training Step 2760 \"loss\" =  4.918045\n",
      "2018-08-30 06:26:15.208696 Test Step 2765 Finished\n",
      "2018-08-30 06:26:15.208769 Test Step 2765 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:15.209193 Test Step 2765 \"loss\" =  7.386328\n",
      "2018-08-30 06:26:15.255529 Training Step 2765 Finished Timing (Training: 0.911618, Test: 0.082353) after 0.25129 seconds\n",
      "2018-08-30 06:26:15.255804 Training Step 2765 \"min loss\" =  4.2278557\n",
      "2018-08-30 06:26:15.256002 Training Step 2765 \"loss\" =  4.805419\n",
      "2018-08-30 06:26:15.460654 Test Step 2770 Finished\n",
      "2018-08-30 06:26:15.461003 Test Step 2770 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:15.461060 Test Step 2770 \"loss\" =  7.163097\n",
      "2018-08-30 06:26:15.507670 Training Step 2770 Finished Timing (Training: 0.911617, Test: 0.0823308) after 0.251395 seconds\n",
      "2018-08-30 06:26:15.507733 Training Step 2770 \"min loss\" =  4.2278557\n",
      "2018-08-30 06:26:15.508208 Training Step 2770 \"loss\" =  4.9714828\n",
      "2018-08-30 06:26:15.712697 Test Step 2775 Finished\n",
      "2018-08-30 06:26:15.713046 Test Step 2775 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:15.713102 Test Step 2775 \"loss\" =  7.1351237\n",
      "2018-08-30 06:26:15.759414 Training Step 2775 Finished Timing (Training: 0.911635, Test: 0.082334) after 0.251127 seconds\n",
      "2018-08-30 06:26:15.759470 Training Step 2775 \"min loss\" =  4.2278557\n",
      "2018-08-30 06:26:15.759819 Training Step 2775 \"loss\" =  4.2768173\n",
      "2018-08-30 06:26:15.965134 Test Step 2780 Finished\n",
      "2018-08-30 06:26:15.965512 Test Step 2780 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:15.965792 Test Step 2780 \"loss\" =  7.62393\n",
      "2018-08-30 06:26:16.011960 Training Step 2780 Finished Timing (Training: 0.911567, Test: 0.0824179) after 0.25183 seconds\n",
      "2018-08-30 06:26:16.012019 Training Step 2780 \"min loss\" =  4.2278557\n",
      "2018-08-30 06:26:16.012581 Training Step 2780 \"loss\" =  4.7660728\n",
      "2018-08-30 06:26:16.217505 Test Step 2785 Finished\n",
      "2018-08-30 06:26:16.217585 Test Step 2785 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:16.218021 Test Step 2785 \"loss\" =  7.3681498\n",
      "2018-08-30 06:26:16.264456 Training Step 2785 Finished Timing (Training: 0.911567, Test: 0.0824154) after 0.25181 seconds\n",
      "2018-08-30 06:26:16.264513 Training Step 2785 \"min loss\" =  4.2278557\n",
      "2018-08-30 06:26:16.264847 Training Step 2785 \"loss\" =  4.732338\n",
      "2018-08-30 06:26:16.477504 Test Step 2790 Finished\n",
      "2018-08-30 06:26:16.477617 Test Step 2790 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:16.478118 Test Step 2790 \"loss\" =  7.226903\n",
      "2018-08-30 06:26:16.524813 Training Step 2790 Finished Timing (Training: 0.911652, Test: 0.0823134) after 0.259655 seconds\n",
      "2018-08-30 06:26:16.525111 Training Step 2790 \"min loss\" =  4.2229753\n",
      "2018-08-30 06:26:16.525282 Training Step 2790 \"loss\" =  4.758973\n",
      "2018-08-30 06:26:16.730574 Test Step 2795 Finished\n",
      "2018-08-30 06:26:16.730648 Test Step 2795 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:16.730702 Test Step 2795 \"loss\" =  7.4881053\n",
      "2018-08-30 06:26:16.777433 Training Step 2795 Finished Timing (Training: 0.911617, Test: 0.0822875) after 0.251612 seconds\n",
      "2018-08-30 06:26:16.777496 Training Step 2795 \"min loss\" =  4.2229753\n",
      "2018-08-30 06:26:16.777871 Training Step 2795 \"loss\" =  4.4311795\n",
      "2018-08-30 06:26:16.982891 Test Step 2800 Finished\n",
      "2018-08-30 06:26:16.982966 Test Step 2800 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:16.983029 Test Step 2800 \"loss\" =  7.172654\n",
      "2018-08-30 06:26:17.029569 Training Step 2800 Finished Timing (Training: 0.911589, Test: 0.0822876) after 0.251266 seconds\n",
      "2018-08-30 06:26:17.029637 Training Step 2800 \"min loss\" =  4.2229753\n",
      "2018-08-30 06:26:17.029996 Training Step 2800 \"loss\" =  4.6370068\n",
      "2018-08-30 06:26:17.235220 Test Step 2805 Finished\n",
      "2018-08-30 06:26:17.235285 Test Step 2805 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:17.235696 Test Step 2805 \"loss\" =  7.281568\n",
      "2018-08-30 06:26:17.282212 Training Step 2805 Finished Timing (Training: 0.913723, Test: 0.0831175) after 0.251876 seconds\n",
      "2018-08-30 06:26:17.282269 Training Step 2805 \"min loss\" =  4.2229753\n",
      "2018-08-30 06:26:17.282618 Training Step 2805 \"loss\" =  4.609337\n",
      "2018-08-30 06:26:17.487959 Test Step 2810 Finished\n",
      "2018-08-30 06:26:17.488077 Test Step 2810 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:17.488705 Test Step 2810 \"loss\" =  6.9837203\n",
      "2018-08-30 06:26:17.535101 Training Step 2810 Finished Timing (Training: 0.912093, Test: 0.0825117) after 0.251966 seconds\n",
      "2018-08-30 06:26:17.535181 Training Step 2810 \"min loss\" =  4.2229753\n",
      "2018-08-30 06:26:17.535255 Training Step 2810 \"loss\" =  4.9233646\n",
      "2018-08-30 06:26:17.739681 Test Step 2815 Finished\n",
      "2018-08-30 06:26:17.739774 Test Step 2815 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:17.739834 Test Step 2815 \"loss\" =  6.9882183\n",
      "2018-08-30 06:26:17.787080 Training Step 2815 Finished Timing (Training: 0.912366, Test: 0.0825332) after 0.251738 seconds\n",
      "2018-08-30 06:26:17.787212 Training Step 2815 \"min loss\" =  4.2229753\n",
      "2018-08-30 06:26:17.787271 Training Step 2815 \"loss\" =  4.654063\n",
      "2018-08-30 06:26:17.994581 Test Step 2820 Finished\n",
      "2018-08-30 06:26:17.994677 Test Step 2820 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:17.994740 Test Step 2820 \"loss\" =  7.1105185\n",
      "2018-08-30 06:26:18.041989 Training Step 2820 Finished Timing (Training: 0.911928, Test: 0.0825103) after 0.254052 seconds\n",
      "2018-08-30 06:26:18.042074 Training Step 2820 \"min loss\" =  4.2229753\n",
      "2018-08-30 06:26:18.042481 Training Step 2820 \"loss\" =  4.7106776\n",
      "2018-08-30 06:26:18.248053 Test Step 2825 Finished\n",
      "2018-08-30 06:26:18.248139 Test Step 2825 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:18.248678 Test Step 2825 \"loss\" =  7.525592\n",
      "2018-08-30 06:26:18.295145 Training Step 2825 Finished Timing (Training: 0.911679, Test: 0.0823945) after 0.252332 seconds\n",
      "2018-08-30 06:26:18.295218 Training Step 2825 \"min loss\" =  4.2229753\n",
      "2018-08-30 06:26:18.295265 Training Step 2825 \"loss\" =  4.6587324\n",
      "2018-08-30 06:26:18.501389 Test Step 2830 Finished\n",
      "2018-08-30 06:26:18.501778 Test Step 2830 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:18.501854 Test Step 2830 \"loss\" =  7.275437\n",
      "2018-08-30 06:26:18.548357 Training Step 2830 Finished Timing (Training: 0.912108, Test: 0.0822621) after 0.253024 seconds\n",
      "2018-08-30 06:26:18.548487 Training Step 2830 \"min loss\" =  4.2229753\n",
      "2018-08-30 06:26:18.548928 Training Step 2830 \"loss\" =  4.832738\n",
      "2018-08-30 06:26:18.754868 Test Step 2835 Finished\n",
      "2018-08-30 06:26:18.754956 Test Step 2835 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:18.755411 Test Step 2835 \"loss\" =  7.696674\n",
      "2018-08-30 06:26:18.801838 Training Step 2835 Finished Timing (Training: 0.912015, Test: 0.0822833) after 0.252562 seconds\n",
      "2018-08-30 06:26:18.801898 Training Step 2835 \"min loss\" =  4.2229753\n",
      "2018-08-30 06:26:18.802310 Training Step 2835 \"loss\" =  4.462526\n",
      "2018-08-30 06:26:19.007679 Test Step 2840 Finished\n",
      "2018-08-30 06:26:19.008063 Test Step 2840 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:19.008319 Test Step 2840 \"loss\" =  7.3307076\n",
      "2018-08-30 06:26:19.054531 Training Step 2840 Finished Timing (Training: 0.911804, Test: 0.082461) after 0.252155 seconds\n",
      "2018-08-30 06:26:19.054601 Training Step 2840 \"min loss\" =  4.2229753\n",
      "2018-08-30 06:26:19.054965 Training Step 2840 \"loss\" =  4.9366655\n",
      "2018-08-30 06:26:19.259702 Test Step 2845 Finished\n",
      "2018-08-30 06:26:19.259797 Test Step 2845 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:19.260658 Test Step 2845 \"loss\" =  8.137822\n",
      "2018-08-30 06:26:19.307562 Training Step 2845 Finished Timing (Training: 0.911588, Test: 0.0823969) after 0.252258 seconds\n",
      "2018-08-30 06:26:19.308005 Training Step 2845 \"min loss\" =  4.2229753\n",
      "2018-08-30 06:26:19.308541 Training Step 2845 \"loss\" =  4.7714725\n",
      "2018-08-30 06:26:19.513442 Test Step 2850 Finished\n",
      "2018-08-30 06:26:19.513533 Test Step 2850 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:19.514232 Test Step 2850 \"loss\" =  7.114227\n",
      "2018-08-30 06:26:19.560815 Training Step 2850 Finished Timing (Training: 0.911215, Test: 0.0823872) after 0.252176 seconds\n",
      "2018-08-30 06:26:19.560911 Training Step 2850 \"min loss\" =  4.2229753\n",
      "2018-08-30 06:26:19.561533 Training Step 2850 \"loss\" =  4.480418\n",
      "2018-08-30 06:26:19.766455 Test Step 2855 Finished\n",
      "2018-08-30 06:26:19.766959 Test Step 2855 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:19.767310 Test Step 2855 \"loss\" =  7.481867\n",
      "2018-08-30 06:26:19.813818 Training Step 2855 Finished Timing (Training: 0.910843, Test: 0.0823052) after 0.251573 seconds\n",
      "2018-08-30 06:26:19.813905 Training Step 2855 \"min loss\" =  4.2229753\n",
      "2018-08-30 06:26:19.814650 Training Step 2855 \"loss\" =  4.5660367\n",
      "2018-08-30 06:26:20.020765 Test Step 2860 Finished\n",
      "2018-08-30 06:26:20.020898 Test Step 2860 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:20.020967 Test Step 2860 \"loss\" =  7.1117587\n",
      "2018-08-30 06:26:20.067894 Training Step 2860 Finished Timing (Training: 0.91088, Test: 0.0823012) after 0.252749 seconds\n",
      "2018-08-30 06:26:20.068238 Training Step 2860 \"min loss\" =  4.2229753\n",
      "2018-08-30 06:26:20.068301 Training Step 2860 \"loss\" =  4.6181936\n",
      "2018-08-30 06:26:20.274144 Test Step 2865 Finished\n",
      "2018-08-30 06:26:20.274539 Test Step 2865 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:20.274598 Test Step 2865 \"loss\" =  7.523086\n",
      "2018-08-30 06:26:20.320935 Training Step 2865 Finished Timing (Training: 0.910924, Test: 0.0822715) after 0.252227 seconds\n",
      "2018-08-30 06:26:20.321200 Training Step 2865 \"min loss\" =  4.2229753\n",
      "2018-08-30 06:26:20.321399 Training Step 2865 \"loss\" =  4.81609\n",
      "2018-08-30 06:26:20.526389 Test Step 2870 Finished\n",
      "2018-08-30 06:26:20.526516 Test Step 2870 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:20.526980 Test Step 2870 \"loss\" =  7.449187\n",
      "2018-08-30 06:26:20.573404 Training Step 2870 Finished Timing (Training: 0.91093, Test: 0.0822205) after 0.25173 seconds\n",
      "2018-08-30 06:26:20.573477 Training Step 2870 \"min loss\" =  4.2229753\n",
      "2018-08-30 06:26:20.573806 Training Step 2870 \"loss\" =  4.484689\n",
      "2018-08-30 06:26:20.779270 Test Step 2875 Finished\n",
      "2018-08-30 06:26:20.779565 Test Step 2875 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:20.779815 Test Step 2875 \"loss\" =  7.2038894\n",
      "2018-08-30 06:26:20.826249 Training Step 2875 Finished Timing (Training: 0.910964, Test: 0.0822168) after 0.252121 seconds\n",
      "2018-08-30 06:26:20.826422 Training Step 2875 \"min loss\" =  4.2229753\n",
      "2018-08-30 06:26:20.826666 Training Step 2875 \"loss\" =  4.4317384\n",
      "2018-08-30 06:26:21.032050 Test Step 2880 Finished\n",
      "2018-08-30 06:26:21.032139 Test Step 2880 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:21.032625 Test Step 2880 \"loss\" =  8.103814\n",
      "2018-08-30 06:26:21.079339 Training Step 2880 Finished Timing (Training: 0.910998, Test: 0.0821966) after 0.252355 seconds\n",
      "2018-08-30 06:26:21.079647 Training Step 2880 \"min loss\" =  4.2229753\n",
      "2018-08-30 06:26:21.079709 Training Step 2880 \"loss\" =  5.1023445\n",
      "2018-08-30 06:26:21.285408 Test Step 2885 Finished\n",
      "2018-08-30 06:26:21.285814 Test Step 2885 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:21.286073 Test Step 2885 \"loss\" =  7.180376\n",
      "2018-08-30 06:26:21.332279 Training Step 2885 Finished Timing (Training: 0.910986, Test: 0.0821912) after 0.25209 seconds\n",
      "2018-08-30 06:26:21.332341 Training Step 2885 \"min loss\" =  4.2229753\n",
      "2018-08-30 06:26:21.332693 Training Step 2885 \"loss\" =  4.2429066\n",
      "2018-08-30 06:26:21.537274 Test Step 2890 Finished\n",
      "2018-08-30 06:26:21.537683 Test Step 2890 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:21.537930 Test Step 2890 \"loss\" =  7.3136544\n",
      "2018-08-30 06:26:21.584263 Training Step 2890 Finished Timing (Training: 0.91101, Test: 0.0822196) after 0.251257 seconds\n",
      "2018-08-30 06:26:21.584321 Training Step 2890 \"min loss\" =  4.2229753\n",
      "2018-08-30 06:26:21.584377 Training Step 2890 \"loss\" =  4.7611423\n",
      "2018-08-30 06:26:21.789940 Test Step 2895 Finished\n",
      "2018-08-30 06:26:21.790011 Test Step 2895 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:21.790787 Test Step 2895 \"loss\" =  7.648755\n",
      "2018-08-30 06:26:21.837103 Training Step 2895 Finished Timing (Training: 0.910964, Test: 0.0822203) after 0.252125 seconds\n",
      "2018-08-30 06:26:21.837173 Training Step 2895 \"min loss\" =  4.2229753\n",
      "2018-08-30 06:26:21.837238 Training Step 2895 \"loss\" =  5.1586485\n",
      "2018-08-30 06:26:22.042367 Test Step 2900 Finished\n",
      "2018-08-30 06:26:22.042456 Test Step 2900 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:22.042522 Test Step 2900 \"loss\" =  8.151022\n",
      "2018-08-30 06:26:22.089554 Training Step 2900 Finished Timing (Training: 0.911143, Test: 0.0822965) after 0.252252 seconds\n",
      "2018-08-30 06:26:22.089652 Training Step 2900 \"min loss\" =  4.2229753\n",
      "2018-08-30 06:26:22.090215 Training Step 2900 \"loss\" =  4.691695\n",
      "2018-08-30 06:26:22.295091 Test Step 2905 Finished\n",
      "2018-08-30 06:26:22.295175 Test Step 2905 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:22.295236 Test Step 2905 \"loss\" =  7.8146157\n",
      "2018-08-30 06:26:22.341276 Training Step 2905 Finished Timing (Training: 0.916342, Test: 0.0826629) after 0.250683 seconds\n",
      "2018-08-30 06:26:22.341370 Training Step 2905 \"min loss\" =  4.2229753\n",
      "2018-08-30 06:26:22.341428 Training Step 2905 \"loss\" =  4.7729506\n",
      "2018-08-30 06:26:22.546670 Test Step 2910 Finished\n",
      "2018-08-30 06:26:22.547089 Test Step 2910 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:22.547158 Test Step 2910 \"loss\" =  7.371498\n",
      "2018-08-30 06:26:22.593658 Training Step 2910 Finished Timing (Training: 0.915397, Test: 0.0825086) after 0.252153 seconds\n",
      "2018-08-30 06:26:22.593722 Training Step 2910 \"min loss\" =  4.2229753\n",
      "2018-08-30 06:26:22.593783 Training Step 2910 \"loss\" =  4.527693\n",
      "2018-08-30 06:26:22.798745 Test Step 2915 Finished\n",
      "2018-08-30 06:26:22.798829 Test Step 2915 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:22.799445 Test Step 2915 \"loss\" =  7.5995913\n",
      "2018-08-30 06:26:22.845902 Training Step 2915 Finished Timing (Training: 0.914859, Test: 0.0823381) after 0.252057 seconds\n",
      "2018-08-30 06:26:22.845966 Training Step 2915 \"min loss\" =  4.2229753\n",
      "2018-08-30 06:26:22.846022 Training Step 2915 \"loss\" =  4.9906693\n",
      "2018-08-30 06:26:23.059772 Test Step 2920 Finished\n",
      "2018-08-30 06:26:23.059854 Test Step 2920 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:23.060131 Test Step 2920 \"loss\" =  7.422973\n",
      "2018-08-30 06:26:23.106237 Training Step 2920 Finished Timing (Training: 0.907039, Test: 0.0896172) after 0.259498 seconds\n",
      "2018-08-30 06:26:23.106301 Training Step 2920 \"min loss\" =  4.2229753\n",
      "2018-08-30 06:26:23.106830 Training Step 2920 \"loss\" =  4.340766\n",
      "2018-08-30 06:26:23.312291 Test Step 2925 Finished\n",
      "2018-08-30 06:26:23.312445 Test Step 2925 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:23.312510 Test Step 2925 \"loss\" =  7.44032\n",
      "2018-08-30 06:26:23.359644 Training Step 2925 Finished Timing (Training: 0.908427, Test: 0.0881183) after 0.252725 seconds\n",
      "2018-08-30 06:26:23.359767 Training Step 2925 \"min loss\" =  4.2229753\n",
      "2018-08-30 06:26:23.359823 Training Step 2925 \"loss\" =  4.9090567\n",
      "2018-08-30 06:26:23.565033 Test Step 2930 Finished\n",
      "2018-08-30 06:26:23.565119 Test Step 2930 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:23.565177 Test Step 2930 \"loss\" =  7.18875\n",
      "2018-08-30 06:26:23.611990 Training Step 2930 Finished Timing (Training: 0.909027, Test: 0.0872027) after 0.252104 seconds\n",
      "2018-08-30 06:26:23.612047 Training Step 2930 \"min loss\" =  4.2229753\n",
      "2018-08-30 06:26:23.612396 Training Step 2930 \"loss\" =  4.7677445\n",
      "2018-08-30 06:26:23.817659 Test Step 2935 Finished\n",
      "2018-08-30 06:26:23.817777 Test Step 2935 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:23.818312 Test Step 2935 \"loss\" =  7.0689397\n",
      "2018-08-30 06:26:23.864676 Training Step 2935 Finished Timing (Training: 0.909228, Test: 0.0866627) after 0.252215 seconds\n",
      "2018-08-30 06:26:23.864745 Training Step 2935 \"min loss\" =  4.2229753\n",
      "2018-08-30 06:26:23.864807 Training Step 2935 \"loss\" =  4.857698\n",
      "2018-08-30 06:26:24.070332 Test Step 2940 Finished\n",
      "2018-08-30 06:26:24.070441 Test Step 2940 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:24.070864 Test Step 2940 \"loss\" =  7.2200365\n",
      "2018-08-30 06:26:24.117406 Training Step 2940 Finished Timing (Training: 0.909617, Test: 0.086175) after 0.252534 seconds\n",
      "2018-08-30 06:26:24.117465 Training Step 2940 \"min loss\" =  3.9518304\n",
      "2018-08-30 06:26:24.117991 Training Step 2940 \"loss\" =  4.5224595\n",
      "2018-08-30 06:26:24.322896 Test Step 2945 Finished\n",
      "2018-08-30 06:26:24.323338 Test Step 2945 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:24.323406 Test Step 2945 \"loss\" =  7.8399367\n",
      "2018-08-30 06:26:24.369849 Training Step 2945 Finished Timing (Training: 0.909886, Test: 0.0856408) after 0.25179 seconds\n",
      "2018-08-30 06:26:24.369911 Training Step 2945 \"min loss\" =  3.9518304\n",
      "2018-08-30 06:26:24.369964 Training Step 2945 \"loss\" =  4.4267073\n",
      "2018-08-30 06:26:24.575983 Test Step 2950 Finished\n",
      "2018-08-30 06:26:24.576104 Test Step 2950 \"min loss\" =  6.9635506\n",
      "2018-08-30 06:26:24.576170 Test Step 2950 \"loss\" =  7.2865024\n",
      "2018-08-30 06:26:24.622530 Training Step 2950 Finished Timing (Training: 0.910428, Test: 0.0853716) after 0.252493 seconds\n",
      "2018-08-30 06:26:24.622679 Training Step 2950 \"min loss\" =  3.9518304\n",
      "2018-08-30 06:26:24.623255 Training Step 2950 \"loss\" =  4.506307\n",
      "2018-08-30 06:26:24.828973 Test Step 2955 Finished\n",
      "2018-08-30 06:26:24.829113 Test Step 2955 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:24.829167 Test Step 2955 \"loss\" =  6.8684387\n",
      "2018-08-30 06:26:24.876356 Training Step 2955 Finished Timing (Training: 0.91031, Test: 0.0851797) after 0.253023 seconds\n",
      "2018-08-30 06:26:24.876443 Training Step 2955 \"min loss\" =  3.9518304\n",
      "2018-08-30 06:26:24.876500 Training Step 2955 \"loss\" =  4.4684143\n",
      "2018-08-30 06:26:25.081833 Test Step 2960 Finished\n",
      "2018-08-30 06:26:25.082152 Test Step 2960 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:25.082461 Test Step 2960 \"loss\" =  7.236767\n",
      "2018-08-30 06:26:25.128899 Training Step 2960 Finished Timing (Training: 0.910528, Test: 0.0849563) after 0.252335 seconds\n",
      "2018-08-30 06:26:25.129175 Training Step 2960 \"min loss\" =  3.9518304\n",
      "2018-08-30 06:26:25.129412 Training Step 2960 \"loss\" =  4.135149\n",
      "2018-08-30 06:26:25.333982 Test Step 2965 Finished\n",
      "2018-08-30 06:26:25.334282 Test Step 2965 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:25.334374 Test Step 2965 \"loss\" =  7.53732\n",
      "2018-08-30 06:26:25.380873 Training Step 2965 Finished Timing (Training: 0.910551, Test: 0.0847382) after 0.251125 seconds\n",
      "2018-08-30 06:26:25.380931 Training Step 2965 \"min loss\" =  3.9518304\n",
      "2018-08-30 06:26:25.381345 Training Step 2965 \"loss\" =  4.4359894\n",
      "2018-08-30 06:26:25.586409 Test Step 2970 Finished\n",
      "2018-08-30 06:26:25.586495 Test Step 2970 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:25.586553 Test Step 2970 \"loss\" =  7.537493\n",
      "2018-08-30 06:26:25.633669 Training Step 2970 Finished Timing (Training: 0.910604, Test: 0.0845296) after 0.251883 seconds\n",
      "2018-08-30 06:26:25.633736 Training Step 2970 \"min loss\" =  3.9518304\n",
      "2018-08-30 06:26:25.634047 Training Step 2970 \"loss\" =  4.204343\n",
      "2018-08-30 06:26:25.839403 Test Step 2975 Finished\n",
      "2018-08-30 06:26:25.839487 Test Step 2975 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:25.839933 Test Step 2975 \"loss\" =  7.305715\n",
      "2018-08-30 06:26:25.886473 Training Step 2975 Finished Timing (Training: 0.910651, Test: 0.0843918) after 0.252101 seconds\n",
      "2018-08-30 06:26:25.886555 Training Step 2975 \"min loss\" =  3.9518304\n",
      "2018-08-30 06:26:25.886943 Training Step 2975 \"loss\" =  4.561111\n",
      "2018-08-30 06:26:26.093066 Test Step 2980 Finished\n",
      "2018-08-30 06:26:26.093915 Test Step 2980 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:26.094160 Test Step 2980 \"loss\" =  7.4536567\n",
      "2018-08-30 06:26:26.140530 Training Step 2980 Finished Timing (Training: 0.910595, Test: 0.0842082) after 0.253275 seconds\n",
      "2018-08-30 06:26:26.140588 Training Step 2980 \"min loss\" =  3.9518304\n",
      "2018-08-30 06:26:26.140638 Training Step 2980 \"loss\" =  4.3631835\n",
      "2018-08-30 06:26:26.346072 Test Step 2985 Finished\n",
      "2018-08-30 06:26:26.346139 Test Step 2985 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:26.346182 Test Step 2985 \"loss\" =  7.253119\n",
      "2018-08-30 06:26:26.393055 Training Step 2985 Finished Timing (Training: 0.910616, Test: 0.0840781) after 0.251835 seconds\n",
      "2018-08-30 06:26:26.393114 Training Step 2985 \"min loss\" =  3.9518304\n",
      "2018-08-30 06:26:26.393633 Training Step 2985 \"loss\" =  4.6041903\n",
      "2018-08-30 06:26:26.598881 Test Step 2990 Finished\n",
      "2018-08-30 06:26:26.598987 Test Step 2990 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:26.599548 Test Step 2990 \"loss\" =  7.0576277\n",
      "2018-08-30 06:26:26.645966 Training Step 2990 Finished Timing (Training: 0.910619, Test: 0.0839783) after 0.252263 seconds\n",
      "2018-08-30 06:26:26.646027 Training Step 2990 \"min loss\" =  3.9518304\n",
      "2018-08-30 06:26:26.646604 Training Step 2990 \"loss\" =  4.415886\n",
      "2018-08-30 06:26:26.851599 Test Step 2995 Finished\n",
      "2018-08-30 06:26:26.851716 Test Step 2995 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:26.852241 Test Step 2995 \"loss\" =  7.2382445\n",
      "2018-08-30 06:26:26.898562 Training Step 2995 Finished Timing (Training: 0.910663, Test: 0.0839182) after 0.251887 seconds\n",
      "2018-08-30 06:26:26.898629 Training Step 2995 \"min loss\" =  3.9518304\n",
      "2018-08-30 06:26:26.898690 Training Step 2995 \"loss\" =  4.282141\n",
      "2018-08-30 06:26:27.104348 Test Step 3000 Finished\n",
      "2018-08-30 06:26:27.104785 Test Step 3000 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:27.104852 Test Step 3000 \"loss\" =  7.6403694\n",
      "2018-08-30 06:26:27.151378 Training Step 3000 Finished Timing (Training: 0.910776, Test: 0.0838079) after 0.252623 seconds\n",
      "2018-08-30 06:26:27.151435 Training Step 3000 \"min loss\" =  3.9518304\n",
      "2018-08-30 06:26:27.151485 Training Step 3000 \"loss\" =  4.686616\n",
      "2018-08-30 06:26:27.356712 Test Step 3005 Finished\n",
      "2018-08-30 06:26:27.356795 Test Step 3005 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:27.356849 Test Step 3005 \"loss\" =  7.1443305\n",
      "2018-08-30 06:26:27.404266 Training Step 3005 Finished Timing (Training: 0.914128, Test: 0.0823196) after 0.252721 seconds\n",
      "2018-08-30 06:26:27.404337 Training Step 3005 \"min loss\" =  3.9518304\n",
      "2018-08-30 06:26:27.404390 Training Step 3005 \"loss\" =  4.4811625\n",
      "2018-08-30 06:26:27.610209 Test Step 3010 Finished\n",
      "2018-08-30 06:26:27.610495 Test Step 3010 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:27.610731 Test Step 3010 \"loss\" =  7.1472363\n",
      "2018-08-30 06:26:27.657354 Training Step 3010 Finished Timing (Training: 0.912853, Test: 0.083285) after 0.252873 seconds\n",
      "2018-08-30 06:26:27.657483 Training Step 3010 \"min loss\" =  3.9518304\n",
      "2018-08-30 06:26:27.657824 Training Step 3010 \"loss\" =  4.715381\n",
      "2018-08-30 06:26:27.863506 Test Step 3015 Finished\n",
      "2018-08-30 06:26:27.863578 Test Step 3015 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:27.863635 Test Step 3015 \"loss\" =  7.309173\n",
      "2018-08-30 06:26:27.910467 Training Step 3015 Finished Timing (Training: 0.913299, Test: 0.0827312) after 0.252336 seconds\n",
      "2018-08-30 06:26:27.910536 Training Step 3015 \"min loss\" =  3.9518304\n",
      "2018-08-30 06:26:27.910575 Training Step 3015 \"loss\" =  4.6028643\n",
      "2018-08-30 06:26:28.116541 Test Step 3020 Finished\n",
      "2018-08-30 06:26:28.116757 Test Step 3020 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:28.116884 Test Step 3020 \"loss\" =  7.4472775\n",
      "2018-08-30 06:26:28.164061 Training Step 3020 Finished Timing (Training: 0.912063, Test: 0.082611) after 0.252578 seconds\n",
      "2018-08-30 06:26:28.164442 Training Step 3020 \"min loss\" =  3.9518304\n",
      "2018-08-30 06:26:28.164792 Training Step 3020 \"loss\" =  4.600404\n",
      "2018-08-30 06:26:28.369856 Test Step 3025 Finished\n",
      "2018-08-30 06:26:28.370121 Test Step 3025 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:28.370404 Test Step 3025 \"loss\" =  8.056273\n",
      "2018-08-30 06:26:28.416803 Training Step 3025 Finished Timing (Training: 0.911722, Test: 0.0824643) after 0.251665 seconds\n",
      "2018-08-30 06:26:28.417027 Training Step 3025 \"min loss\" =  3.9518304\n",
      "2018-08-30 06:26:28.417268 Training Step 3025 \"loss\" =  4.5678406\n",
      "2018-08-30 06:26:28.621941 Test Step 3030 Finished\n",
      "2018-08-30 06:26:28.622317 Test Step 3030 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:28.622515 Test Step 3030 \"loss\" =  7.7848105\n",
      "2018-08-30 06:26:28.668881 Training Step 3030 Finished Timing (Training: 0.911608, Test: 0.082419) after 0.251294 seconds\n",
      "2018-08-30 06:26:28.669139 Training Step 3030 \"min loss\" =  3.9518304\n",
      "2018-08-30 06:26:28.669362 Training Step 3030 \"loss\" =  4.184837\n",
      "2018-08-30 06:26:28.874586 Test Step 3035 Finished\n",
      "2018-08-30 06:26:28.874842 Test Step 3035 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:28.875134 Test Step 3035 \"loss\" =  7.6403117\n",
      "2018-08-30 06:26:28.921326 Training Step 3035 Finished Timing (Training: 0.911591, Test: 0.08233) after 0.251638 seconds\n",
      "2018-08-30 06:26:28.921590 Training Step 3035 \"min loss\" =  3.9518304\n",
      "2018-08-30 06:26:28.921654 Training Step 3035 \"loss\" =  4.662679\n",
      "2018-08-30 06:26:29.126558 Test Step 3040 Finished\n",
      "2018-08-30 06:26:29.126639 Test Step 3040 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:29.127089 Test Step 3040 \"loss\" =  8.35677\n",
      "2018-08-30 06:26:29.173607 Training Step 3040 Finished Timing (Training: 0.91149, Test: 0.0823615) after 0.251546 seconds\n",
      "2018-08-30 06:26:29.173675 Training Step 3040 \"min loss\" =  3.9518304\n",
      "2018-08-30 06:26:29.174047 Training Step 3040 \"loss\" =  4.7649946\n",
      "2018-08-30 06:26:29.378763 Test Step 3045 Finished\n",
      "2018-08-30 06:26:29.378848 Test Step 3045 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:29.378906 Test Step 3045 \"loss\" =  7.56545\n",
      "2018-08-30 06:26:29.425576 Training Step 3045 Finished Timing (Training: 0.911517, Test: 0.0823021) after 0.251197 seconds\n",
      "2018-08-30 06:26:29.425653 Training Step 3045 \"min loss\" =  3.9518304\n",
      "2018-08-30 06:26:29.425997 Training Step 3045 \"loss\" =  4.224899\n",
      "2018-08-30 06:26:29.630754 Test Step 3050 Finished\n",
      "2018-08-30 06:26:29.630870 Test Step 3050 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:29.631749 Test Step 3050 \"loss\" =  7.6062765\n",
      "2018-08-30 06:26:29.678238 Training Step 3050 Finished Timing (Training: 0.911295, Test: 0.0823122) after 0.251927 seconds\n",
      "2018-08-30 06:26:29.678592 Training Step 3050 \"min loss\" =  3.9518304\n",
      "2018-08-30 06:26:29.679048 Training Step 3050 \"loss\" =  4.530207\n",
      "2018-08-30 06:26:29.883956 Test Step 3055 Finished\n",
      "2018-08-30 06:26:29.884347 Test Step 3055 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:29.884412 Test Step 3055 \"loss\" =  7.1114554\n",
      "2018-08-30 06:26:29.930727 Training Step 3055 Finished Timing (Training: 0.911261, Test: 0.0823121) after 0.251322 seconds\n",
      "2018-08-30 06:26:29.930874 Training Step 3055 \"min loss\" =  3.9518304\n",
      "2018-08-30 06:26:29.931312 Training Step 3055 \"loss\" =  4.333889\n",
      "2018-08-30 06:26:30.136442 Test Step 3060 Finished\n",
      "2018-08-30 06:26:30.136555 Test Step 3060 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:30.137109 Test Step 3060 \"loss\" =  7.238069\n",
      "2018-08-30 06:26:30.183457 Training Step 3060 Finished Timing (Training: 0.91139, Test: 0.0822427) after 0.252065 seconds\n",
      "2018-08-30 06:26:30.183523 Training Step 3060 \"min loss\" =  3.9518304\n",
      "2018-08-30 06:26:30.183563 Training Step 3060 \"loss\" =  4.9693956\n",
      "2018-08-30 06:26:30.388886 Test Step 3065 Finished\n",
      "2018-08-30 06:26:30.389294 Test Step 3065 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:30.389514 Test Step 3065 \"loss\" =  7.4554996\n",
      "2018-08-30 06:26:30.435928 Training Step 3065 Finished Timing (Training: 0.91165, Test: 0.0822054) after 0.252308 seconds\n",
      "2018-08-30 06:26:30.436218 Training Step 3065 \"min loss\" =  3.9518304\n",
      "2018-08-30 06:26:30.436280 Training Step 3065 \"loss\" =  4.1389604\n",
      "2018-08-30 06:26:30.648514 Test Step 3070 Finished\n",
      "2018-08-30 06:26:30.648878 Test Step 3070 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:30.648952 Test Step 3070 \"loss\" =  7.323243\n",
      "2018-08-30 06:26:30.695502 Training Step 3070 Finished Timing (Training: 0.90974, Test: 0.0840964) after 0.258677 seconds\n",
      "2018-08-30 06:26:30.695577 Training Step 3070 \"min loss\" =  3.9518304\n",
      "2018-08-30 06:26:30.695642 Training Step 3070 \"loss\" =  4.4325547\n",
      "2018-08-30 06:26:30.901272 Test Step 3075 Finished\n",
      "2018-08-30 06:26:30.901386 Test Step 3075 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:30.901912 Test Step 3075 \"loss\" =  7.8227367\n",
      "2018-08-30 06:26:30.948056 Training Step 3075 Finished Timing (Training: 0.909998, Test: 0.0839971) after 0.252343 seconds\n",
      "2018-08-30 06:26:30.948118 Training Step 3075 \"min loss\" =  3.9518304\n",
      "2018-08-30 06:26:30.948179 Training Step 3075 \"loss\" =  4.2691894\n",
      "2018-08-30 06:26:31.153966 Test Step 3080 Finished\n",
      "2018-08-30 06:26:31.154074 Test Step 3080 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:31.154136 Test Step 3080 \"loss\" =  7.64217\n",
      "2018-08-30 06:26:31.200967 Training Step 3080 Finished Timing (Training: 0.910344, Test: 0.0839128) after 0.252709 seconds\n",
      "2018-08-30 06:26:31.201037 Training Step 3080 \"min loss\" =  3.9518304\n",
      "2018-08-30 06:26:31.201096 Training Step 3080 \"loss\" =  4.169566\n",
      "2018-08-30 06:26:31.406788 Test Step 3085 Finished\n",
      "2018-08-30 06:26:31.406873 Test Step 3085 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:31.406933 Test Step 3085 \"loss\" =  7.4257693\n",
      "2018-08-30 06:26:31.453665 Training Step 3085 Finished Timing (Training: 0.910677, Test: 0.0838156) after 0.252508 seconds\n",
      "2018-08-30 06:26:31.453729 Training Step 3085 \"min loss\" =  3.9463332\n",
      "2018-08-30 06:26:31.453787 Training Step 3085 \"loss\" =  3.9466987\n",
      "2018-08-30 06:26:31.658537 Test Step 3090 Finished\n",
      "2018-08-30 06:26:31.658655 Test Step 3090 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:31.658715 Test Step 3090 \"loss\" =  7.1540236\n",
      "2018-08-30 06:26:31.704842 Training Step 3090 Finished Timing (Training: 0.910908, Test: 0.0837904) after 0.250992 seconds\n",
      "2018-08-30 06:26:31.704915 Training Step 3090 \"min loss\" =  3.9463332\n",
      "2018-08-30 06:26:31.704984 Training Step 3090 \"loss\" =  4.1589894\n",
      "2018-08-30 06:26:31.910167 Test Step 3095 Finished\n",
      "2018-08-30 06:26:31.910378 Test Step 3095 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:31.910501 Test Step 3095 \"loss\" =  7.4159894\n",
      "2018-08-30 06:26:31.956657 Training Step 3095 Finished Timing (Training: 0.911075, Test: 0.0837701) after 0.25161 seconds\n",
      "2018-08-30 06:26:31.956721 Training Step 3095 \"min loss\" =  3.9463332\n",
      "2018-08-30 06:26:31.957078 Training Step 3095 \"loss\" =  4.3714433\n",
      "2018-08-30 06:26:32.163004 Test Step 3100 Finished\n",
      "2018-08-30 06:26:32.163089 Test Step 3100 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:32.163148 Test Step 3100 \"loss\" =  7.087336\n",
      "2018-08-30 06:26:32.210176 Training Step 3100 Finished Timing (Training: 0.911193, Test: 0.0836898) after 0.252626 seconds\n",
      "2018-08-30 06:26:32.210239 Training Step 3100 \"min loss\" =  3.9463332\n",
      "2018-08-30 06:26:32.210639 Training Step 3100 \"loss\" =  4.4018235\n",
      "2018-08-30 06:26:32.415307 Test Step 3105 Finished\n",
      "2018-08-30 06:26:32.415401 Test Step 3105 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:32.415502 Test Step 3105 \"loss\" =  7.146159\n",
      "2018-08-30 06:26:32.461711 Training Step 3105 Finished Timing (Training: 0.915617, Test: 0.0832835) after 0.251004 seconds\n",
      "2018-08-30 06:26:32.461779 Training Step 3105 \"min loss\" =  3.9463332\n",
      "2018-08-30 06:26:32.461840 Training Step 3105 \"loss\" =  4.4367023\n",
      "2018-08-30 06:26:32.666633 Test Step 3110 Finished\n",
      "2018-08-30 06:26:32.666723 Test Step 3110 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:32.666782 Test Step 3110 \"loss\" =  7.106729\n",
      "2018-08-30 06:26:32.712802 Training Step 3110 Finished Timing (Training: 0.914022, Test: 0.0832011) after 0.250195 seconds\n",
      "2018-08-30 06:26:32.712874 Training Step 3110 \"min loss\" =  3.9463332\n",
      "2018-08-30 06:26:32.713359 Training Step 3110 \"loss\" =  4.362544\n",
      "2018-08-30 06:26:32.918546 Test Step 3115 Finished\n",
      "2018-08-30 06:26:32.919007 Test Step 3115 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:32.919165 Test Step 3115 \"loss\" =  7.588509\n",
      "2018-08-30 06:26:32.965821 Training Step 3115 Finished Timing (Training: 0.913114, Test: 0.083163) after 0.252394 seconds\n",
      "2018-08-30 06:26:32.966072 Training Step 3115 \"min loss\" =  3.9463332\n",
      "2018-08-30 06:26:32.966134 Training Step 3115 \"loss\" =  4.1754713\n",
      "2018-08-30 06:26:33.172229 Test Step 3120 Finished\n",
      "2018-08-30 06:26:33.172425 Test Step 3120 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:33.172583 Test Step 3120 \"loss\" =  7.277843\n",
      "2018-08-30 06:26:33.219585 Training Step 3120 Finished Timing (Training: 0.913388, Test: 0.0830135) after 0.253383 seconds\n",
      "2018-08-30 06:26:33.219734 Training Step 3120 \"min loss\" =  3.9463332\n",
      "2018-08-30 06:26:33.219791 Training Step 3120 \"loss\" =  4.5039873\n",
      "2018-08-30 06:26:33.425189 Test Step 3125 Finished\n",
      "2018-08-30 06:26:33.425288 Test Step 3125 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:33.425345 Test Step 3125 \"loss\" =  7.306129\n",
      "2018-08-30 06:26:33.472652 Training Step 3125 Finished Timing (Training: 0.913264, Test: 0.0828386) after 0.252798 seconds\n",
      "2018-08-30 06:26:33.472717 Training Step 3125 \"min loss\" =  3.9033334\n",
      "2018-08-30 06:26:33.473226 Training Step 3125 \"loss\" =  4.4333296\n",
      "2018-08-30 06:26:33.678874 Test Step 3130 Finished\n",
      "2018-08-30 06:26:33.678949 Test Step 3130 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:33.679543 Test Step 3130 \"loss\" =  7.2657824\n",
      "2018-08-30 06:26:33.726049 Training Step 3130 Finished Timing (Training: 0.91296, Test: 0.0826826) after 0.252459 seconds\n",
      "2018-08-30 06:26:33.726195 Training Step 3130 \"min loss\" =  3.9033334\n",
      "2018-08-30 06:26:33.726326 Training Step 3130 \"loss\" =  4.3791943\n",
      "2018-08-30 06:26:33.931458 Test Step 3135 Finished\n",
      "2018-08-30 06:26:33.931901 Test Step 3135 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:33.931965 Test Step 3135 \"loss\" =  7.4506993\n",
      "2018-08-30 06:26:33.978049 Training Step 3135 Finished Timing (Training: 0.912765, Test: 0.0825901) after 0.25098 seconds\n",
      "2018-08-30 06:26:33.978147 Training Step 3135 \"min loss\" =  3.9033334\n",
      "2018-08-30 06:26:33.978188 Training Step 3135 \"loss\" =  4.243383\n",
      "2018-08-30 06:26:34.184443 Test Step 3140 Finished\n",
      "2018-08-30 06:26:34.184823 Test Step 3140 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:34.184886 Test Step 3140 \"loss\" =  7.4827275\n",
      "2018-08-30 06:26:34.231498 Training Step 3140 Finished Timing (Training: 0.91258, Test: 0.0826836) after 0.252622 seconds\n",
      "2018-08-30 06:26:34.231561 Training Step 3140 \"min loss\" =  3.9033334\n",
      "2018-08-30 06:26:34.231617 Training Step 3140 \"loss\" =  4.3357215\n",
      "2018-08-30 06:26:34.437644 Test Step 3145 Finished\n",
      "2018-08-30 06:26:34.437720 Test Step 3145 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:34.437767 Test Step 3145 \"loss\" =  7.187741\n",
      "2018-08-30 06:26:34.484579 Training Step 3145 Finished Timing (Training: 0.912553, Test: 0.0827293) after 0.252138 seconds\n",
      "2018-08-30 06:26:34.484642 Training Step 3145 \"min loss\" =  3.9033334\n",
      "2018-08-30 06:26:34.485071 Training Step 3145 \"loss\" =  4.4788866\n",
      "2018-08-30 06:26:34.690326 Test Step 3150 Finished\n",
      "2018-08-30 06:26:34.690413 Test Step 3150 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:34.691132 Test Step 3150 \"loss\" =  7.2561364\n",
      "2018-08-30 06:26:34.737334 Training Step 3150 Finished Timing (Training: 0.912458, Test: 0.082721) after 0.252182 seconds\n",
      "2018-08-30 06:26:34.737407 Training Step 3150 \"min loss\" =  3.8940606\n",
      "2018-08-30 06:26:34.738214 Training Step 3150 \"loss\" =  4.366848\n",
      "2018-08-30 06:26:34.943799 Test Step 3155 Finished\n",
      "2018-08-30 06:26:34.943913 Test Step 3155 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:34.943975 Test Step 3155 \"loss\" =  7.4681854\n",
      "2018-08-30 06:26:34.990822 Training Step 3155 Finished Timing (Training: 0.912277, Test: 0.0827188) after 0.252047 seconds\n",
      "2018-08-30 06:26:34.990881 Training Step 3155 \"min loss\" =  3.8940606\n",
      "2018-08-30 06:26:34.990932 Training Step 3155 \"loss\" =  4.1688895\n",
      "2018-08-30 06:26:35.197266 Test Step 3160 Finished\n",
      "2018-08-30 06:26:35.197390 Test Step 3160 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:35.198040 Test Step 3160 \"loss\" =  7.635085\n",
      "2018-08-30 06:26:35.244151 Training Step 3160 Finished Timing (Training: 0.911984, Test: 0.0826389) after 0.251834 seconds\n",
      "2018-08-30 06:26:35.244239 Training Step 3160 \"min loss\" =  3.8940606\n",
      "2018-08-30 06:26:35.244304 Training Step 3160 \"loss\" =  4.2623158\n",
      "2018-08-30 06:26:35.448691 Test Step 3165 Finished\n",
      "2018-08-30 06:26:35.448781 Test Step 3165 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:35.448870 Test Step 3165 \"loss\" =  7.3831663\n",
      "2018-08-30 06:26:35.494797 Training Step 3165 Finished Timing (Training: 0.912267, Test: 0.0826123) after 0.250424 seconds\n",
      "2018-08-30 06:26:35.494861 Training Step 3165 \"min loss\" =  3.8940606\n",
      "2018-08-30 06:26:35.494926 Training Step 3165 \"loss\" =  4.572118\n",
      "2018-08-30 06:26:35.700141 Test Step 3170 Finished\n",
      "2018-08-30 06:26:35.700262 Test Step 3170 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:35.700325 Test Step 3170 \"loss\" =  7.436114\n",
      "2018-08-30 06:26:35.747035 Training Step 3170 Finished Timing (Training: 0.912564, Test: 0.0825486) after 0.25204 seconds\n",
      "2018-08-30 06:26:35.747101 Training Step 3170 \"min loss\" =  3.8940606\n",
      "2018-08-30 06:26:35.747184 Training Step 3170 \"loss\" =  4.6796603\n",
      "2018-08-30 06:26:35.952893 Test Step 3175 Finished\n",
      "2018-08-30 06:26:35.953003 Test Step 3175 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:35.953087 Test Step 3175 \"loss\" =  7.297589\n",
      "2018-08-30 06:26:36.000629 Training Step 3175 Finished Timing (Training: 0.912775, Test: 0.0825339) after 0.253376 seconds\n",
      "2018-08-30 06:26:36.000749 Training Step 3175 \"min loss\" =  3.8940606\n",
      "2018-08-30 06:26:36.001336 Training Step 3175 \"loss\" =  4.3302207\n",
      "2018-08-30 06:26:36.212519 Test Step 3180 Finished\n",
      "2018-08-30 06:26:36.212627 Test Step 3180 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:36.212707 Test Step 3180 \"loss\" =  7.705311\n",
      "2018-08-30 06:26:36.258748 Training Step 3180 Finished Timing (Training: 0.91284, Test: 0.0825032) after 0.257332 seconds\n",
      "2018-08-30 06:26:36.258821 Training Step 3180 \"min loss\" =  3.8940606\n",
      "2018-08-30 06:26:36.258877 Training Step 3180 \"loss\" =  4.2674346\n",
      "2018-08-30 06:26:36.464582 Test Step 3185 Finished\n",
      "2018-08-30 06:26:36.464678 Test Step 3185 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:36.464743 Test Step 3185 \"loss\" =  7.4118257\n",
      "2018-08-30 06:26:36.511462 Training Step 3185 Finished Timing (Training: 0.913005, Test: 0.0824998) after 0.252505 seconds\n",
      "2018-08-30 06:26:36.511525 Training Step 3185 \"min loss\" =  3.8940606\n",
      "2018-08-30 06:26:36.511592 Training Step 3185 \"loss\" =  4.8388853\n",
      "2018-08-30 06:26:36.716324 Test Step 3190 Finished\n",
      "2018-08-30 06:26:36.716406 Test Step 3190 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:36.716490 Test Step 3190 \"loss\" =  7.3427086\n",
      "2018-08-30 06:26:36.762919 Training Step 3190 Finished Timing (Training: 0.913036, Test: 0.082525) after 0.251271 seconds\n",
      "2018-08-30 06:26:36.762982 Training Step 3190 \"min loss\" =  3.8940606\n",
      "2018-08-30 06:26:36.763390 Training Step 3190 \"loss\" =  4.2525954\n",
      "2018-08-30 06:26:36.968567 Test Step 3195 Finished\n",
      "2018-08-30 06:26:36.968683 Test Step 3195 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:36.968764 Test Step 3195 \"loss\" =  7.1823764\n",
      "2018-08-30 06:26:37.014650 Training Step 3195 Finished Timing (Training: 0.91303, Test: 0.0825896) after 0.251187 seconds\n",
      "2018-08-30 06:26:37.014725 Training Step 3195 \"min loss\" =  3.8940606\n",
      "2018-08-30 06:26:37.015172 Training Step 3195 \"loss\" =  4.1855345\n",
      "2018-08-30 06:26:37.220535 Test Step 3200 Finished\n",
      "2018-08-30 06:26:37.220636 Test Step 3200 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:37.220704 Test Step 3200 \"loss\" =  7.3140116\n",
      "2018-08-30 06:26:37.266747 Training Step 3200 Finished Timing (Training: 0.913044, Test: 0.0825396) after 0.251106 seconds\n",
      "2018-08-30 06:26:37.266818 Training Step 3200 \"min loss\" =  3.8940606\n",
      "2018-08-30 06:26:37.266920 Training Step 3200 \"loss\" =  4.4676547\n",
      "2018-08-30 06:26:37.472887 Test Step 3205 Finished\n",
      "2018-08-30 06:26:37.472979 Test Step 3205 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:37.473043 Test Step 3205 \"loss\" =  7.38419\n",
      "2018-08-30 06:26:37.519148 Training Step 3205 Finished Timing (Training: 0.916393, Test: 0.082536) after 0.251268 seconds\n",
      "2018-08-30 06:26:37.519228 Training Step 3205 \"min loss\" =  3.8940606\n",
      "2018-08-30 06:26:37.519668 Training Step 3205 \"loss\" =  4.509066\n",
      "2018-08-30 06:26:37.724681 Test Step 3210 Finished\n",
      "2018-08-30 06:26:37.724774 Test Step 3210 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:37.724840 Test Step 3210 \"loss\" =  7.5415816\n",
      "2018-08-30 06:26:37.770876 Training Step 3210 Finished Timing (Training: 0.914701, Test: 0.0824448) after 0.250824 seconds\n",
      "2018-08-30 06:26:37.770952 Training Step 3210 \"min loss\" =  3.8940606\n",
      "2018-08-30 06:26:37.771016 Training Step 3210 \"loss\" =  4.5775285\n",
      "2018-08-30 06:26:37.975346 Test Step 3215 Finished\n",
      "2018-08-30 06:26:37.975455 Test Step 3215 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:37.975934 Test Step 3215 \"loss\" =  7.234736\n",
      "2018-08-30 06:26:38.022401 Training Step 3215 Finished Timing (Training: 0.914187, Test: 0.0827009) after 0.251297 seconds\n",
      "2018-08-30 06:26:38.022470 Training Step 3215 \"min loss\" =  3.8539553\n",
      "2018-08-30 06:26:38.022558 Training Step 3215 \"loss\" =  4.1318107\n",
      "2018-08-30 06:26:38.228166 Test Step 3220 Finished\n",
      "2018-08-30 06:26:38.228247 Test Step 3220 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:38.228313 Test Step 3220 \"loss\" =  7.182874\n",
      "2018-08-30 06:26:38.275092 Training Step 3220 Finished Timing (Training: 0.914614, Test: 0.0825689) after 0.252449 seconds\n",
      "2018-08-30 06:26:38.275158 Training Step 3220 \"min loss\" =  3.8539553\n",
      "2018-08-30 06:26:38.275226 Training Step 3220 \"loss\" =  4.2580633\n",
      "2018-08-30 06:26:38.481268 Test Step 3225 Finished\n",
      "2018-08-30 06:26:38.481394 Test Step 3225 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:38.481473 Test Step 3225 \"loss\" =  7.5482254\n",
      "2018-08-30 06:26:38.527493 Training Step 3225 Finished Timing (Training: 0.914853, Test: 0.0824839) after 0.252173 seconds\n",
      "2018-08-30 06:26:38.527559 Training Step 3225 \"min loss\" =  3.8539553\n",
      "2018-08-30 06:26:38.527613 Training Step 3225 \"loss\" =  4.041845\n",
      "2018-08-30 06:26:38.732849 Test Step 3230 Finished\n",
      "2018-08-30 06:26:38.732927 Test Step 3230 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:38.733016 Test Step 3230 \"loss\" =  7.79891\n",
      "2018-08-30 06:26:38.780223 Training Step 3230 Finished Timing (Training: 0.914645, Test: 0.0823071) after 0.251745 seconds\n",
      "2018-08-30 06:26:38.780299 Training Step 3230 \"min loss\" =  3.8539553\n",
      "2018-08-30 06:26:38.780370 Training Step 3230 \"loss\" =  4.2041354\n",
      "2018-08-30 06:26:38.985579 Test Step 3235 Finished\n",
      "2018-08-30 06:26:38.985674 Test Step 3235 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:38.985784 Test Step 3235 \"loss\" =  7.2283163\n",
      "2018-08-30 06:26:39.031835 Training Step 3235 Finished Timing (Training: 0.914495, Test: 0.0822465) after 0.250754 seconds\n",
      "2018-08-30 06:26:39.031906 Training Step 3235 \"min loss\" =  3.8539553\n",
      "2018-08-30 06:26:39.031970 Training Step 3235 \"loss\" =  4.3947773\n",
      "2018-08-30 06:26:39.238357 Test Step 3240 Finished\n",
      "2018-08-30 06:26:39.238445 Test Step 3240 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:39.238506 Test Step 3240 \"loss\" =  7.34496\n",
      "2018-08-30 06:26:39.285216 Training Step 3240 Finished Timing (Training: 0.914802, Test: 0.0821208) after 0.253157 seconds\n",
      "2018-08-30 06:26:39.285574 Training Step 3240 \"min loss\" =  3.8539553\n",
      "2018-08-30 06:26:39.285808 Training Step 3240 \"loss\" =  4.3085804\n",
      "2018-08-30 06:26:39.491042 Test Step 3245 Finished\n",
      "2018-08-30 06:26:39.491140 Test Step 3245 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:39.491225 Test Step 3245 \"loss\" =  7.4939494\n",
      "2018-08-30 06:26:39.538339 Training Step 3245 Finished Timing (Training: 0.914731, Test: 0.0821266) after 0.252462 seconds\n",
      "2018-08-30 06:26:39.538652 Training Step 3245 \"min loss\" =  3.8539553\n",
      "2018-08-30 06:26:39.538719 Training Step 3245 \"loss\" =  4.2749567\n",
      "2018-08-30 06:26:39.744053 Test Step 3250 Finished\n",
      "2018-08-30 06:26:39.744171 Test Step 3250 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:39.744302 Test Step 3250 \"loss\" =  7.3248434\n",
      "2018-08-30 06:26:39.791218 Training Step 3250 Finished Timing (Training: 0.914713, Test: 0.0821316) after 0.252431 seconds\n",
      "2018-08-30 06:26:39.791603 Training Step 3250 \"min loss\" =  3.8539553\n",
      "2018-08-30 06:26:39.791675 Training Step 3250 \"loss\" =  4.225179\n",
      "2018-08-30 06:26:39.997070 Test Step 3255 Finished\n",
      "2018-08-30 06:26:39.997529 Test Step 3255 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:39.997604 Test Step 3255 \"loss\" =  6.969225\n",
      "2018-08-30 06:26:40.044321 Training Step 3255 Finished Timing (Training: 0.914588, Test: 0.0821304) after 0.252571 seconds\n",
      "2018-08-30 06:26:40.044422 Training Step 3255 \"min loss\" =  3.8539553\n",
      "2018-08-30 06:26:40.045040 Training Step 3255 \"loss\" =  4.1797423\n",
      "2018-08-30 06:26:40.251291 Test Step 3260 Finished\n",
      "2018-08-30 06:26:40.251385 Test Step 3260 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:40.251451 Test Step 3260 \"loss\" =  7.2411113\n",
      "2018-08-30 06:26:40.297524 Training Step 3260 Finished Timing (Training: 0.914485, Test: 0.0821245) after 0.252313 seconds\n",
      "2018-08-30 06:26:40.297595 Training Step 3260 \"min loss\" =  3.8539553\n",
      "2018-08-30 06:26:40.297655 Training Step 3260 \"loss\" =  4.2157817\n",
      "2018-08-30 06:26:40.502633 Test Step 3265 Finished\n",
      "2018-08-30 06:26:40.503029 Test Step 3265 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:40.503296 Test Step 3265 \"loss\" =  7.790353\n",
      "2018-08-30 06:26:40.549389 Training Step 3265 Finished Timing (Training: 0.914426, Test: 0.0821485) after 0.251652 seconds\n",
      "2018-08-30 06:26:40.549461 Training Step 3265 \"min loss\" =  3.8539553\n",
      "2018-08-30 06:26:40.549847 Training Step 3265 \"loss\" =  4.5128493\n",
      "2018-08-30 06:26:40.755380 Test Step 3270 Finished\n",
      "2018-08-30 06:26:40.755510 Test Step 3270 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:40.755575 Test Step 3270 \"loss\" =  7.7071056\n",
      "2018-08-30 06:26:40.802330 Training Step 3270 Finished Timing (Training: 0.914424, Test: 0.0821648) after 0.25241 seconds\n",
      "2018-08-30 06:26:40.802401 Training Step 3270 \"min loss\" =  3.8539553\n",
      "2018-08-30 06:26:40.802456 Training Step 3270 \"loss\" =  4.3883767\n",
      "2018-08-30 06:26:41.007794 Test Step 3275 Finished\n",
      "2018-08-30 06:26:41.007919 Test Step 3275 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:41.007988 Test Step 3275 \"loss\" =  7.3921304\n",
      "2018-08-30 06:26:41.054624 Training Step 3275 Finished Timing (Training: 0.914267, Test: 0.0821712) after 0.251163 seconds\n",
      "2018-08-30 06:26:41.054718 Training Step 3275 \"min loss\" =  3.8539553\n",
      "2018-08-30 06:26:41.055287 Training Step 3275 \"loss\" =  4.2646303\n",
      "2018-08-30 06:26:41.259856 Test Step 3280 Finished\n",
      "2018-08-30 06:26:41.259961 Test Step 3280 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:41.260026 Test Step 3280 \"loss\" =  7.522228\n",
      "2018-08-30 06:26:41.306894 Training Step 3280 Finished Timing (Training: 0.914285, Test: 0.0821303) after 0.251535 seconds\n",
      "2018-08-30 06:26:41.306964 Training Step 3280 \"min loss\" =  3.8539553\n",
      "2018-08-30 06:26:41.307026 Training Step 3280 \"loss\" =  4.3489122\n",
      "2018-08-30 06:26:41.512805 Test Step 3285 Finished\n",
      "2018-08-30 06:26:41.512891 Test Step 3285 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:41.512976 Test Step 3285 \"loss\" =  7.7348566\n",
      "2018-08-30 06:26:41.559022 Training Step 3285 Finished Timing (Training: 0.914371, Test: 0.0821454) after 0.251928 seconds\n",
      "2018-08-30 06:26:41.559106 Training Step 3285 \"min loss\" =  3.8539553\n",
      "2018-08-30 06:26:41.559170 Training Step 3285 \"loss\" =  4.289116\n",
      "2018-08-30 06:26:41.764697 Test Step 3290 Finished\n",
      "2018-08-30 06:26:41.764792 Test Step 3290 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:41.764878 Test Step 3290 \"loss\" =  7.1267066\n",
      "2018-08-30 06:26:41.812378 Training Step 3290 Finished Timing (Training: 0.914295, Test: 0.0821585) after 0.253083 seconds\n",
      "2018-08-30 06:26:41.812636 Training Step 3290 \"min loss\" =  3.7715495\n",
      "2018-08-30 06:26:41.812907 Training Step 3290 \"loss\" =  3.8881457\n",
      "2018-08-30 06:26:42.017896 Test Step 3295 Finished\n",
      "2018-08-30 06:26:42.018013 Test Step 3295 \"min loss\" =  6.8684387\n",
      "2018-08-30 06:26:42.018094 Test Step 3295 \"loss\" =  6.9341836\n",
      "2018-08-30 06:26:42.064265 Training Step 3295 Finished Timing (Training: 0.914265, Test: 0.0821906) after 0.251286 seconds\n",
      "2018-08-30 06:26:42.064340 Training Step 3295 \"min loss\" =  3.7715495\n",
      "2018-08-30 06:26:42.064405 Training Step 3295 \"loss\" =  4.996301\n",
      "2018-08-30 06:26:42.270135 Test Step 3300 Finished\n",
      "2018-08-30 06:26:42.270306 Test Step 3300 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:42.270368 Test Step 3300 \"loss\" =  6.8407335\n",
      "2018-08-30 06:26:42.317120 Training Step 3300 Finished Timing (Training: 0.914304, Test: 0.0822192) after 0.252622 seconds\n",
      "2018-08-30 06:26:42.317188 Training Step 3300 \"min loss\" =  3.7715495\n",
      "2018-08-30 06:26:42.317289 Training Step 3300 \"loss\" =  3.8188956\n",
      "2018-08-30 06:26:42.522618 Test Step 3305 Finished\n",
      "2018-08-30 06:26:42.522771 Test Step 3305 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:42.522867 Test Step 3305 \"loss\" =  7.0600147\n",
      "2018-08-30 06:26:42.569146 Training Step 3305 Finished Timing (Training: 0.916314, Test: 0.0821627) after 0.251762 seconds\n",
      "2018-08-30 06:26:42.569239 Training Step 3305 \"min loss\" =  3.7715495\n",
      "2018-08-30 06:26:42.569901 Training Step 3305 \"loss\" =  4.0953417\n",
      "2018-08-30 06:26:42.774657 Test Step 3310 Finished\n",
      "2018-08-30 06:26:42.774754 Test Step 3310 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:42.775242 Test Step 3310 \"loss\" =  6.9912024\n",
      "2018-08-30 06:26:42.821575 Training Step 3310 Finished Timing (Training: 0.913587, Test: 0.0820833) after 0.251585 seconds\n",
      "2018-08-30 06:26:42.821642 Training Step 3310 \"min loss\" =  3.7715495\n",
      "2018-08-30 06:26:42.822250 Training Step 3310 \"loss\" =  4.2668633\n",
      "2018-08-30 06:26:43.027474 Test Step 3315 Finished\n",
      "2018-08-30 06:26:43.027618 Test Step 3315 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:43.027776 Test Step 3315 \"loss\" =  7.195739\n",
      "2018-08-30 06:26:43.074654 Training Step 3315 Finished Timing (Training: 0.912912, Test: 0.0821599) after 0.252176 seconds\n",
      "2018-08-30 06:26:43.074728 Training Step 3315 \"min loss\" =  3.7715495\n",
      "2018-08-30 06:26:43.074792 Training Step 3315 \"loss\" =  3.8335764\n",
      "2018-08-30 06:26:43.279916 Test Step 3320 Finished\n",
      "2018-08-30 06:26:43.280019 Test Step 3320 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:43.280083 Test Step 3320 \"loss\" =  7.4976053\n",
      "2018-08-30 06:26:43.326930 Training Step 3320 Finished Timing (Training: 0.913519, Test: 0.0823082) after 0.252048 seconds\n",
      "2018-08-30 06:26:43.327000 Training Step 3320 \"min loss\" =  3.7715495\n",
      "2018-08-30 06:26:43.327085 Training Step 3320 \"loss\" =  4.096145\n",
      "2018-08-30 06:26:43.531764 Test Step 3325 Finished\n",
      "2018-08-30 06:26:43.531875 Test Step 3325 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:43.531962 Test Step 3325 \"loss\" =  7.7805624\n",
      "2018-08-30 06:26:43.578015 Training Step 3325 Finished Timing (Training: 0.913925, Test: 0.0823245) after 0.250866 seconds\n",
      "2018-08-30 06:26:43.578091 Training Step 3325 \"min loss\" =  3.7715495\n",
      "2018-08-30 06:26:43.578239 Training Step 3325 \"loss\" =  4.0954695\n",
      "2018-08-30 06:26:43.783557 Test Step 3330 Finished\n",
      "2018-08-30 06:26:43.783965 Test Step 3330 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:43.784028 Test Step 3330 \"loss\" =  8.156204\n",
      "2018-08-30 06:26:43.830081 Training Step 3330 Finished Timing (Training: 0.91379, Test: 0.0825017) after 0.251747 seconds\n",
      "2018-08-30 06:26:43.830383 Training Step 3330 \"min loss\" =  3.7715495\n",
      "2018-08-30 06:26:43.830463 Training Step 3330 \"loss\" =  4.1080756\n",
      "2018-08-30 06:26:44.035441 Test Step 3335 Finished\n",
      "2018-08-30 06:26:44.035559 Test Step 3335 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:44.035628 Test Step 3335 \"loss\" =  7.4447823\n",
      "2018-08-30 06:26:44.082345 Training Step 3335 Finished Timing (Training: 0.913972, Test: 0.0824349) after 0.25181 seconds\n",
      "2018-08-30 06:26:44.082416 Training Step 3335 \"min loss\" =  3.7715495\n",
      "2018-08-30 06:26:44.082469 Training Step 3335 \"loss\" =  4.3456287\n",
      "2018-08-30 06:26:44.288218 Test Step 3340 Finished\n",
      "2018-08-30 06:26:44.288315 Test Step 3340 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:44.288379 Test Step 3340 \"loss\" =  7.563219\n",
      "2018-08-30 06:26:44.335123 Training Step 3340 Finished Timing (Training: 0.913679, Test: 0.0825672) after 0.251792 seconds\n",
      "2018-08-30 06:26:44.335192 Training Step 3340 \"min loss\" =  3.7715495\n",
      "2018-08-30 06:26:44.335262 Training Step 3340 \"loss\" =  4.29982\n",
      "2018-08-30 06:26:44.540001 Test Step 3345 Finished\n",
      "2018-08-30 06:26:44.540112 Test Step 3345 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:44.540202 Test Step 3345 \"loss\" =  7.3182073\n",
      "2018-08-30 06:26:44.586968 Training Step 3345 Finished Timing (Training: 0.913857, Test: 0.0825796) after 0.25162 seconds\n",
      "2018-08-30 06:26:44.587038 Training Step 3345 \"min loss\" =  3.7715495\n",
      "2018-08-30 06:26:44.587592 Training Step 3345 \"loss\" =  4.0292788\n",
      "2018-08-30 06:26:44.792806 Test Step 3350 Finished\n",
      "2018-08-30 06:26:44.792919 Test Step 3350 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:44.792982 Test Step 3350 \"loss\" =  7.3256364\n",
      "2018-08-30 06:26:44.839637 Training Step 3350 Finished Timing (Training: 0.913712, Test: 0.0826962) after 0.251973 seconds\n",
      "2018-08-30 06:26:44.839709 Training Step 3350 \"min loss\" =  3.7715495\n",
      "2018-08-30 06:26:44.839774 Training Step 3350 \"loss\" =  4.5174127\n",
      "2018-08-30 06:26:45.045687 Test Step 3355 Finished\n",
      "2018-08-30 06:26:45.045841 Test Step 3355 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:45.045909 Test Step 3355 \"loss\" =  7.1133313\n",
      "2018-08-30 06:26:45.092941 Training Step 3355 Finished Timing (Training: 0.913686, Test: 0.0828609) after 0.253096 seconds\n",
      "2018-08-30 06:26:45.093015 Training Step 3355 \"min loss\" =  3.7715495\n",
      "2018-08-30 06:26:45.093098 Training Step 3355 \"loss\" =  4.019577\n",
      "2018-08-30 06:26:45.298627 Test Step 3360 Finished\n",
      "2018-08-30 06:26:45.298724 Test Step 3360 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:45.298804 Test Step 3360 \"loss\" =  7.3049374\n",
      "2018-08-30 06:26:45.345578 Training Step 3360 Finished Timing (Training: 0.913837, Test: 0.0828365) after 0.252411 seconds\n",
      "2018-08-30 06:26:45.345647 Training Step 3360 \"min loss\" =  3.7715495\n",
      "2018-08-30 06:26:45.345711 Training Step 3360 \"loss\" =  4.04567\n",
      "2018-08-30 06:26:45.551115 Test Step 3365 Finished\n",
      "2018-08-30 06:26:45.551216 Test Step 3365 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:45.551277 Test Step 3365 \"loss\" =  7.129938\n",
      "2018-08-30 06:26:45.598146 Training Step 3365 Finished Timing (Training: 0.913944, Test: 0.0828259) after 0.252303 seconds\n",
      "2018-08-30 06:26:45.598228 Training Step 3365 \"min loss\" =  3.7715495\n",
      "2018-08-30 06:26:45.598296 Training Step 3365 \"loss\" =  4.0811596\n",
      "2018-08-30 06:26:45.803679 Test Step 3370 Finished\n",
      "2018-08-30 06:26:45.803798 Test Step 3370 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:45.803863 Test Step 3370 \"loss\" =  7.062301\n",
      "2018-08-30 06:26:45.850605 Training Step 3370 Finished Timing (Training: 0.913897, Test: 0.0827963) after 0.251669 seconds\n",
      "2018-08-30 06:26:45.850706 Training Step 3370 \"min loss\" =  3.7715495\n",
      "2018-08-30 06:26:45.851259 Training Step 3370 \"loss\" =  4.2093973\n",
      "2018-08-30 06:26:46.056182 Test Step 3375 Finished\n",
      "2018-08-30 06:26:46.056427 Test Step 3375 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:46.056539 Test Step 3375 \"loss\" =  7.082932\n",
      "2018-08-30 06:26:46.103683 Training Step 3375 Finished Timing (Training: 0.913729, Test: 0.0828734) after 0.25235 seconds\n",
      "2018-08-30 06:26:46.103757 Training Step 3375 \"min loss\" =  3.7715495\n",
      "2018-08-30 06:26:46.104112 Training Step 3375 \"loss\" =  3.843454\n",
      "2018-08-30 06:26:46.309567 Test Step 3380 Finished\n",
      "2018-08-30 06:26:46.309959 Test Step 3380 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:46.310022 Test Step 3380 \"loss\" =  7.8807955\n",
      "2018-08-30 06:26:46.356602 Training Step 3380 Finished Timing (Training: 0.913589, Test: 0.0828329) after 0.252392 seconds\n",
      "2018-08-30 06:26:46.356670 Training Step 3380 \"min loss\" =  3.6832733\n",
      "2018-08-30 06:26:46.356724 Training Step 3380 \"loss\" =  4.0427933\n",
      "2018-08-30 06:26:46.561603 Test Step 3385 Finished\n",
      "2018-08-30 06:26:46.562036 Test Step 3385 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:46.562098 Test Step 3385 \"loss\" =  7.361992\n",
      "2018-08-30 06:26:46.608756 Training Step 3385 Finished Timing (Training: 0.913606, Test: 0.0828465) after 0.251954 seconds\n",
      "2018-08-30 06:26:46.608827 Training Step 3385 \"min loss\" =  3.6832733\n",
      "2018-08-30 06:26:46.608887 Training Step 3385 \"loss\" =  4.1488547\n",
      "2018-08-30 06:26:46.813953 Test Step 3390 Finished\n",
      "2018-08-30 06:26:46.814051 Test Step 3390 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:46.814107 Test Step 3390 \"loss\" =  7.42841\n",
      "2018-08-30 06:26:46.860378 Training Step 3390 Finished Timing (Training: 0.913705, Test: 0.0828437) after 0.251412 seconds\n",
      "2018-08-30 06:26:46.860441 Training Step 3390 \"min loss\" =  3.6832733\n",
      "2018-08-30 06:26:46.860493 Training Step 3390 \"loss\" =  4.230495\n",
      "2018-08-30 06:26:47.065908 Test Step 3395 Finished\n",
      "2018-08-30 06:26:47.065990 Test Step 3395 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:47.066050 Test Step 3395 \"loss\" =  7.1657915\n",
      "2018-08-30 06:26:47.112916 Training Step 3395 Finished Timing (Training: 0.913822, Test: 0.0828223) after 0.252365 seconds\n",
      "2018-08-30 06:26:47.112983 Training Step 3395 \"min loss\" =  3.6832733\n",
      "2018-08-30 06:26:47.113062 Training Step 3395 \"loss\" =  4.193485\n",
      "2018-08-30 06:26:47.318043 Test Step 3400 Finished\n",
      "2018-08-30 06:26:47.318269 Test Step 3400 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:47.318374 Test Step 3400 \"loss\" =  7.5293255\n",
      "2018-08-30 06:26:47.364823 Training Step 3400 Finished Timing (Training: 0.913872, Test: 0.0828104) after 0.251686 seconds\n",
      "2018-08-30 06:26:47.364885 Training Step 3400 \"min loss\" =  3.6832733\n",
      "2018-08-30 06:26:47.364946 Training Step 3400 \"loss\" =  4.309405\n",
      "2018-08-30 06:26:47.570720 Test Step 3405 Finished\n",
      "2018-08-30 06:26:47.570810 Test Step 3405 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:47.570869 Test Step 3405 \"loss\" =  7.497171\n",
      "2018-08-30 06:26:47.617575 Training Step 3405 Finished Timing (Training: 0.916534, Test: 0.0825889) after 0.252547 seconds\n",
      "2018-08-30 06:26:47.617636 Training Step 3405 \"min loss\" =  3.6832733\n",
      "2018-08-30 06:26:47.617676 Training Step 3405 \"loss\" =  4.3449864\n",
      "2018-08-30 06:26:47.822319 Test Step 3410 Finished\n",
      "2018-08-30 06:26:47.822459 Test Step 3410 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:47.822536 Test Step 3410 \"loss\" =  7.4790764\n",
      "2018-08-30 06:26:47.869679 Training Step 3410 Finished Timing (Training: 0.915719, Test: 0.0828615) after 0.251916 seconds\n",
      "2018-08-30 06:26:47.869756 Training Step 3410 \"min loss\" =  3.6832733\n",
      "2018-08-30 06:26:47.870102 Training Step 3410 \"loss\" =  3.9292643\n",
      "2018-08-30 06:26:48.075746 Test Step 3415 Finished\n",
      "2018-08-30 06:26:48.076212 Test Step 3415 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:48.076420 Test Step 3415 \"loss\" =  7.461815\n",
      "2018-08-30 06:26:48.122787 Training Step 3415 Finished Timing (Training: 0.913865, Test: 0.0828516) after 0.252367 seconds\n",
      "2018-08-30 06:26:48.122865 Training Step 3415 \"min loss\" =  3.6832733\n",
      "2018-08-30 06:26:48.122922 Training Step 3415 \"loss\" =  3.9293332\n",
      "2018-08-30 06:26:48.328631 Test Step 3420 Finished\n",
      "2018-08-30 06:26:48.328731 Test Step 3420 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:48.329207 Test Step 3420 \"loss\" =  7.3098464\n",
      "2018-08-30 06:26:48.375242 Training Step 3420 Finished Timing (Training: 0.913277, Test: 0.0828553) after 0.251703 seconds\n",
      "2018-08-30 06:26:48.375319 Training Step 3420 \"min loss\" =  3.6832733\n",
      "2018-08-30 06:26:48.375374 Training Step 3420 \"loss\" =  4.238136\n",
      "2018-08-30 06:26:48.580486 Test Step 3425 Finished\n",
      "2018-08-30 06:26:48.580567 Test Step 3425 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:48.581020 Test Step 3425 \"loss\" =  7.2162747\n",
      "2018-08-30 06:26:48.627487 Training Step 3425 Finished Timing (Training: 0.912849, Test: 0.0827464) after 0.251473 seconds\n",
      "2018-08-30 06:26:48.627549 Training Step 3425 \"min loss\" =  3.6832733\n",
      "2018-08-30 06:26:48.627882 Training Step 3425 \"loss\" =  3.9634717\n",
      "2018-08-30 06:26:48.833037 Test Step 3430 Finished\n",
      "2018-08-30 06:26:48.833161 Test Step 3430 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:48.833213 Test Step 3430 \"loss\" =  7.239383\n",
      "2018-08-30 06:26:48.879928 Training Step 3430 Finished Timing (Training: 0.912919, Test: 0.0827638) after 0.251736 seconds\n",
      "2018-08-30 06:26:48.880001 Training Step 3430 \"min loss\" =  3.6832733\n",
      "2018-08-30 06:26:48.880382 Training Step 3430 \"loss\" =  3.7766593\n",
      "2018-08-30 06:26:49.085914 Test Step 3435 Finished\n",
      "2018-08-30 06:26:49.085981 Test Step 3435 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:49.086495 Test Step 3435 \"loss\" =  7.317957\n",
      "2018-08-30 06:26:49.132866 Training Step 3435 Finished Timing (Training: 0.912605, Test: 0.0829335) after 0.252426 seconds\n",
      "2018-08-30 06:26:49.132940 Training Step 3435 \"min loss\" =  3.6832733\n",
      "2018-08-30 06:26:49.132996 Training Step 3435 \"loss\" =  4.1398315\n",
      "2018-08-30 06:26:49.339311 Test Step 3440 Finished\n",
      "2018-08-30 06:26:49.339419 Test Step 3440 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:49.339906 Test Step 3440 \"loss\" =  7.249341\n",
      "2018-08-30 06:26:49.386376 Training Step 3440 Finished Timing (Training: 0.912438, Test: 0.0828216) after 0.252749 seconds\n",
      "2018-08-30 06:26:49.386458 Training Step 3440 \"min loss\" =  3.6832733\n",
      "2018-08-30 06:26:49.386515 Training Step 3440 \"loss\" =  4.169654\n",
      "2018-08-30 06:26:49.592422 Test Step 3445 Finished\n",
      "2018-08-30 06:26:49.592505 Test Step 3445 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:49.592576 Test Step 3445 \"loss\" =  7.276721\n",
      "2018-08-30 06:26:49.639443 Training Step 3445 Finished Timing (Training: 0.912295, Test: 0.0827997) after 0.252326 seconds\n",
      "2018-08-30 06:26:49.639514 Training Step 3445 \"min loss\" =  3.6832733\n",
      "2018-08-30 06:26:49.639845 Training Step 3445 \"loss\" =  3.9802313\n",
      "2018-08-30 06:26:49.845499 Test Step 3450 Finished\n",
      "2018-08-30 06:26:49.845587 Test Step 3450 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:49.845646 Test Step 3450 \"loss\" =  7.699139\n",
      "2018-08-30 06:26:49.893018 Training Step 3450 Finished Timing (Training: 0.912269, Test: 0.0826785) after 0.252862 seconds\n",
      "2018-08-30 06:26:49.893322 Training Step 3450 \"min loss\" =  3.6832733\n",
      "2018-08-30 06:26:49.893386 Training Step 3450 \"loss\" =  4.712922\n",
      "2018-08-30 06:26:50.098998 Test Step 3455 Finished\n",
      "2018-08-30 06:26:50.099397 Test Step 3455 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:50.099603 Test Step 3455 \"loss\" =  7.8236666\n",
      "2018-08-30 06:26:50.145832 Training Step 3455 Finished Timing (Training: 0.912101, Test: 0.0826774) after 0.252023 seconds\n",
      "2018-08-30 06:26:50.146071 Training Step 3455 \"min loss\" =  3.6832733\n",
      "2018-08-30 06:26:50.146271 Training Step 3455 \"loss\" =  4.8048973\n",
      "2018-08-30 06:26:50.350884 Test Step 3460 Finished\n",
      "2018-08-30 06:26:50.350975 Test Step 3460 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:50.351036 Test Step 3460 \"loss\" =  7.413342\n",
      "2018-08-30 06:26:50.398094 Training Step 3460 Finished Timing (Training: 0.912095, Test: 0.0826053) after 0.251764 seconds\n",
      "2018-08-30 06:26:50.398168 Training Step 3460 \"min loss\" =  3.6832733\n",
      "2018-08-30 06:26:50.398511 Training Step 3460 \"loss\" =  3.9752078\n",
      "2018-08-30 06:26:50.603861 Test Step 3465 Finished\n",
      "2018-08-30 06:26:50.603945 Test Step 3465 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:50.604002 Test Step 3465 \"loss\" =  7.3700414\n",
      "2018-08-30 06:26:50.650796 Training Step 3465 Finished Timing (Training: 0.912011, Test: 0.0826045) after 0.251961 seconds\n",
      "2018-08-30 06:26:50.650854 Training Step 3465 \"min loss\" =  3.6832733\n",
      "2018-08-30 06:26:50.651185 Training Step 3465 \"loss\" =  3.8505912\n",
      "2018-08-30 06:26:50.856527 Test Step 3470 Finished\n",
      "2018-08-30 06:26:50.856625 Test Step 3470 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:50.856681 Test Step 3470 \"loss\" =  7.423777\n",
      "2018-08-30 06:26:50.903415 Training Step 3470 Finished Timing (Training: 0.911987, Test: 0.0825756) after 0.25192 seconds\n",
      "2018-08-30 06:26:50.903689 Training Step 3470 \"min loss\" =  3.6832733\n",
      "2018-08-30 06:26:50.903746 Training Step 3470 \"loss\" =  4.4862785\n",
      "2018-08-30 06:26:51.109487 Test Step 3475 Finished\n",
      "2018-08-30 06:26:51.109584 Test Step 3475 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:51.110129 Test Step 3475 \"loss\" =  7.336504\n",
      "2018-08-30 06:26:51.156390 Training Step 3475 Finished Timing (Training: 0.91187, Test: 0.0826277) after 0.252261 seconds\n",
      "2018-08-30 06:26:51.156477 Training Step 3475 \"min loss\" =  3.6832733\n",
      "2018-08-30 06:26:51.156881 Training Step 3475 \"loss\" =  3.8917034\n",
      "2018-08-30 06:26:51.362011 Test Step 3480 Finished\n",
      "2018-08-30 06:26:51.362095 Test Step 3480 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:51.362152 Test Step 3480 \"loss\" =  7.7184196\n",
      "2018-08-30 06:26:51.408820 Training Step 3480 Finished Timing (Training: 0.911833, Test: 0.0826049) after 0.251627 seconds\n",
      "2018-08-30 06:26:51.409047 Training Step 3480 \"min loss\" =  3.6832733\n",
      "2018-08-30 06:26:51.409388 Training Step 3480 \"loss\" =  4.035742\n",
      "2018-08-30 06:26:51.614390 Test Step 3485 Finished\n",
      "2018-08-30 06:26:51.614464 Test Step 3485 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:51.614863 Test Step 3485 \"loss\" =  8.100679\n",
      "2018-08-30 06:26:51.661292 Training Step 3485 Finished Timing (Training: 0.91173, Test: 0.0826643) after 0.251711 seconds\n",
      "2018-08-30 06:26:51.661362 Training Step 3485 \"min loss\" =  3.6832733\n",
      "2018-08-30 06:26:51.661813 Training Step 3485 \"loss\" =  4.1356564\n",
      "2018-08-30 06:26:51.866890 Test Step 3490 Finished\n",
      "2018-08-30 06:26:51.866972 Test Step 3490 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:51.867028 Test Step 3490 \"loss\" =  7.5714726\n",
      "2018-08-30 06:26:51.914790 Training Step 3490 Finished Timing (Training: 0.911792, Test: 0.0825754) after 0.252782 seconds\n",
      "2018-08-30 06:26:51.914865 Training Step 3490 \"min loss\" =  3.653084\n",
      "2018-08-30 06:26:51.915240 Training Step 3490 \"loss\" =  3.824088\n",
      "2018-08-30 06:26:52.119897 Test Step 3495 Finished\n",
      "2018-08-30 06:26:52.119982 Test Step 3495 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:52.120040 Test Step 3495 \"loss\" =  7.5027475\n",
      "2018-08-30 06:26:52.166798 Training Step 3495 Finished Timing (Training: 0.911774, Test: 0.0825507) after 0.251248 seconds\n",
      "2018-08-30 06:26:52.167043 Training Step 3495 \"min loss\" =  3.653084\n",
      "2018-08-30 06:26:52.167234 Training Step 3495 \"loss\" =  4.047582\n",
      "2018-08-30 06:26:52.371924 Test Step 3500 Finished\n",
      "2018-08-30 06:26:52.371989 Test Step 3500 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:52.372522 Test Step 3500 \"loss\" =  7.5749273\n",
      "2018-08-30 06:26:52.418842 Training Step 3500 Finished Timing (Training: 0.911749, Test: 0.0825425) after 0.251302 seconds\n",
      "2018-08-30 06:26:52.418900 Training Step 3500 \"min loss\" =  3.653084\n",
      "2018-08-30 06:26:52.419428 Training Step 3500 \"loss\" =  4.1729894\n",
      "2018-08-30 06:26:52.624877 Test Step 3505 Finished\n",
      "2018-08-30 06:26:52.624964 Test Step 3505 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:52.625023 Test Step 3505 \"loss\" =  8.150758\n",
      "2018-08-30 06:26:52.671669 Training Step 3505 Finished Timing (Training: 0.913674, Test: 0.0829361) after 0.251964 seconds\n",
      "2018-08-30 06:26:52.671894 Training Step 3505 \"min loss\" =  3.5767324\n",
      "2018-08-30 06:26:52.672103 Training Step 3505 \"loss\" =  3.5767324\n",
      "2018-08-30 06:26:52.877394 Test Step 3510 Finished\n",
      "2018-08-30 06:26:52.877477 Test Step 3510 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:52.877546 Test Step 3510 \"loss\" =  7.281301\n",
      "2018-08-30 06:26:52.924224 Training Step 3510 Finished Timing (Training: 0.91204, Test: 0.0831866) after 0.251812 seconds\n",
      "2018-08-30 06:26:52.924280 Training Step 3510 \"min loss\" =  3.5767324\n",
      "2018-08-30 06:26:52.924729 Training Step 3510 \"loss\" =  4.0337844\n",
      "2018-08-30 06:26:53.138346 Test Step 3515 Finished\n",
      "2018-08-30 06:26:53.138693 Test Step 3515 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:53.138891 Test Step 3515 \"loss\" =  7.552571\n",
      "2018-08-30 06:26:53.185370 Training Step 3515 Finished Timing (Training: 0.912871, Test: 0.0818619) after 0.260393 seconds\n",
      "2018-08-30 06:26:53.185428 Training Step 3515 \"min loss\" =  3.5767324\n",
      "2018-08-30 06:26:53.185817 Training Step 3515 \"loss\" =  4.050783\n",
      "2018-08-30 06:26:53.391008 Test Step 3520 Finished\n",
      "2018-08-30 06:26:53.391252 Test Step 3520 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:53.391546 Test Step 3520 \"loss\" =  7.691133\n",
      "2018-08-30 06:26:53.437872 Training Step 3520 Finished Timing (Training: 0.912313, Test: 0.0824216) after 0.251785 seconds\n",
      "2018-08-30 06:26:53.438145 Training Step 3520 \"min loss\" =  3.5767324\n",
      "2018-08-30 06:26:53.438208 Training Step 3520 \"loss\" =  4.114525\n",
      "2018-08-30 06:26:53.643533 Test Step 3525 Finished\n",
      "2018-08-30 06:26:53.643847 Test Step 3525 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:53.644097 Test Step 3525 \"loss\" =  7.266443\n",
      "2018-08-30 06:26:53.690493 Training Step 3525 Finished Timing (Training: 0.911984, Test: 0.0824985) after 0.251877 seconds\n",
      "2018-08-30 06:26:53.690715 Training Step 3525 \"min loss\" =  3.5767324\n",
      "2018-08-30 06:26:53.690911 Training Step 3525 \"loss\" =  4.038817\n",
      "2018-08-30 06:26:53.895397 Test Step 3530 Finished\n",
      "2018-08-30 06:26:53.895479 Test Step 3530 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:53.895537 Test Step 3530 \"loss\" =  7.367354\n",
      "2018-08-30 06:26:53.942755 Training Step 3530 Finished Timing (Training: 0.91219, Test: 0.0823099) after 0.251786 seconds\n",
      "2018-08-30 06:26:53.942813 Training Step 3530 \"min loss\" =  3.5573895\n",
      "2018-08-30 06:26:53.943208 Training Step 3530 \"loss\" =  4.0511613\n",
      "2018-08-30 06:26:54.148368 Test Step 3535 Finished\n",
      "2018-08-30 06:26:54.148454 Test Step 3535 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:54.148514 Test Step 3535 \"loss\" =  7.565663\n",
      "2018-08-30 06:26:54.195294 Training Step 3535 Finished Timing (Training: 0.912115, Test: 0.0822716) after 0.251809 seconds\n",
      "2018-08-30 06:26:54.195370 Training Step 3535 \"min loss\" =  3.5573895\n",
      "2018-08-30 06:26:54.195425 Training Step 3535 \"loss\" =  4.3781266\n",
      "2018-08-30 06:26:54.400716 Test Step 3540 Finished\n",
      "2018-08-30 06:26:54.400835 Test Step 3540 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:54.401397 Test Step 3540 \"loss\" =  7.492883\n",
      "2018-08-30 06:26:54.448086 Training Step 3540 Finished Timing (Training: 0.911781, Test: 0.0824415) after 0.252054 seconds\n",
      "2018-08-30 06:26:54.448350 Training Step 3540 \"min loss\" =  3.5573895\n",
      "2018-08-30 06:26:54.448553 Training Step 3540 \"loss\" =  4.1005263\n",
      "2018-08-30 06:26:54.654569 Test Step 3545 Finished\n",
      "2018-08-30 06:26:54.654953 Test Step 3545 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:54.655159 Test Step 3545 \"loss\" =  7.340266\n",
      "2018-08-30 06:26:54.701577 Training Step 3545 Finished Timing (Training: 0.911515, Test: 0.0825825) after 0.252701 seconds\n",
      "2018-08-30 06:26:54.701652 Training Step 3545 \"min loss\" =  3.5573895\n",
      "2018-08-30 06:26:54.702028 Training Step 3545 \"loss\" =  3.845515\n",
      "2018-08-30 06:26:54.907514 Test Step 3550 Finished\n",
      "2018-08-30 06:26:54.907602 Test Step 3550 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:54.907660 Test Step 3550 \"loss\" =  7.176724\n",
      "2018-08-30 06:26:54.954508 Training Step 3550 Finished Timing (Training: 0.911552, Test: 0.0824882) after 0.252171 seconds\n",
      "2018-08-30 06:26:54.954573 Training Step 3550 \"min loss\" =  3.5573895\n",
      "2018-08-30 06:26:54.954901 Training Step 3550 \"loss\" =  4.0872817\n",
      "2018-08-30 06:26:55.160820 Test Step 3555 Finished\n",
      "2018-08-30 06:26:55.160922 Test Step 3555 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:55.160982 Test Step 3555 \"loss\" =  7.5904756\n",
      "2018-08-30 06:26:55.207799 Training Step 3555 Finished Timing (Training: 0.911758, Test: 0.0824819) after 0.252585 seconds\n",
      "2018-08-30 06:26:55.207861 Training Step 3555 \"min loss\" =  3.5573895\n",
      "2018-08-30 06:26:55.208316 Training Step 3555 \"loss\" =  3.9235213\n",
      "2018-08-30 06:26:55.413445 Test Step 3560 Finished\n",
      "2018-08-30 06:26:55.413550 Test Step 3560 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:55.413607 Test Step 3560 \"loss\" =  8.191143\n",
      "2018-08-30 06:26:55.460303 Training Step 3560 Finished Timing (Training: 0.911776, Test: 0.0823969) after 0.251729 seconds\n",
      "2018-08-30 06:26:55.460378 Training Step 3560 \"min loss\" =  3.5573895\n",
      "2018-08-30 06:26:55.460434 Training Step 3560 \"loss\" =  3.6551328\n",
      "2018-08-30 06:26:55.666073 Test Step 3565 Finished\n",
      "2018-08-30 06:26:55.666180 Test Step 3565 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:55.666676 Test Step 3565 \"loss\" =  7.914128\n",
      "2018-08-30 06:26:55.713037 Training Step 3565 Finished Timing (Training: 0.91184, Test: 0.0823478) after 0.252002 seconds\n",
      "2018-08-30 06:26:55.713099 Training Step 3565 \"min loss\" =  3.5573895\n",
      "2018-08-30 06:26:55.713548 Training Step 3565 \"loss\" =  4.1049147\n",
      "2018-08-30 06:26:55.920314 Test Step 3570 Finished\n",
      "2018-08-30 06:26:55.920390 Test Step 3570 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:55.921070 Test Step 3570 \"loss\" =  7.2735233\n",
      "2018-08-30 06:26:55.967478 Training Step 3570 Finished Timing (Training: 0.911834, Test: 0.0822802) after 0.253861 seconds\n",
      "2018-08-30 06:26:55.967540 Training Step 3570 \"min loss\" =  3.5573895\n",
      "2018-08-30 06:26:55.968124 Training Step 3570 \"loss\" =  3.8668756\n",
      "2018-08-30 06:26:56.174248 Test Step 3575 Finished\n",
      "2018-08-30 06:26:56.174353 Test Step 3575 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:56.174420 Test Step 3575 \"loss\" =  7.2782073\n",
      "2018-08-30 06:26:56.221402 Training Step 3575 Finished Timing (Training: 0.911906, Test: 0.0823437) after 0.253202 seconds\n",
      "2018-08-30 06:26:56.221467 Training Step 3575 \"min loss\" =  3.5573895\n",
      "2018-08-30 06:26:56.221529 Training Step 3575 \"loss\" =  4.1284995\n",
      "2018-08-30 06:26:56.427882 Test Step 3580 Finished\n",
      "2018-08-30 06:26:56.427955 Test Step 3580 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:56.428594 Test Step 3580 \"loss\" =  7.311677\n",
      "2018-08-30 06:26:56.474899 Training Step 3580 Finished Timing (Training: 0.911896, Test: 0.0823041) after 0.25263 seconds\n",
      "2018-08-30 06:26:56.475000 Training Step 3580 \"min loss\" =  3.5573895\n",
      "2018-08-30 06:26:56.475038 Training Step 3580 \"loss\" =  4.2757616\n",
      "2018-08-30 06:26:56.679751 Test Step 3585 Finished\n",
      "2018-08-30 06:26:56.679825 Test Step 3585 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:56.680508 Test Step 3585 \"loss\" =  7.875775\n",
      "2018-08-30 06:26:56.726758 Training Step 3585 Finished Timing (Training: 0.911932, Test: 0.0823283) after 0.251669 seconds\n",
      "2018-08-30 06:26:56.726816 Training Step 3585 \"min loss\" =  3.5573895\n",
      "2018-08-30 06:26:56.727346 Training Step 3585 \"loss\" =  3.9069157\n",
      "2018-08-30 06:26:56.932305 Test Step 3590 Finished\n",
      "2018-08-30 06:26:56.932408 Test Step 3590 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:56.932861 Test Step 3590 \"loss\" =  7.513419\n",
      "2018-08-30 06:26:56.978778 Training Step 3590 Finished Timing (Training: 0.911972, Test: 0.0823196) after 0.251359 seconds\n",
      "2018-08-30 06:26:56.978841 Training Step 3590 \"min loss\" =  3.5573895\n",
      "2018-08-30 06:26:56.978879 Training Step 3590 \"loss\" =  4.0210323\n",
      "2018-08-30 06:26:57.185206 Test Step 3595 Finished\n",
      "2018-08-30 06:26:57.185292 Test Step 3595 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:57.185784 Test Step 3595 \"loss\" =  7.23258\n",
      "2018-08-30 06:26:57.232136 Training Step 3595 Finished Timing (Training: 0.912012, Test: 0.0822739) after 0.252541 seconds\n",
      "2018-08-30 06:26:57.232196 Training Step 3595 \"min loss\" =  3.5573895\n",
      "2018-08-30 06:26:57.232236 Training Step 3595 \"loss\" =  3.8271303\n",
      "2018-08-30 06:26:57.437819 Test Step 3600 Finished\n",
      "2018-08-30 06:26:57.437898 Test Step 3600 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:57.437958 Test Step 3600 \"loss\" =  7.147863\n",
      "2018-08-30 06:26:57.485110 Training Step 3600 Finished Timing (Training: 0.9119, Test: 0.0822544) after 0.251919 seconds\n",
      "2018-08-30 06:26:57.485171 Training Step 3600 \"min loss\" =  3.5573895\n",
      "2018-08-30 06:26:57.485638 Training Step 3600 \"loss\" =  3.7777627\n",
      "2018-08-30 06:26:57.690595 Test Step 3605 Finished\n",
      "2018-08-30 06:26:57.690664 Test Step 3605 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:57.691204 Test Step 3605 \"loss\" =  7.551518\n",
      "2018-08-30 06:26:57.737317 Training Step 3605 Finished Timing (Training: 0.915517, Test: 0.0817687) after 0.25161 seconds\n",
      "2018-08-30 06:26:57.737381 Training Step 3605 \"min loss\" =  3.5573895\n",
      "2018-08-30 06:26:57.737855 Training Step 3605 \"loss\" =  3.8236\n",
      "2018-08-30 06:26:57.942224 Test Step 3610 Finished\n",
      "2018-08-30 06:26:57.942306 Test Step 3610 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:57.942359 Test Step 3610 \"loss\" =  7.616636\n",
      "2018-08-30 06:26:57.989196 Training Step 3610 Finished Timing (Training: 0.912904, Test: 0.0817559) after 0.250879 seconds\n",
      "2018-08-30 06:26:57.989273 Training Step 3610 \"min loss\" =  3.5573895\n",
      "2018-08-30 06:26:57.989315 Training Step 3610 \"loss\" =  4.042108\n",
      "2018-08-30 06:26:58.194342 Test Step 3615 Finished\n",
      "2018-08-30 06:26:58.194414 Test Step 3615 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:58.194977 Test Step 3615 \"loss\" =  7.3028536\n",
      "2018-08-30 06:26:58.241431 Training Step 3615 Finished Timing (Training: 0.913511, Test: 0.0817372) after 0.252045 seconds\n",
      "2018-08-30 06:26:58.241595 Training Step 3615 \"min loss\" =  3.5573895\n",
      "2018-08-30 06:26:58.241650 Training Step 3615 \"loss\" =  3.765842\n",
      "2018-08-30 06:26:58.447236 Test Step 3620 Finished\n",
      "2018-08-30 06:26:58.447316 Test Step 3620 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:58.447886 Test Step 3620 \"loss\" =  7.182894\n",
      "2018-08-30 06:26:58.494156 Training Step 3620 Finished Timing (Training: 0.913075, Test: 0.0816706) after 0.251763 seconds\n",
      "2018-08-30 06:26:58.494226 Training Step 3620 \"min loss\" =  3.5573895\n",
      "2018-08-30 06:26:58.494285 Training Step 3620 \"loss\" =  4.0411177\n",
      "2018-08-30 06:26:58.699573 Test Step 3625 Finished\n",
      "2018-08-30 06:26:58.700031 Test Step 3625 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:58.700254 Test Step 3625 \"loss\" =  7.2644796\n",
      "2018-08-30 06:26:58.746208 Training Step 3625 Finished Timing (Training: 0.91306, Test: 0.0819757) after 0.251858 seconds\n",
      "2018-08-30 06:26:58.746274 Training Step 3625 \"min loss\" =  3.5573895\n",
      "2018-08-30 06:26:58.746324 Training Step 3625 \"loss\" =  4.0412307\n",
      "2018-08-30 06:26:58.951819 Test Step 3630 Finished\n",
      "2018-08-30 06:26:58.952238 Test Step 3630 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:58.952467 Test Step 3630 \"loss\" =  7.781733\n",
      "2018-08-30 06:26:58.998700 Training Step 3630 Finished Timing (Training: 0.913028, Test: 0.0819759) after 0.252318 seconds\n",
      "2018-08-30 06:26:58.999056 Training Step 3630 \"min loss\" =  3.5573895\n",
      "2018-08-30 06:26:58.999274 Training Step 3630 \"loss\" =  3.9473407\n",
      "2018-08-30 06:26:59.204297 Test Step 3635 Finished\n",
      "2018-08-30 06:26:59.204721 Test Step 3635 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:59.204784 Test Step 3635 \"loss\" =  7.980612\n",
      "2018-08-30 06:26:59.251444 Training Step 3635 Finished Timing (Training: 0.912749, Test: 0.0819976) after 0.252102 seconds\n",
      "2018-08-30 06:26:59.251506 Training Step 3635 \"min loss\" =  3.5573895\n",
      "2018-08-30 06:26:59.252055 Training Step 3635 \"loss\" =  3.7096846\n",
      "2018-08-30 06:26:59.456985 Test Step 3640 Finished\n",
      "2018-08-30 06:26:59.457059 Test Step 3640 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:59.457316 Test Step 3640 \"loss\" =  7.9322014\n",
      "2018-08-30 06:26:59.503301 Training Step 3640 Finished Timing (Training: 0.912905, Test: 0.0819552) after 0.251177 seconds\n",
      "2018-08-30 06:26:59.503366 Training Step 3640 \"min loss\" =  3.5573895\n",
      "2018-08-30 06:26:59.503416 Training Step 3640 \"loss\" =  3.9234536\n",
      "2018-08-30 06:26:59.707870 Test Step 3645 Finished\n",
      "2018-08-30 06:26:59.708281 Test Step 3645 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:59.708499 Test Step 3645 \"loss\" =  7.7888374\n",
      "2018-08-30 06:26:59.754462 Training Step 3645 Finished Timing (Training: 0.913024, Test: 0.0820029) after 0.250976 seconds\n",
      "2018-08-30 06:26:59.754524 Training Step 3645 \"min loss\" =  3.5573895\n",
      "2018-08-30 06:26:59.754573 Training Step 3645 \"loss\" =  3.8006613\n",
      "2018-08-30 06:26:59.960139 Test Step 3650 Finished\n",
      "2018-08-30 06:26:59.960249 Test Step 3650 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:26:59.960327 Test Step 3650 \"loss\" =  7.679811\n",
      "2018-08-30 06:27:00.006355 Training Step 3650 Finished Timing (Training: 0.913171, Test: 0.0821731) after 0.251724 seconds\n",
      "2018-08-30 06:27:00.006417 Training Step 3650 \"min loss\" =  3.5573895\n",
      "2018-08-30 06:27:00.006476 Training Step 3650 \"loss\" =  3.9648747\n",
      "2018-08-30 06:27:00.212018 Test Step 3655 Finished\n",
      "2018-08-30 06:27:00.212443 Test Step 3655 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:00.212506 Test Step 3655 \"loss\" =  7.446306\n",
      "2018-08-30 06:27:00.259102 Training Step 3655 Finished Timing (Training: 0.913346, Test: 0.0821515) after 0.25256 seconds\n",
      "2018-08-30 06:27:00.259170 Training Step 3655 \"min loss\" =  3.5573895\n",
      "2018-08-30 06:27:00.259217 Training Step 3655 \"loss\" =  3.994187\n",
      "2018-08-30 06:27:00.464726 Test Step 3660 Finished\n",
      "2018-08-30 06:27:00.464826 Test Step 3660 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:00.464891 Test Step 3660 \"loss\" =  7.4058113\n",
      "2018-08-30 06:27:00.510916 Training Step 3660 Finished Timing (Training: 0.913473, Test: 0.0822484) after 0.251618 seconds\n",
      "2018-08-30 06:27:00.510980 Training Step 3660 \"min loss\" =  3.5573895\n",
      "2018-08-30 06:27:00.511021 Training Step 3660 \"loss\" =  4.633964\n",
      "2018-08-30 06:27:00.716900 Test Step 3665 Finished\n",
      "2018-08-30 06:27:00.716982 Test Step 3665 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:00.717038 Test Step 3665 \"loss\" =  7.1996093\n",
      "2018-08-30 06:27:00.763052 Training Step 3665 Finished Timing (Training: 0.913605, Test: 0.0823104) after 0.251956 seconds\n",
      "2018-08-30 06:27:00.763120 Training Step 3665 \"min loss\" =  3.5573895\n",
      "2018-08-30 06:27:00.763336 Training Step 3665 \"loss\" =  3.930217\n",
      "2018-08-30 06:27:00.968146 Test Step 3670 Finished\n",
      "2018-08-30 06:27:00.968230 Test Step 3670 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:00.969007 Test Step 3670 \"loss\" =  7.2650857\n",
      "2018-08-30 06:27:01.015437 Training Step 3670 Finished Timing (Training: 0.913532, Test: 0.0822591) after 0.252034 seconds\n",
      "2018-08-30 06:27:01.015499 Training Step 3670 \"min loss\" =  3.5573895\n",
      "2018-08-30 06:27:01.015562 Training Step 3670 \"loss\" =  4.08549\n",
      "2018-08-30 06:27:01.221960 Test Step 3675 Finished\n",
      "2018-08-30 06:27:01.222064 Test Step 3675 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:01.222573 Test Step 3675 \"loss\" =  7.243153\n",
      "2018-08-30 06:27:01.268981 Training Step 3675 Finished Timing (Training: 0.913561, Test: 0.082274) after 0.253352 seconds\n",
      "2018-08-30 06:27:01.269045 Training Step 3675 \"min loss\" =  3.5573895\n",
      "2018-08-30 06:27:01.269085 Training Step 3675 \"loss\" =  3.7925727\n",
      "2018-08-30 06:27:01.474175 Test Step 3680 Finished\n",
      "2018-08-30 06:27:01.474255 Test Step 3680 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:01.474303 Test Step 3680 \"loss\" =  7.7000265\n",
      "2018-08-30 06:27:01.520417 Training Step 3680 Finished Timing (Training: 0.913749, Test: 0.0822499) after 0.251279 seconds\n",
      "2018-08-30 06:27:01.520502 Training Step 3680 \"min loss\" =  3.5573895\n",
      "2018-08-30 06:27:01.521047 Training Step 3680 \"loss\" =  3.7974548\n",
      "2018-08-30 06:27:01.726715 Test Step 3685 Finished\n",
      "2018-08-30 06:27:01.726803 Test Step 3685 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:01.726865 Test Step 3685 \"loss\" =  7.475988\n",
      "2018-08-30 06:27:01.773808 Training Step 3685 Finished Timing (Training: 0.913712, Test: 0.0822381) after 0.25239 seconds\n",
      "2018-08-30 06:27:01.773894 Training Step 3685 \"min loss\" =  3.5170515\n",
      "2018-08-30 06:27:01.773971 Training Step 3685 \"loss\" =  3.7813342\n",
      "2018-08-30 06:27:01.979228 Test Step 3690 Finished\n",
      "2018-08-30 06:27:01.979320 Test Step 3690 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:01.980206 Test Step 3690 \"loss\" =  7.593839\n",
      "2018-08-30 06:27:02.026366 Training Step 3690 Finished Timing (Training: 0.913589, Test: 0.0822622) after 0.25233 seconds\n",
      "2018-08-30 06:27:02.026430 Training Step 3690 \"min loss\" =  3.5170515\n",
      "2018-08-30 06:27:02.026501 Training Step 3690 \"loss\" =  3.8960764\n",
      "2018-08-30 06:27:02.231755 Test Step 3695 Finished\n",
      "2018-08-30 06:27:02.231834 Test Step 3695 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:02.232442 Test Step 3695 \"loss\" =  7.367354\n",
      "2018-08-30 06:27:02.278880 Training Step 3695 Finished Timing (Training: 0.913607, Test: 0.0822286) after 0.252324 seconds\n",
      "2018-08-30 06:27:02.278939 Training Step 3695 \"min loss\" =  3.5170515\n",
      "2018-08-30 06:27:02.278980 Training Step 3695 \"loss\" =  3.7636492\n",
      "2018-08-30 06:27:02.483606 Test Step 3700 Finished\n",
      "2018-08-30 06:27:02.483703 Test Step 3700 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:02.484176 Test Step 3700 \"loss\" =  7.5674276\n",
      "2018-08-30 06:27:02.530702 Training Step 3700 Finished Timing (Training: 0.913603, Test: 0.0822179) after 0.251671 seconds\n",
      "2018-08-30 06:27:02.530778 Training Step 3700 \"min loss\" =  3.5170515\n",
      "2018-08-30 06:27:02.530835 Training Step 3700 \"loss\" =  3.7731497\n",
      "2018-08-30 06:27:02.736238 Test Step 3705 Finished\n",
      "2018-08-30 06:27:02.736653 Test Step 3705 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:02.736715 Test Step 3705 \"loss\" =  7.2847056\n",
      "2018-08-30 06:27:02.783133 Training Step 3705 Finished Timing (Training: 0.91422, Test: 0.0820944) after 0.251652 seconds\n",
      "2018-08-30 06:27:02.783198 Training Step 3705 \"min loss\" =  3.5170515\n",
      "2018-08-30 06:27:02.783766 Training Step 3705 \"loss\" =  3.9129877\n",
      "2018-08-30 06:27:02.988172 Test Step 3710 Finished\n",
      "2018-08-30 06:27:02.988260 Test Step 3710 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:02.988881 Test Step 3710 \"loss\" =  7.650701\n",
      "2018-08-30 06:27:03.035116 Training Step 3710 Finished Timing (Training: 0.913135, Test: 0.0820742) after 0.251284 seconds\n",
      "2018-08-30 06:27:03.035184 Training Step 3710 \"min loss\" =  3.5170515\n",
      "2018-08-30 06:27:03.035570 Training Step 3710 \"loss\" =  3.9952009\n",
      "2018-08-30 06:27:03.241654 Test Step 3715 Finished\n",
      "2018-08-30 06:27:03.242052 Test Step 3715 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:03.242381 Test Step 3715 \"loss\" =  7.204898\n",
      "2018-08-30 06:27:03.288730 Training Step 3715 Finished Timing (Training: 0.912788, Test: 0.0819053) after 0.252812 seconds\n",
      "2018-08-30 06:27:03.288801 Training Step 3715 \"min loss\" =  3.5170515\n",
      "2018-08-30 06:27:03.289196 Training Step 3715 \"loss\" =  4.02032\n",
      "2018-08-30 06:27:03.494416 Test Step 3720 Finished\n",
      "2018-08-30 06:27:03.494499 Test Step 3720 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:03.494983 Test Step 3720 \"loss\" =  7.2073755\n",
      "2018-08-30 06:27:03.541512 Training Step 3720 Finished Timing (Training: 0.912167, Test: 0.0820431) after 0.251945 seconds\n",
      "2018-08-30 06:27:03.541593 Training Step 3720 \"min loss\" =  3.5170515\n",
      "2018-08-30 06:27:03.541652 Training Step 3720 \"loss\" =  3.8235977\n",
      "2018-08-30 06:27:03.747116 Test Step 3725 Finished\n",
      "2018-08-30 06:27:03.747196 Test Step 3725 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:03.747681 Test Step 3725 \"loss\" =  7.138533\n",
      "2018-08-30 06:27:03.794377 Training Step 3725 Finished Timing (Training: 0.911718, Test: 0.0822831) after 0.252067 seconds\n",
      "2018-08-30 06:27:03.794588 Training Step 3725 \"min loss\" =  3.5170515\n",
      "2018-08-30 06:27:03.794840 Training Step 3725 \"loss\" =  3.7063582\n",
      "2018-08-30 06:27:04.008223 Test Step 3730 Finished\n",
      "2018-08-30 06:27:04.008429 Test Step 3730 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:04.008968 Test Step 3730 \"loss\" =  7.4891663\n",
      "2018-08-30 06:27:04.055502 Training Step 3730 Finished Timing (Training: 0.912055, Test: 0.0818794) after 0.260326 seconds\n",
      "2018-08-30 06:27:04.055568 Training Step 3730 \"min loss\" =  3.452053\n",
      "2018-08-30 06:27:04.055624 Training Step 3730 \"loss\" =  3.9766319\n",
      "2018-08-30 06:27:04.262094 Test Step 3735 Finished\n",
      "2018-08-30 06:27:04.262173 Test Step 3735 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:04.262232 Test Step 3735 \"loss\" =  7.440629\n",
      "2018-08-30 06:27:04.309041 Training Step 3735 Finished Timing (Training: 0.912197, Test: 0.0819915) after 0.252674 seconds\n",
      "2018-08-30 06:27:04.309111 Training Step 3735 \"min loss\" =  3.452053\n",
      "2018-08-30 06:27:04.309708 Training Step 3735 \"loss\" =  4.0338163\n",
      "2018-08-30 06:27:04.514514 Test Step 3740 Finished\n",
      "2018-08-30 06:27:04.514613 Test Step 3740 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:04.514694 Test Step 3740 \"loss\" =  7.211987\n",
      "2018-08-30 06:27:04.561613 Training Step 3740 Finished Timing (Training: 0.912421, Test: 0.0819977) after 0.25183 seconds\n",
      "2018-08-30 06:27:04.561673 Training Step 3740 \"min loss\" =  3.452053\n",
      "2018-08-30 06:27:04.562162 Training Step 3740 \"loss\" =  3.7607384\n",
      "2018-08-30 06:27:04.774219 Test Step 3745 Finished\n",
      "2018-08-30 06:27:04.774336 Test Step 3745 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:04.774950 Test Step 3745 \"loss\" =  7.20603\n",
      "2018-08-30 06:27:04.821538 Training Step 3745 Finished Timing (Training: 0.912432, Test: 0.0818604) after 0.258987 seconds\n",
      "2018-08-30 06:27:04.821707 Training Step 3745 \"min loss\" =  3.452053\n",
      "2018-08-30 06:27:04.821765 Training Step 3745 \"loss\" =  3.6860476\n",
      "2018-08-30 06:27:05.028289 Test Step 3750 Finished\n",
      "2018-08-30 06:27:05.028386 Test Step 3750 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:05.029128 Test Step 3750 \"loss\" =  7.0142217\n",
      "2018-08-30 06:27:05.075590 Training Step 3750 Finished Timing (Training: 0.912245, Test: 0.0820552) after 0.253764 seconds\n",
      "2018-08-30 06:27:05.075654 Training Step 3750 \"min loss\" =  3.452053\n",
      "2018-08-30 06:27:05.076056 Training Step 3750 \"loss\" =  3.8943124\n",
      "2018-08-30 06:27:05.282025 Test Step 3755 Finished\n",
      "2018-08-30 06:27:05.282136 Test Step 3755 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:05.282602 Test Step 3755 \"loss\" =  7.3217483\n",
      "2018-08-30 06:27:05.329552 Training Step 3755 Finished Timing (Training: 0.912119, Test: 0.0821305) after 0.253036 seconds\n",
      "2018-08-30 06:27:05.329647 Training Step 3755 \"min loss\" =  3.452053\n",
      "2018-08-30 06:27:05.329742 Training Step 3755 \"loss\" =  3.8412697\n",
      "2018-08-30 06:27:05.535679 Test Step 3760 Finished\n",
      "2018-08-30 06:27:05.535793 Test Step 3760 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:05.536374 Test Step 3760 \"loss\" =  7.6290436\n",
      "2018-08-30 06:27:05.582895 Training Step 3760 Finished Timing (Training: 0.912217, Test: 0.0821504) after 0.253039 seconds\n",
      "2018-08-30 06:27:05.583194 Training Step 3760 \"min loss\" =  3.452053\n",
      "2018-08-30 06:27:05.583262 Training Step 3760 \"loss\" =  3.8359733\n",
      "2018-08-30 06:27:05.788730 Test Step 3765 Finished\n",
      "2018-08-30 06:27:05.788839 Test Step 3765 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:05.788902 Test Step 3765 \"loss\" =  7.41736\n",
      "2018-08-30 06:27:05.835214 Training Step 3765 Finished Timing (Training: 0.912398, Test: 0.0821904) after 0.251891 seconds\n",
      "2018-08-30 06:27:05.835279 Training Step 3765 \"min loss\" =  3.408145\n",
      "2018-08-30 06:27:05.835339 Training Step 3765 \"loss\" =  3.408145\n",
      "2018-08-30 06:27:06.039937 Test Step 3770 Finished\n",
      "2018-08-30 06:27:06.040038 Test Step 3770 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:06.040101 Test Step 3770 \"loss\" =  7.072359\n",
      "2018-08-30 06:27:06.086835 Training Step 3770 Finished Timing (Training: 0.912645, Test: 0.0822045) after 0.251433 seconds\n",
      "2018-08-30 06:27:06.086900 Training Step 3770 \"min loss\" =  3.408145\n",
      "2018-08-30 06:27:06.086963 Training Step 3770 \"loss\" =  3.8608959\n",
      "2018-08-30 06:27:06.292666 Test Step 3775 Finished\n",
      "2018-08-30 06:27:06.292783 Test Step 3775 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:06.292846 Test Step 3775 \"loss\" =  7.1383705\n",
      "2018-08-30 06:27:06.339340 Training Step 3775 Finished Timing (Training: 0.912858, Test: 0.0822085) after 0.252295 seconds\n",
      "2018-08-30 06:27:06.339399 Training Step 3775 \"min loss\" =  3.408145\n",
      "2018-08-30 06:27:06.339456 Training Step 3775 \"loss\" =  3.4352179\n",
      "2018-08-30 06:27:06.543312 Test Step 3780 Finished\n",
      "2018-08-30 06:27:06.543399 Test Step 3780 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:06.543458 Test Step 3780 \"loss\" =  7.3326254\n",
      "2018-08-30 06:27:06.589811 Training Step 3780 Finished Timing (Training: 0.912859, Test: 0.0822505) after 0.249631 seconds\n",
      "2018-08-30 06:27:06.589887 Training Step 3780 \"min loss\" =  3.408145\n",
      "2018-08-30 06:27:06.589954 Training Step 3780 \"loss\" =  3.692028\n",
      "2018-08-30 06:27:06.794403 Test Step 3785 Finished\n",
      "2018-08-30 06:27:06.794877 Test Step 3785 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:06.794938 Test Step 3785 \"loss\" =  7.2371454\n",
      "2018-08-30 06:27:06.841694 Training Step 3785 Finished Timing (Training: 0.91298, Test: 0.0822256) after 0.251683 seconds\n",
      "2018-08-30 06:27:06.841960 Training Step 3785 \"min loss\" =  3.408145\n",
      "2018-08-30 06:27:06.842024 Training Step 3785 \"loss\" =  3.70093\n",
      "2018-08-30 06:27:07.045570 Test Step 3790 Finished\n",
      "2018-08-30 06:27:07.045663 Test Step 3790 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:07.045721 Test Step 3790 \"loss\" =  7.263669\n",
      "2018-08-30 06:27:07.092197 Training Step 3790 Finished Timing (Training: 0.912789, Test: 0.0822483) after 0.249569 seconds\n",
      "2018-08-30 06:27:07.092256 Training Step 3790 \"min loss\" =  3.408145\n",
      "2018-08-30 06:27:07.092297 Training Step 3790 \"loss\" =  3.7339585\n",
      "2018-08-30 06:27:07.296512 Test Step 3795 Finished\n",
      "2018-08-30 06:27:07.296614 Test Step 3795 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:07.296674 Test Step 3795 \"loss\" =  6.931908\n",
      "2018-08-30 06:27:07.343421 Training Step 3795 Finished Timing (Training: 0.912815, Test: 0.0822797) after 0.251064 seconds\n",
      "2018-08-30 06:27:07.343690 Training Step 3795 \"min loss\" =  3.408145\n",
      "2018-08-30 06:27:07.343753 Training Step 3795 \"loss\" =  3.735312\n",
      "2018-08-30 06:27:07.547779 Test Step 3800 Finished\n",
      "2018-08-30 06:27:07.547884 Test Step 3800 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:07.547959 Test Step 3800 \"loss\" =  7.0442333\n",
      "2018-08-30 06:27:07.594419 Training Step 3800 Finished Timing (Training: 0.912826, Test: 0.0822902) after 0.250132 seconds\n",
      "2018-08-30 06:27:07.594481 Training Step 3800 \"min loss\" =  3.408145\n",
      "2018-08-30 06:27:07.594894 Training Step 3800 \"loss\" =  4.146565\n",
      "2018-08-30 06:27:07.799804 Test Step 3805 Finished\n",
      "2018-08-30 06:27:07.800118 Test Step 3805 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:07.800428 Test Step 3805 \"loss\" =  7.345084\n",
      "2018-08-30 06:27:07.846458 Training Step 3805 Finished Timing (Training: 0.913728, Test: 0.0824915) after 0.25125 seconds\n",
      "2018-08-30 06:27:07.846525 Training Step 3805 \"min loss\" =  3.408145\n",
      "2018-08-30 06:27:07.846891 Training Step 3805 \"loss\" =  3.9776938\n",
      "2018-08-30 06:27:08.050916 Test Step 3810 Finished\n",
      "2018-08-30 06:27:08.051171 Test Step 3810 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:08.051450 Test Step 3810 \"loss\" =  7.75647\n",
      "2018-08-30 06:27:08.097602 Training Step 3810 Finished Timing (Training: 0.912381, Test: 0.0825331) after 0.250397 seconds\n",
      "2018-08-30 06:27:08.097697 Training Step 3810 \"min loss\" =  3.408145\n",
      "2018-08-30 06:27:08.098064 Training Step 3810 \"loss\" =  4.1280074\n",
      "2018-08-30 06:27:08.302702 Test Step 3815 Finished\n",
      "2018-08-30 06:27:08.302806 Test Step 3815 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:08.303434 Test Step 3815 \"loss\" =  7.347485\n",
      "2018-08-30 06:27:08.349611 Training Step 3815 Finished Timing (Training: 0.91194, Test: 0.0822885) after 0.25123 seconds\n",
      "2018-08-30 06:27:08.349731 Training Step 3815 \"min loss\" =  3.408145\n",
      "2018-08-30 06:27:08.350069 Training Step 3815 \"loss\" =  3.6057203\n",
      "2018-08-30 06:27:08.553919 Test Step 3820 Finished\n",
      "2018-08-30 06:27:08.554270 Test Step 3820 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:08.554486 Test Step 3820 \"loss\" =  7.1959105\n",
      "2018-08-30 06:27:08.600611 Training Step 3820 Finished Timing (Training: 0.911666, Test: 0.0823109) after 0.250232 seconds\n",
      "2018-08-30 06:27:08.600692 Training Step 3820 \"min loss\" =  3.408145\n",
      "2018-08-30 06:27:08.601062 Training Step 3820 \"loss\" =  3.7736557\n",
      "2018-08-30 06:27:08.805042 Test Step 3825 Finished\n",
      "2018-08-30 06:27:08.805322 Test Step 3825 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:08.805616 Test Step 3825 \"loss\" =  7.7443743\n",
      "2018-08-30 06:27:08.852040 Training Step 3825 Finished Timing (Training: 0.911444, Test: 0.0823928) after 0.250656 seconds\n",
      "2018-08-30 06:27:08.852305 Training Step 3825 \"min loss\" =  3.408145\n",
      "2018-08-30 06:27:08.852508 Training Step 3825 \"loss\" =  3.4639108\n",
      "2018-08-30 06:27:09.056841 Test Step 3830 Finished\n",
      "2018-08-30 06:27:09.057122 Test Step 3830 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:09.057418 Test Step 3830 \"loss\" =  7.6406026\n",
      "2018-08-30 06:27:09.103220 Training Step 3830 Finished Timing (Training: 0.911372, Test: 0.0823006) after 0.250295 seconds\n",
      "2018-08-30 06:27:09.103294 Training Step 3830 \"min loss\" =  3.408145\n",
      "2018-08-30 06:27:09.103349 Training Step 3830 \"loss\" =  4.0893955\n",
      "2018-08-30 06:27:09.307393 Test Step 3835 Finished\n",
      "2018-08-30 06:27:09.307630 Test Step 3835 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:09.307906 Test Step 3835 \"loss\" =  7.5070744\n",
      "2018-08-30 06:27:09.353951 Training Step 3835 Finished Timing (Training: 0.911446, Test: 0.0822384) after 0.249995 seconds\n",
      "2018-08-30 06:27:09.354014 Training Step 3835 \"min loss\" =  3.408145\n",
      "2018-08-30 06:27:09.354363 Training Step 3835 \"loss\" =  3.8622792\n",
      "2018-08-30 06:27:09.558221 Test Step 3840 Finished\n",
      "2018-08-30 06:27:09.558299 Test Step 3840 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:09.558731 Test Step 3840 \"loss\" =  7.0889115\n",
      "2018-08-30 06:27:09.605088 Training Step 3840 Finished Timing (Training: 0.91132, Test: 0.0823438) after 0.250361 seconds\n",
      "2018-08-30 06:27:09.605320 Training Step 3840 \"min loss\" =  3.408145\n",
      "2018-08-30 06:27:09.605582 Training Step 3840 \"loss\" =  3.691372\n",
      "2018-08-30 06:27:09.817538 Test Step 3845 Finished\n",
      "2018-08-30 06:27:09.817769 Test Step 3845 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:09.818048 Test Step 3845 \"loss\" =  7.5393453\n",
      "2018-08-30 06:27:09.864432 Training Step 3845 Finished Timing (Training: 0.911672, Test: 0.0819964) after 0.258543 seconds\n",
      "2018-08-30 06:27:09.864645 Training Step 3845 \"min loss\" =  3.408145\n",
      "2018-08-30 06:27:09.864934 Training Step 3845 \"loss\" =  3.5119967\n",
      "2018-08-30 06:27:10.068822 Test Step 3850 Finished\n",
      "2018-08-30 06:27:10.068900 Test Step 3850 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:10.069353 Test Step 3850 \"loss\" =  8.010498\n",
      "2018-08-30 06:27:10.115470 Training Step 3850 Finished Timing (Training: 0.911595, Test: 0.082016) after 0.250158 seconds\n",
      "2018-08-30 06:27:10.115614 Training Step 3850 \"min loss\" =  3.408145\n",
      "2018-08-30 06:27:10.116068 Training Step 3850 \"loss\" =  3.5300057\n",
      "2018-08-30 06:27:10.320581 Test Step 3855 Finished\n",
      "2018-08-30 06:27:10.320735 Test Step 3855 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:10.320834 Test Step 3855 \"loss\" =  7.5341525\n",
      "2018-08-30 06:27:10.367560 Training Step 3855 Finished Timing (Training: 0.911508, Test: 0.082085) after 0.25143 seconds\n",
      "2018-08-30 06:27:10.367629 Training Step 3855 \"min loss\" =  3.408145\n",
      "2018-08-30 06:27:10.367988 Training Step 3855 \"loss\" =  3.6307044\n",
      "2018-08-30 06:27:10.572305 Test Step 3860 Finished\n",
      "2018-08-30 06:27:10.572440 Test Step 3860 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:10.573088 Test Step 3860 \"loss\" =  7.3633013\n",
      "2018-08-30 06:27:10.619070 Training Step 3860 Finished Timing (Training: 0.911385, Test: 0.0822019) after 0.250755 seconds\n",
      "2018-08-30 06:27:10.619140 Training Step 3860 \"min loss\" =  3.4080377\n",
      "2018-08-30 06:27:10.619230 Training Step 3860 \"loss\" =  3.7478762\n",
      "2018-08-30 06:27:10.822473 Test Step 3865 Finished\n",
      "2018-08-30 06:27:10.822567 Test Step 3865 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:10.822644 Test Step 3865 \"loss\" =  7.579515\n",
      "2018-08-30 06:27:10.869265 Training Step 3865 Finished Timing (Training: 0.911763, Test: 0.0821704) after 0.249978 seconds\n",
      "2018-08-30 06:27:10.869338 Training Step 3865 \"min loss\" =  3.4080377\n",
      "2018-08-30 06:27:10.869414 Training Step 3865 \"loss\" =  3.6217477\n",
      "2018-08-30 06:27:11.073862 Test Step 3870 Finished\n",
      "2018-08-30 06:27:11.073947 Test Step 3870 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:11.074026 Test Step 3870 \"loss\" =  7.8465405\n",
      "2018-08-30 06:27:11.119722 Training Step 3870 Finished Timing (Training: 0.912007, Test: 0.0822249) after 0.250247 seconds\n",
      "2018-08-30 06:27:11.120039 Training Step 3870 \"min loss\" =  3.4080377\n",
      "2018-08-30 06:27:11.120101 Training Step 3870 \"loss\" =  3.760442\n",
      "2018-08-30 06:27:11.323529 Test Step 3875 Finished\n",
      "2018-08-30 06:27:11.323985 Test Step 3875 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:11.324055 Test Step 3875 \"loss\" =  7.291279\n",
      "2018-08-30 06:27:11.370119 Training Step 3875 Finished Timing (Training: 0.91199, Test: 0.0822087) after 0.249955 seconds\n",
      "2018-08-30 06:27:11.370180 Training Step 3875 \"min loss\" =  3.3350635\n",
      "2018-08-30 06:27:11.370710 Training Step 3875 \"loss\" =  3.4560814\n",
      "2018-08-30 06:27:11.573888 Test Step 3880 Finished\n",
      "2018-08-30 06:27:11.573989 Test Step 3880 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:11.574049 Test Step 3880 \"loss\" =  7.508138\n",
      "2018-08-30 06:27:11.620535 Training Step 3880 Finished Timing (Training: 0.912043, Test: 0.0822045) after 0.249402 seconds\n",
      "2018-08-30 06:27:11.620762 Training Step 3880 \"min loss\" =  3.3350635\n",
      "2018-08-30 06:27:11.620824 Training Step 3880 \"loss\" =  3.5369072\n",
      "2018-08-30 06:27:11.824507 Test Step 3885 Finished\n",
      "2018-08-30 06:27:11.824588 Test Step 3885 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:11.824628 Test Step 3885 \"loss\" =  8.010644\n",
      "2018-08-30 06:27:11.871089 Training Step 3885 Finished Timing (Training: 0.912141, Test: 0.082202) after 0.249715 seconds\n",
      "2018-08-30 06:27:11.871154 Training Step 3885 \"min loss\" =  3.3350635\n",
      "2018-08-30 06:27:11.871193 Training Step 3885 \"loss\" =  3.911287\n",
      "2018-08-30 06:27:12.075244 Test Step 3890 Finished\n",
      "2018-08-30 06:27:12.075336 Test Step 3890 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:12.075906 Test Step 3890 \"loss\" =  7.597337\n",
      "2018-08-30 06:27:12.121918 Training Step 3890 Finished Timing (Training: 0.912072, Test: 0.0821924) after 0.249804 seconds\n",
      "2018-08-30 06:27:12.121981 Training Step 3890 \"min loss\" =  3.2674775\n",
      "2018-08-30 06:27:12.122524 Training Step 3890 \"loss\" =  3.6631103\n",
      "2018-08-30 06:27:12.325626 Test Step 3895 Finished\n",
      "2018-08-30 06:27:12.325703 Test Step 3895 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:12.325760 Test Step 3895 \"loss\" =  7.2561607\n",
      "2018-08-30 06:27:12.372135 Training Step 3895 Finished Timing (Training: 0.912036, Test: 0.0821907) after 0.24954 seconds\n",
      "2018-08-30 06:27:12.372199 Training Step 3895 \"min loss\" =  3.2674775\n",
      "2018-08-30 06:27:12.372247 Training Step 3895 \"loss\" =  3.755362\n",
      "2018-08-30 06:27:12.575228 Test Step 3900 Finished\n",
      "2018-08-30 06:27:12.575323 Test Step 3900 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:12.575402 Test Step 3900 \"loss\" =  7.309195\n",
      "2018-08-30 06:27:12.621117 Training Step 3900 Finished Timing (Training: 0.912183, Test: 0.0822379) after 0.24878 seconds\n",
      "2018-08-30 06:27:12.621202 Training Step 3900 \"min loss\" =  3.2610786\n",
      "2018-08-30 06:27:12.621825 Training Step 3900 \"loss\" =  3.4012535\n",
      "2018-08-30 06:27:12.825380 Test Step 3905 Finished\n",
      "2018-08-30 06:27:12.825456 Test Step 3905 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:12.825497 Test Step 3905 \"loss\" =  7.206092\n",
      "2018-08-30 06:27:12.871804 Training Step 3905 Finished Timing (Training: 0.917562, Test: 0.0816176) after 0.249909 seconds\n",
      "2018-08-30 06:27:12.871894 Training Step 3905 \"min loss\" =  3.2610786\n",
      "2018-08-30 06:27:12.871963 Training Step 3905 \"loss\" =  3.584414\n",
      "2018-08-30 06:27:13.075648 Test Step 3910 Finished\n",
      "2018-08-30 06:27:13.075732 Test Step 3910 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:13.075802 Test Step 3910 \"loss\" =  7.4792314\n",
      "2018-08-30 06:27:13.121539 Training Step 3910 Finished Timing (Training: 0.916542, Test: 0.0820986) after 0.249509 seconds\n",
      "2018-08-30 06:27:13.121606 Training Step 3910 \"min loss\" =  3.2610786\n",
      "2018-08-30 06:27:13.121648 Training Step 3910 \"loss\" =  3.7102096\n",
      "2018-08-30 06:27:13.325260 Test Step 3915 Finished\n",
      "2018-08-30 06:27:13.325346 Test Step 3915 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:13.325388 Test Step 3915 \"loss\" =  7.410365\n",
      "2018-08-30 06:27:13.371078 Training Step 3915 Finished Timing (Training: 0.916213, Test: 0.0823749) after 0.249378 seconds\n",
      "2018-08-30 06:27:13.371146 Training Step 3915 \"min loss\" =  3.1446595\n",
      "2018-08-30 06:27:13.371813 Training Step 3915 \"loss\" =  3.8243425\n",
      "2018-08-30 06:27:13.575574 Test Step 3920 Finished\n",
      "2018-08-30 06:27:13.575679 Test Step 3920 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:13.576166 Test Step 3920 \"loss\" =  7.5456705\n",
      "2018-08-30 06:27:13.622705 Training Step 3920 Finished Timing (Training: 0.914681, Test: 0.0822893) after 0.250818 seconds\n",
      "2018-08-30 06:27:13.622774 Training Step 3920 \"min loss\" =  3.1446595\n",
      "2018-08-30 06:27:13.623254 Training Step 3920 \"loss\" =  3.4335213\n",
      "2018-08-30 06:27:13.826464 Test Step 3925 Finished\n",
      "2018-08-30 06:27:13.826544 Test Step 3925 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:13.826584 Test Step 3925 \"loss\" =  7.346786\n",
      "2018-08-30 06:27:13.872164 Training Step 3925 Finished Timing (Training: 0.914259, Test: 0.0824255) after 0.24856 seconds\n",
      "2018-08-30 06:27:13.872251 Training Step 3925 \"min loss\" =  3.1446595\n",
      "2018-08-30 06:27:13.872299 Training Step 3925 \"loss\" =  3.5308318\n",
      "2018-08-30 06:27:14.075840 Test Step 3930 Finished\n",
      "2018-08-30 06:27:14.075943 Test Step 3930 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:14.076375 Test Step 3930 \"loss\" =  7.123308\n",
      "2018-08-30 06:27:14.122829 Training Step 3930 Finished Timing (Training: 0.914019, Test: 0.0825636) after 0.250457 seconds\n",
      "2018-08-30 06:27:14.122889 Training Step 3930 \"min loss\" =  3.1446595\n",
      "2018-08-30 06:27:14.123414 Training Step 3930 \"loss\" =  3.6745384\n",
      "2018-08-30 06:27:14.327314 Test Step 3935 Finished\n",
      "2018-08-30 06:27:14.327387 Test Step 3935 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:14.327444 Test Step 3935 \"loss\" =  7.137886\n",
      "2018-08-30 06:27:14.373263 Training Step 3935 Finished Timing (Training: 0.913894, Test: 0.0826818) after 0.249756 seconds\n",
      "2018-08-30 06:27:14.373327 Training Step 3935 \"min loss\" =  3.1446595\n",
      "2018-08-30 06:27:14.374054 Training Step 3935 \"loss\" =  3.5590186\n",
      "2018-08-30 06:27:14.577704 Test Step 3940 Finished\n",
      "2018-08-30 06:27:14.577788 Test Step 3940 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:14.578346 Test Step 3940 \"loss\" =  7.503572\n",
      "2018-08-30 06:27:14.624027 Training Step 3940 Finished Timing (Training: 0.91354, Test: 0.0826595) after 0.249906 seconds\n",
      "2018-08-30 06:27:14.624094 Training Step 3940 \"min loss\" =  3.1446595\n",
      "2018-08-30 06:27:14.624147 Training Step 3940 \"loss\" =  3.817285\n",
      "2018-08-30 06:27:14.827638 Test Step 3945 Finished\n",
      "2018-08-30 06:27:14.827716 Test Step 3945 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:14.827771 Test Step 3945 \"loss\" =  7.6093097\n",
      "2018-08-30 06:27:14.874337 Training Step 3945 Finished Timing (Training: 0.913784, Test: 0.0826603) after 0.250126 seconds\n",
      "2018-08-30 06:27:14.874398 Training Step 3945 \"min loss\" =  3.1446595\n",
      "2018-08-30 06:27:14.874456 Training Step 3945 \"loss\" =  3.4114206\n",
      "2018-08-30 06:27:15.078216 Test Step 3950 Finished\n",
      "2018-08-30 06:27:15.078329 Test Step 3950 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:15.078390 Test Step 3950 \"loss\" =  7.325452\n",
      "2018-08-30 06:27:15.125101 Training Step 3950 Finished Timing (Training: 0.913689, Test: 0.0825922) after 0.250581 seconds\n",
      "2018-08-30 06:27:15.125171 Training Step 3950 \"min loss\" =  3.1446595\n",
      "2018-08-30 06:27:15.125247 Training Step 3950 \"loss\" =  3.7735589\n",
      "2018-08-30 06:27:15.329461 Test Step 3955 Finished\n",
      "2018-08-30 06:27:15.329573 Test Step 3955 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:15.329652 Test Step 3955 \"loss\" =  7.0902653\n",
      "2018-08-30 06:27:15.376303 Training Step 3955 Finished Timing (Training: 0.913897, Test: 0.0825439) after 0.250988 seconds\n",
      "2018-08-30 06:27:15.376638 Training Step 3955 \"min loss\" =  3.1446595\n",
      "2018-08-30 06:27:15.376720 Training Step 3955 \"loss\" =  3.749544\n",
      "2018-08-30 06:27:15.581965 Test Step 3960 Finished\n",
      "2018-08-30 06:27:15.582453 Test Step 3960 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:15.582670 Test Step 3960 \"loss\" =  6.871911\n",
      "2018-08-30 06:27:15.628987 Training Step 3960 Finished Timing (Training: 0.913462, Test: 0.082561) after 0.251567 seconds\n",
      "2018-08-30 06:27:15.629065 Training Step 3960 \"min loss\" =  3.1446595\n",
      "2018-08-30 06:27:15.629482 Training Step 3960 \"loss\" =  3.7176151\n",
      "2018-08-30 06:27:15.833899 Test Step 3965 Finished\n",
      "2018-08-30 06:27:15.834193 Test Step 3965 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:15.834497 Test Step 3965 \"loss\" =  7.006718\n",
      "2018-08-30 06:27:15.880589 Training Step 3965 Finished Timing (Training: 0.913226, Test: 0.0825142) after 0.250632 seconds\n",
      "2018-08-30 06:27:15.880657 Training Step 3965 \"min loss\" =  3.1446595\n",
      "2018-08-30 06:27:15.881040 Training Step 3965 \"loss\" =  3.483742\n",
      "2018-08-30 06:27:16.084467 Test Step 3970 Finished\n",
      "2018-08-30 06:27:16.084863 Test Step 3970 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:16.084923 Test Step 3970 \"loss\" =  7.0817413\n",
      "2018-08-30 06:27:16.131021 Training Step 3970 Finished Timing (Training: 0.913072, Test: 0.0824927) after 0.249633 seconds\n",
      "2018-08-30 06:27:16.131243 Training Step 3970 \"min loss\" =  3.1446595\n",
      "2018-08-30 06:27:16.131483 Training Step 3970 \"loss\" =  3.6885004\n",
      "2018-08-30 06:27:16.336148 Test Step 3975 Finished\n",
      "2018-08-30 06:27:16.336238 Test Step 3975 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:16.336692 Test Step 3975 \"loss\" =  7.3031697\n",
      "2018-08-30 06:27:16.382727 Training Step 3975 Finished Timing (Training: 0.913065, Test: 0.0824259) after 0.251186 seconds\n",
      "2018-08-30 06:27:16.382796 Training Step 3975 \"min loss\" =  3.1446595\n",
      "2018-08-30 06:27:16.383162 Training Step 3975 \"loss\" =  3.7690437\n",
      "2018-08-30 06:27:16.586765 Test Step 3980 Finished\n",
      "2018-08-30 06:27:16.587037 Test Step 3980 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:16.587320 Test Step 3980 \"loss\" =  7.1165895\n",
      "2018-08-30 06:27:16.633442 Training Step 3980 Finished Timing (Training: 0.912952, Test: 0.0824136) after 0.249971 seconds\n",
      "2018-08-30 06:27:16.633667 Training Step 3980 \"min loss\" =  3.1446595\n",
      "2018-08-30 06:27:16.633957 Training Step 3980 \"loss\" =  3.659243\n",
      "2018-08-30 06:27:16.837944 Test Step 3985 Finished\n",
      "2018-08-30 06:27:16.838032 Test Step 3985 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:16.838088 Test Step 3985 \"loss\" =  7.371509\n",
      "2018-08-30 06:27:16.884615 Training Step 3985 Finished Timing (Training: 0.912864, Test: 0.0823873) after 0.250355 seconds\n",
      "2018-08-30 06:27:16.884692 Training Step 3985 \"min loss\" =  3.1446595\n",
      "2018-08-30 06:27:16.884746 Training Step 3985 \"loss\" =  3.8937976\n",
      "2018-08-30 06:27:17.088882 Test Step 3990 Finished\n",
      "2018-08-30 06:27:17.088959 Test Step 3990 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:17.089424 Test Step 3990 \"loss\" =  7.958459\n",
      "2018-08-30 06:27:17.135803 Training Step 3990 Finished Timing (Training: 0.912774, Test: 0.082384) after 0.250448 seconds\n",
      "2018-08-30 06:27:17.135866 Training Step 3990 \"min loss\" =  3.1446595\n",
      "2018-08-30 06:27:17.135918 Training Step 3990 \"loss\" =  3.5738814\n",
      "2018-08-30 06:27:17.339834 Test Step 3995 Finished\n",
      "2018-08-30 06:27:17.339914 Test Step 3995 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:17.340358 Test Step 3995 \"loss\" =  7.6861453\n",
      "2018-08-30 06:27:17.386572 Training Step 3995 Finished Timing (Training: 0.91272, Test: 0.0823433) after 0.249956 seconds\n",
      "2018-08-30 06:27:17.386774 Training Step 3995 \"min loss\" =  3.1446595\n",
      "2018-08-30 06:27:17.387012 Training Step 3995 \"loss\" =  3.680137\n",
      "2018-08-30 06:27:17.591270 Test Step 4000 Finished\n",
      "2018-08-30 06:27:17.591357 Test Step 4000 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:17.591827 Test Step 4000 \"loss\" =  7.569151\n",
      "2018-08-30 06:27:17.637881 Training Step 4000 Finished Timing (Training: 0.912637, Test: 0.0823468) after 0.250557 seconds\n",
      "2018-08-30 06:27:17.638189 Training Step 4000 \"min loss\" =  3.1446595\n",
      "2018-08-30 06:27:17.638461 Training Step 4000 \"loss\" =  3.6878166\n",
      "2018-08-30 06:27:17.842426 Test Step 4005 Finished\n",
      "2018-08-30 06:27:17.842571 Test Step 4005 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:17.843082 Test Step 4005 \"loss\" =  7.4344325\n",
      "2018-08-30 06:27:17.889377 Training Step 4005 Finished Timing (Training: 0.913508, Test: 0.0824798) after 0.250629 seconds\n",
      "2018-08-30 06:27:17.889445 Training Step 4005 \"min loss\" =  3.1446595\n",
      "2018-08-30 06:27:17.889908 Training Step 4005 \"loss\" =  4.109991\n",
      "2018-08-30 06:27:18.093838 Test Step 4010 Finished\n",
      "2018-08-30 06:27:18.093970 Test Step 4010 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:18.094054 Test Step 4010 \"loss\" =  7.43105\n",
      "2018-08-30 06:27:18.140647 Training Step 4010 Finished Timing (Training: 0.913609, Test: 0.0820281) after 0.250394 seconds\n",
      "2018-08-30 06:27:18.140735 Training Step 4010 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:18.140784 Training Step 4010 \"loss\" =  3.1283975\n",
      "2018-08-30 06:27:18.344955 Test Step 4015 Finished\n",
      "2018-08-30 06:27:18.345050 Test Step 4015 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:18.345113 Test Step 4015 \"loss\" =  7.701042\n",
      "2018-08-30 06:27:18.391196 Training Step 4015 Finished Timing (Training: 0.914029, Test: 0.0824583) after 0.250347 seconds\n",
      "2018-08-30 06:27:18.391298 Training Step 4015 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:18.391356 Training Step 4015 \"loss\" =  3.6299381\n",
      "2018-08-30 06:27:18.595793 Test Step 4020 Finished\n",
      "2018-08-30 06:27:18.595899 Test Step 4020 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:18.595959 Test Step 4020 \"loss\" =  7.6593866\n",
      "2018-08-30 06:27:18.642018 Training Step 4020 Finished Timing (Training: 0.914455, Test: 0.0824255) after 0.250599 seconds\n",
      "2018-08-30 06:27:18.642085 Training Step 4020 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:18.642143 Training Step 4020 \"loss\" =  3.7078807\n",
      "2018-08-30 06:27:18.846310 Test Step 4025 Finished\n",
      "2018-08-30 06:27:18.846689 Test Step 4025 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:18.846750 Test Step 4025 \"loss\" =  7.539243\n",
      "2018-08-30 06:27:18.892932 Training Step 4025 Finished Timing (Training: 0.914544, Test: 0.0823933) after 0.250725 seconds\n",
      "2018-08-30 06:27:18.892993 Training Step 4025 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:18.893479 Training Step 4025 \"loss\" =  3.5424285\n",
      "2018-08-30 06:27:19.097606 Test Step 4030 Finished\n",
      "2018-08-30 06:27:19.098068 Test Step 4030 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:19.098370 Test Step 4030 \"loss\" =  7.212006\n",
      "2018-08-30 06:27:19.144275 Training Step 4030 Finished Timing (Training: 0.91411, Test: 0.0823599) after 0.250719 seconds\n",
      "2018-08-30 06:27:19.144459 Training Step 4030 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:19.144539 Training Step 4030 \"loss\" =  3.4986227\n",
      "2018-08-30 06:27:19.349799 Test Step 4035 Finished\n",
      "2018-08-30 06:27:19.350160 Test Step 4035 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:19.350223 Test Step 4035 \"loss\" =  7.5704813\n",
      "2018-08-30 06:27:19.396535 Training Step 4035 Finished Timing (Training: 0.91398, Test: 0.0825132) after 0.25193 seconds\n",
      "2018-08-30 06:27:19.396881 Training Step 4035 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:19.397248 Training Step 4035 \"loss\" =  3.90248\n",
      "2018-08-30 06:27:19.601613 Test Step 4040 Finished\n",
      "2018-08-30 06:27:19.602027 Test Step 4040 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:19.602090 Test Step 4040 \"loss\" =  7.6419296\n",
      "2018-08-30 06:27:19.648270 Training Step 4040 Finished Timing (Training: 0.913494, Test: 0.0825291) after 0.250948 seconds\n",
      "2018-08-30 06:27:19.648340 Training Step 4040 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:19.648397 Training Step 4040 \"loss\" =  3.576581\n",
      "2018-08-30 06:27:19.852277 Test Step 4045 Finished\n",
      "2018-08-30 06:27:19.852698 Test Step 4045 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:19.852965 Test Step 4045 \"loss\" =  7.768464\n",
      "2018-08-30 06:27:19.899058 Training Step 4045 Finished Timing (Training: 0.913355, Test: 0.0825548) after 0.250596 seconds\n",
      "2018-08-30 06:27:19.899124 Training Step 4045 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:19.899179 Training Step 4045 \"loss\" =  3.7308192\n",
      "2018-08-30 06:27:20.103099 Test Step 4050 Finished\n",
      "2018-08-30 06:27:20.103235 Test Step 4050 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:20.103308 Test Step 4050 \"loss\" =  7.505379\n",
      "2018-08-30 06:27:20.149292 Training Step 4050 Finished Timing (Training: 0.913583, Test: 0.0825465) after 0.250051 seconds\n",
      "2018-08-30 06:27:20.149356 Training Step 4050 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:20.149828 Training Step 4050 \"loss\" =  3.5727775\n",
      "2018-08-30 06:27:20.372550 Test Step 4055 Finished\n",
      "2018-08-30 06:27:20.372688 Test Step 4055 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:20.373336 Test Step 4055 \"loss\" =  7.7471766\n",
      "2018-08-30 06:27:20.419509 Training Step 4055 Finished Timing (Training: 0.913827, Test: 0.0820032) after 0.269218 seconds\n",
      "2018-08-30 06:27:20.419570 Training Step 4055 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:20.419622 Training Step 4055 \"loss\" =  3.5687854\n",
      "2018-08-30 06:27:20.624569 Test Step 4060 Finished\n",
      "2018-08-30 06:27:20.624758 Test Step 4060 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:20.624880 Test Step 4060 \"loss\" =  7.798974\n",
      "2018-08-30 06:27:20.671802 Training Step 4060 Finished Timing (Training: 0.913622, Test: 0.082058) after 0.252122 seconds\n",
      "2018-08-30 06:27:20.671866 Training Step 4060 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:20.672313 Training Step 4060 \"loss\" =  3.3402224\n",
      "2018-08-30 06:27:20.876184 Test Step 4065 Finished\n",
      "2018-08-30 06:27:20.876592 Test Step 4065 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:20.876811 Test Step 4065 \"loss\" =  7.363336\n",
      "2018-08-30 06:27:20.922641 Training Step 4065 Finished Timing (Training: 0.913537, Test: 0.0820806) after 0.250263 seconds\n",
      "2018-08-30 06:27:20.922721 Training Step 4065 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:20.922797 Training Step 4065 \"loss\" =  3.708378\n",
      "2018-08-30 06:27:21.128008 Test Step 4070 Finished\n",
      "2018-08-30 06:27:21.128141 Test Step 4070 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:21.128221 Test Step 4070 \"loss\" =  7.7025595\n",
      "2018-08-30 06:27:21.175185 Training Step 4070 Finished Timing (Training: 0.91339, Test: 0.0821223) after 0.252295 seconds\n",
      "2018-08-30 06:27:21.175325 Training Step 4070 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:21.175394 Training Step 4070 \"loss\" =  3.72488\n",
      "2018-08-30 06:27:21.379464 Test Step 4075 Finished\n",
      "2018-08-30 06:27:21.379598 Test Step 4075 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:21.380107 Test Step 4075 \"loss\" =  7.5687838\n",
      "2018-08-30 06:27:21.426125 Training Step 4075 Finished Timing (Training: 0.913414, Test: 0.0821243) after 0.25066 seconds\n",
      "2018-08-30 06:27:21.426194 Training Step 4075 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:21.426253 Training Step 4075 \"loss\" =  3.6455214\n",
      "2018-08-30 06:27:21.630470 Test Step 4080 Finished\n",
      "2018-08-30 06:27:21.630557 Test Step 4080 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:21.630628 Test Step 4080 \"loss\" =  7.7719345\n",
      "2018-08-30 06:27:21.676498 Training Step 4080 Finished Timing (Training: 0.913361, Test: 0.0821696) after 0.249465 seconds\n",
      "2018-08-30 06:27:21.676593 Training Step 4080 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:21.676654 Training Step 4080 \"loss\" =  3.4228446\n",
      "2018-08-30 06:27:21.880943 Test Step 4085 Finished\n",
      "2018-08-30 06:27:21.881031 Test Step 4085 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:21.881087 Test Step 4085 \"loss\" =  7.2669344\n",
      "2018-08-30 06:27:21.927525 Training Step 4085 Finished Timing (Training: 0.913518, Test: 0.0821678) after 0.250806 seconds\n",
      "2018-08-30 06:27:21.927594 Training Step 4085 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:21.928072 Training Step 4085 \"loss\" =  3.7301018\n",
      "2018-08-30 06:27:22.131508 Test Step 4090 Finished\n",
      "2018-08-30 06:27:22.131948 Test Step 4090 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:22.132026 Test Step 4090 \"loss\" =  7.8251734\n",
      "2018-08-30 06:27:22.178373 Training Step 4090 Finished Timing (Training: 0.913381, Test: 0.0821714) after 0.250232 seconds\n",
      "2018-08-30 06:27:22.178446 Training Step 4090 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:22.178505 Training Step 4090 \"loss\" =  3.6320107\n",
      "2018-08-30 06:27:22.382592 Test Step 4095 Finished\n",
      "2018-08-30 06:27:22.382672 Test Step 4095 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:22.382740 Test Step 4095 \"loss\" =  7.426856\n",
      "2018-08-30 06:27:22.429006 Training Step 4095 Finished Timing (Training: 0.913506, Test: 0.0821911) after 0.250435 seconds\n",
      "2018-08-30 06:27:22.429077 Training Step 4095 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:22.429135 Training Step 4095 \"loss\" =  3.2033923\n",
      "2018-08-30 06:27:22.634341 Test Step 4100 Finished\n",
      "2018-08-30 06:27:22.634427 Test Step 4100 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:22.634486 Test Step 4100 \"loss\" =  7.3726754\n",
      "2018-08-30 06:27:22.680558 Training Step 4100 Finished Timing (Training: 0.913434, Test: 0.0822335) after 0.250566 seconds\n",
      "2018-08-30 06:27:22.680638 Training Step 4100 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:22.680702 Training Step 4100 \"loss\" =  3.7569382\n",
      "2018-08-30 06:27:22.885248 Test Step 4105 Finished\n",
      "2018-08-30 06:27:22.885372 Test Step 4105 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:22.885509 Test Step 4105 \"loss\" =  7.7727556\n",
      "2018-08-30 06:27:22.931716 Training Step 4105 Finished Timing (Training: 0.913938, Test: 0.08292) after 0.250122 seconds\n",
      "2018-08-30 06:27:22.931785 Training Step 4105 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:22.932235 Training Step 4105 \"loss\" =  3.85269\n",
      "2018-08-30 06:27:23.143581 Test Step 4110 Finished\n",
      "2018-08-30 06:27:23.144003 Test Step 4110 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:23.144068 Test Step 4110 \"loss\" =  7.3213315\n",
      "2018-08-30 06:27:23.190985 Training Step 4110 Finished Timing (Training: 0.915106, Test: 0.0810817) after 0.258669 seconds\n",
      "2018-08-30 06:27:23.191130 Training Step 4110 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:23.191719 Training Step 4110 \"loss\" =  3.7749138\n",
      "2018-08-30 06:27:23.395518 Test Step 4115 Finished\n",
      "2018-08-30 06:27:23.395597 Test Step 4115 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:23.396101 Test Step 4115 \"loss\" =  7.133328\n",
      "2018-08-30 06:27:23.442097 Training Step 4115 Finished Timing (Training: 0.913997, Test: 0.0814978) after 0.250305 seconds\n",
      "2018-08-30 06:27:23.442221 Training Step 4115 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:23.442264 Training Step 4115 \"loss\" =  3.8992317\n",
      "2018-08-30 06:27:23.646048 Test Step 4120 Finished\n",
      "2018-08-30 06:27:23.646162 Test Step 4120 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:23.646444 Test Step 4120 \"loss\" =  7.2876806\n",
      "2018-08-30 06:27:23.692095 Training Step 4120 Finished Timing (Training: 0.914186, Test: 0.0817253) after 0.249782 seconds\n",
      "2018-08-30 06:27:23.692159 Training Step 4120 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:23.692213 Training Step 4120 \"loss\" =  3.3526254\n",
      "2018-08-30 06:27:23.897098 Test Step 4125 Finished\n",
      "2018-08-30 06:27:23.897185 Test Step 4125 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:23.897298 Test Step 4125 \"loss\" =  7.4869237\n",
      "2018-08-30 06:27:23.944015 Training Step 4125 Finished Timing (Training: 0.913885, Test: 0.0818818) after 0.251742 seconds\n",
      "2018-08-30 06:27:23.944078 Training Step 4125 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:23.944138 Training Step 4125 \"loss\" =  3.2273958\n",
      "2018-08-30 06:27:24.148544 Test Step 4130 Finished\n",
      "2018-08-30 06:27:24.148941 Test Step 4130 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:24.149004 Test Step 4130 \"loss\" =  7.4443817\n",
      "2018-08-30 06:27:24.195609 Training Step 4130 Finished Timing (Training: 0.913554, Test: 0.0819643) after 0.250686 seconds\n",
      "2018-08-30 06:27:24.196019 Training Step 4130 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:24.196088 Training Step 4130 \"loss\" =  3.297682\n",
      "2018-08-30 06:27:24.400174 Test Step 4135 Finished\n",
      "2018-08-30 06:27:24.400523 Test Step 4135 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:24.400607 Test Step 4135 \"loss\" =  7.444391\n",
      "2018-08-30 06:27:24.446484 Training Step 4135 Finished Timing (Training: 0.913154, Test: 0.0820518) after 0.249797 seconds\n",
      "2018-08-30 06:27:24.446552 Training Step 4135 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:24.446608 Training Step 4135 \"loss\" =  3.7248106\n",
      "2018-08-30 06:27:24.651728 Test Step 4140 Finished\n",
      "2018-08-30 06:27:24.651853 Test Step 4140 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:24.651923 Test Step 4140 \"loss\" =  8.323812\n",
      "2018-08-30 06:27:24.698395 Training Step 4140 Finished Timing (Training: 0.913186, Test: 0.082015) after 0.250993 seconds\n",
      "2018-08-30 06:27:24.698461 Training Step 4140 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:24.698519 Training Step 4140 \"loss\" =  3.5078409\n",
      "2018-08-30 06:27:24.902646 Test Step 4145 Finished\n",
      "2018-08-30 06:27:24.902738 Test Step 4145 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:24.902798 Test Step 4145 \"loss\" =  7.549498\n",
      "2018-08-30 06:27:24.949423 Training Step 4145 Finished Timing (Training: 0.913439, Test: 0.0820878) after 0.250825 seconds\n",
      "2018-08-30 06:27:24.949561 Training Step 4145 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:24.949627 Training Step 4145 \"loss\" =  3.5640159\n",
      "2018-08-30 06:27:25.154746 Test Step 4150 Finished\n",
      "2018-08-30 06:27:25.154890 Test Step 4150 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:25.154964 Test Step 4150 \"loss\" =  7.776355\n",
      "2018-08-30 06:27:25.201589 Training Step 4150 Finished Timing (Training: 0.913666, Test: 0.0820704) after 0.251886 seconds\n",
      "2018-08-30 06:27:25.201705 Training Step 4150 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:25.201744 Training Step 4150 \"loss\" =  3.8666003\n",
      "2018-08-30 06:27:25.407006 Test Step 4155 Finished\n",
      "2018-08-30 06:27:25.407195 Test Step 4155 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:25.407285 Test Step 4155 \"loss\" =  7.563885\n",
      "2018-08-30 06:27:25.454033 Training Step 4155 Finished Timing (Training: 0.91342, Test: 0.0821829) after 0.25222 seconds\n",
      "2018-08-30 06:27:25.454095 Training Step 4155 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:25.454178 Training Step 4155 \"loss\" =  3.3721607\n",
      "2018-08-30 06:27:25.658442 Test Step 4160 Finished\n",
      "2018-08-30 06:27:25.658822 Test Step 4160 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:25.658883 Test Step 4160 \"loss\" =  8.169265\n",
      "2018-08-30 06:27:25.705286 Training Step 4160 Finished Timing (Training: 0.913334, Test: 0.0821803) after 0.250389 seconds\n",
      "2018-08-30 06:27:25.705379 Training Step 4160 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:25.705445 Training Step 4160 \"loss\" =  3.4608452\n",
      "2018-08-30 06:27:25.909048 Test Step 4165 Finished\n",
      "2018-08-30 06:27:25.909268 Test Step 4165 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:25.909328 Test Step 4165 \"loss\" =  8.394156\n",
      "2018-08-30 06:27:25.955888 Training Step 4165 Finished Timing (Training: 0.913483, Test: 0.0821921) after 0.250373 seconds\n",
      "2018-08-30 06:27:25.955952 Training Step 4165 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:25.956011 Training Step 4165 \"loss\" =  3.5155413\n",
      "2018-08-30 06:27:26.159582 Test Step 4170 Finished\n",
      "2018-08-30 06:27:26.159658 Test Step 4170 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:26.159710 Test Step 4170 \"loss\" =  8.275727\n",
      "2018-08-30 06:27:26.205399 Training Step 4170 Finished Timing (Training: 0.913673, Test: 0.0821993) after 0.249321 seconds\n",
      "2018-08-30 06:27:26.205478 Training Step 4170 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:26.206335 Training Step 4170 \"loss\" =  3.2683785\n",
      "2018-08-30 06:27:26.417631 Test Step 4175 Finished\n",
      "2018-08-30 06:27:26.417721 Test Step 4175 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:26.417783 Test Step 4175 \"loss\" =  7.3720465\n",
      "2018-08-30 06:27:26.464444 Training Step 4175 Finished Timing (Training: 0.913532, Test: 0.0819972) after 0.257741 seconds\n",
      "2018-08-30 06:27:26.464505 Training Step 4175 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:26.464557 Training Step 4175 \"loss\" =  3.514155\n",
      "2018-08-30 06:27:26.668242 Test Step 4180 Finished\n",
      "2018-08-30 06:27:26.668332 Test Step 4180 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:26.668395 Test Step 4180 \"loss\" =  7.5034695\n",
      "2018-08-30 06:27:26.714198 Training Step 4180 Finished Timing (Training: 0.913522, Test: 0.0819764) after 0.248761 seconds\n",
      "2018-08-30 06:27:26.714265 Training Step 4180 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:26.714305 Training Step 4180 \"loss\" =  3.7658584\n",
      "2018-08-30 06:27:26.917509 Test Step 4185 Finished\n",
      "2018-08-30 06:27:26.917605 Test Step 4185 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:26.917664 Test Step 4185 \"loss\" =  7.3102565\n",
      "2018-08-30 06:27:26.964107 Training Step 4185 Finished Timing (Training: 0.913673, Test: 0.0819976) after 0.249752 seconds\n",
      "2018-08-30 06:27:26.964175 Training Step 4185 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:26.964234 Training Step 4185 \"loss\" =  3.4362838\n",
      "2018-08-30 06:27:27.168925 Test Step 4190 Finished\n",
      "2018-08-30 06:27:27.169119 Test Step 4190 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:27.169266 Test Step 4190 \"loss\" =  7.6456738\n",
      "2018-08-30 06:27:27.215771 Training Step 4190 Finished Timing (Training: 0.913576, Test: 0.0820582) after 0.250841 seconds\n",
      "2018-08-30 06:27:27.215834 Training Step 4190 \"min loss\" =  3.1283975\n",
      "2018-08-30 06:27:27.215895 Training Step 4190 \"loss\" =  3.5098662\n",
      "2018-08-30 06:27:27.419364 Test Step 4195 Finished\n",
      "2018-08-30 06:27:27.419454 Test Step 4195 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:27.419514 Test Step 4195 \"loss\" =  7.451345\n",
      "2018-08-30 06:27:27.465247 Training Step 4195 Finished Timing (Training: 0.913695, Test: 0.0820758) after 0.249285 seconds\n",
      "2018-08-30 06:27:27.465331 Training Step 4195 \"min loss\" =  3.0845075\n",
      "2018-08-30 06:27:27.465389 Training Step 4195 \"loss\" =  3.1984897\n",
      "2018-08-30 06:27:27.669602 Test Step 4200 Finished\n",
      "2018-08-30 06:27:27.669691 Test Step 4200 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:27.669781 Test Step 4200 \"loss\" =  7.4140897\n",
      "2018-08-30 06:27:27.716329 Training Step 4200 Finished Timing (Training: 0.91381, Test: 0.0820766) after 0.250878 seconds\n",
      "2018-08-30 06:27:27.716618 Training Step 4200 \"min loss\" =  3.0845075\n",
      "2018-08-30 06:27:27.716686 Training Step 4200 \"loss\" =  3.5549242\n",
      "2018-08-30 06:27:27.921002 Test Step 4205 Finished\n",
      "2018-08-30 06:27:27.921102 Test Step 4205 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:27.921159 Test Step 4205 \"loss\" =  7.6330147\n",
      "2018-08-30 06:27:27.967830 Training Step 4205 Finished Timing (Training: 0.917047, Test: 0.0820396) after 0.250505 seconds\n",
      "2018-08-30 06:27:27.967898 Training Step 4205 \"min loss\" =  3.0845075\n",
      "2018-08-30 06:27:27.968396 Training Step 4205 \"loss\" =  3.7383428\n",
      "2018-08-30 06:27:28.171608 Test Step 4210 Finished\n",
      "2018-08-30 06:27:28.171708 Test Step 4210 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:28.171767 Test Step 4210 \"loss\" =  7.174022\n",
      "2018-08-30 06:27:28.217938 Training Step 4210 Finished Timing (Training: 0.915798, Test: 0.0820022) after 0.249472 seconds\n",
      "2018-08-30 06:27:28.218015 Training Step 4210 \"min loss\" =  3.0845075\n",
      "2018-08-30 06:27:28.218076 Training Step 4210 \"loss\" =  3.430881\n",
      "2018-08-30 06:27:28.422608 Test Step 4215 Finished\n",
      "2018-08-30 06:27:28.422699 Test Step 4215 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:28.422759 Test Step 4215 \"loss\" =  7.1619425\n",
      "2018-08-30 06:27:28.468970 Training Step 4215 Finished Timing (Training: 0.914834, Test: 0.0824208) after 0.250319 seconds\n",
      "2018-08-30 06:27:28.469034 Training Step 4215 \"min loss\" =  3.0845075\n",
      "2018-08-30 06:27:28.469085 Training Step 4215 \"loss\" =  3.3542569\n",
      "2018-08-30 06:27:28.672737 Test Step 4220 Finished\n",
      "2018-08-30 06:27:28.672845 Test Step 4220 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:28.673414 Test Step 4220 \"loss\" =  8.039887\n",
      "2018-08-30 06:27:28.719116 Training Step 4220 Finished Timing (Training: 0.914432, Test: 0.082562) after 0.249956 seconds\n",
      "2018-08-30 06:27:28.719174 Training Step 4220 \"min loss\" =  3.0845075\n",
      "2018-08-30 06:27:28.719256 Training Step 4220 \"loss\" =  3.3802152\n",
      "2018-08-30 06:27:28.931179 Test Step 4225 Finished\n",
      "2018-08-30 06:27:28.931263 Test Step 4225 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:28.931323 Test Step 4225 \"loss\" =  7.8472314\n",
      "2018-08-30 06:27:28.978212 Training Step 4225 Finished Timing (Training: 0.915108, Test: 0.0821621) after 0.258906 seconds\n",
      "2018-08-30 06:27:28.978274 Training Step 4225 \"min loss\" =  3.0845075\n",
      "2018-08-30 06:27:28.978743 Training Step 4225 \"loss\" =  3.4536376\n",
      "2018-08-30 06:27:29.182919 Test Step 4230 Finished\n",
      "2018-08-30 06:27:29.183006 Test Step 4230 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:29.183070 Test Step 4230 \"loss\" =  7.4717712\n",
      "2018-08-30 06:27:29.228940 Training Step 4230 Finished Timing (Training: 0.914826, Test: 0.0823263) after 0.25013 seconds\n",
      "2018-08-30 06:27:29.229007 Training Step 4230 \"min loss\" =  3.0845075\n",
      "2018-08-30 06:27:29.229056 Training Step 4230 \"loss\" =  3.3330095\n",
      "2018-08-30 06:27:29.432749 Test Step 4235 Finished\n",
      "2018-08-30 06:27:29.433145 Test Step 4235 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:29.433207 Test Step 4235 \"loss\" =  7.2452416\n",
      "2018-08-30 06:27:29.479485 Training Step 4235 Finished Timing (Training: 0.91476, Test: 0.0823779) after 0.250374 seconds\n",
      "2018-08-30 06:27:29.479546 Training Step 4235 \"min loss\" =  3.0845075\n",
      "2018-08-30 06:27:29.479942 Training Step 4235 \"loss\" =  3.4447773\n",
      "2018-08-30 06:27:29.683909 Test Step 4240 Finished\n",
      "2018-08-30 06:27:29.684238 Test Step 4240 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:29.684308 Test Step 4240 \"loss\" =  7.703275\n",
      "2018-08-30 06:27:29.730606 Training Step 4240 Finished Timing (Training: 0.914552, Test: 0.0824417) after 0.250598 seconds\n",
      "2018-08-30 06:27:29.730914 Training Step 4240 \"min loss\" =  3.0845075\n",
      "2018-08-30 06:27:29.731135 Training Step 4240 \"loss\" =  3.2566812\n",
      "2018-08-30 06:27:29.935425 Test Step 4245 Finished\n",
      "2018-08-30 06:27:29.935503 Test Step 4245 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:29.935550 Test Step 4245 \"loss\" =  7.4498944\n",
      "2018-08-30 06:27:29.982088 Training Step 4245 Finished Timing (Training: 0.914422, Test: 0.0825452) after 0.250887 seconds\n",
      "2018-08-30 06:27:29.982150 Training Step 4245 \"min loss\" =  3.0845075\n",
      "2018-08-30 06:27:29.982192 Training Step 4245 \"loss\" =  3.2409809\n",
      "2018-08-30 06:27:30.186705 Test Step 4250 Finished\n",
      "2018-08-30 06:27:30.186814 Test Step 4250 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:30.187323 Test Step 4250 \"loss\" =  7.5574036\n",
      "2018-08-30 06:27:30.233153 Training Step 4250 Finished Timing (Training: 0.914064, Test: 0.0825758) after 0.250185 seconds\n",
      "2018-08-30 06:27:30.233214 Training Step 4250 \"min loss\" =  3.0845075\n",
      "2018-08-30 06:27:30.233291 Training Step 4250 \"loss\" =  3.2729685\n",
      "2018-08-30 06:27:30.437389 Test Step 4255 Finished\n",
      "2018-08-30 06:27:30.437495 Test Step 4255 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:30.437998 Test Step 4255 \"loss\" =  7.5551434\n",
      "2018-08-30 06:27:30.484040 Training Step 4255 Finished Timing (Training: 0.914108, Test: 0.0825134) after 0.250688 seconds\n",
      "2018-08-30 06:27:30.484107 Training Step 4255 \"min loss\" =  3.0845075\n",
      "2018-08-30 06:27:30.484168 Training Step 4255 \"loss\" =  3.4144433\n",
      "2018-08-30 06:27:30.687619 Test Step 4260 Finished\n",
      "2018-08-30 06:27:30.687770 Test Step 4260 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:30.688420 Test Step 4260 \"loss\" =  7.784413\n",
      "2018-08-30 06:27:30.734277 Training Step 4260 Finished Timing (Training: 0.913979, Test: 0.08256) after 0.250025 seconds\n",
      "2018-08-30 06:27:30.734337 Training Step 4260 \"min loss\" =  3.0845075\n",
      "2018-08-30 06:27:30.734384 Training Step 4260 \"loss\" =  3.6848524\n",
      "2018-08-30 06:27:30.938297 Test Step 4265 Finished\n",
      "2018-08-30 06:27:30.938393 Test Step 4265 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:30.938962 Test Step 4265 \"loss\" =  7.500583\n",
      "2018-08-30 06:27:30.984763 Training Step 4265 Finished Timing (Training: 0.913984, Test: 0.0825331) after 0.250317 seconds\n",
      "2018-08-30 06:27:30.984827 Training Step 4265 \"min loss\" =  3.0845075\n",
      "2018-08-30 06:27:30.984895 Training Step 4265 \"loss\" =  3.7969496\n",
      "2018-08-30 06:27:31.188203 Test Step 4270 Finished\n",
      "2018-08-30 06:27:31.188311 Test Step 4270 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:31.188989 Test Step 4270 \"loss\" =  7.7923136\n",
      "2018-08-30 06:27:31.235466 Training Step 4270 Finished Timing (Training: 0.913954, Test: 0.082506) after 0.250497 seconds\n",
      "2018-08-30 06:27:31.235623 Training Step 4270 \"min loss\" =  3.0845075\n",
      "2018-08-30 06:27:31.235730 Training Step 4270 \"loss\" =  3.2878718\n",
      "2018-08-30 06:27:31.439273 Test Step 4275 Finished\n",
      "2018-08-30 06:27:31.439354 Test Step 4275 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:31.439413 Test Step 4275 \"loss\" =  7.363097\n",
      "2018-08-30 06:27:31.486047 Training Step 4275 Finished Timing (Training: 0.914052, Test: 0.0824876) after 0.250253 seconds\n",
      "2018-08-30 06:27:31.486111 Training Step 4275 \"min loss\" =  3.0845075\n",
      "2018-08-30 06:27:31.486151 Training Step 4275 \"loss\" =  3.7302744\n",
      "2018-08-30 06:27:31.689612 Test Step 4280 Finished\n",
      "2018-08-30 06:27:31.689693 Test Step 4280 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:31.689750 Test Step 4280 \"loss\" =  7.6667314\n",
      "2018-08-30 06:27:31.736287 Training Step 4280 Finished Timing (Training: 0.913987, Test: 0.082489) after 0.250079 seconds\n",
      "2018-08-30 06:27:31.736377 Training Step 4280 \"min loss\" =  3.0845075\n",
      "2018-08-30 06:27:31.736443 Training Step 4280 \"loss\" =  3.3927593\n",
      "2018-08-30 06:27:31.940134 Test Step 4285 Finished\n",
      "2018-08-30 06:27:31.940212 Test Step 4285 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:31.940827 Test Step 4285 \"loss\" =  7.3526287\n",
      "2018-08-30 06:27:31.987078 Training Step 4285 Finished Timing (Training: 0.913923, Test: 0.0825169) after 0.250553 seconds\n",
      "2018-08-30 06:27:31.987165 Training Step 4285 \"min loss\" =  3.0845075\n",
      "2018-08-30 06:27:31.987539 Training Step 4285 \"loss\" =  3.5552278\n",
      "2018-08-30 06:27:32.191088 Test Step 4290 Finished\n",
      "2018-08-30 06:27:32.191240 Test Step 4290 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:32.191304 Test Step 4290 \"loss\" =  7.1269236\n",
      "2018-08-30 06:27:32.237442 Training Step 4290 Finished Timing (Training: 0.913876, Test: 0.0825187) after 0.249585 seconds\n",
      "2018-08-30 06:27:32.237506 Training Step 4290 \"min loss\" =  3.0845075\n",
      "2018-08-30 06:27:32.237563 Training Step 4290 \"loss\" =  3.5045815\n",
      "2018-08-30 06:27:32.442358 Test Step 4295 Finished\n",
      "2018-08-30 06:27:32.442448 Test Step 4295 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:32.442530 Test Step 4295 \"loss\" =  7.4326444\n",
      "2018-08-30 06:27:32.488348 Training Step 4295 Finished Timing (Training: 0.913949, Test: 0.0825341) after 0.250712 seconds\n",
      "2018-08-30 06:27:32.488413 Training Step 4295 \"min loss\" =  3.0845075\n",
      "2018-08-30 06:27:32.488464 Training Step 4295 \"loss\" =  3.3396015\n",
      "2018-08-30 06:27:32.692809 Test Step 4300 Finished\n",
      "2018-08-30 06:27:32.692888 Test Step 4300 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:32.693437 Test Step 4300 \"loss\" =  8.088665\n",
      "2018-08-30 06:27:32.739307 Training Step 4300 Finished Timing (Training: 0.913788, Test: 0.0825536) after 0.250079 seconds\n",
      "2018-08-30 06:27:32.739586 Training Step 4300 \"min loss\" =  3.0845075\n",
      "2018-08-30 06:27:32.739649 Training Step 4300 \"loss\" =  3.3403747\n",
      "2018-08-30 06:27:32.943867 Test Step 4305 Finished\n",
      "2018-08-30 06:27:32.943948 Test Step 4305 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:32.944485 Test Step 4305 \"loss\" =  7.339827\n",
      "2018-08-30 06:27:32.990799 Training Step 4305 Finished Timing (Training: 0.913446, Test: 0.0825704) after 0.251087 seconds\n",
      "2018-08-30 06:27:32.990860 Training Step 4305 \"min loss\" =  3.0845075\n",
      "2018-08-30 06:27:32.990899 Training Step 4305 \"loss\" =  3.1707826\n",
      "2018-08-30 06:27:33.194612 Test Step 4310 Finished\n",
      "2018-08-30 06:27:33.195055 Test Step 4310 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:33.195152 Test Step 4310 \"loss\" =  7.655081\n",
      "2018-08-30 06:27:33.241144 Training Step 4310 Finished Timing (Training: 0.913704, Test: 0.0827) after 0.250195 seconds\n",
      "2018-08-30 06:27:33.241245 Training Step 4310 \"min loss\" =  3.0845075\n",
      "2018-08-30 06:27:33.241862 Training Step 4310 \"loss\" =  3.373713\n",
      "2018-08-30 06:27:33.446871 Test Step 4315 Finished\n",
      "2018-08-30 06:27:33.447284 Test Step 4315 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:33.447495 Test Step 4315 \"loss\" =  7.3420324\n",
      "2018-08-30 06:27:33.493901 Training Step 4315 Finished Timing (Training: 0.911865, Test: 0.0826472) after 0.251388 seconds\n",
      "2018-08-30 06:27:33.493963 Training Step 4315 \"min loss\" =  3.0845075\n",
      "2018-08-30 06:27:33.494382 Training Step 4315 \"loss\" =  3.49879\n",
      "2018-08-30 06:27:33.698914 Test Step 4320 Finished\n",
      "2018-08-30 06:27:33.698990 Test Step 4320 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:33.699449 Test Step 4320 \"loss\" =  8.314456\n",
      "2018-08-30 06:27:33.746117 Training Step 4320 Finished Timing (Training: 0.911578, Test: 0.0824845) after 0.251395 seconds\n",
      "2018-08-30 06:27:33.746200 Training Step 4320 \"min loss\" =  3.0845075\n",
      "2018-08-30 06:27:33.746579 Training Step 4320 \"loss\" =  3.3641005\n",
      "2018-08-30 06:27:33.951048 Test Step 4325 Finished\n",
      "2018-08-30 06:27:33.951130 Test Step 4325 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:33.951703 Test Step 4325 \"loss\" =  7.3638515\n",
      "2018-08-30 06:27:33.997569 Training Step 4325 Finished Timing (Training: 0.911222, Test: 0.0826038) after 0.250399 seconds\n",
      "2018-08-30 06:27:33.997746 Training Step 4325 \"min loss\" =  3.0845075\n",
      "2018-08-30 06:27:33.997880 Training Step 4325 \"loss\" =  3.1863363\n",
      "2018-08-30 06:27:34.202007 Test Step 4330 Finished\n",
      "2018-08-30 06:27:34.202290 Test Step 4330 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:34.202591 Test Step 4330 \"loss\" =  7.4633155\n",
      "2018-08-30 06:27:34.249024 Training Step 4330 Finished Timing (Training: 0.911046, Test: 0.0824463) after 0.250334 seconds\n",
      "2018-08-30 06:27:34.249174 Training Step 4330 \"min loss\" =  3.0845075\n",
      "2018-08-30 06:27:34.249642 Training Step 4330 \"loss\" =  3.523342\n",
      "2018-08-30 06:27:34.454242 Test Step 4335 Finished\n",
      "2018-08-30 06:27:34.454543 Test Step 4335 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:34.454638 Test Step 4335 \"loss\" =  8.220598\n",
      "2018-08-30 06:27:34.501251 Training Step 4335 Finished Timing (Training: 0.911213, Test: 0.0823882) after 0.251264 seconds\n",
      "2018-08-30 06:27:34.501317 Training Step 4335 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:34.501657 Training Step 4335 \"loss\" =  3.6716037\n",
      "2018-08-30 06:27:34.706478 Test Step 4340 Finished\n",
      "2018-08-30 06:27:34.706742 Test Step 4340 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:34.707152 Test Step 4340 \"loss\" =  8.220817\n",
      "2018-08-30 06:27:34.753298 Training Step 4340 Finished Timing (Training: 0.911001, Test: 0.0824683) after 0.251313 seconds\n",
      "2018-08-30 06:27:34.753390 Training Step 4340 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:34.753785 Training Step 4340 \"loss\" =  3.6498277\n",
      "2018-08-30 06:27:34.957802 Test Step 4345 Finished\n",
      "2018-08-30 06:27:34.957882 Test Step 4345 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:34.958327 Test Step 4345 \"loss\" =  7.9487386\n",
      "2018-08-30 06:27:35.004417 Training Step 4345 Finished Timing (Training: 0.911118, Test: 0.0824486) after 0.250299 seconds\n",
      "2018-08-30 06:27:35.004474 Training Step 4345 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:35.004836 Training Step 4345 \"loss\" =  3.4600542\n",
      "2018-08-30 06:27:35.209109 Test Step 4350 Finished\n",
      "2018-08-30 06:27:35.209536 Test Step 4350 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:35.209908 Test Step 4350 \"loss\" =  8.287335\n",
      "2018-08-30 06:27:35.255889 Training Step 4350 Finished Timing (Training: 0.911068, Test: 0.0824201) after 0.250715 seconds\n",
      "2018-08-30 06:27:35.255948 Training Step 4350 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:35.256329 Training Step 4350 \"loss\" =  3.5204716\n",
      "2018-08-30 06:27:35.460865 Test Step 4355 Finished\n",
      "2018-08-30 06:27:35.460929 Test Step 4355 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:35.460981 Test Step 4355 \"loss\" =  8.200644\n",
      "2018-08-30 06:27:35.507372 Training Step 4355 Finished Timing (Training: 0.911067, Test: 0.0824417) after 0.25071 seconds\n",
      "2018-08-30 06:27:35.507431 Training Step 4355 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:35.507757 Training Step 4355 \"loss\" =  3.308999\n",
      "2018-08-30 06:27:35.712588 Test Step 4360 Finished\n",
      "2018-08-30 06:27:35.712670 Test Step 4360 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:35.712725 Test Step 4360 \"loss\" =  8.129505\n",
      "2018-08-30 06:27:35.759135 Training Step 4360 Finished Timing (Training: 0.910968, Test: 0.0826162) after 0.251067 seconds\n",
      "2018-08-30 06:27:35.759207 Training Step 4360 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:35.759563 Training Step 4360 \"loss\" =  3.420385\n",
      "2018-08-30 06:27:35.964105 Test Step 4365 Finished\n",
      "2018-08-30 06:27:35.964199 Test Step 4365 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:35.964258 Test Step 4365 \"loss\" =  7.9815426\n",
      "2018-08-30 06:27:36.010965 Training Step 4365 Finished Timing (Training: 0.91087, Test: 0.0827124) after 0.251073 seconds\n",
      "2018-08-30 06:27:36.011183 Training Step 4365 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:36.011450 Training Step 4365 \"loss\" =  3.5533261\n",
      "2018-08-30 06:27:36.216284 Test Step 4370 Finished\n",
      "2018-08-30 06:27:36.216408 Test Step 4370 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:36.216937 Test Step 4370 \"loss\" =  7.9213986\n",
      "2018-08-30 06:27:36.263478 Training Step 4370 Finished Timing (Training: 0.91065, Test: 0.0828019) after 0.251671 seconds\n",
      "2018-08-30 06:27:36.263544 Training Step 4370 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:36.263914 Training Step 4370 \"loss\" =  3.740499\n",
      "2018-08-30 06:27:36.468551 Test Step 4375 Finished\n",
      "2018-08-30 06:27:36.468849 Test Step 4375 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:36.469162 Test Step 4375 \"loss\" =  7.865825\n",
      "2018-08-30 06:27:36.515436 Training Step 4375 Finished Timing (Training: 0.910618, Test: 0.082799) after 0.251182 seconds\n",
      "2018-08-30 06:27:36.515509 Training Step 4375 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:36.515901 Training Step 4375 \"loss\" =  3.6479406\n",
      "2018-08-30 06:27:36.719222 Test Step 4380 Finished\n",
      "2018-08-30 06:27:36.719343 Test Step 4380 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:36.719835 Test Step 4380 \"loss\" =  8.066299\n",
      "2018-08-30 06:27:36.766129 Training Step 4380 Finished Timing (Training: 0.91063, Test: 0.0827608) after 0.249895 seconds\n",
      "2018-08-30 06:27:36.766196 Training Step 4380 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:36.766566 Training Step 4380 \"loss\" =  3.3850732\n",
      "2018-08-30 06:27:36.970923 Test Step 4385 Finished\n",
      "2018-08-30 06:27:36.971064 Test Step 4385 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:36.971528 Test Step 4385 \"loss\" =  7.494441\n",
      "2018-08-30 06:27:37.017734 Training Step 4385 Finished Timing (Training: 0.910717, Test: 0.0827187) after 0.250828 seconds\n",
      "2018-08-30 06:27:37.017824 Training Step 4385 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:37.017882 Training Step 4385 \"loss\" =  3.2067666\n",
      "2018-08-30 06:27:37.222324 Test Step 4390 Finished\n",
      "2018-08-30 06:27:37.222753 Test Step 4390 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:37.222989 Test Step 4390 \"loss\" =  7.3250675\n",
      "2018-08-30 06:27:37.269117 Training Step 4390 Finished Timing (Training: 0.910651, Test: 0.0827041) after 0.250461 seconds\n",
      "2018-08-30 06:27:37.269181 Training Step 4390 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:37.269252 Training Step 4390 \"loss\" =  3.27807\n",
      "2018-08-30 06:27:37.473512 Test Step 4395 Finished\n",
      "2018-08-30 06:27:37.473675 Test Step 4395 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:37.474196 Test Step 4395 \"loss\" =  7.0444956\n",
      "2018-08-30 06:27:37.520368 Training Step 4395 Finished Timing (Training: 0.910783, Test: 0.0827177) after 0.25105 seconds\n",
      "2018-08-30 06:27:37.520428 Training Step 4395 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:37.520476 Training Step 4395 \"loss\" =  3.4399905\n",
      "2018-08-30 06:27:37.725253 Test Step 4400 Finished\n",
      "2018-08-30 06:27:37.725345 Test Step 4400 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:37.725771 Test Step 4400 \"loss\" =  7.169408\n",
      "2018-08-30 06:27:37.771876 Training Step 4400 Finished Timing (Training: 0.910701, Test: 0.0827872) after 0.250666 seconds\n",
      "2018-08-30 06:27:37.772136 Training Step 4400 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:37.772198 Training Step 4400 \"loss\" =  3.3368769\n",
      "2018-08-30 06:27:37.976723 Test Step 4405 Finished\n",
      "2018-08-30 06:27:37.976803 Test Step 4405 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:37.977234 Test Step 4405 \"loss\" =  7.861197\n",
      "2018-08-30 06:27:38.023527 Training Step 4405 Finished Timing (Training: 0.912396, Test: 0.0842522) after 0.250878 seconds\n",
      "2018-08-30 06:27:38.023602 Training Step 4405 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:38.023961 Training Step 4405 \"loss\" =  3.2365937\n",
      "2018-08-30 06:27:38.228144 Test Step 4410 Finished\n",
      "2018-08-30 06:27:38.228485 Test Step 4410 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:38.228905 Test Step 4410 \"loss\" =  7.2870893\n",
      "2018-08-30 06:27:38.274904 Training Step 4410 Finished Timing (Training: 0.9118, Test: 0.0830661) after 0.250611 seconds\n",
      "2018-08-30 06:27:38.274964 Training Step 4410 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:38.275374 Training Step 4410 \"loss\" =  3.505531\n",
      "2018-08-30 06:27:38.478755 Test Step 4415 Finished\n",
      "2018-08-30 06:27:38.478859 Test Step 4415 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:38.479314 Test Step 4415 \"loss\" =  7.935338\n",
      "2018-08-30 06:27:38.525413 Training Step 4415 Finished Timing (Training: 0.911584, Test: 0.0827949) after 0.249747 seconds\n",
      "2018-08-30 06:27:38.525494 Training Step 4415 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:38.526053 Training Step 4415 \"loss\" =  3.6838255\n",
      "2018-08-30 06:27:38.729890 Test Step 4420 Finished\n",
      "2018-08-30 06:27:38.730000 Test Step 4420 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:38.730950 Test Step 4420 \"loss\" =  7.257584\n",
      "2018-08-30 06:27:38.777125 Training Step 4420 Finished Timing (Training: 0.910966, Test: 0.0826658) after 0.250756 seconds\n",
      "2018-08-30 06:27:38.777250 Training Step 4420 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:38.777382 Training Step 4420 \"loss\" =  3.380793\n",
      "2018-08-30 06:27:38.981057 Test Step 4425 Finished\n",
      "2018-08-30 06:27:38.981150 Test Step 4425 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:38.981220 Test Step 4425 \"loss\" =  7.5345383\n",
      "2018-08-30 06:27:39.027792 Training Step 4425 Finished Timing (Training: 0.911419, Test: 0.0826051) after 0.250332 seconds\n",
      "2018-08-30 06:27:39.027873 Training Step 4425 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:39.027939 Training Step 4425 \"loss\" =  3.6339269\n",
      "2018-08-30 06:27:39.232136 Test Step 4430 Finished\n",
      "2018-08-30 06:27:39.232227 Test Step 4430 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:39.232659 Test Step 4430 \"loss\" =  7.4625463\n",
      "2018-08-30 06:27:39.279000 Training Step 4430 Finished Timing (Training: 0.911822, Test: 0.0826319) after 0.250968 seconds\n",
      "2018-08-30 06:27:39.279067 Training Step 4430 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:39.279580 Training Step 4430 \"loss\" =  3.360752\n",
      "2018-08-30 06:27:39.483126 Test Step 4435 Finished\n",
      "2018-08-30 06:27:39.483536 Test Step 4435 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:39.483602 Test Step 4435 \"loss\" =  7.2140517\n",
      "2018-08-30 06:27:39.529819 Training Step 4435 Finished Timing (Training: 0.911952, Test: 0.0826037) after 0.250168 seconds\n",
      "2018-08-30 06:27:39.529898 Training Step 4435 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:39.530319 Training Step 4435 \"loss\" =  3.2371197\n",
      "2018-08-30 06:27:39.734723 Test Step 4440 Finished\n",
      "2018-08-30 06:27:39.734818 Test Step 4440 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:39.734883 Test Step 4440 \"loss\" =  7.4509606\n",
      "2018-08-30 06:27:39.781481 Training Step 4440 Finished Timing (Training: 0.912053, Test: 0.0827684) after 0.251081 seconds\n",
      "2018-08-30 06:27:39.781624 Training Step 4440 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:39.781760 Training Step 4440 \"loss\" =  3.329434\n",
      "2018-08-30 06:27:39.986455 Test Step 4445 Finished\n",
      "2018-08-30 06:27:39.986529 Test Step 4445 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:39.986966 Test Step 4445 \"loss\" =  7.452678\n",
      "2018-08-30 06:27:40.032827 Training Step 4445 Finished Timing (Training: 0.911894, Test: 0.0827218) after 0.250193 seconds\n",
      "2018-08-30 06:27:40.032910 Training Step 4445 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:40.032976 Training Step 4445 \"loss\" =  3.550895\n",
      "2018-08-30 06:27:40.238266 Test Step 4450 Finished\n",
      "2018-08-30 06:27:40.238356 Test Step 4450 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:40.239053 Test Step 4450 \"loss\" =  7.3230476\n",
      "2018-08-30 06:27:40.285182 Training Step 4450 Finished Timing (Training: 0.911607, Test: 0.0827111) after 0.251148 seconds\n",
      "2018-08-30 06:27:40.285263 Training Step 4450 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:40.285326 Training Step 4450 \"loss\" =  3.4001396\n",
      "2018-08-30 06:27:40.489833 Test Step 4455 Finished\n",
      "2018-08-30 06:27:40.490024 Test Step 4455 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:40.490090 Test Step 4455 \"loss\" =  7.1871066\n",
      "2018-08-30 06:27:40.535848 Training Step 4455 Finished Timing (Training: 0.911746, Test: 0.0828831) after 0.250453 seconds\n",
      "2018-08-30 06:27:40.535925 Training Step 4455 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:40.535985 Training Step 4455 \"loss\" =  3.2933362\n",
      "2018-08-30 06:27:40.740900 Test Step 4460 Finished\n",
      "2018-08-30 06:27:40.741018 Test Step 4460 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:40.741082 Test Step 4460 \"loss\" =  7.264978\n",
      "2018-08-30 06:27:40.787399 Training Step 4460 Finished Timing (Training: 0.911933, Test: 0.0828346) after 0.250895 seconds\n",
      "2018-08-30 06:27:40.787470 Training Step 4460 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:40.787532 Training Step 4460 \"loss\" =  3.3709495\n",
      "2018-08-30 06:27:40.991991 Test Step 4465 Finished\n",
      "2018-08-30 06:27:40.992152 Test Step 4465 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:40.992248 Test Step 4465 \"loss\" =  7.660046\n",
      "2018-08-30 06:27:41.039347 Training Step 4465 Finished Timing (Training: 0.912225, Test: 0.0827814) after 0.251745 seconds\n",
      "2018-08-30 06:27:41.039424 Training Step 4465 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:41.039977 Training Step 4465 \"loss\" =  3.3687646\n",
      "2018-08-30 06:27:41.244476 Test Step 4470 Finished\n",
      "2018-08-30 06:27:41.244610 Test Step 4470 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:41.244689 Test Step 4470 \"loss\" =  7.5346413\n",
      "2018-08-30 06:27:41.290484 Training Step 4470 Finished Timing (Training: 0.912239, Test: 0.0828307) after 0.250429 seconds\n",
      "2018-08-30 06:27:41.290561 Training Step 4470 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:41.290626 Training Step 4470 \"loss\" =  3.5204785\n",
      "2018-08-30 06:27:41.494084 Test Step 4475 Finished\n",
      "2018-08-30 06:27:41.494169 Test Step 4475 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:41.494752 Test Step 4475 \"loss\" =  7.1847906\n",
      "2018-08-30 06:27:41.540736 Training Step 4475 Finished Timing (Training: 0.912326, Test: 0.0828102) after 0.25003 seconds\n",
      "2018-08-30 06:27:41.540811 Training Step 4475 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:41.540877 Training Step 4475 \"loss\" =  3.6099894\n",
      "2018-08-30 06:27:41.746661 Test Step 4480 Finished\n",
      "2018-08-30 06:27:41.746775 Test Step 4480 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:41.747333 Test Step 4480 \"loss\" =  7.2483573\n",
      "2018-08-30 06:27:41.793311 Training Step 4480 Finished Timing (Training: 0.91242, Test: 0.0827782) after 0.25235 seconds\n",
      "2018-08-30 06:27:41.793422 Training Step 4480 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:41.793482 Training Step 4480 \"loss\" =  3.2388096\n",
      "2018-08-30 06:27:41.998266 Test Step 4485 Finished\n",
      "2018-08-30 06:27:41.998363 Test Step 4485 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:41.998426 Test Step 4485 \"loss\" =  7.5993023\n",
      "2018-08-30 06:27:42.044852 Training Step 4485 Finished Timing (Training: 0.912603, Test: 0.082761) after 0.251302 seconds\n",
      "2018-08-30 06:27:42.044924 Training Step 4485 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:42.044991 Training Step 4485 \"loss\" =  3.5483482\n",
      "2018-08-30 06:27:42.248524 Test Step 4490 Finished\n",
      "2018-08-30 06:27:42.248916 Test Step 4490 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:42.248982 Test Step 4490 \"loss\" =  8.149365\n",
      "2018-08-30 06:27:42.295215 Training Step 4490 Finished Timing (Training: 0.912706, Test: 0.0827493) after 0.250154 seconds\n",
      "2018-08-30 06:27:42.295285 Training Step 4490 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:42.295347 Training Step 4490 \"loss\" =  3.5219612\n",
      "2018-08-30 06:27:42.498968 Test Step 4495 Finished\n",
      "2018-08-30 06:27:42.499044 Test Step 4495 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:42.499119 Test Step 4495 \"loss\" =  7.507972\n",
      "2018-08-30 06:27:42.544982 Training Step 4495 Finished Timing (Training: 0.912855, Test: 0.0827481) after 0.249567 seconds\n",
      "2018-08-30 06:27:42.545056 Training Step 4495 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:42.545122 Training Step 4495 \"loss\" =  3.5729375\n",
      "2018-08-30 06:27:42.748911 Test Step 4500 Finished\n",
      "2018-08-30 06:27:42.748994 Test Step 4500 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:42.749295 Test Step 4500 \"loss\" =  7.960741\n",
      "2018-08-30 06:27:42.795036 Training Step 4500 Finished Timing (Training: 0.912822, Test: 0.0827045) after 0.249038 seconds\n",
      "2018-08-30 06:27:42.795107 Training Step 4500 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:42.795170 Training Step 4500 \"loss\" =  3.2652655\n",
      "2018-08-30 06:27:42.998619 Test Step 4505 Finished\n",
      "2018-08-30 06:27:42.998706 Test Step 4505 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:42.998757 Test Step 4505 \"loss\" =  7.768525\n",
      "2018-08-30 06:27:43.045295 Training Step 4505 Finished Timing (Training: 0.916908, Test: 0.0821084) after 0.250059 seconds\n",
      "2018-08-30 06:27:43.045374 Training Step 4505 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:43.045890 Training Step 4505 \"loss\" =  3.44619\n",
      "2018-08-30 06:27:43.249560 Test Step 4510 Finished\n",
      "2018-08-30 06:27:43.249634 Test Step 4510 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:43.249681 Test Step 4510 \"loss\" =  7.5666456\n",
      "2018-08-30 06:27:43.296092 Training Step 4510 Finished Timing (Training: 0.91554, Test: 0.0816792) after 0.249847 seconds\n",
      "2018-08-30 06:27:43.296170 Training Step 4510 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:43.296621 Training Step 4510 \"loss\" =  3.1155133\n",
      "2018-08-30 06:27:43.499695 Test Step 4515 Finished\n",
      "2018-08-30 06:27:43.500121 Test Step 4515 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:43.500184 Test Step 4515 \"loss\" =  7.844345\n",
      "2018-08-30 06:27:43.546462 Training Step 4515 Finished Timing (Training: 0.914144, Test: 0.0817592) after 0.249772 seconds\n",
      "2018-08-30 06:27:43.546533 Training Step 4515 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:43.546598 Training Step 4515 \"loss\" =  3.1319795\n",
      "2018-08-30 06:27:43.750581 Test Step 4520 Finished\n",
      "2018-08-30 06:27:43.750653 Test Step 4520 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:43.750719 Test Step 4520 \"loss\" =  7.9772797\n",
      "2018-08-30 06:27:43.797440 Training Step 4520 Finished Timing (Training: 0.913712, Test: 0.0816808) after 0.250404 seconds\n",
      "2018-08-30 06:27:43.797501 Training Step 4520 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:43.797539 Training Step 4520 \"loss\" =  3.6045651\n",
      "2018-08-30 06:27:44.001290 Test Step 4525 Finished\n",
      "2018-08-30 06:27:44.001379 Test Step 4525 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:44.002177 Test Step 4525 \"loss\" =  7.6082034\n",
      "2018-08-30 06:27:44.047891 Training Step 4525 Finished Timing (Training: 0.913775, Test: 0.0816255) after 0.250274 seconds\n",
      "2018-08-30 06:27:44.047961 Training Step 4525 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:44.048025 Training Step 4525 \"loss\" =  3.2071373\n",
      "2018-08-30 06:27:44.252304 Test Step 4530 Finished\n",
      "2018-08-30 06:27:44.252391 Test Step 4530 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:44.253092 Test Step 4530 \"loss\" =  7.7442136\n",
      "2018-08-30 06:27:44.299217 Training Step 4530 Finished Timing (Training: 0.91376, Test: 0.0816812) after 0.251107 seconds\n",
      "2018-08-30 06:27:44.299292 Training Step 4530 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:44.299862 Training Step 4530 \"loss\" =  3.3558595\n",
      "2018-08-30 06:27:44.503603 Test Step 4535 Finished\n",
      "2018-08-30 06:27:44.503684 Test Step 4535 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:44.503741 Test Step 4535 \"loss\" =  7.472137\n",
      "2018-08-30 06:27:44.550583 Training Step 4535 Finished Timing (Training: 0.913323, Test: 0.0817252) after 0.250649 seconds\n",
      "2018-08-30 06:27:44.550651 Training Step 4535 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:44.550714 Training Step 4535 \"loss\" =  3.3433907\n",
      "2018-08-30 06:27:44.754904 Test Step 4540 Finished\n",
      "2018-08-30 06:27:44.754988 Test Step 4540 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:44.755068 Test Step 4540 \"loss\" =  8.192416\n",
      "2018-08-30 06:27:44.800767 Training Step 4540 Finished Timing (Training: 0.913572, Test: 0.0818755) after 0.249984 seconds\n",
      "2018-08-30 06:27:44.801069 Training Step 4540 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:44.801139 Training Step 4540 \"loss\" =  3.3981616\n",
      "2018-08-30 06:27:45.005836 Test Step 4545 Finished\n",
      "2018-08-30 06:27:45.005913 Test Step 4545 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:45.005956 Test Step 4545 \"loss\" =  7.493158\n",
      "2018-08-30 06:27:45.051918 Training Step 4545 Finished Timing (Training: 0.913726, Test: 0.0819454) after 0.250715 seconds\n",
      "2018-08-30 06:27:45.051990 Training Step 4545 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:45.052049 Training Step 4545 \"loss\" =  3.3370116\n",
      "2018-08-30 06:27:45.256304 Test Step 4550 Finished\n",
      "2018-08-30 06:27:45.256851 Test Step 4550 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:45.256928 Test Step 4550 \"loss\" =  7.398021\n",
      "2018-08-30 06:27:45.302805 Training Step 4550 Finished Timing (Training: 0.913456, Test: 0.082285) after 0.25069 seconds\n",
      "2018-08-30 06:27:45.302880 Training Step 4550 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:45.302944 Training Step 4550 \"loss\" =  3.3215287\n",
      "2018-08-30 06:27:45.507527 Test Step 4555 Finished\n",
      "2018-08-30 06:27:45.507603 Test Step 4555 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:45.508093 Test Step 4555 \"loss\" =  7.098798\n",
      "2018-08-30 06:27:45.553936 Training Step 4555 Finished Timing (Training: 0.913428, Test: 0.08238) after 0.250915 seconds\n",
      "2018-08-30 06:27:45.554013 Training Step 4555 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:45.554087 Training Step 4555 \"loss\" =  3.4393232\n",
      "2018-08-30 06:27:45.758320 Test Step 4560 Finished\n",
      "2018-08-30 06:27:45.758425 Test Step 4560 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:45.759009 Test Step 4560 \"loss\" =  7.146021\n",
      "2018-08-30 06:27:45.805519 Training Step 4560 Finished Timing (Training: 0.913432, Test: 0.0823795) after 0.251364 seconds\n",
      "2018-08-30 06:27:45.805587 Training Step 4560 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:45.806171 Training Step 4560 \"loss\" =  3.3332052\n",
      "2018-08-30 06:27:46.010392 Test Step 4565 Finished\n",
      "2018-08-30 06:27:46.010477 Test Step 4565 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:46.010544 Test Step 4565 \"loss\" =  7.0512466\n",
      "2018-08-30 06:27:46.057086 Training Step 4565 Finished Timing (Training: 0.913389, Test: 0.0823768) after 0.250643 seconds\n",
      "2018-08-30 06:27:46.057166 Training Step 4565 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:46.057265 Training Step 4565 \"loss\" =  3.1022425\n",
      "2018-08-30 06:27:46.262091 Test Step 4570 Finished\n",
      "2018-08-30 06:27:46.262742 Test Step 4570 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:46.262933 Test Step 4570 \"loss\" =  7.2818313\n",
      "2018-08-30 06:27:46.309341 Training Step 4570 Finished Timing (Training: 0.913097, Test: 0.0824554) after 0.251397 seconds\n",
      "2018-08-30 06:27:46.309411 Training Step 4570 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:46.309470 Training Step 4570 \"loss\" =  3.1140046\n",
      "2018-08-30 06:27:46.513344 Test Step 4575 Finished\n",
      "2018-08-30 06:27:46.513427 Test Step 4575 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:46.513513 Test Step 4575 \"loss\" =  7.441306\n",
      "2018-08-30 06:27:46.559977 Training Step 4575 Finished Timing (Training: 0.913241, Test: 0.0824777) after 0.25044 seconds\n",
      "2018-08-30 06:27:46.560045 Training Step 4575 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:46.560333 Training Step 4575 \"loss\" =  3.3786614\n",
      "2018-08-30 06:27:46.764296 Test Step 4580 Finished\n",
      "2018-08-30 06:27:46.764409 Test Step 4580 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:46.764853 Test Step 4580 \"loss\" =  7.458383\n",
      "2018-08-30 06:27:46.810613 Training Step 4580 Finished Timing (Training: 0.913184, Test: 0.0825333) after 0.250208 seconds\n",
      "2018-08-30 06:27:46.810688 Training Step 4580 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:46.810749 Training Step 4580 \"loss\" =  3.1759045\n",
      "2018-08-30 06:27:47.015461 Test Step 4585 Finished\n",
      "2018-08-30 06:27:47.015543 Test Step 4585 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:47.015614 Test Step 4585 \"loss\" =  7.5478415\n",
      "2018-08-30 06:27:47.062646 Training Step 4585 Finished Timing (Training: 0.913376, Test: 0.0824786) after 0.251827 seconds\n",
      "2018-08-30 06:27:47.062714 Training Step 4585 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:47.063259 Training Step 4585 \"loss\" =  3.3286386\n",
      "2018-08-30 06:27:47.267156 Test Step 4590 Finished\n",
      "2018-08-30 06:27:47.267263 Test Step 4590 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:47.267322 Test Step 4590 \"loss\" =  7.617886\n",
      "2018-08-30 06:27:47.313048 Training Step 4590 Finished Timing (Training: 0.913316, Test: 0.082517) after 0.249514 seconds\n",
      "2018-08-30 06:27:47.313117 Training Step 4590 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:47.313185 Training Step 4590 \"loss\" =  3.3710127\n",
      "2018-08-30 06:27:47.516744 Test Step 4595 Finished\n",
      "2018-08-30 06:27:47.516849 Test Step 4595 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:47.516936 Test Step 4595 \"loss\" =  8.101089\n",
      "2018-08-30 06:27:47.562807 Training Step 4595 Finished Timing (Training: 0.913407, Test: 0.08253) after 0.24951 seconds\n",
      "2018-08-30 06:27:47.562873 Training Step 4595 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:47.562923 Training Step 4595 \"loss\" =  3.2959664\n",
      "2018-08-30 06:27:47.767789 Test Step 4600 Finished\n",
      "2018-08-30 06:27:47.768358 Test Step 4600 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:47.768732 Test Step 4600 \"loss\" =  7.8019443\n",
      "2018-08-30 06:27:47.814908 Training Step 4600 Finished Timing (Training: 0.913182, Test: 0.0825439) after 0.251349 seconds\n",
      "2018-08-30 06:27:47.815006 Training Step 4600 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:47.815766 Training Step 4600 \"loss\" =  3.2997615\n",
      "2018-08-30 06:27:48.020544 Test Step 4605 Finished\n",
      "2018-08-30 06:27:48.020673 Test Step 4605 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:48.021542 Test Step 4605 \"loss\" =  7.6980205\n",
      "2018-08-30 06:27:48.068025 Training Step 4605 Finished Timing (Training: 0.912118, Test: 0.0824124) after 0.251786 seconds\n",
      "2018-08-30 06:27:48.068109 Training Step 4605 \"min loss\" =  2.9768434\n",
      "2018-08-30 06:27:48.068191 Training Step 4605 \"loss\" =  3.2731087\n",
      "2018-08-30 06:27:48.272137 Test Step 4610 Finished\n",
      "2018-08-30 06:27:48.272236 Test Step 4610 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:48.273092 Test Step 4610 \"loss\" =  7.6222873\n",
      "2018-08-30 06:27:48.319167 Training Step 4610 Finished Timing (Training: 0.909962, Test: 0.0821134) after 0.249861 seconds\n",
      "2018-08-30 06:27:48.319363 Training Step 4610 \"min loss\" =  2.9734943\n",
      "2018-08-30 06:27:48.320100 Training Step 4610 \"loss\" =  3.408706\n",
      "2018-08-30 06:27:48.524137 Test Step 4615 Finished\n",
      "2018-08-30 06:27:48.524565 Test Step 4615 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:48.525099 Test Step 4615 \"loss\" =  8.21885\n",
      "2018-08-30 06:27:48.571262 Training Step 4615 Finished Timing (Training: 0.909103, Test: 0.0821161) after 0.250797 seconds\n",
      "2018-08-30 06:27:48.571612 Training Step 4615 \"min loss\" =  2.9734943\n",
      "2018-08-30 06:27:48.572149 Training Step 4615 \"loss\" =  3.2519045\n",
      "2018-08-30 06:27:48.776431 Test Step 4620 Finished\n",
      "2018-08-30 06:27:48.776859 Test Step 4620 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:48.777575 Test Step 4620 \"loss\" =  7.900165\n",
      "2018-08-30 06:27:48.823660 Training Step 4620 Finished Timing (Training: 0.908425, Test: 0.0820922) after 0.25103 seconds\n",
      "2018-08-30 06:27:48.823745 Training Step 4620 \"min loss\" =  2.9543977\n",
      "2018-08-30 06:27:48.824488 Training Step 4620 \"loss\" =  3.1760263\n",
      "2018-08-30 06:27:49.028649 Test Step 4625 Finished\n",
      "2018-08-30 06:27:49.028771 Test Step 4625 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:49.028844 Test Step 4625 \"loss\" =  7.6372757\n",
      "2018-08-30 06:27:49.075203 Training Step 4625 Finished Timing (Training: 0.909192, Test: 0.0818999) after 0.250158 seconds\n",
      "2018-08-30 06:27:49.075266 Training Step 4625 \"min loss\" =  2.9543977\n",
      "2018-08-30 06:27:49.075322 Training Step 4625 \"loss\" =  3.3799593\n",
      "2018-08-30 06:27:49.279751 Test Step 4630 Finished\n",
      "2018-08-30 06:27:49.279839 Test Step 4630 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:49.279901 Test Step 4630 \"loss\" =  7.6294584\n",
      "2018-08-30 06:27:49.326790 Training Step 4630 Finished Timing (Training: 0.909561, Test: 0.082137) after 0.251397 seconds\n",
      "2018-08-30 06:27:49.326850 Training Step 4630 \"min loss\" =  2.9543977\n",
      "2018-08-30 06:27:49.327316 Training Step 4630 \"loss\" =  3.3508635\n",
      "2018-08-30 06:27:49.530072 Test Step 4635 Finished\n",
      "2018-08-30 06:27:49.530146 Test Step 4635 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:49.530203 Test Step 4635 \"loss\" =  7.9130177\n",
      "2018-08-30 06:27:49.576634 Training Step 4635 Finished Timing (Training: 0.909948, Test: 0.0821122) after 0.249249 seconds\n",
      "2018-08-30 06:27:49.576701 Training Step 4635 \"min loss\" =  2.9543977\n",
      "2018-08-30 06:27:49.577130 Training Step 4635 \"loss\" =  3.476602\n",
      "2018-08-30 06:27:49.780697 Test Step 4640 Finished\n",
      "2018-08-30 06:27:49.780776 Test Step 4640 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:49.781538 Test Step 4640 \"loss\" =  7.671485\n",
      "2018-08-30 06:27:49.827234 Training Step 4640 Finished Timing (Training: 0.91015, Test: 0.0821569) after 0.250036 seconds\n",
      "2018-08-30 06:27:49.827298 Training Step 4640 \"min loss\" =  2.9543977\n",
      "2018-08-30 06:27:49.827666 Training Step 4640 \"loss\" =  3.0727053\n",
      "2018-08-30 06:27:50.031322 Test Step 4645 Finished\n",
      "2018-08-30 06:27:50.031419 Test Step 4645 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:50.032010 Test Step 4645 \"loss\" =  7.4988475\n",
      "2018-08-30 06:27:50.078135 Training Step 4645 Finished Timing (Training: 0.910122, Test: 0.0821492) after 0.250058 seconds\n",
      "2018-08-30 06:27:50.078198 Training Step 4645 \"min loss\" =  2.9543977\n",
      "2018-08-30 06:27:50.078239 Training Step 4645 \"loss\" =  3.1952562\n",
      "2018-08-30 06:27:50.281521 Test Step 4650 Finished\n",
      "2018-08-30 06:27:50.281623 Test Step 4650 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:50.282195 Test Step 4650 \"loss\" =  7.892627\n",
      "2018-08-30 06:27:50.328068 Training Step 4650 Finished Timing (Training: 0.910359, Test: 0.0822908) after 0.249719 seconds\n",
      "2018-08-30 06:27:50.328132 Training Step 4650 \"min loss\" =  2.9543977\n",
      "2018-08-30 06:27:50.328188 Training Step 4650 \"loss\" =  3.1951022\n",
      "2018-08-30 06:27:50.531273 Test Step 4655 Finished\n",
      "2018-08-30 06:27:50.531353 Test Step 4655 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:50.531906 Test Step 4655 \"loss\" =  7.62907\n",
      "2018-08-30 06:27:50.577615 Training Step 4655 Finished Timing (Training: 0.910744, Test: 0.0822452) after 0.249365 seconds\n",
      "2018-08-30 06:27:50.577877 Training Step 4655 \"min loss\" =  2.8634512\n",
      "2018-08-30 06:27:50.578143 Training Step 4655 \"loss\" =  2.8634512\n",
      "2018-08-30 06:27:50.781582 Test Step 4660 Finished\n",
      "2018-08-30 06:27:50.782072 Test Step 4660 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:50.782148 Test Step 4660 \"loss\" =  7.8469567\n",
      "2018-08-30 06:27:50.827801 Training Step 4660 Finished Timing (Training: 0.9108, Test: 0.0822492) after 0.249256 seconds\n",
      "2018-08-30 06:27:50.827868 Training Step 4660 \"min loss\" =  2.8634512\n",
      "2018-08-30 06:27:50.827912 Training Step 4660 \"loss\" =  3.3099637\n",
      "2018-08-30 06:27:51.030571 Test Step 4665 Finished\n",
      "2018-08-30 06:27:51.030883 Test Step 4665 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:51.030946 Test Step 4665 \"loss\" =  7.737939\n",
      "2018-08-30 06:27:51.076598 Training Step 4665 Finished Timing (Training: 0.911152, Test: 0.0822317) after 0.248609 seconds\n",
      "2018-08-30 06:27:51.076870 Training Step 4665 \"min loss\" =  2.8634512\n",
      "2018-08-30 06:27:51.077138 Training Step 4665 \"loss\" =  3.255235\n",
      "2018-08-30 06:27:51.281619 Test Step 4670 Finished\n",
      "2018-08-30 06:27:51.281746 Test Step 4670 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:51.281827 Test Step 4670 \"loss\" =  8.359881\n",
      "2018-08-30 06:27:51.328417 Training Step 4670 Finished Timing (Training: 0.911299, Test: 0.0823013) after 0.25121 seconds\n",
      "2018-08-30 06:27:51.328484 Training Step 4670 \"min loss\" =  2.8634512\n",
      "2018-08-30 06:27:51.329074 Training Step 4670 \"loss\" =  3.34604\n",
      "2018-08-30 06:27:51.532852 Test Step 4675 Finished\n",
      "2018-08-30 06:27:51.532935 Test Step 4675 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:51.532992 Test Step 4675 \"loss\" =  7.7674465\n",
      "2018-08-30 06:27:51.578892 Training Step 4675 Finished Timing (Training: 0.911427, Test: 0.0823411) after 0.249751 seconds\n",
      "2018-08-30 06:27:51.579210 Training Step 4675 \"min loss\" =  2.8634512\n",
      "2018-08-30 06:27:51.579504 Training Step 4675 \"loss\" =  3.3152928\n",
      "2018-08-30 06:27:51.783727 Test Step 4680 Finished\n",
      "2018-08-30 06:27:51.783890 Test Step 4680 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:51.783955 Test Step 4680 \"loss\" =  7.9351435\n",
      "2018-08-30 06:27:51.830080 Training Step 4680 Finished Timing (Training: 0.911506, Test: 0.0824014) after 0.250496 seconds\n",
      "2018-08-30 06:27:51.830204 Training Step 4680 \"min loss\" =  2.8634512\n",
      "2018-08-30 06:27:51.830262 Training Step 4680 \"loss\" =  3.122068\n",
      "2018-08-30 06:27:52.033855 Test Step 4685 Finished\n",
      "2018-08-30 06:27:52.033944 Test Step 4685 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:52.034034 Test Step 4685 \"loss\" =  7.9388013\n",
      "2018-08-30 06:27:52.080966 Training Step 4685 Finished Timing (Training: 0.9116, Test: 0.0823847) after 0.250641 seconds\n",
      "2018-08-30 06:27:52.081041 Training Step 4685 \"min loss\" =  2.8634512\n",
      "2018-08-30 06:27:52.081112 Training Step 4685 \"loss\" =  2.9023128\n",
      "2018-08-30 06:27:52.285723 Test Step 4690 Finished\n",
      "2018-08-30 06:27:52.285798 Test Step 4690 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:52.285873 Test Step 4690 \"loss\" =  7.87303\n",
      "2018-08-30 06:27:52.331513 Training Step 4690 Finished Timing (Training: 0.91167, Test: 0.0824178) after 0.249747 seconds\n",
      "2018-08-30 06:27:52.331582 Training Step 4690 \"min loss\" =  2.8634512\n",
      "2018-08-30 06:27:52.331623 Training Step 4690 \"loss\" =  3.0163064\n",
      "2018-08-30 06:27:52.535774 Test Step 4695 Finished\n",
      "2018-08-30 06:27:52.536163 Test Step 4695 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:52.536225 Test Step 4695 \"loss\" =  7.5522246\n",
      "2018-08-30 06:27:52.582233 Training Step 4695 Finished Timing (Training: 0.911814, Test: 0.0824346) after 0.250533 seconds\n",
      "2018-08-30 06:27:52.582311 Training Step 4695 \"min loss\" =  2.8634512\n",
      "2018-08-30 06:27:52.582386 Training Step 4695 \"loss\" =  3.4773643\n",
      "2018-08-30 06:27:52.787607 Test Step 4700 Finished\n",
      "2018-08-30 06:27:52.787706 Test Step 4700 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:52.787790 Test Step 4700 \"loss\" =  8.226168\n",
      "2018-08-30 06:27:52.834779 Training Step 4700 Finished Timing (Training: 0.91206, Test: 0.0823804) after 0.252315 seconds\n",
      "2018-08-30 06:27:52.834837 Training Step 4700 \"min loss\" =  2.8634512\n",
      "2018-08-30 06:27:52.834908 Training Step 4700 \"loss\" =  2.9543536\n",
      "2018-08-30 06:27:53.039366 Test Step 4705 Finished\n",
      "2018-08-30 06:27:53.039748 Test Step 4705 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:53.039810 Test Step 4705 \"loss\" =  8.094238\n",
      "2018-08-30 06:27:53.086373 Training Step 4705 Finished Timing (Training: 0.913737, Test: 0.0841934) after 0.251396 seconds\n",
      "2018-08-30 06:27:53.086441 Training Step 4705 \"min loss\" =  2.8634512\n",
      "2018-08-30 06:27:53.086502 Training Step 4705 \"loss\" =  2.9867203\n",
      "2018-08-30 06:27:53.290031 Test Step 4710 Finished\n",
      "2018-08-30 06:27:53.290126 Test Step 4710 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:53.290189 Test Step 4710 \"loss\" =  8.085963\n",
      "2018-08-30 06:27:53.335952 Training Step 4710 Finished Timing (Training: 0.91493, Test: 0.0831063) after 0.249372 seconds\n",
      "2018-08-30 06:27:53.336381 Training Step 4710 \"min loss\" =  2.8634512\n",
      "2018-08-30 06:27:53.336539 Training Step 4710 \"loss\" =  3.4344277\n",
      "2018-08-30 06:27:53.541526 Test Step 4715 Finished\n",
      "2018-08-30 06:27:53.541613 Test Step 4715 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:53.541683 Test Step 4715 \"loss\" =  7.7257814\n",
      "2018-08-30 06:27:53.588380 Training Step 4715 Finished Timing (Training: 0.912857, Test: 0.0835089) after 0.251688 seconds\n",
      "2018-08-30 06:27:53.588447 Training Step 4715 \"min loss\" =  2.8634512\n",
      "2018-08-30 06:27:53.588507 Training Step 4715 \"loss\" =  3.478653\n",
      "2018-08-30 06:27:53.792787 Test Step 4720 Finished\n",
      "2018-08-30 06:27:53.793118 Test Step 4720 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:53.793512 Test Step 4720 \"loss\" =  7.685578\n",
      "2018-08-30 06:27:53.839472 Training Step 4720 Finished Timing (Training: 0.91284, Test: 0.0834379) after 0.250899 seconds\n",
      "2018-08-30 06:27:53.839536 Training Step 4720 \"min loss\" =  2.8634512\n",
      "2018-08-30 06:27:53.839596 Training Step 4720 \"loss\" =  3.0848365\n",
      "2018-08-30 06:27:54.043871 Test Step 4725 Finished\n",
      "2018-08-30 06:27:54.043981 Test Step 4725 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:54.044073 Test Step 4725 \"loss\" =  8.109086\n",
      "2018-08-30 06:27:54.089855 Training Step 4725 Finished Timing (Training: 0.91343, Test: 0.0832045) after 0.250178 seconds\n",
      "2018-08-30 06:27:54.089928 Training Step 4725 \"min loss\" =  2.8634512\n",
      "2018-08-30 06:27:54.089985 Training Step 4725 \"loss\" =  3.173117\n",
      "2018-08-30 06:27:54.293797 Test Step 4730 Finished\n",
      "2018-08-30 06:27:54.293878 Test Step 4730 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:54.294724 Test Step 4730 \"loss\" =  8.262352\n",
      "2018-08-30 06:27:54.340794 Training Step 4730 Finished Timing (Training: 0.913249, Test: 0.0830405) after 0.25074 seconds\n",
      "2018-08-30 06:27:54.340900 Training Step 4730 \"min loss\" =  2.8634512\n",
      "2018-08-30 06:27:54.340973 Training Step 4730 \"loss\" =  3.333551\n",
      "2018-08-30 06:27:54.546428 Test Step 4735 Finished\n",
      "2018-08-30 06:27:54.546537 Test Step 4735 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:54.546596 Test Step 4735 \"loss\" =  7.746344\n",
      "2018-08-30 06:27:54.593355 Training Step 4735 Finished Timing (Training: 0.913526, Test: 0.0830098) after 0.252319 seconds\n",
      "2018-08-30 06:27:54.593415 Training Step 4735 \"min loss\" =  2.8634512\n",
      "2018-08-30 06:27:54.593470 Training Step 4735 \"loss\" =  2.9689357\n",
      "2018-08-30 06:27:54.797392 Test Step 4740 Finished\n",
      "2018-08-30 06:27:54.797489 Test Step 4740 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:54.797946 Test Step 4740 \"loss\" =  8.19795\n",
      "2018-08-30 06:27:54.844210 Training Step 4740 Finished Timing (Training: 0.913298, Test: 0.0830231) after 0.250678 seconds\n",
      "2018-08-30 06:27:54.844275 Training Step 4740 \"min loss\" =  2.8634512\n",
      "2018-08-30 06:27:54.844795 Training Step 4740 \"loss\" =  3.2352238\n",
      "2018-08-30 06:27:55.049143 Test Step 4745 Finished\n",
      "2018-08-30 06:27:55.049256 Test Step 4745 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:55.049338 Test Step 4745 \"loss\" =  7.815762\n",
      "2018-08-30 06:27:55.095840 Training Step 4745 Finished Timing (Training: 0.913119, Test: 0.0829351) after 0.250974 seconds\n",
      "2018-08-30 06:27:55.095930 Training Step 4745 \"min loss\" =  2.8634512\n",
      "2018-08-30 06:27:55.096497 Training Step 4745 \"loss\" =  3.5116692\n",
      "2018-08-30 06:27:55.301245 Test Step 4750 Finished\n",
      "2018-08-30 06:27:55.301369 Test Step 4750 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:55.301438 Test Step 4750 \"loss\" =  8.292569\n",
      "2018-08-30 06:27:55.347185 Training Step 4750 Finished Timing (Training: 0.913068, Test: 0.0829112) after 0.250443 seconds\n",
      "2018-08-30 06:27:55.347252 Training Step 4750 \"min loss\" =  2.8634512\n",
      "2018-08-30 06:27:55.347649 Training Step 4750 \"loss\" =  3.2519338\n",
      "2018-08-30 06:27:55.551623 Test Step 4755 Finished\n",
      "2018-08-30 06:27:55.551702 Test Step 4755 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:55.551771 Test Step 4755 \"loss\" =  7.928016\n",
      "2018-08-30 06:27:55.597522 Training Step 4755 Finished Timing (Training: 0.913267, Test: 0.0827978) after 0.249801 seconds\n",
      "2018-08-30 06:27:55.597599 Training Step 4755 \"min loss\" =  2.8634512\n",
      "2018-08-30 06:27:55.597979 Training Step 4755 \"loss\" =  2.916868\n",
      "2018-08-30 06:27:55.802139 Test Step 4760 Finished\n",
      "2018-08-30 06:27:55.802222 Test Step 4760 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:55.802310 Test Step 4760 \"loss\" =  7.671903\n",
      "2018-08-30 06:27:55.849406 Training Step 4760 Finished Timing (Training: 0.913183, Test: 0.0827183) after 0.251352 seconds\n",
      "2018-08-30 06:27:55.849471 Training Step 4760 \"min loss\" =  2.8634512\n",
      "2018-08-30 06:27:55.850101 Training Step 4760 \"loss\" =  3.2518113\n",
      "2018-08-30 06:27:56.054195 Test Step 4765 Finished\n",
      "2018-08-30 06:27:56.054283 Test Step 4765 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:56.054345 Test Step 4765 \"loss\" =  7.6079516\n",
      "2018-08-30 06:27:56.100323 Training Step 4765 Finished Timing (Training: 0.913238, Test: 0.0826123) after 0.249967 seconds\n",
      "2018-08-30 06:27:56.100388 Training Step 4765 \"min loss\" =  2.8634512\n",
      "2018-08-30 06:27:56.100475 Training Step 4765 \"loss\" =  3.3124015\n",
      "2018-08-30 06:27:56.305180 Test Step 4770 Finished\n",
      "2018-08-30 06:27:56.305344 Test Step 4770 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:56.305415 Test Step 4770 \"loss\" =  8.020216\n",
      "2018-08-30 06:27:56.351384 Training Step 4770 Finished Timing (Training: 0.913119, Test: 0.0828663) after 0.250824 seconds\n",
      "2018-08-30 06:27:56.351462 Training Step 4770 \"min loss\" =  2.8634512\n",
      "2018-08-30 06:27:56.351516 Training Step 4770 \"loss\" =  3.5687115\n",
      "2018-08-30 06:27:56.555655 Test Step 4775 Finished\n",
      "2018-08-30 06:27:56.555754 Test Step 4775 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:56.555833 Test Step 4775 \"loss\" =  7.7265363\n",
      "2018-08-30 06:27:56.602345 Training Step 4775 Finished Timing (Training: 0.913318, Test: 0.0828078) after 0.250746 seconds\n",
      "2018-08-30 06:27:56.602407 Training Step 4775 \"min loss\" =  2.8634512\n",
      "2018-08-30 06:27:56.602446 Training Step 4775 \"loss\" =  3.2677054\n",
      "2018-08-30 06:27:56.805649 Test Step 4780 Finished\n",
      "2018-08-30 06:27:56.805726 Test Step 4780 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:56.806348 Test Step 4780 \"loss\" =  7.8281465\n",
      "2018-08-30 06:27:56.852368 Training Step 4780 Finished Timing (Training: 0.913375, Test: 0.0827588) after 0.249869 seconds\n",
      "2018-08-30 06:27:56.852452 Training Step 4780 \"min loss\" =  2.8634512\n",
      "2018-08-30 06:27:56.852493 Training Step 4780 \"loss\" =  2.9485502\n",
      "2018-08-30 06:27:57.056886 Test Step 4785 Finished\n",
      "2018-08-30 06:27:57.056973 Test Step 4785 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:57.057049 Test Step 4785 \"loss\" =  7.854907\n",
      "2018-08-30 06:27:57.103041 Training Step 4785 Finished Timing (Training: 0.913409, Test: 0.0827109) after 0.249897 seconds\n",
      "2018-08-30 06:27:57.103162 Training Step 4785 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:27:57.103626 Training Step 4785 \"loss\" =  3.3713768\n",
      "2018-08-30 06:27:57.307798 Test Step 4790 Finished\n",
      "2018-08-30 06:27:57.307874 Test Step 4790 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:57.308487 Test Step 4790 \"loss\" =  7.823026\n",
      "2018-08-30 06:27:57.354458 Training Step 4790 Finished Timing (Training: 0.913245, Test: 0.0827191) after 0.250762 seconds\n",
      "2018-08-30 06:27:57.354539 Training Step 4790 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:27:57.354592 Training Step 4790 \"loss\" =  3.1638496\n",
      "2018-08-30 06:27:57.558762 Test Step 4795 Finished\n",
      "2018-08-30 06:27:57.558845 Test Step 4795 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:57.558908 Test Step 4795 \"loss\" =  8.171311\n",
      "2018-08-30 06:27:57.604816 Training Step 4795 Finished Timing (Training: 0.913413, Test: 0.0826681) after 0.25015 seconds\n",
      "2018-08-30 06:27:57.604879 Training Step 4795 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:27:57.605442 Training Step 4795 \"loss\" =  2.923029\n",
      "2018-08-30 06:27:57.808617 Test Step 4800 Finished\n",
      "2018-08-30 06:27:57.808700 Test Step 4800 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:57.809143 Test Step 4800 \"loss\" =  8.16942\n",
      "2018-08-30 06:27:57.855514 Training Step 4800 Finished Timing (Training: 0.913337, Test: 0.0826265) after 0.250002 seconds\n",
      "2018-08-30 06:27:57.855598 Training Step 4800 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:27:57.855965 Training Step 4800 \"loss\" =  3.5142698\n",
      "2018-08-30 06:27:58.059255 Test Step 4805 Finished\n",
      "2018-08-30 06:27:58.059577 Test Step 4805 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:58.059815 Test Step 4805 \"loss\" =  8.14916\n",
      "2018-08-30 06:27:58.105841 Training Step 4805 Finished Timing (Training: 0.914016, Test: 0.0824288) after 0.249561 seconds\n",
      "2018-08-30 06:27:58.105913 Training Step 4805 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:27:58.106285 Training Step 4805 \"loss\" =  3.5390377\n",
      "2018-08-30 06:27:58.309799 Test Step 4810 Finished\n",
      "2018-08-30 06:27:58.309887 Test Step 4810 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:58.309943 Test Step 4810 \"loss\" =  7.503604\n",
      "2018-08-30 06:27:58.356408 Training Step 4810 Finished Timing (Training: 0.913416, Test: 0.0820388) after 0.250063 seconds\n",
      "2018-08-30 06:27:58.356486 Training Step 4810 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:27:58.356541 Training Step 4810 \"loss\" =  3.09418\n",
      "2018-08-30 06:27:58.560067 Test Step 4815 Finished\n",
      "2018-08-30 06:27:58.560179 Test Step 4815 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:58.561067 Test Step 4815 \"loss\" =  7.837396\n",
      "2018-08-30 06:27:58.607148 Training Step 4815 Finished Timing (Training: 0.912241, Test: 0.0819168) after 0.250005 seconds\n",
      "2018-08-30 06:27:58.607231 Training Step 4815 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:27:58.607872 Training Step 4815 \"loss\" =  3.1509984\n",
      "2018-08-30 06:27:58.811627 Test Step 4820 Finished\n",
      "2018-08-30 06:27:58.811733 Test Step 4820 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:58.812614 Test Step 4820 \"loss\" =  7.6896076\n",
      "2018-08-30 06:27:58.858729 Training Step 4820 Finished Timing (Training: 0.911245, Test: 0.0816807) after 0.250271 seconds\n",
      "2018-08-30 06:27:58.859101 Training Step 4820 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:27:58.859205 Training Step 4820 \"loss\" =  3.3597224\n",
      "2018-08-30 06:27:59.062864 Test Step 4825 Finished\n",
      "2018-08-30 06:27:59.062964 Test Step 4825 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:59.063827 Test Step 4825 \"loss\" =  8.503894\n",
      "2018-08-30 06:27:59.110122 Training Step 4825 Finished Timing (Training: 0.911082, Test: 0.0817213) after 0.250813 seconds\n",
      "2018-08-30 06:27:59.110213 Training Step 4825 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:27:59.110328 Training Step 4825 \"loss\" =  3.3124733\n",
      "2018-08-30 06:27:59.315513 Test Step 4830 Finished\n",
      "2018-08-30 06:27:59.315607 Test Step 4830 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:59.316460 Test Step 4830 \"loss\" =  7.622188\n",
      "2018-08-30 06:27:59.362333 Training Step 4830 Finished Timing (Training: 0.911222, Test: 0.0818757) after 0.251904 seconds\n",
      "2018-08-30 06:27:59.362408 Training Step 4830 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:27:59.363007 Training Step 4830 \"loss\" =  3.543874\n",
      "2018-08-30 06:27:59.567606 Test Step 4835 Finished\n",
      "2018-08-30 06:27:59.567700 Test Step 4835 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:59.567761 Test Step 4835 \"loss\" =  8.462187\n",
      "2018-08-30 06:27:59.614324 Training Step 4835 Finished Timing (Training: 0.911011, Test: 0.0818363) after 0.250729 seconds\n",
      "2018-08-30 06:27:59.614401 Training Step 4835 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:27:59.614453 Training Step 4835 \"loss\" =  3.432993\n",
      "2018-08-30 06:27:59.818073 Test Step 4840 Finished\n",
      "2018-08-30 06:27:59.818166 Test Step 4840 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:27:59.818229 Test Step 4840 \"loss\" =  7.7980986\n",
      "2018-08-30 06:27:59.864586 Training Step 4840 Finished Timing (Training: 0.911083, Test: 0.0818596) after 0.249526 seconds\n",
      "2018-08-30 06:27:59.864660 Training Step 4840 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:27:59.864715 Training Step 4840 \"loss\" =  3.2716136\n",
      "2018-08-30 06:28:00.069205 Test Step 4845 Finished\n",
      "2018-08-30 06:28:00.069582 Test Step 4845 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:28:00.069833 Test Step 4845 \"loss\" =  8.339064\n",
      "2018-08-30 06:28:00.115863 Training Step 4845 Finished Timing (Training: 0.911064, Test: 0.0818923) after 0.250507 seconds\n",
      "2018-08-30 06:28:00.115941 Training Step 4845 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:28:00.115999 Training Step 4845 \"loss\" =  3.2061257\n",
      "2018-08-30 06:28:00.320182 Test Step 4850 Finished\n",
      "2018-08-30 06:28:00.320276 Test Step 4850 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:28:00.320836 Test Step 4850 \"loss\" =  7.938223\n",
      "2018-08-30 06:28:00.367117 Training Step 4850 Finished Timing (Training: 0.910967, Test: 0.0818946) after 0.250441 seconds\n",
      "2018-08-30 06:28:00.367192 Training Step 4850 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:28:00.367249 Training Step 4850 \"loss\" =  3.3170905\n",
      "2018-08-30 06:28:00.571942 Test Step 4855 Finished\n",
      "2018-08-30 06:28:00.572051 Test Step 4855 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:28:00.572107 Test Step 4855 \"loss\" =  7.4106793\n",
      "2018-08-30 06:28:00.618465 Training Step 4855 Finished Timing (Training: 0.911177, Test: 0.0819789) after 0.250612 seconds\n",
      "2018-08-30 06:28:00.618524 Training Step 4855 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:28:00.618956 Training Step 4855 \"loss\" =  3.2353537\n",
      "2018-08-30 06:28:00.823035 Test Step 4860 Finished\n",
      "2018-08-30 06:28:00.823116 Test Step 4860 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:28:00.823177 Test Step 4860 \"loss\" =  8.028557\n",
      "2018-08-30 06:28:00.869814 Training Step 4860 Finished Timing (Training: 0.911265, Test: 0.0819958) after 0.250792 seconds\n",
      "2018-08-30 06:28:00.870118 Training Step 4860 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:28:00.870187 Training Step 4860 \"loss\" =  3.3168266\n",
      "2018-08-30 06:28:01.074409 Test Step 4865 Finished\n",
      "2018-08-30 06:28:01.074658 Test Step 4865 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:28:01.075096 Test Step 4865 \"loss\" =  7.3484473\n",
      "2018-08-30 06:28:01.121161 Training Step 4865 Finished Timing (Training: 0.911246, Test: 0.0819804) after 0.250494 seconds\n",
      "2018-08-30 06:28:01.121284 Training Step 4865 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:28:01.121663 Training Step 4865 \"loss\" =  3.0545156\n",
      "2018-08-30 06:28:01.325696 Test Step 4870 Finished\n",
      "2018-08-30 06:28:01.325820 Test Step 4870 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:28:01.326361 Test Step 4870 \"loss\" =  7.8451185\n",
      "2018-08-30 06:28:01.372744 Training Step 4870 Finished Timing (Training: 0.911188, Test: 0.0819972) after 0.250767 seconds\n",
      "2018-08-30 06:28:01.372825 Training Step 4870 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:28:01.373199 Training Step 4870 \"loss\" =  3.39811\n",
      "2018-08-30 06:28:01.577553 Test Step 4875 Finished\n",
      "2018-08-30 06:28:01.577825 Test Step 4875 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:28:01.578106 Test Step 4875 \"loss\" =  7.7303495\n",
      "2018-08-30 06:28:01.624575 Training Step 4875 Finished Timing (Training: 0.911167, Test: 0.0820338) after 0.251055 seconds\n",
      "2018-08-30 06:28:01.624633 Training Step 4875 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:28:01.624959 Training Step 4875 \"loss\" =  3.4537604\n",
      "2018-08-30 06:28:01.829671 Test Step 4880 Finished\n",
      "2018-08-30 06:28:01.829837 Test Step 4880 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:28:01.829898 Test Step 4880 \"loss\" =  8.980885\n",
      "2018-08-30 06:28:01.876648 Training Step 4880 Finished Timing (Training: 0.911219, Test: 0.0821101) after 0.251192 seconds\n",
      "2018-08-30 06:28:01.876715 Training Step 4880 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:28:01.877214 Training Step 4880 \"loss\" =  3.1755154\n",
      "2018-08-30 06:28:02.080891 Test Step 4885 Finished\n",
      "2018-08-30 06:28:02.080978 Test Step 4885 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:28:02.081060 Test Step 4885 \"loss\" =  8.125794\n",
      "2018-08-30 06:28:02.127530 Training Step 4885 Finished Timing (Training: 0.911369, Test: 0.0820864) after 0.250015 seconds\n",
      "2018-08-30 06:28:02.127593 Training Step 4885 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:28:02.128050 Training Step 4885 \"loss\" =  3.2957923\n",
      "2018-08-30 06:28:02.331944 Test Step 4890 Finished\n",
      "2018-08-30 06:28:02.332042 Test Step 4890 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:28:02.332637 Test Step 4890 \"loss\" =  7.6931067\n",
      "2018-08-30 06:28:02.378773 Training Step 4890 Finished Timing (Training: 0.911297, Test: 0.0821118) after 0.250322 seconds\n",
      "2018-08-30 06:28:02.378944 Training Step 4890 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:28:02.378999 Training Step 4890 \"loss\" =  3.0928962\n",
      "2018-08-30 06:28:02.582639 Test Step 4895 Finished\n",
      "2018-08-30 06:28:02.582748 Test Step 4895 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:28:02.582814 Test Step 4895 \"loss\" =  7.400178\n",
      "2018-08-30 06:28:02.628963 Training Step 4895 Finished Timing (Training: 0.91146, Test: 0.082177) after 0.249898 seconds\n",
      "2018-08-30 06:28:02.629028 Training Step 4895 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:28:02.629630 Training Step 4895 \"loss\" =  3.3874981\n",
      "2018-08-30 06:28:02.834625 Test Step 4900 Finished\n",
      "2018-08-30 06:28:02.835013 Test Step 4900 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:28:02.835074 Test Step 4900 \"loss\" =  8.159687\n",
      "2018-08-30 06:28:02.881371 Training Step 4900 Finished Timing (Training: 0.911557, Test: 0.0821475) after 0.25167 seconds\n",
      "2018-08-30 06:28:02.881444 Training Step 4900 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:28:02.881496 Training Step 4900 \"loss\" =  3.1442742\n",
      "2018-08-30 06:28:03.085821 Test Step 4905 Finished\n",
      "2018-08-30 06:28:03.085910 Test Step 4905 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:28:03.086526 Test Step 4905 \"loss\" =  8.640578\n",
      "2018-08-30 06:28:03.132743 Training Step 4905 Finished Timing (Training: 0.914591, Test: 0.0822529) after 0.2504 seconds\n",
      "2018-08-30 06:28:03.132807 Training Step 4905 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:28:03.133355 Training Step 4905 \"loss\" =  2.9213936\n",
      "2018-08-30 06:28:03.338469 Test Step 4910 Finished\n",
      "2018-08-30 06:28:03.338556 Test Step 4910 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:28:03.339032 Test Step 4910 \"loss\" =  8.070307\n",
      "2018-08-30 06:28:03.384916 Training Step 4910 Finished Timing (Training: 0.91243, Test: 0.083132) after 0.251393 seconds\n",
      "2018-08-30 06:28:03.385058 Training Step 4910 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:28:03.385199 Training Step 4910 \"loss\" =  3.1816072\n",
      "2018-08-30 06:28:03.590010 Test Step 4915 Finished\n",
      "2018-08-30 06:28:03.590094 Test Step 4915 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:28:03.590733 Test Step 4915 \"loss\" =  8.665683\n",
      "2018-08-30 06:28:03.636601 Training Step 4915 Finished Timing (Training: 0.912616, Test: 0.0828349) after 0.251324 seconds\n",
      "2018-08-30 06:28:03.636666 Training Step 4915 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:28:03.636722 Training Step 4915 \"loss\" =  3.3037202\n",
      "2018-08-30 06:28:03.842261 Test Step 4920 Finished\n",
      "2018-08-30 06:28:03.842342 Test Step 4920 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:28:03.842405 Test Step 4920 \"loss\" =  8.210111\n",
      "2018-08-30 06:28:03.888180 Training Step 4920 Finished Timing (Training: 0.912054, Test: 0.0833612) after 0.250651 seconds\n",
      "2018-08-30 06:28:03.888249 Training Step 4920 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:28:03.888323 Training Step 4920 \"loss\" =  3.000118\n",
      "2018-08-30 06:28:04.092809 Test Step 4925 Finished\n",
      "2018-08-30 06:28:04.092892 Test Step 4925 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:28:04.092933 Test Step 4925 \"loss\" =  7.668201\n",
      "2018-08-30 06:28:04.138726 Training Step 4925 Finished Timing (Training: 0.912305, Test: 0.0831989) after 0.249717 seconds\n",
      "2018-08-30 06:28:04.139025 Training Step 4925 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:28:04.139324 Training Step 4925 \"loss\" =  3.0148175\n",
      "2018-08-30 06:28:04.343511 Test Step 4930 Finished\n",
      "2018-08-30 06:28:04.343847 Test Step 4930 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:28:04.344140 Test Step 4930 \"loss\" =  7.4916754\n",
      "2018-08-30 06:28:04.390085 Training Step 4930 Finished Timing (Training: 0.911975, Test: 0.0830536) after 0.250463 seconds\n",
      "2018-08-30 06:28:04.390344 Training Step 4930 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:28:04.390638 Training Step 4930 \"loss\" =  3.2868726\n",
      "2018-08-30 06:28:04.594723 Test Step 4935 Finished\n",
      "2018-08-30 06:28:04.595091 Test Step 4935 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:28:04.595386 Test Step 4935 \"loss\" =  8.619435\n",
      "2018-08-30 06:28:04.641456 Training Step 4935 Finished Timing (Training: 0.911498, Test: 0.0831955) after 0.250504 seconds\n",
      "2018-08-30 06:28:04.641765 Training Step 4935 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:28:04.642062 Training Step 4935 \"loss\" =  3.056533\n",
      "2018-08-30 06:28:04.845833 Test Step 4940 Finished\n",
      "2018-08-30 06:28:04.846187 Test Step 4940 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:28:04.846481 Test Step 4940 \"loss\" =  8.877543\n",
      "2018-08-30 06:28:04.892386 Training Step 4940 Finished Timing (Training: 0.911145, Test: 0.0832795) after 0.250024 seconds\n",
      "2018-08-30 06:28:04.892653 Training Step 4940 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:28:04.892966 Training Step 4940 \"loss\" =  3.5537143\n",
      "2018-08-30 06:28:05.096947 Test Step 4945 Finished\n",
      "2018-08-30 06:28:05.097331 Test Step 4945 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:28:05.097625 Test Step 4945 \"loss\" =  8.510361\n",
      "2018-08-30 06:28:05.143450 Training Step 4945 Finished Timing (Training: 0.911065, Test: 0.0831431) after 0.250162 seconds\n",
      "2018-08-30 06:28:05.143732 Training Step 4945 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:28:05.144026 Training Step 4945 \"loss\" =  3.26358\n",
      "2018-08-30 06:28:05.348067 Test Step 4950 Finished\n",
      "2018-08-30 06:28:05.348543 Test Step 4950 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:28:05.348843 Test Step 4950 \"loss\" =  8.052039\n",
      "2018-08-30 06:28:05.394922 Training Step 4950 Finished Timing (Training: 0.910955, Test: 0.0830526) after 0.250585 seconds\n",
      "2018-08-30 06:28:05.395191 Training Step 4950 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:28:05.395500 Training Step 4950 \"loss\" =  3.478089\n",
      "2018-08-30 06:28:05.599044 Test Step 4955 Finished\n",
      "2018-08-30 06:28:05.599383 Test Step 4955 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:28:05.599681 Test Step 4955 \"loss\" =  8.910504\n",
      "2018-08-30 06:28:05.645668 Training Step 4955 Finished Timing (Training: 0.910873, Test: 0.0830109) after 0.24987 seconds\n",
      "2018-08-30 06:28:05.645926 Training Step 4955 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:28:05.646225 Training Step 4955 \"loss\" =  3.1983082\n",
      "2018-08-30 06:28:05.850310 Test Step 4960 Finished\n",
      "2018-08-30 06:28:05.850650 Test Step 4960 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:28:05.850945 Test Step 4960 \"loss\" =  8.028136\n",
      "2018-08-30 06:28:05.897272 Training Step 4960 Finished Timing (Training: 0.910816, Test: 0.0829813) after 0.250749 seconds\n",
      "2018-08-30 06:28:05.897543 Training Step 4960 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:28:05.897891 Training Step 4960 \"loss\" =  3.3163464\n",
      "2018-08-30 06:28:06.101228 Test Step 4965 Finished\n",
      "2018-08-30 06:28:06.101597 Test Step 4965 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:28:06.101894 Test Step 4965 \"loss\" =  8.438829\n",
      "2018-08-30 06:28:06.148185 Training Step 4965 Finished Timing (Training: 0.910814, Test: 0.0828646) after 0.249958 seconds\n",
      "2018-08-30 06:28:06.148470 Training Step 4965 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:28:06.148792 Training Step 4965 \"loss\" =  3.1671216\n",
      "2018-08-30 06:28:06.352485 Test Step 4970 Finished\n",
      "2018-08-30 06:28:06.352942 Test Step 4970 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:28:06.353288 Test Step 4970 \"loss\" =  7.360592\n",
      "2018-08-30 06:28:06.399378 Training Step 4970 Finished Timing (Training: 0.910686, Test: 0.0828566) after 0.250283 seconds\n",
      "2018-08-30 06:28:06.399671 Training Step 4970 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:28:06.399970 Training Step 4970 \"loss\" =  3.135674\n",
      "2018-08-30 06:28:06.610795 Test Step 4975 Finished\n",
      "2018-08-30 06:28:06.611140 Test Step 4975 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:28:06.611441 Test Step 4975 \"loss\" =  7.790592\n",
      "2018-08-30 06:28:06.657339 Training Step 4975 Finished Timing (Training: 0.908869, Test: 0.0846226) after 0.25707 seconds\n",
      "2018-08-30 06:28:06.657620 Training Step 4975 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:28:06.657919 Training Step 4975 \"loss\" =  3.0682702\n",
      "2018-08-30 06:28:06.862355 Test Step 4980 Finished\n",
      "2018-08-30 06:28:06.862778 Test Step 4980 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:28:06.863079 Test Step 4980 \"loss\" =  7.8144054\n",
      "2018-08-30 06:28:06.908987 Training Step 4980 Finished Timing (Training: 0.908886, Test: 0.0845337) after 0.250765 seconds\n",
      "2018-08-30 06:28:06.909298 Training Step 4980 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:28:06.909627 Training Step 4980 \"loss\" =  3.2207243\n",
      "2018-08-30 06:28:07.113302 Test Step 4985 Finished\n",
      "2018-08-30 06:28:07.113674 Test Step 4985 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:28:07.113967 Test Step 4985 \"loss\" =  8.725709\n",
      "2018-08-30 06:28:07.159897 Training Step 4985 Finished Timing (Training: 0.908941, Test: 0.0844099) after 0.249941 seconds\n",
      "2018-08-30 06:28:07.160153 Training Step 4985 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:28:07.160446 Training Step 4985 \"loss\" =  3.2922013\n",
      "2018-08-30 06:28:07.364724 Test Step 4990 Finished\n",
      "2018-08-30 06:28:07.365083 Test Step 4990 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:28:07.365418 Test Step 4990 \"loss\" =  7.826119\n",
      "2018-08-30 06:28:07.411434 Training Step 4990 Finished Timing (Training: 0.908985, Test: 0.0843238) after 0.250693 seconds\n",
      "2018-08-30 06:28:07.411713 Training Step 4990 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:28:07.412015 Training Step 4990 \"loss\" =  3.1437237\n",
      "2018-08-30 06:28:07.615744 Test Step 4995 Finished\n",
      "2018-08-30 06:28:07.616113 Test Step 4995 \"min loss\" =  6.8407335\n",
      "2018-08-30 06:28:07.616413 Test Step 4995 \"loss\" =  8.497002\n",
      "2018-08-30 06:28:07.662787 Training Step 4995 Finished Timing (Training: 0.909062, Test: 0.0842088) after 0.250472 seconds\n",
      "2018-08-30 06:28:07.663045 Training Step 4995 \"min loss\" =  2.8312857\n",
      "2018-08-30 06:28:07.663340 Training Step 4995 \"loss\" =  3.193584\n",
      "2018-08-30 06:28:08.333812 Test Step 5000 Finished\n",
      "2018-08-30 06:28:08.334304 Training completed, starting cleanup!\n",
      "2018-08-30 06:28:08.334550 Cleanup completed!\n"
     ]
    }
   ],
   "source": [
    "class SA1Experiment():\n",
    "    def __init__(self, neurons, blocks):\n",
    "        self.blocks = blocks\n",
    "        self.neurons = neurons\n",
    "    \n",
    "    def create_network(self, net, input):\n",
    "        net.create_network(input)\n",
    "        \n",
    "#         net.make_reverse_auxilary_linkage_layer(0)\n",
    "#         net.make_auxilary_linkage_layer(0, with_act_func = False)\n",
    "        \n",
    "        net.make_embedding_layer(self.neurons)\n",
    "        net.make_dropout_layer()\n",
    "        \n",
    "        for _ in range(self.blocks):\n",
    "            net.make_graphcnn_layer(self.neurons)\n",
    "            net.make_dropout_layer()\n",
    "            net.make_embedding_layer(self.neurons)\n",
    "            net.make_dropout_layer()\n",
    "        \n",
    "#         net.make_auxilary_embedding_layer(self.neurons)\n",
    "#         net.make_dropout_layer(input_type = 'current_V_auxilary')\n",
    "        net.make_reverse_auxilary_linkage_layer(0)\n",
    "#         net.make_auxilary_embedding_layer(self.neurons)\n",
    "#         net.make_dropout_layer(input_type = 'current_V_auxilary')\n",
    "        net.make_auxilary_graphcnn_layer(self.neurons)\n",
    "        net.make_dropout_layer(input_type = 'current_V_auxilary')\n",
    "        net.make_auxilary_linkage_layer(0, with_act_func = False)\n",
    "        \n",
    "        net.make_embedding_layer(self.neurons)\n",
    "        net.make_embedding_layer(1, name='final', with_bn=False, with_act_func = False)\n",
    "\n",
    "\n",
    "no_folds = 5\n",
    "inst = KFold(n_splits = no_folds, shuffle=True, random_state=125)\n",
    "\n",
    "l = 2\n",
    "n = 128\n",
    "i = 4\n",
    "\n",
    "    \n",
    "exp = experiment.GGCNNExperiment('2018-08-28-SA1SA2', '2018-08-28-SA1SA2', SA1Experiment(neurons = n, blocks = l))\n",
    "\n",
    "\n",
    "exp.num_iterations = 5000\n",
    "exp.optimizer = 'adam'\n",
    "exp.loss_type = 'linear'\n",
    "\n",
    "exp.debug = True  # Was True\n",
    "\n",
    "exp.preprocess_data(dataset)\n",
    "\n",
    "# train_idx, test_idx = list(inst.split(np.arange(len(dataset[0]))))[i]\n",
    "test_idx, train_idx = list(inst.split(np.arange(len(dataset[0]))))[i]  # Reversed to get more samples in the test set than the training set\n",
    "\n",
    "\n",
    "exp.create_data(train_idx, test_idx)\n",
    "exp.build_network()\n",
    "results = exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(results[0])\n",
    "test_df = pd.DataFrame(results[1])\n",
    "test_df.set_index(test_df.index * exp.iterations_per_test, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_df['accuracy'].plot()\n",
    "test_df['accuracy'].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df['cross_entropy'].loc[10:].plot()\n",
    "test_df['cross_entropy'].loc[10:].plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.590785980224609\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_df['loss'].loc[500:].plot()\n",
    "test_df['loss'].loc[500:].plot()\n",
    "train_df['min loss'].loc[500:].plot()\n",
    "test_df['min loss'].loc[500:].plot()\n",
    "print(test_df['min loss'].iloc[-1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = results[-1].ravel()[test_idx]\n",
    "actual = dataset[2].ravel()[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max error:  23.590006734535194\n"
     ]
    }
   ],
   "source": [
    "plt.scatter(actual, predictions); plt.xlabel('Actual'); plt.ylabel('Predicted'); plt.show()\n",
    "print('Max error: ', np.max(np.abs(actual - predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(actual - predictions, bins = 80); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9720815239861504"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "sklearn.metrics.r2_score(predictions, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.       , 0.9916774],\n",
       "       [0.9916774, 1.       ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(predictions, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
