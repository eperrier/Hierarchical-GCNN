{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/tf-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/paperspace/anaconda3/envs/tf-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# %load runSA1SA2.py\n",
    "import ggcnn.experiment as experiment\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "def load_sa1_dataset():\n",
    "    keys_SA1 = []\n",
    "    features_SA1 = []\n",
    "    labels = []\n",
    "    keys_SA2 = []\n",
    "    features_SA2 = []\n",
    "    \n",
    "    # Load SA1 Node Features\n",
    "    with open('Data/2018-08-24-NSW-SA1Input-Normalised.csv', 'r') as file:\n",
    "        for i, line in enumerate(file):\n",
    "            if i == 0:  # Skip first line (header)\n",
    "                continue\n",
    "            s = line[:-1].split(',')  # Last value in line is \\n\n",
    "            keys_SA1.append(s[0])\n",
    "            features_SA1.extend([float(v) for v in s[1:-1]])  # Last column is the outcome y\n",
    "#             labels.append(np.floor(float(s[-1]) / 10).astype(int))\n",
    "            labels.append(float(s[-1]))\n",
    "    \n",
    "    \n",
    "    # Load SA2 Node Features\n",
    "    with open('Data/2018-08-28-NSW-SA2Input-Normalised.csv', 'r') as file:\n",
    "        for i, line in enumerate(file):\n",
    "            if i == 0:  # Skip first line (header)\n",
    "                continue\n",
    "            s = line[:-1].split(',')  # Last value in line is \\n\n",
    "            keys_SA2.append(s[0])\n",
    "            features_SA2.extend([float(v) for v in s[1:-1]])  # Last column is the outcome y\n",
    "\n",
    "    labels = np.array(labels)\n",
    "    features_SA1 = np.array(features_SA1).reshape((len(keys_SA1), -1))\n",
    "    features_SA2 = np.array(features_SA2).reshape((len(keys_SA2), -1))\n",
    "    \n",
    "    # Load SA1 Link Features\n",
    "    with open('Data/2018-08-25-NSW-NeighbourDistance.csv', 'r') as file:\n",
    "        adj_mat_SA1 = np.zeros((len(keys_SA1), len(keys_SA1)))\n",
    "        for i, line in enumerate(file):\n",
    "            if i == 0:  # Skip first line (header)\n",
    "                continue\n",
    "            s = line[:-1].split(',')\n",
    "            a = keys_SA1.index(s[0])\n",
    "            b = keys_SA1.index(s[1])\n",
    "            adj_mat_SA1[a, b] = 1\n",
    "            adj_mat_SA1[b, a] = 1\n",
    "    \n",
    "\n",
    "    # Load SA2 Link Features\n",
    "    with open('Data/Geography/2018-08-28-NSW-SA2_Neighbouring_Suburbs_With_Bridges-GCC.csv', 'r') as file:\n",
    "        adj_mat_SA2 = np.zeros((len(keys_SA2), len(keys_SA2)))\n",
    "        for i, line in enumerate(file):\n",
    "            if i == 0:  # Skip first line (header)\n",
    "                continue\n",
    "            s = line[:-1].split(',')\n",
    "            a = keys_SA2.index(s[0])\n",
    "            b = keys_SA2.index(s[1])\n",
    "            adj_mat_SA2[a, b] = 1\n",
    "            adj_mat_SA2[b, a] = 1\n",
    "    \n",
    "    \n",
    "    # Load SA1, SA2 Links\n",
    "    with open('Data/SA1SA2Links.csv', 'r') as file:\n",
    "        adj_mat_SA1SA2 = np.zeros((len(keys_SA1), len(keys_SA2)))\n",
    "        for i, line in enumerate(file):\n",
    "            if i == 0:  # Skip first line (header)\n",
    "                continue\n",
    "            s = line[:-1].split(',')\n",
    "            a = keys_SA1.index(s[0])\n",
    "            b = keys_SA2.index(s[1])\n",
    "            adj_mat_SA1SA2[a, b] = 1\n",
    "    \n",
    "    adj_mat_SA2SA1 = np.transpose(adj_mat_SA1SA2)\n",
    "    \n",
    "#     adj_mat_SA1SA2 = adj_mat_SA1SA2 / np.sum(adj_mat_SA1SA2, axis = -1, keepdims = True)\n",
    "#     adj_mat_SA2SA1 = adj_mat_SA2SA1 / np.sum(adj_mat_SA2SA1, axis = -1, keepdims = True)\n",
    "    \n",
    "    return features_SA1, adj_mat_SA1, labels, features_SA2, adj_mat_SA2, adj_mat_SA1SA2, adj_mat_SA2SA1\n",
    "\n",
    "dataset = load_sa1_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:16:20.789898 Creating training Tensorflow Tensors\n",
      "2018-08-29 09:16:20.790790 Creating training network\n",
      "2018-08-29 09:16:21.870937 Creating loss function and summaries\n",
      "2018-08-29 09:16:21.926543 Training model \"2018-08-28-SA1SA2\"!\n",
      "2018-08-29 09:16:21.926671 Preparing training\n",
      "2018-08-29 09:16:24.574191 Starting threads\n",
      "2018-08-29 09:16:24.574452 Starting training. train_batch_size: 0 test_batch_size: 0\n",
      "2018-08-29 09:16:25.166567 Test Step 0 Finished\n",
      "2018-08-29 09:16:25.166704 Test Step 0 \"min loss\" =  1.1789432e+21\n",
      "2018-08-29 09:16:25.166772 Test Step 0 \"loss\" =  1.1789432e+21\n",
      "2018-08-29 09:16:26.999297 Training Step 0 Finished Timing (Training: 0.756021, Test: 0.24385) after 2.42376 seconds\n",
      "2018-08-29 09:16:26.999429 Training Step 0 \"min loss\" =  2893.8071\n",
      "2018-08-29 09:16:26.999494 Training Step 0 \"loss\" =  2893.8071\n",
      "2018-08-29 09:16:27.201145 Test Step 5 Finished\n",
      "2018-08-29 09:16:27.201808 Test Step 5 \"min loss\" =  2778.2944\n",
      "2018-08-29 09:16:27.201905 Test Step 5 \"loss\" =  2778.2944\n",
      "2018-08-29 09:16:27.247367 Training Step 5 Finished Timing (Training: 0.912485, Test: 0.0840077) after 0.247769 seconds\n",
      "2018-08-29 09:16:27.247493 Training Step 5 \"min loss\" =  2846.399\n",
      "2018-08-29 09:16:27.247973 Training Step 5 \"loss\" =  2846.399\n",
      "2018-08-29 09:16:27.451069 Test Step 10 Finished\n",
      "2018-08-29 09:16:27.451646 Test Step 10 \"min loss\" =  2746.597\n",
      "2018-08-29 09:16:27.452315 Test Step 10 \"loss\" =  2746.597\n",
      "2018-08-29 09:16:27.497625 Training Step 10 Finished Timing (Training: 0.909891, Test: 0.0836643) after 0.249326 seconds\n",
      "2018-08-29 09:16:27.498105 Training Step 10 \"min loss\" =  2799.0427\n",
      "2018-08-29 09:16:27.498180 Training Step 10 \"loss\" =  2799.0427\n",
      "2018-08-29 09:16:27.700365 Test Step 15 Finished\n",
      "2018-08-29 09:16:27.700501 Test Step 15 \"min loss\" =  2707.5396\n",
      "2018-08-29 09:16:27.701267 Test Step 15 \"loss\" =  2707.5396\n",
      "2018-08-29 09:16:27.746252 Training Step 15 Finished Timing (Training: 0.908779, Test: 0.0841481) after 0.247602 seconds\n",
      "2018-08-29 09:16:27.746398 Training Step 15 \"min loss\" =  2744.236\n",
      "2018-08-29 09:16:27.746463 Training Step 15 \"loss\" =  2744.236\n",
      "2018-08-29 09:16:27.948543 Test Step 20 Finished\n",
      "2018-08-29 09:16:27.948726 Test Step 20 \"min loss\" =  2661.9858\n",
      "2018-08-29 09:16:27.948792 Test Step 20 \"loss\" =  2661.9858\n",
      "2018-08-29 09:16:27.994687 Training Step 20 Finished Timing (Training: 0.909398, Test: 0.0839417) after 0.247455 seconds\n",
      "2018-08-29 09:16:27.994846 Training Step 20 \"min loss\" =  2694.6418\n",
      "2018-08-29 09:16:27.994915 Training Step 20 \"loss\" =  2694.6418\n",
      "2018-08-29 09:16:28.205541 Test Step 25 Finished\n",
      "2018-08-29 09:16:28.205756 Test Step 25 \"min loss\" =  2601.5503\n",
      "2018-08-29 09:16:28.206464 Test Step 25 \"loss\" =  2601.5503\n",
      "2018-08-29 09:16:28.251754 Training Step 25 Finished Timing (Training: 0.902912, Test: 0.0896288) after 0.255415 seconds\n",
      "2018-08-29 09:16:28.251885 Training Step 25 \"min loss\" =  2646.7466\n",
      "2018-08-29 09:16:28.252367 Training Step 25 \"loss\" =  2646.7466\n",
      "2018-08-29 09:16:28.453766 Test Step 30 Finished\n",
      "2018-08-29 09:16:28.454290 Test Step 30 \"min loss\" =  2541.2207\n",
      "2018-08-29 09:16:28.454368 Test Step 30 \"loss\" =  2541.2207\n",
      "2018-08-29 09:16:28.500249 Training Step 30 Finished Timing (Training: 0.903908, Test: 0.0884356) after 0.247686 seconds\n",
      "2018-08-29 09:16:28.500395 Training Step 30 \"min loss\" =  2600.1313\n",
      "2018-08-29 09:16:28.500464 Training Step 30 \"loss\" =  2600.1313\n",
      "2018-08-29 09:16:28.702216 Test Step 35 Finished\n",
      "2018-08-29 09:16:28.702853 Test Step 35 \"min loss\" =  2482.9783\n",
      "2018-08-29 09:16:28.702929 Test Step 35 \"loss\" =  2482.9783\n",
      "2018-08-29 09:16:28.748754 Training Step 35 Finished Timing (Training: 0.904962, Test: 0.0878034) after 0.248202 seconds\n",
      "2018-08-29 09:16:28.748893 Training Step 35 \"min loss\" =  2553.879\n",
      "2018-08-29 09:16:28.749362 Training Step 35 \"loss\" =  2553.879\n",
      "2018-08-29 09:16:28.951117 Test Step 40 Finished\n",
      "2018-08-29 09:16:28.951294 Test Step 40 \"min loss\" =  2428.1035\n",
      "2018-08-29 09:16:28.951945 Test Step 40 \"loss\" =  2428.1035\n",
      "2018-08-29 09:16:28.997506 Training Step 40 Finished Timing (Training: 0.90507, Test: 0.0873528) after 0.247212 seconds\n",
      "2018-08-29 09:16:28.998085 Training Step 40 \"min loss\" =  2509.609\n",
      "2018-08-29 09:16:28.998539 Training Step 40 \"loss\" =  2509.609\n",
      "2018-08-29 09:16:29.199804 Test Step 45 Finished\n",
      "2018-08-29 09:16:29.199935 Test Step 45 \"min loss\" =  2380.7625\n",
      "2018-08-29 09:16:29.200483 Test Step 45 \"loss\" =  2380.7625\n",
      "2018-08-29 09:16:29.246062 Training Step 45 Finished Timing (Training: 0.905303, Test: 0.086827) after 0.247118 seconds\n",
      "2018-08-29 09:16:29.246211 Training Step 45 \"min loss\" =  2461.9294\n",
      "2018-08-29 09:16:29.246868 Training Step 45 \"loss\" =  2461.9294\n",
      "2018-08-29 09:16:29.448484 Test Step 50 Finished\n",
      "2018-08-29 09:16:29.449010 Test Step 50 \"min loss\" =  2336.4897\n",
      "2018-08-29 09:16:29.449857 Test Step 50 \"loss\" =  2336.4897\n",
      "2018-08-29 09:16:29.495548 Training Step 50 Finished Timing (Training: 0.905298, Test: 0.0865132) after 0.248592 seconds\n",
      "2018-08-29 09:16:29.495694 Training Step 50 \"min loss\" =  2416.7153\n",
      "2018-08-29 09:16:29.495786 Training Step 50 \"loss\" =  2416.7153\n",
      "2018-08-29 09:16:29.697429 Test Step 55 Finished\n",
      "2018-08-29 09:16:29.697556 Test Step 55 \"min loss\" =  2297.8647\n",
      "2018-08-29 09:16:29.698306 Test Step 55 \"loss\" =  2297.8647\n",
      "2018-08-29 09:16:29.743608 Training Step 55 Finished Timing (Training: 0.905398, Test: 0.0861375) after 0.246475 seconds\n",
      "2018-08-29 09:16:29.743740 Training Step 55 \"min loss\" =  2371.628\n",
      "2018-08-29 09:16:29.744189 Training Step 55 \"loss\" =  2371.628\n",
      "2018-08-29 09:16:29.946133 Test Step 60 Finished\n",
      "2018-08-29 09:16:29.946298 Test Step 60 \"min loss\" =  2262.9287\n",
      "2018-08-29 09:16:29.947265 Test Step 60 \"loss\" =  2262.9287\n",
      "2018-08-29 09:16:29.992544 Training Step 60 Finished Timing (Training: 0.905712, Test: 0.0858889) after 0.248268 seconds\n",
      "2018-08-29 09:16:29.992713 Training Step 60 \"min loss\" =  2325.5283\n",
      "2018-08-29 09:16:29.992779 Training Step 60 \"loss\" =  2325.5283\n",
      "2018-08-29 09:16:30.194572 Test Step 65 Finished\n",
      "2018-08-29 09:16:30.194712 Test Step 65 \"min loss\" =  2227.6836\n",
      "2018-08-29 09:16:30.194780 Test Step 65 \"loss\" =  2227.6836\n",
      "2018-08-29 09:16:30.240752 Training Step 65 Finished Timing (Training: 0.906375, Test: 0.0856712) after 0.24789 seconds\n",
      "2018-08-29 09:16:30.240880 Training Step 65 \"min loss\" =  2280.9392\n",
      "2018-08-29 09:16:30.240948 Training Step 65 \"loss\" =  2280.9392\n",
      "2018-08-29 09:16:30.445660 Test Step 70 Finished\n",
      "2018-08-29 09:16:30.445881 Test Step 70 \"min loss\" =  2192.8755\n",
      "2018-08-29 09:16:30.445952 Test Step 70 \"loss\" =  2192.8755\n",
      "2018-08-29 09:16:30.491806 Training Step 70 Finished Timing (Training: 0.906949, Test: 0.0854627) after 0.250764 seconds\n",
      "2018-08-29 09:16:30.491952 Training Step 70 \"min loss\" =  2239.3792\n",
      "2018-08-29 09:16:30.492030 Training Step 70 \"loss\" =  2239.3792\n",
      "2018-08-29 09:16:30.695503 Test Step 75 Finished\n",
      "2018-08-29 09:16:30.696174 Test Step 75 \"min loss\" =  2156.416\n",
      "2018-08-29 09:16:30.696559 Test Step 75 \"loss\" =  2156.416\n",
      "2018-08-29 09:16:30.742262 Training Step 75 Finished Timing (Training: 0.906831, Test: 0.0852825) after 0.248616 seconds\n",
      "2018-08-29 09:16:30.742437 Training Step 75 \"min loss\" =  2195.1196\n",
      "2018-08-29 09:16:30.742974 Training Step 75 \"loss\" =  2195.1196\n",
      "2018-08-29 09:16:30.945510 Test Step 80 Finished\n",
      "2018-08-29 09:16:30.945747 Test Step 80 \"min loss\" =  2115.809\n",
      "2018-08-29 09:16:30.945885 Test Step 80 \"loss\" =  2115.809\n",
      "2018-08-29 09:16:30.991443 Training Step 80 Finished Timing (Training: 0.906997, Test: 0.0851373) after 0.247871 seconds\n",
      "2018-08-29 09:16:30.991590 Training Step 80 \"min loss\" =  2151.6135\n",
      "2018-08-29 09:16:30.991655 Training Step 80 \"loss\" =  2151.6135\n",
      "2018-08-29 09:16:31.193499 Test Step 85 Finished\n",
      "2018-08-29 09:16:31.193625 Test Step 85 \"min loss\" =  2069.0361\n",
      "2018-08-29 09:16:31.194207 Test Step 85 \"loss\" =  2069.0361\n",
      "2018-08-29 09:16:31.239107 Training Step 85 Finished Timing (Training: 0.907129, Test: 0.0849938) after 0.246488 seconds\n",
      "2018-08-29 09:16:31.239281 Training Step 85 \"min loss\" =  2110.0618\n",
      "2018-08-29 09:16:31.239347 Training Step 85 \"loss\" =  2110.0618\n",
      "2018-08-29 09:16:31.441768 Test Step 90 Finished\n",
      "2018-08-29 09:16:31.442420 Test Step 90 \"min loss\" =  2025.3229\n",
      "2018-08-29 09:16:31.442512 Test Step 90 \"loss\" =  2025.3229\n",
      "2018-08-29 09:16:31.488303 Training Step 90 Finished Timing (Training: 0.907204, Test: 0.0849442) after 0.248878 seconds\n",
      "2018-08-29 09:16:31.488408 Training Step 90 \"min loss\" =  2068.155\n",
      "2018-08-29 09:16:31.488474 Training Step 90 \"loss\" =  2068.155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:16:31.689869 Test Step 95 Finished\n",
      "2018-08-29 09:16:31.689998 Test Step 95 \"min loss\" =  1984.066\n",
      "2018-08-29 09:16:31.690061 Test Step 95 \"loss\" =  1984.066\n",
      "2018-08-29 09:16:31.735880 Training Step 95 Finished Timing (Training: 0.90745, Test: 0.0848156) after 0.247328 seconds\n",
      "2018-08-29 09:16:31.736015 Training Step 95 \"min loss\" =  2025.1403\n",
      "2018-08-29 09:16:31.736080 Training Step 95 \"loss\" =  2025.1403\n",
      "2018-08-29 09:16:31.938559 Test Step 100 Finished\n",
      "2018-08-29 09:16:31.938687 Test Step 100 \"min loss\" =  1934.6302\n",
      "2018-08-29 09:16:31.939289 Test Step 100 \"loss\" =  1934.6302\n",
      "2018-08-29 09:16:31.984918 Training Step 100 Finished Timing (Training: 0.907475, Test: 0.0847074) after 0.24786 seconds\n",
      "2018-08-29 09:16:31.985044 Training Step 100 \"min loss\" =  1980.3411\n",
      "2018-08-29 09:16:31.985110 Training Step 100 \"loss\" =  1980.3411\n",
      "2018-08-29 09:16:32.185614 Test Step 105 Finished\n",
      "2018-08-29 09:16:32.186300 Test Step 105 \"min loss\" =  1887.2228\n",
      "2018-08-29 09:16:32.186378 Test Step 105 \"loss\" =  1887.2228\n",
      "2018-08-29 09:16:32.232764 Training Step 105 Finished Timing (Training: 0.912964, Test: 0.0834893) after 0.247561 seconds\n",
      "2018-08-29 09:16:32.232907 Training Step 105 \"min loss\" =  1936.4404\n",
      "2018-08-29 09:16:32.232981 Training Step 105 \"loss\" =  1936.4404\n",
      "2018-08-29 09:16:32.434527 Test Step 110 Finished\n",
      "2018-08-29 09:16:32.434725 Test Step 110 \"min loss\" =  1846.7335\n",
      "2018-08-29 09:16:32.435529 Test Step 110 \"loss\" =  1846.7335\n",
      "2018-08-29 09:16:32.480792 Training Step 110 Finished Timing (Training: 0.910404, Test: 0.0849211) after 0.247726 seconds\n",
      "2018-08-29 09:16:32.480928 Training Step 110 \"min loss\" =  1892.6537\n",
      "2018-08-29 09:16:32.481023 Training Step 110 \"loss\" =  1892.6537\n",
      "2018-08-29 09:16:32.683425 Test Step 115 Finished\n",
      "2018-08-29 09:16:32.683579 Test Step 115 \"min loss\" =  1803.3541\n",
      "2018-08-29 09:16:32.683691 Test Step 115 \"loss\" =  1803.3541\n",
      "2018-08-29 09:16:32.729185 Training Step 115 Finished Timing (Training: 0.910387, Test: 0.0855464) after 0.248072 seconds\n",
      "2018-08-29 09:16:32.729662 Training Step 115 \"min loss\" =  1850.7775\n",
      "2018-08-29 09:16:32.729737 Training Step 115 \"loss\" =  1850.7775\n",
      "2018-08-29 09:16:32.932241 Test Step 120 Finished\n",
      "2018-08-29 09:16:32.932463 Test Step 120 \"min loss\" =  1763.839\n",
      "2018-08-29 09:16:32.932585 Test Step 120 \"loss\" =  1763.839\n",
      "2018-08-29 09:16:32.978111 Training Step 120 Finished Timing (Training: 0.910149, Test: 0.0856264) after 0.248281 seconds\n",
      "2018-08-29 09:16:32.978300 Training Step 120 \"min loss\" =  1805.2607\n",
      "2018-08-29 09:16:32.978429 Training Step 120 \"loss\" =  1805.2607\n",
      "2018-08-29 09:16:33.181190 Test Step 125 Finished\n",
      "2018-08-29 09:16:33.181771 Test Step 125 \"min loss\" =  1722.7858\n",
      "2018-08-29 09:16:33.181886 Test Step 125 \"loss\" =  1722.7858\n",
      "2018-08-29 09:16:33.227077 Training Step 125 Finished Timing (Training: 0.910421, Test: 0.0851396) after 0.248511 seconds\n",
      "2018-08-29 09:16:33.227230 Training Step 125 \"min loss\" =  1760.5566\n",
      "2018-08-29 09:16:33.227295 Training Step 125 \"loss\" =  1760.5566\n",
      "2018-08-29 09:16:33.430068 Test Step 130 Finished\n",
      "2018-08-29 09:16:33.430579 Test Step 130 \"min loss\" =  1675.1063\n",
      "2018-08-29 09:16:33.431287 Test Step 130 \"loss\" =  1675.1063\n",
      "2018-08-29 09:16:33.476845 Training Step 130 Finished Timing (Training: 0.910162, Test: 0.0850233) after 0.24947 seconds\n",
      "2018-08-29 09:16:33.477325 Training Step 130 \"min loss\" =  1717.4843\n",
      "2018-08-29 09:16:33.477413 Training Step 130 \"loss\" =  1717.4843\n",
      "2018-08-29 09:16:33.679872 Test Step 135 Finished\n",
      "2018-08-29 09:16:33.680016 Test Step 135 \"min loss\" =  1630.7748\n",
      "2018-08-29 09:16:33.680090 Test Step 135 \"loss\" =  1630.7748\n",
      "2018-08-29 09:16:33.726523 Training Step 135 Finished Timing (Training: 0.910022, Test: 0.084643) after 0.249019 seconds\n",
      "2018-08-29 09:16:33.726686 Training Step 135 \"min loss\" =  1673.024\n",
      "2018-08-29 09:16:33.726763 Training Step 135 \"loss\" =  1673.024\n",
      "2018-08-29 09:16:33.929440 Test Step 140 Finished\n",
      "2018-08-29 09:16:33.930140 Test Step 140 \"min loss\" =  1591.171\n",
      "2018-08-29 09:16:33.930236 Test Step 140 \"loss\" =  1591.171\n",
      "2018-08-29 09:16:33.975528 Training Step 140 Finished Timing (Training: 0.910275, Test: 0.084431) after 0.248678 seconds\n",
      "2018-08-29 09:16:33.975665 Training Step 140 \"min loss\" =  1629.4158\n",
      "2018-08-29 09:16:33.975737 Training Step 140 \"loss\" =  1629.4158\n",
      "2018-08-29 09:16:34.178194 Test Step 145 Finished\n",
      "2018-08-29 09:16:34.178918 Test Step 145 \"min loss\" =  1549.933\n",
      "2018-08-29 09:16:34.179070 Test Step 145 \"loss\" =  1549.933\n",
      "2018-08-29 09:16:34.224540 Training Step 145 Finished Timing (Training: 0.910463, Test: 0.0842073) after 0.248688 seconds\n",
      "2018-08-29 09:16:34.224712 Training Step 145 \"min loss\" =  1583.9806\n",
      "2018-08-29 09:16:34.225219 Training Step 145 \"loss\" =  1583.9806\n",
      "2018-08-29 09:16:34.427170 Test Step 150 Finished\n",
      "2018-08-29 09:16:34.427314 Test Step 150 \"min loss\" =  1504.1378\n",
      "2018-08-29 09:16:34.427880 Test Step 150 \"loss\" =  1504.1378\n",
      "2018-08-29 09:16:34.473498 Training Step 150 Finished Timing (Training: 0.910238, Test: 0.0840826) after 0.247868 seconds\n",
      "2018-08-29 09:16:34.473697 Training Step 150 \"min loss\" =  1538.7953\n",
      "2018-08-29 09:16:34.473775 Training Step 150 \"loss\" =  1538.7953\n",
      "2018-08-29 09:16:34.676290 Test Step 155 Finished\n",
      "2018-08-29 09:16:34.676425 Test Step 155 \"min loss\" =  1455.9299\n",
      "2018-08-29 09:16:34.676548 Test Step 155 \"loss\" =  1455.9299\n",
      "2018-08-29 09:16:34.722850 Training Step 155 Finished Timing (Training: 0.909892, Test: 0.0841218) after 0.248253 seconds\n",
      "2018-08-29 09:16:34.723035 Training Step 155 \"min loss\" =  1492.5608\n",
      "2018-08-29 09:16:34.723144 Training Step 155 \"loss\" =  1492.5608\n",
      "2018-08-29 09:16:34.926832 Test Step 160 Finished\n",
      "2018-08-29 09:16:34.927481 Test Step 160 \"min loss\" =  1412.3495\n",
      "2018-08-29 09:16:34.927559 Test Step 160 \"loss\" =  1412.3495\n",
      "2018-08-29 09:16:34.973287 Training Step 160 Finished Timing (Training: 0.910014, Test: 0.0840779) after 0.250032 seconds\n",
      "2018-08-29 09:16:34.973724 Training Step 160 \"min loss\" =  1447.8055\n",
      "2018-08-29 09:16:34.973969 Training Step 160 \"loss\" =  1447.8055\n",
      "2018-08-29 09:16:35.177707 Test Step 165 Finished\n",
      "2018-08-29 09:16:35.178406 Test Step 165 \"min loss\" =  1361.9673\n",
      "2018-08-29 09:16:35.178669 Test Step 165 \"loss\" =  1361.9673\n",
      "2018-08-29 09:16:35.224363 Training Step 165 Finished Timing (Training: 0.909622, Test: 0.0841424) after 0.250011 seconds\n",
      "2018-08-29 09:16:35.224488 Training Step 165 \"min loss\" =  1404.3981\n",
      "2018-08-29 09:16:35.224575 Training Step 165 \"loss\" =  1404.3981\n",
      "2018-08-29 09:16:35.426431 Test Step 170 Finished\n",
      "2018-08-29 09:16:35.427083 Test Step 170 \"min loss\" =  1311.1038\n",
      "2018-08-29 09:16:35.427395 Test Step 170 \"loss\" =  1311.1038\n",
      "2018-08-29 09:16:35.472794 Training Step 170 Finished Timing (Training: 0.909652, Test: 0.0841114) after 0.24812 seconds\n",
      "2018-08-29 09:16:35.472947 Training Step 170 \"min loss\" =  1360.1892\n",
      "2018-08-29 09:16:35.473500 Training Step 170 \"loss\" =  1360.1892\n",
      "2018-08-29 09:16:35.675359 Test Step 175 Finished\n",
      "2018-08-29 09:16:35.675514 Test Step 175 \"min loss\" =  1264.3629\n",
      "2018-08-29 09:16:35.675580 Test Step 175 \"loss\" =  1264.3629\n",
      "2018-08-29 09:16:35.721846 Training Step 175 Finished Timing (Training: 0.909498, Test: 0.0840635) after 0.248205 seconds\n",
      "2018-08-29 09:16:35.721978 Training Step 175 \"min loss\" =  1315.9697\n",
      "2018-08-29 09:16:35.722047 Training Step 175 \"loss\" =  1315.9697\n",
      "2018-08-29 09:16:35.923895 Test Step 180 Finished\n",
      "2018-08-29 09:16:35.924051 Test Step 180 \"min loss\" =  1221.3479\n",
      "2018-08-29 09:16:35.924159 Test Step 180 \"loss\" =  1221.3479\n",
      "2018-08-29 09:16:35.969394 Training Step 180 Finished Timing (Training: 0.909631, Test: 0.0840177) after 0.246696 seconds\n",
      "2018-08-29 09:16:35.969541 Training Step 180 \"min loss\" =  1273.809\n",
      "2018-08-29 09:16:35.969610 Training Step 180 \"loss\" =  1273.809\n",
      "2018-08-29 09:16:36.171945 Test Step 185 Finished\n",
      "2018-08-29 09:16:36.172101 Test Step 185 \"min loss\" =  1187.4435\n",
      "2018-08-29 09:16:36.172176 Test Step 185 \"loss\" =  1187.4435\n",
      "2018-08-29 09:16:36.218331 Training Step 185 Finished Timing (Training: 0.909768, Test: 0.0841001) after 0.248642 seconds\n",
      "2018-08-29 09:16:36.218946 Training Step 185 \"min loss\" =  1228.355\n",
      "2018-08-29 09:16:36.219028 Training Step 185 \"loss\" =  1228.355\n",
      "2018-08-29 09:16:36.420592 Test Step 190 Finished\n",
      "2018-08-29 09:16:36.420759 Test Step 190 \"min loss\" =  1147.9457\n",
      "2018-08-29 09:16:36.420824 Test Step 190 \"loss\" =  1147.9457\n",
      "2018-08-29 09:16:36.467505 Training Step 190 Finished Timing (Training: 0.909626, Test: 0.0840244) after 0.248388 seconds\n",
      "2018-08-29 09:16:36.467647 Training Step 190 \"min loss\" =  1185.8365\n",
      "2018-08-29 09:16:36.468339 Training Step 190 \"loss\" =  1185.8365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:16:36.670704 Test Step 195 Finished\n",
      "2018-08-29 09:16:36.670836 Test Step 195 \"min loss\" =  1098.4591\n",
      "2018-08-29 09:16:36.671394 Test Step 195 \"loss\" =  1098.4591\n",
      "2018-08-29 09:16:36.717044 Training Step 195 Finished Timing (Training: 0.909449, Test: 0.0840952) after 0.248596 seconds\n",
      "2018-08-29 09:16:36.717217 Training Step 195 \"min loss\" =  1143.2319\n",
      "2018-08-29 09:16:36.717284 Training Step 195 \"loss\" =  1143.2319\n",
      "2018-08-29 09:16:36.920660 Test Step 200 Finished\n",
      "2018-08-29 09:16:36.920838 Test Step 200 \"min loss\" =  1057.8809\n",
      "2018-08-29 09:16:36.920914 Test Step 200 \"loss\" =  1057.8809\n",
      "2018-08-29 09:16:36.967168 Training Step 200 Finished Timing (Training: 0.909452, Test: 0.0840644) after 0.249796 seconds\n",
      "2018-08-29 09:16:36.967309 Training Step 200 \"min loss\" =  1099.8684\n",
      "2018-08-29 09:16:36.967412 Training Step 200 \"loss\" =  1099.8684\n",
      "2018-08-29 09:16:37.169294 Test Step 205 Finished\n",
      "2018-08-29 09:16:37.169427 Test Step 205 \"min loss\" =  1012.44995\n",
      "2018-08-29 09:16:37.169493 Test Step 205 \"loss\" =  1012.44995\n",
      "2018-08-29 09:16:37.215110 Training Step 205 Finished Timing (Training: 0.911804, Test: 0.0849157) after 0.247608 seconds\n",
      "2018-08-29 09:16:37.215261 Training Step 205 \"min loss\" =  1058.5082\n",
      "2018-08-29 09:16:37.215988 Training Step 205 \"loss\" =  1058.5082\n",
      "2018-08-29 09:16:37.418785 Test Step 210 Finished\n",
      "2018-08-29 09:16:37.419451 Test Step 210 \"min loss\" =  968.7445\n",
      "2018-08-29 09:16:37.419687 Test Step 210 \"loss\" =  968.7445\n",
      "2018-08-29 09:16:37.465778 Training Step 210 Finished Timing (Training: 0.909024, Test: 0.0842738) after 0.249704 seconds\n",
      "2018-08-29 09:16:37.465918 Training Step 210 \"min loss\" =  1015.8505\n",
      "2018-08-29 09:16:37.465986 Training Step 210 \"loss\" =  1015.8505\n",
      "2018-08-29 09:16:37.669245 Test Step 215 Finished\n",
      "2018-08-29 09:16:37.669918 Test Step 215 \"min loss\" =  920.153\n",
      "2018-08-29 09:16:37.670058 Test Step 215 \"loss\" =  920.153\n",
      "2018-08-29 09:16:37.715941 Training Step 215 Finished Timing (Training: 0.908131, Test: 0.0847276) after 0.249175 seconds\n",
      "2018-08-29 09:16:37.716086 Training Step 215 \"min loss\" =  975.78674\n",
      "2018-08-29 09:16:37.716203 Training Step 215 \"loss\" =  975.78674\n",
      "2018-08-29 09:16:37.918277 Test Step 220 Finished\n",
      "2018-08-29 09:16:37.918413 Test Step 220 \"min loss\" =  881.4374\n",
      "2018-08-29 09:16:37.919422 Test Step 220 \"loss\" =  881.4374\n",
      "2018-08-29 09:16:37.965265 Training Step 220 Finished Timing (Training: 0.908321, Test: 0.0844279) after 0.248939 seconds\n",
      "2018-08-29 09:16:37.965410 Training Step 220 \"min loss\" =  935.48175\n",
      "2018-08-29 09:16:37.965500 Training Step 220 \"loss\" =  935.48175\n",
      "2018-08-29 09:16:38.169443 Test Step 225 Finished\n",
      "2018-08-29 09:16:38.169609 Test Step 225 \"min loss\" =  840.7114\n",
      "2018-08-29 09:16:38.169685 Test Step 225 \"loss\" =  840.7114\n",
      "2018-08-29 09:16:38.216428 Training Step 225 Finished Timing (Training: 0.908777, Test: 0.0843606) after 0.250837 seconds\n",
      "2018-08-29 09:16:38.216664 Training Step 225 \"min loss\" =  896.6628\n",
      "2018-08-29 09:16:38.216785 Training Step 225 \"loss\" =  896.6628\n",
      "2018-08-29 09:16:38.420258 Test Step 230 Finished\n",
      "2018-08-29 09:16:38.421003 Test Step 230 \"min loss\" =  804.4707\n",
      "2018-08-29 09:16:38.421117 Test Step 230 \"loss\" =  804.4707\n",
      "2018-08-29 09:16:38.467118 Training Step 230 Finished Timing (Training: 0.909296, Test: 0.0840019) after 0.250204 seconds\n",
      "2018-08-29 09:16:38.467268 Training Step 230 \"min loss\" =  858.0505\n",
      "2018-08-29 09:16:38.467329 Training Step 230 \"loss\" =  858.0505\n",
      "2018-08-29 09:16:38.668972 Test Step 235 Finished\n",
      "2018-08-29 09:16:38.669526 Test Step 235 \"min loss\" =  769.3175\n",
      "2018-08-29 09:16:38.669642 Test Step 235 \"loss\" =  769.3175\n",
      "2018-08-29 09:16:38.715460 Training Step 235 Finished Timing (Training: 0.90935, Test: 0.083989) after 0.248036 seconds\n",
      "2018-08-29 09:16:38.715596 Training Step 235 \"min loss\" =  820.56885\n",
      "2018-08-29 09:16:38.715662 Training Step 235 \"loss\" =  820.56885\n",
      "2018-08-29 09:16:38.918860 Test Step 240 Finished\n",
      "2018-08-29 09:16:38.919038 Test Step 240 \"min loss\" =  734.8078\n",
      "2018-08-29 09:16:38.919103 Test Step 240 \"loss\" =  734.8078\n",
      "2018-08-29 09:16:38.965393 Training Step 240 Finished Timing (Training: 0.909578, Test: 0.0838377) after 0.248787 seconds\n",
      "2018-08-29 09:16:38.965526 Training Step 240 \"min loss\" =  784.08374\n",
      "2018-08-29 09:16:38.965619 Training Step 240 \"loss\" =  784.08374\n",
      "2018-08-29 09:16:39.167548 Test Step 245 Finished\n",
      "2018-08-29 09:16:39.167712 Test Step 245 \"min loss\" =  696.86115\n",
      "2018-08-29 09:16:39.168465 Test Step 245 \"loss\" =  696.86115\n",
      "2018-08-29 09:16:39.213684 Training Step 245 Finished Timing (Training: 0.909684, Test: 0.0838521) after 0.247977 seconds\n",
      "2018-08-29 09:16:39.213816 Training Step 245 \"min loss\" =  745.5522\n",
      "2018-08-29 09:16:39.214542 Training Step 245 \"loss\" =  745.5522\n",
      "2018-08-29 09:16:39.417690 Test Step 250 Finished\n",
      "2018-08-29 09:16:39.417833 Test Step 250 \"min loss\" =  659.0575\n",
      "2018-08-29 09:16:39.417892 Test Step 250 \"loss\" =  659.0575\n",
      "2018-08-29 09:16:39.463975 Training Step 250 Finished Timing (Training: 0.909929, Test: 0.083749) after 0.249342 seconds\n",
      "2018-08-29 09:16:39.464662 Training Step 250 \"min loss\" =  711.95\n",
      "2018-08-29 09:16:39.465064 Training Step 250 \"loss\" =  711.95\n",
      "2018-08-29 09:16:39.667538 Test Step 255 Finished\n",
      "2018-08-29 09:16:39.667704 Test Step 255 \"min loss\" =  625.61786\n",
      "2018-08-29 09:16:39.667776 Test Step 255 \"loss\" =  625.61786\n",
      "2018-08-29 09:16:39.713107 Training Step 255 Finished Timing (Training: 0.909991, Test: 0.0836295) after 0.247771 seconds\n",
      "2018-08-29 09:16:39.713238 Training Step 255 \"min loss\" =  676.68555\n",
      "2018-08-29 09:16:39.713301 Training Step 255 \"loss\" =  676.68555\n",
      "2018-08-29 09:16:39.914570 Test Step 260 Finished\n",
      "2018-08-29 09:16:39.915075 Test Step 260 \"min loss\" =  588.2305\n",
      "2018-08-29 09:16:39.915359 Test Step 260 \"loss\" =  588.2305\n",
      "2018-08-29 09:16:39.960723 Training Step 260 Finished Timing (Training: 0.910086, Test: 0.083588) after 0.247337 seconds\n",
      "2018-08-29 09:16:39.960870 Training Step 260 \"min loss\" =  643.26794\n",
      "2018-08-29 09:16:39.960974 Training Step 260 \"loss\" =  643.26794\n",
      "2018-08-29 09:16:40.162483 Test Step 265 Finished\n",
      "2018-08-29 09:16:40.162655 Test Step 265 \"min loss\" =  545.6641\n",
      "2018-08-29 09:16:40.162739 Test Step 265 \"loss\" =  545.6641\n",
      "2018-08-29 09:16:40.209223 Training Step 265 Finished Timing (Training: 0.910156, Test: 0.0836444) after 0.24816 seconds\n",
      "2018-08-29 09:16:40.209371 Training Step 265 \"min loss\" =  610.0647\n",
      "2018-08-29 09:16:40.209433 Training Step 265 \"loss\" =  610.0647\n",
      "2018-08-29 09:16:40.413214 Test Step 270 Finished\n",
      "2018-08-29 09:16:40.413831 Test Step 270 \"min loss\" =  521.5542\n",
      "2018-08-29 09:16:40.413906 Test Step 270 \"loss\" =  521.5542\n",
      "2018-08-29 09:16:40.459437 Training Step 270 Finished Timing (Training: 0.910169, Test: 0.0837592) after 0.24992 seconds\n",
      "2018-08-29 09:16:40.459584 Training Step 270 \"min loss\" =  579.8739\n",
      "2018-08-29 09:16:40.460288 Training Step 270 \"loss\" =  579.8739\n",
      "2018-08-29 09:16:40.662619 Test Step 275 Finished\n",
      "2018-08-29 09:16:40.662748 Test Step 275 \"min loss\" =  505.50684\n",
      "2018-08-29 09:16:40.663631 Test Step 275 \"loss\" =  505.50684\n",
      "2018-08-29 09:16:40.709406 Training Step 275 Finished Timing (Training: 0.910006, Test: 0.0836262) after 0.249023 seconds\n",
      "2018-08-29 09:16:40.709544 Training Step 275 \"min loss\" =  548.51483\n",
      "2018-08-29 09:16:40.709646 Training Step 275 \"loss\" =  548.51483\n",
      "2018-08-29 09:16:40.911201 Test Step 280 Finished\n",
      "2018-08-29 09:16:40.911330 Test Step 280 \"min loss\" =  477.78986\n",
      "2018-08-29 09:16:40.911425 Test Step 280 \"loss\" =  477.78986\n",
      "2018-08-29 09:16:40.958198 Training Step 280 Finished Timing (Training: 0.90999, Test: 0.083646) after 0.248436 seconds\n",
      "2018-08-29 09:16:40.958339 Training Step 280 \"min loss\" =  519.68976\n",
      "2018-08-29 09:16:40.958405 Training Step 280 \"loss\" =  519.68976\n",
      "2018-08-29 09:16:41.161067 Test Step 285 Finished\n",
      "2018-08-29 09:16:41.161211 Test Step 285 \"min loss\" =  448.9158\n",
      "2018-08-29 09:16:41.161288 Test Step 285 \"loss\" =  448.9158\n",
      "2018-08-29 09:16:41.208715 Training Step 285 Finished Timing (Training: 0.909611, Test: 0.0836023) after 0.248956 seconds\n",
      "2018-08-29 09:16:41.208857 Training Step 285 \"min loss\" =  491.3684\n",
      "2018-08-29 09:16:41.208922 Training Step 285 \"loss\" =  491.3684\n",
      "2018-08-29 09:16:41.412010 Test Step 290 Finished\n",
      "2018-08-29 09:16:41.412693 Test Step 290 \"min loss\" =  429.07635\n",
      "2018-08-29 09:16:41.412846 Test Step 290 \"loss\" =  429.07635\n",
      "2018-08-29 09:16:41.458904 Training Step 290 Finished Timing (Training: 0.909383, Test: 0.0836118) after 0.248546 seconds\n",
      "2018-08-29 09:16:41.459112 Training Step 290 \"min loss\" =  461.57315\n",
      "2018-08-29 09:16:41.459243 Training Step 290 \"loss\" =  461.57315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:16:41.661695 Test Step 295 Finished\n",
      "2018-08-29 09:16:41.661838 Test Step 295 \"min loss\" =  414.45932\n",
      "2018-08-29 09:16:41.661906 Test Step 295 \"loss\" =  414.45932\n",
      "2018-08-29 09:16:41.708269 Training Step 295 Finished Timing (Training: 0.909599, Test: 0.0835895) after 0.248873 seconds\n",
      "2018-08-29 09:16:41.708422 Training Step 295 \"min loss\" =  433.96906\n",
      "2018-08-29 09:16:41.709117 Training Step 295 \"loss\" =  433.96906\n",
      "2018-08-29 09:16:41.910802 Test Step 300 Finished\n",
      "2018-08-29 09:16:41.911289 Test Step 300 \"min loss\" =  393.45267\n",
      "2018-08-29 09:16:41.911534 Test Step 300 \"loss\" =  393.45267\n",
      "2018-08-29 09:16:41.957143 Training Step 300 Finished Timing (Training: 0.909585, Test: 0.0834993) after 0.247939 seconds\n",
      "2018-08-29 09:16:41.957289 Training Step 300 \"min loss\" =  409.7918\n",
      "2018-08-29 09:16:41.958041 Training Step 300 \"loss\" =  409.7918\n",
      "2018-08-29 09:16:42.159896 Test Step 305 Finished\n",
      "2018-08-29 09:16:42.160047 Test Step 305 \"min loss\" =  353.26785\n",
      "2018-08-29 09:16:42.160115 Test Step 305 \"loss\" =  353.26785\n",
      "2018-08-29 09:16:42.206687 Training Step 305 Finished Timing (Training: 0.908907, Test: 0.0846017) after 0.248557 seconds\n",
      "2018-08-29 09:16:42.207178 Training Step 305 \"min loss\" =  385.09525\n",
      "2018-08-29 09:16:42.207254 Training Step 305 \"loss\" =  385.09525\n",
      "2018-08-29 09:16:42.408983 Test Step 310 Finished\n",
      "2018-08-29 09:16:42.409514 Test Step 310 \"min loss\" =  327.56653\n",
      "2018-08-29 09:16:42.409587 Test Step 310 \"loss\" =  327.56653\n",
      "2018-08-29 09:16:42.455361 Training Step 310 Finished Timing (Training: 0.908932, Test: 0.0844119) after 0.247702 seconds\n",
      "2018-08-29 09:16:42.455870 Training Step 310 \"min loss\" =  361.05844\n",
      "2018-08-29 09:16:42.455968 Training Step 310 \"loss\" =  361.05844\n",
      "2018-08-29 09:16:42.657479 Test Step 315 Finished\n",
      "2018-08-29 09:16:42.658077 Test Step 315 \"min loss\" =  315.79178\n",
      "2018-08-29 09:16:42.658153 Test Step 315 \"loss\" =  315.79178\n",
      "2018-08-29 09:16:42.704078 Training Step 315 Finished Timing (Training: 0.909481, Test: 0.0840505) after 0.247991 seconds\n",
      "2018-08-29 09:16:42.704222 Training Step 315 \"min loss\" =  338.71823\n",
      "2018-08-29 09:16:42.704294 Training Step 315 \"loss\" =  338.71823\n",
      "2018-08-29 09:16:42.906912 Test Step 320 Finished\n",
      "2018-08-29 09:16:42.907059 Test Step 320 \"min loss\" =  292.03998\n",
      "2018-08-29 09:16:42.907918 Test Step 320 \"loss\" =  292.03998\n",
      "2018-08-29 09:16:42.953941 Training Step 320 Finished Timing (Training: 0.9079, Test: 0.083789) after 0.248255 seconds\n",
      "2018-08-29 09:16:42.954092 Training Step 320 \"min loss\" =  316.2377\n",
      "2018-08-29 09:16:42.954155 Training Step 320 \"loss\" =  316.2377\n",
      "2018-08-29 09:16:43.156612 Test Step 325 Finished\n",
      "2018-08-29 09:16:43.156774 Test Step 325 \"min loss\" =  271.42056\n",
      "2018-08-29 09:16:43.156847 Test Step 325 \"loss\" =  271.42056\n",
      "2018-08-29 09:16:43.202196 Training Step 325 Finished Timing (Training: 0.908169, Test: 0.0837159) after 0.246801 seconds\n",
      "2018-08-29 09:16:43.202340 Training Step 325 \"min loss\" =  297.30603\n",
      "2018-08-29 09:16:43.202406 Training Step 325 \"loss\" =  297.30603\n",
      "2018-08-29 09:16:43.404144 Test Step 330 Finished\n",
      "2018-08-29 09:16:43.404312 Test Step 330 \"min loss\" =  255.16222\n",
      "2018-08-29 09:16:43.404901 Test Step 330 \"loss\" =  255.16222\n",
      "2018-08-29 09:16:43.451187 Training Step 330 Finished Timing (Training: 0.908676, Test: 0.083559) after 0.248687 seconds\n",
      "2018-08-29 09:16:43.451744 Training Step 330 \"min loss\" =  278.54672\n",
      "2018-08-29 09:16:43.451839 Training Step 330 \"loss\" =  278.54672\n",
      "2018-08-29 09:16:43.654691 Test Step 335 Finished\n",
      "2018-08-29 09:16:43.655260 Test Step 335 \"min loss\" =  237.25844\n",
      "2018-08-29 09:16:43.655329 Test Step 335 \"loss\" =  237.25844\n",
      "2018-08-29 09:16:43.701029 Training Step 335 Finished Timing (Training: 0.908471, Test: 0.0834437) after 0.24848 seconds\n",
      "2018-08-29 09:16:43.701170 Training Step 335 \"min loss\" =  258.42514\n",
      "2018-08-29 09:16:43.701243 Training Step 335 \"loss\" =  258.42514\n",
      "2018-08-29 09:16:43.903840 Test Step 340 Finished\n",
      "2018-08-29 09:16:43.904312 Test Step 340 \"min loss\" =  217.983\n",
      "2018-08-29 09:16:43.904377 Test Step 340 \"loss\" =  217.983\n",
      "2018-08-29 09:16:43.949675 Training Step 340 Finished Timing (Training: 0.908566, Test: 0.0838788) after 0.248342 seconds\n",
      "2018-08-29 09:16:43.949802 Training Step 340 \"min loss\" =  242.81645\n",
      "2018-08-29 09:16:43.950614 Training Step 340 \"loss\" =  242.81645\n",
      "2018-08-29 09:16:44.152542 Test Step 345 Finished\n",
      "2018-08-29 09:16:44.152761 Test Step 345 \"min loss\" =  209.62529\n",
      "2018-08-29 09:16:44.152860 Test Step 345 \"loss\" =  209.62529\n",
      "2018-08-29 09:16:44.199454 Training Step 345 Finished Timing (Training: 0.90793, Test: 0.0841251) after 0.248746 seconds\n",
      "2018-08-29 09:16:44.199582 Training Step 345 \"min loss\" =  224.29579\n",
      "2018-08-29 09:16:44.200049 Training Step 345 \"loss\" =  224.29579\n",
      "2018-08-29 09:16:44.402246 Test Step 350 Finished\n",
      "2018-08-29 09:16:44.402742 Test Step 350 \"min loss\" =  195.72748\n",
      "2018-08-29 09:16:44.402809 Test Step 350 \"loss\" =  195.72748\n",
      "2018-08-29 09:16:44.449081 Training Step 350 Finished Timing (Training: 0.907941, Test: 0.0840114) after 0.248575 seconds\n",
      "2018-08-29 09:16:44.449230 Training Step 350 \"min loss\" =  207.70877\n",
      "2018-08-29 09:16:44.449327 Training Step 350 \"loss\" =  207.70877\n",
      "2018-08-29 09:16:44.651158 Test Step 355 Finished\n",
      "2018-08-29 09:16:44.651811 Test Step 355 \"min loss\" =  186.08362\n",
      "2018-08-29 09:16:44.651884 Test Step 355 \"loss\" =  186.08362\n",
      "2018-08-29 09:16:44.697667 Training Step 355 Finished Timing (Training: 0.908118, Test: 0.0839036) after 0.248259 seconds\n",
      "2018-08-29 09:16:44.697797 Training Step 355 \"min loss\" =  192.31029\n",
      "2018-08-29 09:16:44.697872 Training Step 355 \"loss\" =  192.31029\n",
      "2018-08-29 09:16:44.898857 Test Step 360 Finished\n",
      "2018-08-29 09:16:44.899047 Test Step 360 \"min loss\" =  180.81696\n",
      "2018-08-29 09:16:44.899208 Test Step 360 \"loss\" =  180.81696\n",
      "2018-08-29 09:16:44.945257 Training Step 360 Finished Timing (Training: 0.908232, Test: 0.0838844) after 0.247301 seconds\n",
      "2018-08-29 09:16:44.945408 Training Step 360 \"min loss\" =  179.11154\n",
      "2018-08-29 09:16:44.945508 Training Step 360 \"loss\" =  179.11154\n",
      "2018-08-29 09:16:45.146382 Test Step 365 Finished\n",
      "2018-08-29 09:16:45.146536 Test Step 365 \"min loss\" =  163.05843\n",
      "2018-08-29 09:16:45.147601 Test Step 365 \"loss\" =  163.05843\n",
      "2018-08-29 09:16:45.193338 Training Step 365 Finished Timing (Training: 0.908156, Test: 0.0838214) after 0.247039 seconds\n",
      "2018-08-29 09:16:45.193500 Training Step 365 \"min loss\" =  165.85223\n",
      "2018-08-29 09:16:45.193588 Training Step 365 \"loss\" =  165.85223\n",
      "2018-08-29 09:16:45.393947 Test Step 370 Finished\n",
      "2018-08-29 09:16:45.394613 Test Step 370 \"min loss\" =  137.31438\n",
      "2018-08-29 09:16:45.394715 Test Step 370 \"loss\" =  137.31438\n",
      "2018-08-29 09:16:45.439783 Training Step 370 Finished Timing (Training: 0.908222, Test: 0.0837816) after 0.24545 seconds\n",
      "2018-08-29 09:16:45.439910 Training Step 370 \"min loss\" =  153.64224\n",
      "2018-08-29 09:16:45.440015 Training Step 370 \"loss\" =  153.64224\n",
      "2018-08-29 09:16:45.641202 Test Step 375 Finished\n",
      "2018-08-29 09:16:45.641334 Test Step 375 \"min loss\" =  133.51172\n",
      "2018-08-29 09:16:45.642106 Test Step 375 \"loss\" =  133.51172\n",
      "2018-08-29 09:16:45.687218 Training Step 375 Finished Timing (Training: 0.908339, Test: 0.0837321) after 0.247121 seconds\n",
      "2018-08-29 09:16:45.687355 Training Step 375 \"min loss\" =  141.83813\n",
      "2018-08-29 09:16:45.688089 Training Step 375 \"loss\" =  141.83813\n",
      "2018-08-29 09:16:45.887838 Test Step 380 Finished\n",
      "2018-08-29 09:16:45.888371 Test Step 380 \"min loss\" =  128.78413\n",
      "2018-08-29 09:16:45.888608 Test Step 380 \"loss\" =  128.78413\n",
      "2018-08-29 09:16:45.933709 Training Step 380 Finished Timing (Training: 0.908242, Test: 0.0836813) after 0.245126 seconds\n",
      "2018-08-29 09:16:45.933843 Training Step 380 \"min loss\" =  130.62222\n",
      "2018-08-29 09:16:45.934534 Training Step 380 \"loss\" =  130.62222\n",
      "2018-08-29 09:16:46.134757 Test Step 385 Finished\n",
      "2018-08-29 09:16:46.134887 Test Step 385 \"min loss\" =  116.45545\n",
      "2018-08-29 09:16:46.135663 Test Step 385 \"loss\" =  116.45545\n",
      "2018-08-29 09:16:46.180997 Training Step 385 Finished Timing (Training: 0.908213, Test: 0.0836221) after 0.246367 seconds\n",
      "2018-08-29 09:16:46.181453 Training Step 385 \"min loss\" =  121.0468\n",
      "2018-08-29 09:16:46.181530 Training Step 385 \"loss\" =  121.0468\n",
      "2018-08-29 09:16:46.382248 Test Step 390 Finished\n",
      "2018-08-29 09:16:46.382386 Test Step 390 \"min loss\" =  104.8157\n",
      "2018-08-29 09:16:46.382512 Test Step 390 \"loss\" =  104.8157\n",
      "2018-08-29 09:16:46.428428 Training Step 390 Finished Timing (Training: 0.90848, Test: 0.0835836) after 0.246818 seconds\n",
      "2018-08-29 09:16:46.428651 Training Step 390 \"min loss\" =  110.89346\n",
      "2018-08-29 09:16:46.428818 Training Step 390 \"loss\" =  110.89346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:16:46.629697 Test Step 395 Finished\n",
      "2018-08-29 09:16:46.629894 Test Step 395 \"min loss\" =  102.331085\n",
      "2018-08-29 09:16:46.630465 Test Step 395 \"loss\" =  102.331085\n",
      "2018-08-29 09:16:46.675683 Training Step 395 Finished Timing (Training: 0.908534, Test: 0.0836306) after 0.246719 seconds\n",
      "2018-08-29 09:16:46.675812 Training Step 395 \"min loss\" =  102.65161\n",
      "2018-08-29 09:16:46.675868 Training Step 395 \"loss\" =  102.65161\n",
      "2018-08-29 09:16:46.877706 Test Step 400 Finished\n",
      "2018-08-29 09:16:46.877847 Test Step 400 \"min loss\" =  96.018456\n",
      "2018-08-29 09:16:46.878669 Test Step 400 \"loss\" =  96.018456\n",
      "2018-08-29 09:16:46.923712 Training Step 400 Finished Timing (Training: 0.908527, Test: 0.0835651) after 0.246805 seconds\n",
      "2018-08-29 09:16:46.923881 Training Step 400 \"min loss\" =  94.54978\n",
      "2018-08-29 09:16:46.924518 Training Step 400 \"loss\" =  94.54978\n",
      "2018-08-29 09:16:47.125288 Test Step 405 Finished\n",
      "2018-08-29 09:16:47.125890 Test Step 405 \"min loss\" =  94.55837\n",
      "2018-08-29 09:16:47.125965 Test Step 405 \"loss\" =  94.55837\n",
      "2018-08-29 09:16:47.170938 Training Step 405 Finished Timing (Training: 0.913322, Test: 0.0834186) after 0.24633 seconds\n",
      "2018-08-29 09:16:47.171083 Training Step 405 \"min loss\" =  86.82415\n",
      "2018-08-29 09:16:47.171151 Training Step 405 \"loss\" =  86.82415\n",
      "2018-08-29 09:16:47.373335 Test Step 410 Finished\n",
      "2018-08-29 09:16:47.373991 Test Step 410 \"min loss\" =  78.48169\n",
      "2018-08-29 09:16:47.374068 Test Step 410 \"loss\" =  78.48169\n",
      "2018-08-29 09:16:47.420523 Training Step 410 Finished Timing (Training: 0.908614, Test: 0.0845716) after 0.248542 seconds\n",
      "2018-08-29 09:16:47.421102 Training Step 410 \"min loss\" =  81.078835\n",
      "2018-08-29 09:16:47.421214 Training Step 410 \"loss\" =  81.078835\n",
      "2018-08-29 09:16:47.622210 Test Step 415 Finished\n",
      "2018-08-29 09:16:47.622398 Test Step 415 \"min loss\" =  72.13258\n",
      "2018-08-29 09:16:47.622478 Test Step 415 \"loss\" =  72.13258\n",
      "2018-08-29 09:16:47.668814 Training Step 415 Finished Timing (Training: 0.909829, Test: 0.0840493) after 0.247509 seconds\n",
      "2018-08-29 09:16:47.668968 Training Step 415 \"min loss\" =  72.64055\n",
      "2018-08-29 09:16:47.669035 Training Step 415 \"loss\" =  72.64055\n",
      "2018-08-29 09:16:47.869581 Test Step 420 Finished\n",
      "2018-08-29 09:16:47.870212 Test Step 420 \"min loss\" =  72.13258\n",
      "2018-08-29 09:16:47.870341 Test Step 420 \"loss\" =  74.17687\n",
      "2018-08-29 09:16:47.915733 Training Step 420 Finished Timing (Training: 0.910173, Test: 0.0838665) after 0.246588 seconds\n",
      "2018-08-29 09:16:47.915862 Training Step 420 \"min loss\" =  66.52358\n",
      "2018-08-29 09:16:47.916426 Training Step 420 \"loss\" =  66.52358\n",
      "2018-08-29 09:16:48.118249 Test Step 425 Finished\n",
      "2018-08-29 09:16:48.118401 Test Step 425 \"min loss\" =  70.35782\n",
      "2018-08-29 09:16:48.119508 Test Step 425 \"loss\" =  70.35782\n",
      "2018-08-29 09:16:48.164620 Training Step 425 Finished Timing (Training: 0.909394, Test: 0.0839629) after 0.248098 seconds\n",
      "2018-08-29 09:16:48.164866 Training Step 425 \"min loss\" =  63.18749\n",
      "2018-08-29 09:16:48.164998 Training Step 425 \"loss\" =  63.18749\n",
      "2018-08-29 09:16:48.365176 Test Step 430 Finished\n",
      "2018-08-29 09:16:48.365696 Test Step 430 \"min loss\" =  60.772247\n",
      "2018-08-29 09:16:48.365941 Test Step 430 \"loss\" =  60.772247\n",
      "2018-08-29 09:16:48.410934 Training Step 430 Finished Timing (Training: 0.909719, Test: 0.0838219) after 0.245846 seconds\n",
      "2018-08-29 09:16:48.411062 Training Step 430 \"min loss\" =  57.629936\n",
      "2018-08-29 09:16:48.411825 Training Step 430 \"loss\" =  57.629936\n",
      "2018-08-29 09:16:48.611299 Test Step 435 Finished\n",
      "2018-08-29 09:16:48.611460 Test Step 435 \"min loss\" =  59.597065\n",
      "2018-08-29 09:16:48.611525 Test Step 435 \"loss\" =  59.597065\n",
      "2018-08-29 09:16:48.656539 Training Step 435 Finished Timing (Training: 0.909801, Test: 0.0837155) after 0.244307 seconds\n",
      "2018-08-29 09:16:48.656735 Training Step 435 \"min loss\" =  52.787796\n",
      "2018-08-29 09:16:48.657550 Training Step 435 \"loss\" =  52.80282\n",
      "2018-08-29 09:16:48.858654 Test Step 440 Finished\n",
      "2018-08-29 09:16:48.858819 Test Step 440 \"min loss\" =  54.247227\n",
      "2018-08-29 09:16:48.858893 Test Step 440 \"loss\" =  54.247227\n",
      "2018-08-29 09:16:48.903865 Training Step 440 Finished Timing (Training: 0.909555, Test: 0.0836879) after 0.245546 seconds\n",
      "2018-08-29 09:16:48.904336 Training Step 440 \"min loss\" =  49.170094\n",
      "2018-08-29 09:16:48.904607 Training Step 440 \"loss\" =  49.375496\n",
      "2018-08-29 09:16:49.104405 Test Step 445 Finished\n",
      "2018-08-29 09:16:49.104568 Test Step 445 \"min loss\" =  50.88498\n",
      "2018-08-29 09:16:49.105250 Test Step 445 \"loss\" =  50.88498\n",
      "2018-08-29 09:16:49.150437 Training Step 445 Finished Timing (Training: 0.909503, Test: 0.0836786) after 0.245744 seconds\n",
      "2018-08-29 09:16:49.150574 Training Step 445 \"min loss\" =  44.67042\n",
      "2018-08-29 09:16:49.150649 Training Step 445 \"loss\" =  44.67042\n",
      "2018-08-29 09:16:49.350698 Test Step 450 Finished\n",
      "2018-08-29 09:16:49.350840 Test Step 450 \"min loss\" =  46.479893\n",
      "2018-08-29 09:16:49.350907 Test Step 450 \"loss\" =  46.479893\n",
      "2018-08-29 09:16:49.395543 Training Step 450 Finished Timing (Training: 0.909928, Test: 0.0836664) after 0.244787 seconds\n",
      "2018-08-29 09:16:49.395684 Training Step 450 \"min loss\" =  39.863625\n",
      "2018-08-29 09:16:49.395749 Training Step 450 \"loss\" =  39.863625\n",
      "2018-08-29 09:16:49.597044 Test Step 455 Finished\n",
      "2018-08-29 09:16:49.597675 Test Step 455 \"min loss\" =  46.479893\n",
      "2018-08-29 09:16:49.598152 Test Step 455 \"loss\" =  46.492344\n",
      "2018-08-29 09:16:49.643510 Training Step 455 Finished Timing (Training: 0.909548, Test: 0.0837657) after 0.246843 seconds\n",
      "2018-08-29 09:16:49.643644 Training Step 455 \"min loss\" =  37.85793\n",
      "2018-08-29 09:16:49.643728 Training Step 455 \"loss\" =  38.470207\n",
      "2018-08-29 09:16:49.845216 Test Step 460 Finished\n",
      "2018-08-29 09:16:49.845862 Test Step 460 \"min loss\" =  44.18618\n",
      "2018-08-29 09:16:49.845953 Test Step 460 \"loss\" =  44.18618\n",
      "2018-08-29 09:16:49.890996 Training Step 460 Finished Timing (Training: 0.909447, Test: 0.0836817) after 0.246144 seconds\n",
      "2018-08-29 09:16:49.891171 Training Step 460 \"min loss\" =  34.20177\n",
      "2018-08-29 09:16:49.891243 Training Step 460 \"loss\" =  34.20177\n",
      "2018-08-29 09:16:50.092717 Test Step 465 Finished\n",
      "2018-08-29 09:16:50.092863 Test Step 465 \"min loss\" =  42.35935\n",
      "2018-08-29 09:16:50.092944 Test Step 465 \"loss\" =  42.35935\n",
      "2018-08-29 09:16:50.138749 Training Step 465 Finished Timing (Training: 0.90923, Test: 0.0836581) after 0.246402 seconds\n",
      "2018-08-29 09:16:50.138903 Training Step 465 \"min loss\" =  30.744404\n",
      "2018-08-29 09:16:50.139503 Training Step 465 \"loss\" =  30.744404\n",
      "2018-08-29 09:16:50.340835 Test Step 470 Finished\n",
      "2018-08-29 09:16:50.340990 Test Step 470 \"min loss\" =  39.623722\n",
      "2018-08-29 09:16:50.341741 Test Step 470 \"loss\" =  39.623722\n",
      "2018-08-29 09:16:50.386706 Training Step 470 Finished Timing (Training: 0.909196, Test: 0.0836027) after 0.246917 seconds\n",
      "2018-08-29 09:16:50.386840 Training Step 470 \"min loss\" =  30.146544\n",
      "2018-08-29 09:16:50.386911 Training Step 470 \"loss\" =  30.146544\n",
      "2018-08-29 09:16:50.589233 Test Step 475 Finished\n",
      "2018-08-29 09:16:50.589396 Test Step 475 \"min loss\" =  35.868156\n",
      "2018-08-29 09:16:50.589991 Test Step 475 \"loss\" =  35.868156\n",
      "2018-08-29 09:16:50.635457 Training Step 475 Finished Timing (Training: 0.909041, Test: 0.0836635) after 0.247781 seconds\n",
      "2018-08-29 09:16:50.635599 Training Step 475 \"min loss\" =  27.694038\n",
      "2018-08-29 09:16:50.635663 Training Step 475 \"loss\" =  29.071\n",
      "2018-08-29 09:16:50.837732 Test Step 480 Finished\n",
      "2018-08-29 09:16:50.837882 Test Step 480 \"min loss\" =  33.98298\n",
      "2018-08-29 09:16:50.838516 Test Step 480 \"loss\" =  33.98298\n",
      "2018-08-29 09:16:50.883721 Training Step 480 Finished Timing (Training: 0.909053, Test: 0.083796) after 0.247928 seconds\n",
      "2018-08-29 09:16:50.883864 Training Step 480 \"min loss\" =  25.704218\n",
      "2018-08-29 09:16:50.883927 Training Step 480 \"loss\" =  25.704218\n",
      "2018-08-29 09:16:51.084379 Test Step 485 Finished\n",
      "2018-08-29 09:16:51.084526 Test Step 485 \"min loss\" =  33.98298\n",
      "2018-08-29 09:16:51.084657 Test Step 485 \"loss\" =  37.07599\n",
      "2018-08-29 09:16:51.131135 Training Step 485 Finished Timing (Training: 0.909301, Test: 0.0838023) after 0.247126 seconds\n",
      "2018-08-29 09:16:51.131277 Training Step 485 \"min loss\" =  23.206171\n",
      "2018-08-29 09:16:51.131362 Training Step 485 \"loss\" =  23.206171\n",
      "2018-08-29 09:16:51.331433 Test Step 490 Finished\n",
      "2018-08-29 09:16:51.331601 Test Step 490 \"min loss\" =  33.98298\n",
      "2018-08-29 09:16:51.331672 Test Step 490 \"loss\" =  35.276577\n",
      "2018-08-29 09:16:51.377773 Training Step 490 Finished Timing (Training: 0.909295, Test: 0.0837949) after 0.246307 seconds\n",
      "2018-08-29 09:16:51.377925 Training Step 490 \"min loss\" =  22.330774\n",
      "2018-08-29 09:16:51.377995 Training Step 490 \"loss\" =  22.330774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:16:51.579557 Test Step 495 Finished\n",
      "2018-08-29 09:16:51.579795 Test Step 495 \"min loss\" =  33.98298\n",
      "2018-08-29 09:16:51.579919 Test Step 495 \"loss\" =  35.405598\n",
      "2018-08-29 09:16:51.625106 Training Step 495 Finished Timing (Training: 0.909354, Test: 0.0839116) after 0.24702 seconds\n",
      "2018-08-29 09:16:51.625253 Training Step 495 \"min loss\" =  20.47143\n",
      "2018-08-29 09:16:51.625980 Training Step 495 \"loss\" =  20.47143\n",
      "2018-08-29 09:16:51.827139 Test Step 500 Finished\n",
      "2018-08-29 09:16:51.827277 Test Step 500 \"min loss\" =  31.702091\n",
      "2018-08-29 09:16:51.827346 Test Step 500 \"loss\" =  31.702091\n",
      "2018-08-29 09:16:51.872958 Training Step 500 Finished Timing (Training: 0.909147, Test: 0.0839398) after 0.246512 seconds\n",
      "2018-08-29 09:16:51.873081 Training Step 500 \"min loss\" =  18.734343\n",
      "2018-08-29 09:16:51.873698 Training Step 500 \"loss\" =  18.734343\n",
      "2018-08-29 09:16:52.074290 Test Step 505 Finished\n",
      "2018-08-29 09:16:52.074871 Test Step 505 \"min loss\" =  29.495544\n",
      "2018-08-29 09:16:52.075121 Test Step 505 \"loss\" =  29.495544\n",
      "2018-08-29 09:16:52.120652 Training Step 505 Finished Timing (Training: 0.91346, Test: 0.0825794) after 0.246481 seconds\n",
      "2018-08-29 09:16:52.120803 Training Step 505 \"min loss\" =  17.639526\n",
      "2018-08-29 09:16:52.121311 Training Step 505 \"loss\" =  17.639526\n",
      "2018-08-29 09:16:52.322411 Test Step 510 Finished\n",
      "2018-08-29 09:16:52.322558 Test Step 510 \"min loss\" =  29.495544\n",
      "2018-08-29 09:16:52.323341 Test Step 510 \"loss\" =  30.781528\n",
      "2018-08-29 09:16:52.368999 Training Step 510 Finished Timing (Training: 0.909101, Test: 0.083645) after 0.247296 seconds\n",
      "2018-08-29 09:16:52.369146 Training Step 510 \"min loss\" =  17.639526\n",
      "2018-08-29 09:16:52.369843 Training Step 510 \"loss\" =  18.481663\n",
      "2018-08-29 09:16:52.571192 Test Step 515 Finished\n",
      "2018-08-29 09:16:52.571393 Test Step 515 \"min loss\" =  29.495544\n",
      "2018-08-29 09:16:52.571507 Test Step 515 \"loss\" =  30.64377\n",
      "2018-08-29 09:16:52.616646 Training Step 515 Finished Timing (Training: 0.909462, Test: 0.0837804) after 0.246714 seconds\n",
      "2018-08-29 09:16:52.616776 Training Step 515 \"min loss\" =  16.174633\n",
      "2018-08-29 09:16:52.616856 Training Step 515 \"loss\" =  16.174633\n",
      "2018-08-29 09:16:52.817820 Test Step 520 Finished\n",
      "2018-08-29 09:16:52.817951 Test Step 520 \"min loss\" =  26.945345\n",
      "2018-08-29 09:16:52.818672 Test Step 520 \"loss\" =  26.945345\n",
      "2018-08-29 09:16:52.863856 Training Step 520 Finished Timing (Training: 0.909555, Test: 0.0835583) after 0.24645 seconds\n",
      "2018-08-29 09:16:52.863984 Training Step 520 \"min loss\" =  15.874894\n",
      "2018-08-29 09:16:52.864075 Training Step 520 \"loss\" =  15.874894\n",
      "2018-08-29 09:16:53.065474 Test Step 525 Finished\n",
      "2018-08-29 09:16:53.066136 Test Step 525 \"min loss\" =  26.945345\n",
      "2018-08-29 09:16:53.066224 Test Step 525 \"loss\" =  29.625196\n",
      "2018-08-29 09:16:53.111914 Training Step 525 Finished Timing (Training: 0.90906, Test: 0.0834611) after 0.246499 seconds\n",
      "2018-08-29 09:16:53.112043 Training Step 525 \"min loss\" =  14.525947\n",
      "2018-08-29 09:16:53.112106 Training Step 525 \"loss\" =  14.525947\n",
      "2018-08-29 09:16:53.312953 Test Step 530 Finished\n",
      "2018-08-29 09:16:53.313147 Test Step 530 \"min loss\" =  26.945345\n",
      "2018-08-29 09:16:53.313268 Test Step 530 \"loss\" =  28.37018\n",
      "2018-08-29 09:16:53.358373 Training Step 530 Finished Timing (Training: 0.909199, Test: 0.0834593) after 0.245305 seconds\n",
      "2018-08-29 09:16:53.358502 Training Step 530 \"min loss\" =  14.00746\n",
      "2018-08-29 09:16:53.358565 Training Step 530 \"loss\" =  14.00746\n",
      "2018-08-29 09:16:53.559478 Test Step 535 Finished\n",
      "2018-08-29 09:16:53.559638 Test Step 535 \"min loss\" =  26.945345\n",
      "2018-08-29 09:16:53.559770 Test Step 535 \"loss\" =  26.986479\n",
      "2018-08-29 09:16:53.606195 Training Step 535 Finished Timing (Training: 0.908996, Test: 0.0834986) after 0.247546 seconds\n",
      "2018-08-29 09:16:53.606687 Training Step 535 \"min loss\" =  13.74498\n",
      "2018-08-29 09:16:53.606818 Training Step 535 \"loss\" =  13.74498\n",
      "2018-08-29 09:16:53.807458 Test Step 540 Finished\n",
      "2018-08-29 09:16:53.807664 Test Step 540 \"min loss\" =  26.82727\n",
      "2018-08-29 09:16:53.807800 Test Step 540 \"loss\" =  26.82727\n",
      "2018-08-29 09:16:53.854436 Training Step 540 Finished Timing (Training: 0.909306, Test: 0.0834725) after 0.247464 seconds\n",
      "2018-08-29 09:16:53.854699 Training Step 540 \"min loss\" =  13.015565\n",
      "2018-08-29 09:16:53.854775 Training Step 540 \"loss\" =  13.015866\n",
      "2018-08-29 09:16:54.056869 Test Step 545 Finished\n",
      "2018-08-29 09:16:54.056994 Test Step 545 \"min loss\" =  26.82727\n",
      "2018-08-29 09:16:54.057920 Test Step 545 \"loss\" =  27.442753\n",
      "2018-08-29 09:16:54.103388 Training Step 545 Finished Timing (Training: 0.908986, Test: 0.0834028) after 0.247991 seconds\n",
      "2018-08-29 09:16:54.103500 Training Step 545 \"min loss\" =  12.275374\n",
      "2018-08-29 09:16:54.103563 Training Step 545 \"loss\" =  12.275374\n",
      "2018-08-29 09:16:54.304135 Test Step 550 Finished\n",
      "2018-08-29 09:16:54.304636 Test Step 550 \"min loss\" =  26.00738\n",
      "2018-08-29 09:16:54.305091 Test Step 550 \"loss\" =  26.00738\n",
      "2018-08-29 09:16:54.350727 Training Step 550 Finished Timing (Training: 0.908869, Test: 0.0833928) after 0.246243 seconds\n",
      "2018-08-29 09:16:54.350877 Training Step 550 \"min loss\" =  12.275374\n",
      "2018-08-29 09:16:54.351563 Training Step 550 \"loss\" =  12.3685875\n",
      "2018-08-29 09:16:54.552713 Test Step 555 Finished\n",
      "2018-08-29 09:16:54.552875 Test Step 555 \"min loss\" =  23.865267\n",
      "2018-08-29 09:16:54.552944 Test Step 555 \"loss\" =  23.865267\n",
      "2018-08-29 09:16:54.597937 Training Step 555 Finished Timing (Training: 0.908882, Test: 0.0834851) after 0.245945 seconds\n",
      "2018-08-29 09:16:54.598089 Training Step 555 \"min loss\" =  11.224557\n",
      "2018-08-29 09:16:54.598168 Training Step 555 \"loss\" =  12.407381\n",
      "2018-08-29 09:16:54.800891 Test Step 560 Finished\n",
      "2018-08-29 09:16:54.801151 Test Step 560 \"min loss\" =  22.937841\n",
      "2018-08-29 09:16:54.801303 Test Step 560 \"loss\" =  22.937841\n",
      "2018-08-29 09:16:54.846863 Training Step 560 Finished Timing (Training: 0.908914, Test: 0.0837841) after 0.248607 seconds\n",
      "2018-08-29 09:16:54.847007 Training Step 560 \"min loss\" =  11.224557\n",
      "2018-08-29 09:16:54.847077 Training Step 560 \"loss\" =  12.43152\n",
      "2018-08-29 09:16:55.047676 Test Step 565 Finished\n",
      "2018-08-29 09:16:55.047869 Test Step 565 \"min loss\" =  22.937841\n",
      "2018-08-29 09:16:55.047985 Test Step 565 \"loss\" =  22.994915\n",
      "2018-08-29 09:16:55.093162 Training Step 565 Finished Timing (Training: 0.909185, Test: 0.0838234) after 0.245975 seconds\n",
      "2018-08-29 09:16:55.093297 Training Step 565 \"min loss\" =  10.641036\n",
      "2018-08-29 09:16:55.093363 Training Step 565 \"loss\" =  11.570923\n",
      "2018-08-29 09:16:55.294656 Test Step 570 Finished\n",
      "2018-08-29 09:16:55.295165 Test Step 570 \"min loss\" =  22.937841\n",
      "2018-08-29 09:16:55.295400 Test Step 570 \"loss\" =  23.000269\n",
      "2018-08-29 09:16:55.340661 Training Step 570 Finished Timing (Training: 0.909205, Test: 0.0838895) after 0.247217 seconds\n",
      "2018-08-29 09:16:55.340822 Training Step 570 \"min loss\" =  10.641036\n",
      "2018-08-29 09:16:55.340886 Training Step 570 \"loss\" =  10.808332\n",
      "2018-08-29 09:16:55.542325 Test Step 575 Finished\n",
      "2018-08-29 09:16:55.542451 Test Step 575 \"min loss\" =  22.937841\n",
      "2018-08-29 09:16:55.542513 Test Step 575 \"loss\" =  24.485037\n",
      "2018-08-29 09:16:55.588257 Training Step 575 Finished Timing (Training: 0.909287, Test: 0.0838981) after 0.247291 seconds\n",
      "2018-08-29 09:16:55.588413 Training Step 575 \"min loss\" =  9.95201\n",
      "2018-08-29 09:16:55.588479 Training Step 575 \"loss\" =  9.95201\n",
      "2018-08-29 09:16:55.789185 Test Step 580 Finished\n",
      "2018-08-29 09:16:55.789316 Test Step 580 \"min loss\" =  22.937841\n",
      "2018-08-29 09:16:55.789413 Test Step 580 \"loss\" =  23.562605\n",
      "2018-08-29 09:16:55.834233 Training Step 580 Finished Timing (Training: 0.909444, Test: 0.0840005) after 0.245675 seconds\n",
      "2018-08-29 09:16:55.834384 Training Step 580 \"min loss\" =  9.95201\n",
      "2018-08-29 09:16:55.834448 Training Step 580 \"loss\" =  11.683343\n",
      "2018-08-29 09:16:56.035132 Test Step 585 Finished\n",
      "2018-08-29 09:16:56.035282 Test Step 585 \"min loss\" =  21.824427\n",
      "2018-08-29 09:16:56.036041 Test Step 585 \"loss\" =  21.824427\n",
      "2018-08-29 09:16:56.081429 Training Step 585 Finished Timing (Training: 0.909493, Test: 0.0839918) after 0.246901 seconds\n",
      "2018-08-29 09:16:56.081568 Training Step 585 \"min loss\" =  9.95201\n",
      "2018-08-29 09:16:56.081640 Training Step 585 \"loss\" =  10.405302\n",
      "2018-08-29 09:16:56.281934 Test Step 590 Finished\n",
      "2018-08-29 09:16:56.282074 Test Step 590 \"min loss\" =  21.824427\n",
      "2018-08-29 09:16:56.282152 Test Step 590 \"loss\" =  22.741014\n",
      "2018-08-29 09:16:56.327719 Training Step 590 Finished Timing (Training: 0.909613, Test: 0.0839323) after 0.245283 seconds\n",
      "2018-08-29 09:16:56.327854 Training Step 590 \"min loss\" =  9.95201\n",
      "2018-08-29 09:16:56.328487 Training Step 590 \"loss\" =  10.914872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:16:56.529097 Test Step 595 Finished\n",
      "2018-08-29 09:16:56.529252 Test Step 595 \"min loss\" =  21.824427\n",
      "2018-08-29 09:16:56.529328 Test Step 595 \"loss\" =  22.238285\n",
      "2018-08-29 09:16:56.574192 Training Step 595 Finished Timing (Training: 0.909674, Test: 0.0839032) after 0.245377 seconds\n",
      "2018-08-29 09:16:56.574337 Training Step 595 \"min loss\" =  9.547675\n",
      "2018-08-29 09:16:56.574405 Training Step 595 \"loss\" =  10.2899685\n",
      "2018-08-29 09:16:56.774391 Test Step 600 Finished\n",
      "2018-08-29 09:16:56.774540 Test Step 600 \"min loss\" =  21.824427\n",
      "2018-08-29 09:16:56.774600 Test Step 600 \"loss\" =  22.279734\n",
      "2018-08-29 09:16:56.820882 Training Step 600 Finished Timing (Training: 0.909709, Test: 0.0839082) after 0.246395 seconds\n",
      "2018-08-29 09:16:56.821025 Training Step 600 \"min loss\" =  9.547675\n",
      "2018-08-29 09:16:56.821106 Training Step 600 \"loss\" =  12.272292\n",
      "2018-08-29 09:16:57.022865 Test Step 605 Finished\n",
      "2018-08-29 09:16:57.023016 Test Step 605 \"min loss\" =  21.824427\n",
      "2018-08-29 09:16:57.023732 Test Step 605 \"loss\" =  23.577337\n",
      "2018-08-29 09:16:57.069210 Training Step 605 Finished Timing (Training: 0.912984, Test: 0.0829889) after 0.247321 seconds\n",
      "2018-08-29 09:16:57.069361 Training Step 605 \"min loss\" =  8.935065\n",
      "2018-08-29 09:16:57.069427 Training Step 605 \"loss\" =  10.160041\n",
      "2018-08-29 09:16:57.271724 Test Step 610 Finished\n",
      "2018-08-29 09:16:57.271882 Test Step 610 \"min loss\" =  21.824427\n",
      "2018-08-29 09:16:57.272558 Test Step 610 \"loss\" =  22.739216\n",
      "2018-08-29 09:16:57.317463 Training Step 610 Finished Timing (Training: 0.909701, Test: 0.0839331) after 0.247245 seconds\n",
      "2018-08-29 09:16:57.317591 Training Step 610 \"min loss\" =  8.935065\n",
      "2018-08-29 09:16:57.318514 Training Step 610 \"loss\" =  10.697373\n",
      "2018-08-29 09:16:57.520566 Test Step 615 Finished\n",
      "2018-08-29 09:16:57.520712 Test Step 615 \"min loss\" =  21.824427\n",
      "2018-08-29 09:16:57.520795 Test Step 615 \"loss\" =  23.231106\n",
      "2018-08-29 09:16:57.565654 Training Step 615 Finished Timing (Training: 0.910061, Test: 0.0837115) after 0.247052 seconds\n",
      "2018-08-29 09:16:57.565839 Training Step 615 \"min loss\" =  8.935065\n",
      "2018-08-29 09:16:57.566574 Training Step 615 \"loss\" =  9.610154\n",
      "2018-08-29 09:16:57.767907 Test Step 620 Finished\n",
      "2018-08-29 09:16:57.768076 Test Step 620 \"min loss\" =  21.824427\n",
      "2018-08-29 09:16:57.768163 Test Step 620 \"loss\" =  21.982908\n",
      "2018-08-29 09:16:57.813106 Training Step 620 Finished Timing (Training: 0.910381, Test: 0.0835399) after 0.246444 seconds\n",
      "2018-08-29 09:16:57.813267 Training Step 620 \"min loss\" =  8.935065\n",
      "2018-08-29 09:16:57.813753 Training Step 620 \"loss\" =  9.652072\n",
      "2018-08-29 09:16:58.014590 Test Step 625 Finished\n",
      "2018-08-29 09:16:58.014741 Test Step 625 \"min loss\" =  21.824427\n",
      "2018-08-29 09:16:58.014824 Test Step 625 \"loss\" =  21.977608\n",
      "2018-08-29 09:16:58.060525 Training Step 625 Finished Timing (Training: 0.910051, Test: 0.0839474) after 0.246409 seconds\n",
      "2018-08-29 09:16:58.060676 Training Step 625 \"min loss\" =  8.935065\n",
      "2018-08-29 09:16:58.060763 Training Step 625 \"loss\" =  10.03817\n",
      "2018-08-29 09:16:58.261466 Test Step 630 Finished\n",
      "2018-08-29 09:16:58.262226 Test Step 630 \"min loss\" =  21.824427\n",
      "2018-08-29 09:16:58.262337 Test Step 630 \"loss\" =  21.991453\n",
      "2018-08-29 09:16:58.308160 Training Step 630 Finished Timing (Training: 0.909825, Test: 0.0836702) after 0.246415 seconds\n",
      "2018-08-29 09:16:58.308390 Training Step 630 \"min loss\" =  8.388601\n",
      "2018-08-29 09:16:58.308545 Training Step 630 \"loss\" =  9.462867\n",
      "2018-08-29 09:16:58.510820 Test Step 635 Finished\n",
      "2018-08-29 09:16:58.510948 Test Step 635 \"min loss\" =  21.617334\n",
      "2018-08-29 09:16:58.511018 Test Step 635 \"loss\" =  21.617334\n",
      "2018-08-29 09:16:58.555844 Training Step 635 Finished Timing (Training: 0.910132, Test: 0.0837624) after 0.247085 seconds\n",
      "2018-08-29 09:16:58.555972 Training Step 635 \"min loss\" =  8.388601\n",
      "2018-08-29 09:16:58.556038 Training Step 635 \"loss\" =  11.519728\n",
      "2018-08-29 09:16:58.756876 Test Step 640 Finished\n",
      "2018-08-29 09:16:58.757084 Test Step 640 \"min loss\" =  21.377945\n",
      "2018-08-29 09:16:58.757208 Test Step 640 \"loss\" =  21.377945\n",
      "2018-08-29 09:16:58.803354 Training Step 640 Finished Timing (Training: 0.909737, Test: 0.0840146) after 0.247234 seconds\n",
      "2018-08-29 09:16:58.803496 Training Step 640 \"min loss\" =  8.388601\n",
      "2018-08-29 09:16:58.804181 Training Step 640 \"loss\" =  8.6914015\n",
      "2018-08-29 09:16:59.004713 Test Step 645 Finished\n",
      "2018-08-29 09:16:59.004868 Test Step 645 \"min loss\" =  21.355047\n",
      "2018-08-29 09:16:59.004940 Test Step 645 \"loss\" =  21.355047\n",
      "2018-08-29 09:16:59.051134 Training Step 645 Finished Timing (Training: 0.909989, Test: 0.0838803) after 0.24685 seconds\n",
      "2018-08-29 09:16:59.051286 Training Step 645 \"min loss\" =  8.388601\n",
      "2018-08-29 09:16:59.052017 Training Step 645 \"loss\" =  9.279985\n",
      "2018-08-29 09:16:59.252847 Test Step 650 Finished\n",
      "2018-08-29 09:16:59.253065 Test Step 650 \"min loss\" =  21.355047\n",
      "2018-08-29 09:16:59.253183 Test Step 650 \"loss\" =  22.312159\n",
      "2018-08-29 09:16:59.298629 Training Step 650 Finished Timing (Training: 0.909877, Test: 0.0838688) after 0.246166 seconds\n",
      "2018-08-29 09:16:59.298849 Training Step 650 \"min loss\" =  8.388601\n",
      "2018-08-29 09:16:59.298982 Training Step 650 \"loss\" =  8.958966\n",
      "2018-08-29 09:16:59.500361 Test Step 655 Finished\n",
      "2018-08-29 09:16:59.500544 Test Step 655 \"min loss\" =  20.793036\n",
      "2018-08-29 09:16:59.501160 Test Step 655 \"loss\" =  20.793036\n",
      "2018-08-29 09:16:59.546589 Training Step 655 Finished Timing (Training: 0.909383, Test: 0.0838254) after 0.246277 seconds\n",
      "2018-08-29 09:16:59.546734 Training Step 655 \"min loss\" =  8.388601\n",
      "2018-08-29 09:16:59.547206 Training Step 655 \"loss\" =  8.409278\n",
      "2018-08-29 09:16:59.748275 Test Step 660 Finished\n",
      "2018-08-29 09:16:59.748971 Test Step 660 \"min loss\" =  20.640726\n",
      "2018-08-29 09:16:59.749320 Test Step 660 \"loss\" =  20.640726\n",
      "2018-08-29 09:16:59.794837 Training Step 660 Finished Timing (Training: 0.909056, Test: 0.0838224) after 0.247098 seconds\n",
      "2018-08-29 09:16:59.794982 Training Step 660 \"min loss\" =  8.388601\n",
      "2018-08-29 09:16:59.795071 Training Step 660 \"loss\" =  9.294753\n",
      "2018-08-29 09:16:59.996429 Test Step 665 Finished\n",
      "2018-08-29 09:16:59.996597 Test Step 665 \"min loss\" =  20.640726\n",
      "2018-08-29 09:16:59.997251 Test Step 665 \"loss\" =  20.862577\n",
      "2018-08-29 09:17:00.042066 Training Step 665 Finished Timing (Training: 0.90935, Test: 0.0836795) after 0.246909 seconds\n",
      "2018-08-29 09:17:00.042210 Training Step 665 \"min loss\" =  7.616792\n",
      "2018-08-29 09:17:00.042274 Training Step 665 \"loss\" =  7.616792\n",
      "2018-08-29 09:17:00.242627 Test Step 670 Finished\n",
      "2018-08-29 09:17:00.242775 Test Step 670 \"min loss\" =  20.640726\n",
      "2018-08-29 09:17:00.242846 Test Step 670 \"loss\" =  21.948086\n",
      "2018-08-29 09:17:00.288521 Training Step 670 Finished Timing (Training: 0.90951, Test: 0.0836929) after 0.245679 seconds\n",
      "2018-08-29 09:17:00.288688 Training Step 670 \"min loss\" =  7.616792\n",
      "2018-08-29 09:17:00.288766 Training Step 670 \"loss\" =  8.8768425\n",
      "2018-08-29 09:17:00.490462 Test Step 675 Finished\n",
      "2018-08-29 09:17:00.490599 Test Step 675 \"min loss\" =  20.247643\n",
      "2018-08-29 09:17:00.491405 Test Step 675 \"loss\" =  20.247643\n",
      "2018-08-29 09:17:00.536804 Training Step 675 Finished Timing (Training: 0.909291, Test: 0.0837198) after 0.247276 seconds\n",
      "2018-08-29 09:17:00.536923 Training Step 675 \"min loss\" =  7.616792\n",
      "2018-08-29 09:17:00.536989 Training Step 675 \"loss\" =  9.108085\n",
      "2018-08-29 09:17:00.739438 Test Step 680 Finished\n",
      "2018-08-29 09:17:00.739590 Test Step 680 \"min loss\" =  20.247643\n",
      "2018-08-29 09:17:00.739661 Test Step 680 \"loss\" =  21.070082\n",
      "2018-08-29 09:17:00.786127 Training Step 680 Finished Timing (Training: 0.909208, Test: 0.0837002) after 0.24905 seconds\n",
      "2018-08-29 09:17:00.786278 Training Step 680 \"min loss\" =  7.616792\n",
      "2018-08-29 09:17:00.786352 Training Step 680 \"loss\" =  9.270859\n",
      "2018-08-29 09:17:00.988370 Test Step 685 Finished\n",
      "2018-08-29 09:17:00.988928 Test Step 685 \"min loss\" =  20.247643\n",
      "2018-08-29 09:17:00.989148 Test Step 685 \"loss\" =  22.296942\n",
      "2018-08-29 09:17:01.034752 Training Step 685 Finished Timing (Training: 0.90928, Test: 0.0836932) after 0.248302 seconds\n",
      "2018-08-29 09:17:01.034952 Training Step 685 \"min loss\" =  7.616792\n",
      "2018-08-29 09:17:01.035053 Training Step 685 \"loss\" =  10.0697775\n",
      "2018-08-29 09:17:01.236305 Test Step 690 Finished\n",
      "2018-08-29 09:17:01.236464 Test Step 690 \"min loss\" =  20.247643\n",
      "2018-08-29 09:17:01.236539 Test Step 690 \"loss\" =  21.779121\n",
      "2018-08-29 09:17:01.282477 Training Step 690 Finished Timing (Training: 0.909169, Test: 0.0837799) after 0.247286 seconds\n",
      "2018-08-29 09:17:01.283107 Training Step 690 \"min loss\" =  7.616792\n",
      "2018-08-29 09:17:01.283460 Training Step 690 \"loss\" =  8.584676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:17:01.485910 Test Step 695 Finished\n",
      "2018-08-29 09:17:01.486075 Test Step 695 \"min loss\" =  20.247643\n",
      "2018-08-29 09:17:01.487189 Test Step 695 \"loss\" =  21.225367\n",
      "2018-08-29 09:17:01.532529 Training Step 695 Finished Timing (Training: 0.908808, Test: 0.0838623) after 0.248448 seconds\n",
      "2018-08-29 09:17:01.533078 Training Step 695 \"min loss\" =  7.616792\n",
      "2018-08-29 09:17:01.533208 Training Step 695 \"loss\" =  8.987994\n",
      "2018-08-29 09:17:01.736647 Test Step 700 Finished\n",
      "2018-08-29 09:17:01.736871 Test Step 700 \"min loss\" =  20.163656\n",
      "2018-08-29 09:17:01.737005 Test Step 700 \"loss\" =  20.163656\n",
      "2018-08-29 09:17:01.782330 Training Step 700 Finished Timing (Training: 0.908724, Test: 0.0838604) after 0.248134 seconds\n",
      "2018-08-29 09:17:01.782477 Training Step 700 \"min loss\" =  7.616792\n",
      "2018-08-29 09:17:01.782537 Training Step 700 \"loss\" =  8.671356\n",
      "2018-08-29 09:17:01.984334 Test Step 705 Finished\n",
      "2018-08-29 09:17:01.984512 Test Step 705 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:01.984589 Test Step 705 \"loss\" =  18.946516\n",
      "2018-08-29 09:17:02.029525 Training Step 705 Finished Timing (Training: 0.912954, Test: 0.0852081) after 0.245773 seconds\n",
      "2018-08-29 09:17:02.029658 Training Step 705 \"min loss\" =  7.616792\n",
      "2018-08-29 09:17:02.030450 Training Step 705 \"loss\" =  9.883741\n",
      "2018-08-29 09:17:02.231534 Test Step 710 Finished\n",
      "2018-08-29 09:17:02.231692 Test Step 710 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:02.231757 Test Step 710 \"loss\" =  19.421276\n",
      "2018-08-29 09:17:02.277917 Training Step 710 Finished Timing (Training: 0.909733, Test: 0.0843302) after 0.247355 seconds\n",
      "2018-08-29 09:17:02.278045 Training Step 710 \"min loss\" =  7.616792\n",
      "2018-08-29 09:17:02.278109 Training Step 710 \"loss\" =  8.816919\n",
      "2018-08-29 09:17:02.478978 Test Step 715 Finished\n",
      "2018-08-29 09:17:02.479131 Test Step 715 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:02.479211 Test Step 715 \"loss\" =  20.82304\n",
      "2018-08-29 09:17:02.524830 Training Step 715 Finished Timing (Training: 0.910042, Test: 0.08395) after 0.245746 seconds\n",
      "2018-08-29 09:17:02.525023 Training Step 715 \"min loss\" =  7.616792\n",
      "2018-08-29 09:17:02.525138 Training Step 715 \"loss\" =  8.539418\n",
      "2018-08-29 09:17:02.726838 Test Step 720 Finished\n",
      "2018-08-29 09:17:02.726989 Test Step 720 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:02.727870 Test Step 720 \"loss\" =  20.51108\n",
      "2018-08-29 09:17:02.773559 Training Step 720 Finished Timing (Training: 0.908976, Test: 0.0838529) after 0.24788 seconds\n",
      "2018-08-29 09:17:02.773703 Training Step 720 \"min loss\" =  7.616792\n",
      "2018-08-29 09:17:02.774339 Training Step 720 \"loss\" =  9.649191\n",
      "2018-08-29 09:17:02.975608 Test Step 725 Finished\n",
      "2018-08-29 09:17:02.976121 Test Step 725 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:02.976341 Test Step 725 \"loss\" =  19.639425\n",
      "2018-08-29 09:17:03.022384 Training Step 725 Finished Timing (Training: 0.908643, Test: 0.0838512) after 0.247957 seconds\n",
      "2018-08-29 09:17:03.022522 Training Step 725 \"min loss\" =  7.616792\n",
      "2018-08-29 09:17:03.022587 Training Step 725 \"loss\" =  8.913773\n",
      "2018-08-29 09:17:03.223383 Test Step 730 Finished\n",
      "2018-08-29 09:17:03.223552 Test Step 730 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:03.223625 Test Step 730 \"loss\" =  19.307383\n",
      "2018-08-29 09:17:03.269550 Training Step 730 Finished Timing (Training: 0.908388, Test: 0.0836956) after 0.246085 seconds\n",
      "2018-08-29 09:17:03.269699 Training Step 730 \"min loss\" =  7.616792\n",
      "2018-08-29 09:17:03.270428 Training Step 730 \"loss\" =  7.66058\n",
      "2018-08-29 09:17:03.471415 Test Step 735 Finished\n",
      "2018-08-29 09:17:03.471569 Test Step 735 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:03.471633 Test Step 735 \"loss\" =  21.241413\n",
      "2018-08-29 09:17:03.516925 Training Step 735 Finished Timing (Training: 0.908816, Test: 0.083625) after 0.246393 seconds\n",
      "2018-08-29 09:17:03.517075 Training Step 735 \"min loss\" =  7.616792\n",
      "2018-08-29 09:17:03.517145 Training Step 735 \"loss\" =  8.350898\n",
      "2018-08-29 09:17:03.719512 Test Step 740 Finished\n",
      "2018-08-29 09:17:03.719673 Test Step 740 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:03.720543 Test Step 740 \"loss\" =  20.502281\n",
      "2018-08-29 09:17:03.766423 Training Step 740 Finished Timing (Training: 0.908983, Test: 0.0834606) after 0.249188 seconds\n",
      "2018-08-29 09:17:03.766561 Training Step 740 \"min loss\" =  7.616792\n",
      "2018-08-29 09:17:03.767161 Training Step 740 \"loss\" =  8.530774\n",
      "2018-08-29 09:17:03.969003 Test Step 745 Finished\n",
      "2018-08-29 09:17:03.969210 Test Step 745 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:03.969332 Test Step 745 \"loss\" =  20.638056\n",
      "2018-08-29 09:17:04.014999 Training Step 745 Finished Timing (Training: 0.909187, Test: 0.083504) after 0.247756 seconds\n",
      "2018-08-29 09:17:04.015128 Training Step 745 \"min loss\" =  7.4469447\n",
      "2018-08-29 09:17:04.015245 Training Step 745 \"loss\" =  8.969351\n",
      "2018-08-29 09:17:04.216240 Test Step 750 Finished\n",
      "2018-08-29 09:17:04.216437 Test Step 750 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:04.216593 Test Step 750 \"loss\" =  19.890324\n",
      "2018-08-29 09:17:04.261540 Training Step 750 Finished Timing (Training: 0.909575, Test: 0.0834674) after 0.246167 seconds\n",
      "2018-08-29 09:17:04.261668 Training Step 750 \"min loss\" =  7.4469447\n",
      "2018-08-29 09:17:04.262426 Training Step 750 \"loss\" =  8.740318\n",
      "2018-08-29 09:17:04.463049 Test Step 755 Finished\n",
      "2018-08-29 09:17:04.463681 Test Step 755 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:04.463763 Test Step 755 \"loss\" =  20.628307\n",
      "2018-08-29 09:17:04.508933 Training Step 755 Finished Timing (Training: 0.909548, Test: 0.0834656) after 0.246413 seconds\n",
      "2018-08-29 09:17:04.509535 Training Step 755 \"min loss\" =  7.4469447\n",
      "2018-08-29 09:17:04.509911 Training Step 755 \"loss\" =  7.689444\n",
      "2018-08-29 09:17:04.710809 Test Step 760 Finished\n",
      "2018-08-29 09:17:04.711384 Test Step 760 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:04.711499 Test Step 760 \"loss\" =  20.242613\n",
      "2018-08-29 09:17:04.757058 Training Step 760 Finished Timing (Training: 0.909433, Test: 0.0835146) after 0.247062 seconds\n",
      "2018-08-29 09:17:04.757607 Training Step 760 \"min loss\" =  7.4469447\n",
      "2018-08-29 09:17:04.758111 Training Step 760 \"loss\" =  7.847991\n",
      "2018-08-29 09:17:04.959479 Test Step 765 Finished\n",
      "2018-08-29 09:17:04.959711 Test Step 765 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:04.960904 Test Step 765 \"loss\" =  19.491299\n",
      "2018-08-29 09:17:05.006414 Training Step 765 Finished Timing (Training: 0.908828, Test: 0.083576) after 0.247747 seconds\n",
      "2018-08-29 09:17:05.006552 Training Step 765 \"min loss\" =  7.4469447\n",
      "2018-08-29 09:17:05.007192 Training Step 765 \"loss\" =  7.8420954\n",
      "2018-08-29 09:17:05.207958 Test Step 770 Finished\n",
      "2018-08-29 09:17:05.208102 Test Step 770 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:05.208891 Test Step 770 \"loss\" =  19.245977\n",
      "2018-08-29 09:17:05.253988 Training Step 770 Finished Timing (Training: 0.908543, Test: 0.0837243) after 0.246691 seconds\n",
      "2018-08-29 09:17:05.254133 Training Step 770 \"min loss\" =  7.4469447\n",
      "2018-08-29 09:17:05.254199 Training Step 770 \"loss\" =  7.787218\n",
      "2018-08-29 09:17:05.455564 Test Step 775 Finished\n",
      "2018-08-29 09:17:05.456098 Test Step 775 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:05.456164 Test Step 775 \"loss\" =  19.27227\n",
      "2018-08-29 09:17:05.501794 Training Step 775 Finished Timing (Training: 0.908441, Test: 0.0836523) after 0.246413 seconds\n",
      "2018-08-29 09:17:05.502329 Training Step 775 \"min loss\" =  7.258106\n",
      "2018-08-29 09:17:05.502438 Training Step 775 \"loss\" =  8.35208\n",
      "2018-08-29 09:17:05.702837 Test Step 780 Finished\n",
      "2018-08-29 09:17:05.703400 Test Step 780 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:05.703856 Test Step 780 \"loss\" =  19.305082\n",
      "2018-08-29 09:17:05.748855 Training Step 780 Finished Timing (Training: 0.908439, Test: 0.0836715) after 0.246327 seconds\n",
      "2018-08-29 09:17:05.748988 Training Step 780 \"min loss\" =  7.258106\n",
      "2018-08-29 09:17:05.749058 Training Step 780 \"loss\" =  8.186368\n",
      "2018-08-29 09:17:05.948853 Test Step 785 Finished\n",
      "2018-08-29 09:17:05.948989 Test Step 785 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:05.949056 Test Step 785 \"loss\" =  19.81408\n",
      "2018-08-29 09:17:05.995035 Training Step 785 Finished Timing (Training: 0.90876, Test: 0.0836547) after 0.245864 seconds\n",
      "2018-08-29 09:17:05.995211 Training Step 785 \"min loss\" =  7.258106\n",
      "2018-08-29 09:17:05.996175 Training Step 785 \"loss\" =  8.813082\n",
      "2018-08-29 09:17:06.197113 Test Step 790 Finished\n",
      "2018-08-29 09:17:06.197248 Test Step 790 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:06.197315 Test Step 790 \"loss\" =  19.546867\n",
      "2018-08-29 09:17:06.242294 Training Step 790 Finished Timing (Training: 0.908766, Test: 0.0836316) after 0.245632 seconds\n",
      "2018-08-29 09:17:06.242444 Training Step 790 \"min loss\" =  7.258106\n",
      "2018-08-29 09:17:06.243152 Training Step 790 \"loss\" =  8.376722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:17:06.443829 Test Step 795 Finished\n",
      "2018-08-29 09:17:06.444049 Test Step 795 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:06.444603 Test Step 795 \"loss\" =  20.552835\n",
      "2018-08-29 09:17:06.490525 Training Step 795 Finished Timing (Training: 0.90879, Test: 0.0836096) after 0.247279 seconds\n",
      "2018-08-29 09:17:06.490674 Training Step 795 \"min loss\" =  7.258106\n",
      "2018-08-29 09:17:06.491203 Training Step 795 \"loss\" =  7.838952\n",
      "2018-08-29 09:17:06.692490 Test Step 800 Finished\n",
      "2018-08-29 09:17:06.693294 Test Step 800 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:06.693365 Test Step 800 \"loss\" =  22.325119\n",
      "2018-08-29 09:17:06.738267 Training Step 800 Finished Timing (Training: 0.908717, Test: 0.0836221) after 0.246559 seconds\n",
      "2018-08-29 09:17:06.738406 Training Step 800 \"min loss\" =  7.258106\n",
      "2018-08-29 09:17:06.739096 Training Step 800 \"loss\" =  7.710704\n",
      "2018-08-29 09:17:06.939666 Test Step 805 Finished\n",
      "2018-08-29 09:17:06.939801 Test Step 805 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:06.940650 Test Step 805 \"loss\" =  22.459005\n",
      "2018-08-29 09:17:06.986048 Training Step 805 Finished Timing (Training: 0.909436, Test: 0.0836478) after 0.246515 seconds\n",
      "2018-08-29 09:17:06.986178 Training Step 805 \"min loss\" =  7.2508626\n",
      "2018-08-29 09:17:06.986239 Training Step 805 \"loss\" =  7.2508626\n",
      "2018-08-29 09:17:07.187292 Test Step 810 Finished\n",
      "2018-08-29 09:17:07.187450 Test Step 810 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:07.187522 Test Step 810 \"loss\" =  20.929379\n",
      "2018-08-29 09:17:07.233803 Training Step 810 Finished Timing (Training: 0.910474, Test: 0.0833985) after 0.24678 seconds\n",
      "2018-08-29 09:17:07.233945 Training Step 810 \"min loss\" =  7.2508626\n",
      "2018-08-29 09:17:07.234007 Training Step 810 \"loss\" =  8.008586\n",
      "2018-08-29 09:17:07.434922 Test Step 815 Finished\n",
      "2018-08-29 09:17:07.435530 Test Step 815 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:07.436059 Test Step 815 \"loss\" =  21.540049\n",
      "2018-08-29 09:17:07.481620 Training Step 815 Finished Timing (Training: 0.910842, Test: 0.0829715) after 0.247529 seconds\n",
      "2018-08-29 09:17:07.481770 Training Step 815 \"min loss\" =  7.2508626\n",
      "2018-08-29 09:17:07.482611 Training Step 815 \"loss\" =  7.746129\n",
      "2018-08-29 09:17:07.683832 Test Step 820 Finished\n",
      "2018-08-29 09:17:07.684358 Test Step 820 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:07.684419 Test Step 820 \"loss\" =  20.980223\n",
      "2018-08-29 09:17:07.729947 Training Step 820 Finished Timing (Training: 0.910638, Test: 0.0827422) after 0.24707 seconds\n",
      "2018-08-29 09:17:07.730069 Training Step 820 \"min loss\" =  7.2319765\n",
      "2018-08-29 09:17:07.730602 Training Step 820 \"loss\" =  7.349025\n",
      "2018-08-29 09:17:07.931109 Test Step 825 Finished\n",
      "2018-08-29 09:17:07.931334 Test Step 825 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:07.932127 Test Step 825 \"loss\" =  20.035444\n",
      "2018-08-29 09:17:07.977604 Training Step 825 Finished Timing (Training: 0.909727, Test: 0.0830483) after 0.246446 seconds\n",
      "2018-08-29 09:17:07.977737 Training Step 825 \"min loss\" =  7.2319765\n",
      "2018-08-29 09:17:07.977800 Training Step 825 \"loss\" =  8.023254\n",
      "2018-08-29 09:17:08.178191 Test Step 830 Finished\n",
      "2018-08-29 09:17:08.178324 Test Step 830 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:08.178401 Test Step 830 \"loss\" =  19.675564\n",
      "2018-08-29 09:17:08.225864 Training Step 830 Finished Timing (Training: 0.909758, Test: 0.0829035) after 0.247985 seconds\n",
      "2018-08-29 09:17:08.225995 Training Step 830 \"min loss\" =  7.2319765\n",
      "2018-08-29 09:17:08.226062 Training Step 830 \"loss\" =  7.7827783\n",
      "2018-08-29 09:17:08.426221 Test Step 835 Finished\n",
      "2018-08-29 09:17:08.426368 Test Step 835 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:08.426945 Test Step 835 \"loss\" =  19.843557\n",
      "2018-08-29 09:17:08.472249 Training Step 835 Finished Timing (Training: 0.909697, Test: 0.0830554) after 0.246102 seconds\n",
      "2018-08-29 09:17:08.472433 Training Step 835 \"min loss\" =  7.1300216\n",
      "2018-08-29 09:17:08.472542 Training Step 835 \"loss\" =  7.8160806\n",
      "2018-08-29 09:17:08.673191 Test Step 840 Finished\n",
      "2018-08-29 09:17:08.673351 Test Step 840 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:08.673412 Test Step 840 \"loss\" =  19.538797\n",
      "2018-08-29 09:17:08.718342 Training Step 840 Finished Timing (Training: 0.910157, Test: 0.0831089) after 0.245689 seconds\n",
      "2018-08-29 09:17:08.718498 Training Step 840 \"min loss\" =  6.9532337\n",
      "2018-08-29 09:17:08.718579 Training Step 840 \"loss\" =  6.9532337\n",
      "2018-08-29 09:17:08.919252 Test Step 845 Finished\n",
      "2018-08-29 09:17:08.919467 Test Step 845 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:08.919540 Test Step 845 \"loss\" =  19.851572\n",
      "2018-08-29 09:17:08.965072 Training Step 845 Finished Timing (Training: 0.910291, Test: 0.0831682) after 0.246358 seconds\n",
      "2018-08-29 09:17:08.965228 Training Step 845 \"min loss\" =  6.9532337\n",
      "2018-08-29 09:17:08.966167 Training Step 845 \"loss\" =  7.131248\n",
      "2018-08-29 09:17:09.167295 Test Step 850 Finished\n",
      "2018-08-29 09:17:09.167481 Test Step 850 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:09.167553 Test Step 850 \"loss\" =  20.964579\n",
      "2018-08-29 09:17:09.213403 Training Step 850 Finished Timing (Training: 0.909929, Test: 0.083165) after 0.247083 seconds\n",
      "2018-08-29 09:17:09.213952 Training Step 850 \"min loss\" =  6.9532337\n",
      "2018-08-29 09:17:09.214447 Training Step 850 \"loss\" =  7.7226844\n",
      "2018-08-29 09:17:09.415035 Test Step 855 Finished\n",
      "2018-08-29 09:17:09.415173 Test Step 855 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:09.415242 Test Step 855 \"loss\" =  21.100378\n",
      "2018-08-29 09:17:09.460878 Training Step 855 Finished Timing (Training: 0.90998, Test: 0.0831784) after 0.246262 seconds\n",
      "2018-08-29 09:17:09.461021 Training Step 855 \"min loss\" =  6.9532337\n",
      "2018-08-29 09:17:09.461100 Training Step 855 \"loss\" =  7.4159026\n",
      "2018-08-29 09:17:09.664527 Test Step 860 Finished\n",
      "2018-08-29 09:17:09.664703 Test Step 860 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:09.665454 Test Step 860 \"loss\" =  20.128876\n",
      "2018-08-29 09:17:09.711034 Training Step 860 Finished Timing (Training: 0.909584, Test: 0.0832754) after 0.248633 seconds\n",
      "2018-08-29 09:17:09.711179 Training Step 860 \"min loss\" =  6.9532337\n",
      "2018-08-29 09:17:09.711858 Training Step 860 \"loss\" =  7.46681\n",
      "2018-08-29 09:17:09.913269 Test Step 865 Finished\n",
      "2018-08-29 09:17:09.913468 Test Step 865 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:09.914287 Test Step 865 \"loss\" =  20.52393\n",
      "2018-08-29 09:17:09.960359 Training Step 865 Finished Timing (Training: 0.909505, Test: 0.0832577) after 0.248412 seconds\n",
      "2018-08-29 09:17:09.960498 Training Step 865 \"min loss\" =  6.7886314\n",
      "2018-08-29 09:17:09.961190 Training Step 865 \"loss\" =  6.7886314\n",
      "2018-08-29 09:17:10.162198 Test Step 870 Finished\n",
      "2018-08-29 09:17:10.162358 Test Step 870 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:10.162915 Test Step 870 \"loss\" =  21.21844\n",
      "2018-08-29 09:17:10.208026 Training Step 870 Finished Timing (Training: 0.909397, Test: 0.0833774) after 0.246756 seconds\n",
      "2018-08-29 09:17:10.208152 Training Step 870 \"min loss\" =  6.7886314\n",
      "2018-08-29 09:17:10.208209 Training Step 870 \"loss\" =  7.5662637\n",
      "2018-08-29 09:17:10.410760 Test Step 875 Finished\n",
      "2018-08-29 09:17:10.411403 Test Step 875 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:10.411682 Test Step 875 \"loss\" =  19.781694\n",
      "2018-08-29 09:17:10.456934 Training Step 875 Finished Timing (Training: 0.909112, Test: 0.0833453) after 0.247326 seconds\n",
      "2018-08-29 09:17:10.457085 Training Step 875 \"min loss\" =  6.7862716\n",
      "2018-08-29 09:17:10.457815 Training Step 875 \"loss\" =  7.262691\n",
      "2018-08-29 09:17:10.658637 Test Step 880 Finished\n",
      "2018-08-29 09:17:10.659320 Test Step 880 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:10.659638 Test Step 880 \"loss\" =  19.824171\n",
      "2018-08-29 09:17:10.704934 Training Step 880 Finished Timing (Training: 0.909005, Test: 0.0833718) after 0.246937 seconds\n",
      "2018-08-29 09:17:10.705066 Training Step 880 \"min loss\" =  6.4460354\n",
      "2018-08-29 09:17:10.705129 Training Step 880 \"loss\" =  6.94058\n",
      "2018-08-29 09:17:10.907239 Test Step 885 Finished\n",
      "2018-08-29 09:17:10.907378 Test Step 885 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:10.907447 Test Step 885 \"loss\" =  19.636917\n",
      "2018-08-29 09:17:10.953477 Training Step 885 Finished Timing (Training: 0.908971, Test: 0.0835704) after 0.247668 seconds\n",
      "2018-08-29 09:17:10.953686 Training Step 885 \"min loss\" =  6.4460354\n",
      "2018-08-29 09:17:10.953816 Training Step 885 \"loss\" =  6.866122\n",
      "2018-08-29 09:17:11.155190 Test Step 890 Finished\n",
      "2018-08-29 09:17:11.155417 Test Step 890 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:11.155535 Test Step 890 \"loss\" =  19.867111\n",
      "2018-08-29 09:17:11.200801 Training Step 890 Finished Timing (Training: 0.909107, Test: 0.083622) after 0.246837 seconds\n",
      "2018-08-29 09:17:11.200956 Training Step 890 \"min loss\" =  6.4460354\n",
      "2018-08-29 09:17:11.201024 Training Step 890 \"loss\" =  6.5526066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:17:11.401592 Test Step 895 Finished\n",
      "2018-08-29 09:17:11.401734 Test Step 895 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:11.402318 Test Step 895 \"loss\" =  20.728243\n",
      "2018-08-29 09:17:11.448277 Training Step 895 Finished Timing (Training: 0.909177, Test: 0.0836111) after 0.247153 seconds\n",
      "2018-08-29 09:17:11.448406 Training Step 895 \"min loss\" =  6.227859\n",
      "2018-08-29 09:17:11.448468 Training Step 895 \"loss\" =  6.227859\n",
      "2018-08-29 09:17:11.647778 Test Step 900 Finished\n",
      "2018-08-29 09:17:11.647920 Test Step 900 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:11.647967 Test Step 900 \"loss\" =  20.307777\n",
      "2018-08-29 09:17:11.692958 Training Step 900 Finished Timing (Training: 0.90942, Test: 0.0836131) after 0.244408 seconds\n",
      "2018-08-29 09:17:11.693108 Training Step 900 \"min loss\" =  6.227859\n",
      "2018-08-29 09:17:11.693856 Training Step 900 \"loss\" =  7.4922013\n",
      "2018-08-29 09:17:11.894192 Test Step 905 Finished\n",
      "2018-08-29 09:17:11.894362 Test Step 905 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:11.894434 Test Step 905 \"loss\" =  20.012331\n",
      "2018-08-29 09:17:11.940473 Training Step 905 Finished Timing (Training: 0.914945, Test: 0.0835898) after 0.246512 seconds\n",
      "2018-08-29 09:17:11.940666 Training Step 905 \"min loss\" =  6.227859\n",
      "2018-08-29 09:17:11.940737 Training Step 905 \"loss\" =  6.975447\n",
      "2018-08-29 09:17:12.142368 Test Step 910 Finished\n",
      "2018-08-29 09:17:12.142512 Test Step 910 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:12.143095 Test Step 910 \"loss\" =  19.457878\n",
      "2018-08-29 09:17:12.188380 Training Step 910 Finished Timing (Training: 0.913133, Test: 0.0837182) after 0.247552 seconds\n",
      "2018-08-29 09:17:12.189013 Training Step 910 \"min loss\" =  6.0727224\n",
      "2018-08-29 09:17:12.189097 Training Step 910 \"loss\" =  6.6021523\n",
      "2018-08-29 09:17:12.391136 Test Step 915 Finished\n",
      "2018-08-29 09:17:12.391301 Test Step 915 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:12.392163 Test Step 915 \"loss\" =  19.481327\n",
      "2018-08-29 09:17:12.438743 Training Step 915 Finished Timing (Training: 0.910185, Test: 0.0844676) after 0.249564 seconds\n",
      "2018-08-29 09:17:12.438890 Training Step 915 \"min loss\" =  6.0727224\n",
      "2018-08-29 09:17:12.439517 Training Step 915 \"loss\" =  7.099197\n",
      "2018-08-29 09:17:12.641365 Test Step 920 Finished\n",
      "2018-08-29 09:17:12.641525 Test Step 920 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:12.642265 Test Step 920 \"loss\" =  21.2454\n",
      "2018-08-29 09:17:12.687553 Training Step 920 Finished Timing (Training: 0.908242, Test: 0.0848539) after 0.247358 seconds\n",
      "2018-08-29 09:17:12.688045 Training Step 920 \"min loss\" =  6.0727224\n",
      "2018-08-29 09:17:12.688655 Training Step 920 \"loss\" =  7.6893573\n",
      "2018-08-29 09:17:12.889059 Test Step 925 Finished\n",
      "2018-08-29 09:17:12.889539 Test Step 925 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:12.889950 Test Step 925 \"loss\" =  19.51813\n",
      "2018-08-29 09:17:12.935245 Training Step 925 Finished Timing (Training: 0.907957, Test: 0.0844318) after 0.246187 seconds\n",
      "2018-08-29 09:17:12.935373 Training Step 925 \"min loss\" =  6.0727224\n",
      "2018-08-29 09:17:12.935439 Training Step 925 \"loss\" =  7.36913\n",
      "2018-08-29 09:17:13.136708 Test Step 930 Finished\n",
      "2018-08-29 09:17:13.136875 Test Step 930 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:13.136944 Test Step 930 \"loss\" =  19.438795\n",
      "2018-08-29 09:17:13.182897 Training Step 930 Finished Timing (Training: 0.908477, Test: 0.0843035) after 0.246697 seconds\n",
      "2018-08-29 09:17:13.183089 Training Step 930 \"min loss\" =  6.0727224\n",
      "2018-08-29 09:17:13.183188 Training Step 930 \"loss\" =  6.53762\n",
      "2018-08-29 09:17:13.383135 Test Step 935 Finished\n",
      "2018-08-29 09:17:13.383283 Test Step 935 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:13.383350 Test Step 935 \"loss\" =  20.125744\n",
      "2018-08-29 09:17:13.428981 Training Step 935 Finished Timing (Training: 0.909261, Test: 0.0841321) after 0.245708 seconds\n",
      "2018-08-29 09:17:13.429140 Training Step 935 \"min loss\" =  6.0727224\n",
      "2018-08-29 09:17:13.429788 Training Step 935 \"loss\" =  6.801101\n",
      "2018-08-29 09:17:13.630774 Test Step 940 Finished\n",
      "2018-08-29 09:17:13.631596 Test Step 940 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:13.632002 Test Step 940 \"loss\" =  20.294195\n",
      "2018-08-29 09:17:13.677738 Training Step 940 Finished Timing (Training: 0.908808, Test: 0.083905) after 0.247133 seconds\n",
      "2018-08-29 09:17:13.677887 Training Step 940 \"min loss\" =  6.0727224\n",
      "2018-08-29 09:17:13.678650 Training Step 940 \"loss\" =  6.8967085\n",
      "2018-08-29 09:17:13.878336 Test Step 945 Finished\n",
      "2018-08-29 09:17:13.878463 Test Step 945 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:13.878547 Test Step 945 \"loss\" =  20.16488\n",
      "2018-08-29 09:17:13.924616 Training Step 945 Finished Timing (Training: 0.909161, Test: 0.0837405) after 0.245796 seconds\n",
      "2018-08-29 09:17:13.924765 Training Step 945 \"min loss\" =  6.0727224\n",
      "2018-08-29 09:17:13.925331 Training Step 945 \"loss\" =  6.905763\n",
      "2018-08-29 09:17:14.127301 Test Step 950 Finished\n",
      "2018-08-29 09:17:14.128006 Test Step 950 \"min loss\" =  18.946516\n",
      "2018-08-29 09:17:14.128094 Test Step 950 \"loss\" =  19.39888\n",
      "2018-08-29 09:17:14.173876 Training Step 950 Finished Timing (Training: 0.908687, Test: 0.0838089) after 0.248141 seconds\n",
      "2018-08-29 09:17:14.174016 Training Step 950 \"min loss\" =  6.0727224\n",
      "2018-08-29 09:17:14.174084 Training Step 950 \"loss\" =  6.100424\n",
      "2018-08-29 09:17:14.375587 Test Step 955 Finished\n",
      "2018-08-29 09:17:14.375761 Test Step 955 \"min loss\" =  18.743021\n",
      "2018-08-29 09:17:14.376500 Test Step 955 \"loss\" =  18.743021\n",
      "2018-08-29 09:17:14.421691 Training Step 955 Finished Timing (Training: 0.908483, Test: 0.0837673) after 0.246487 seconds\n",
      "2018-08-29 09:17:14.421816 Training Step 955 \"min loss\" =  6.0727224\n",
      "2018-08-29 09:17:14.421880 Training Step 955 \"loss\" =  7.5647445\n",
      "2018-08-29 09:17:14.623610 Test Step 960 Finished\n",
      "2018-08-29 09:17:14.623762 Test Step 960 \"min loss\" =  18.743021\n",
      "2018-08-29 09:17:14.623845 Test Step 960 \"loss\" =  19.243158\n",
      "2018-08-29 09:17:14.669626 Training Step 960 Finished Timing (Training: 0.908639, Test: 0.0837314) after 0.246724 seconds\n",
      "2018-08-29 09:17:14.670197 Training Step 960 \"min loss\" =  6.0727224\n",
      "2018-08-29 09:17:14.670571 Training Step 960 \"loss\" =  6.302479\n",
      "2018-08-29 09:17:14.871010 Test Step 965 Finished\n",
      "2018-08-29 09:17:14.871152 Test Step 965 \"min loss\" =  18.743021\n",
      "2018-08-29 09:17:14.871957 Test Step 965 \"loss\" =  19.162542\n",
      "2018-08-29 09:17:14.917696 Training Step 965 Finished Timing (Training: 0.908473, Test: 0.083624) after 0.246956 seconds\n",
      "2018-08-29 09:17:14.917823 Training Step 965 \"min loss\" =  6.0727224\n",
      "2018-08-29 09:17:14.918639 Training Step 965 \"loss\" =  7.168147\n",
      "2018-08-29 09:17:15.121009 Test Step 970 Finished\n",
      "2018-08-29 09:17:15.121171 Test Step 970 \"min loss\" =  18.743021\n",
      "2018-08-29 09:17:15.121241 Test Step 970 \"loss\" =  20.36413\n",
      "2018-08-29 09:17:15.167326 Training Step 970 Finished Timing (Training: 0.90848, Test: 0.0835918) after 0.247945 seconds\n",
      "2018-08-29 09:17:15.167476 Training Step 970 \"min loss\" =  6.0727224\n",
      "2018-08-29 09:17:15.168064 Training Step 970 \"loss\" =  7.1496797\n",
      "2018-08-29 09:17:15.369190 Test Step 975 Finished\n",
      "2018-08-29 09:17:15.369391 Test Step 975 \"min loss\" =  18.743021\n",
      "2018-08-29 09:17:15.369471 Test Step 975 \"loss\" =  20.000448\n",
      "2018-08-29 09:17:15.414453 Training Step 975 Finished Timing (Training: 0.908466, Test: 0.0837914) after 0.246301 seconds\n",
      "2018-08-29 09:17:15.414661 Training Step 975 \"min loss\" =  6.0506473\n",
      "2018-08-29 09:17:15.415150 Training Step 975 \"loss\" =  6.992288\n",
      "2018-08-29 09:17:15.616122 Test Step 980 Finished\n",
      "2018-08-29 09:17:15.616262 Test Step 980 \"min loss\" =  18.743021\n",
      "2018-08-29 09:17:15.617223 Test Step 980 \"loss\" =  20.355892\n",
      "2018-08-29 09:17:15.662630 Training Step 980 Finished Timing (Training: 0.90848, Test: 0.0837581) after 0.2474 seconds\n",
      "2018-08-29 09:17:15.662769 Training Step 980 \"min loss\" =  6.0506473\n",
      "2018-08-29 09:17:15.662850 Training Step 980 \"loss\" =  6.434923\n",
      "2018-08-29 09:17:15.864885 Test Step 985 Finished\n",
      "2018-08-29 09:17:15.865062 Test Step 985 \"min loss\" =  18.743021\n",
      "2018-08-29 09:17:15.865736 Test Step 985 \"loss\" =  21.1415\n",
      "2018-08-29 09:17:15.911021 Training Step 985 Finished Timing (Training: 0.908502, Test: 0.0838159) after 0.248073 seconds\n",
      "2018-08-29 09:17:15.911607 Training Step 985 \"min loss\" =  6.0506473\n",
      "2018-08-29 09:17:15.912119 Training Step 985 \"loss\" =  6.8931413\n",
      "2018-08-29 09:17:16.112635 Test Step 990 Finished\n",
      "2018-08-29 09:17:16.112832 Test Step 990 \"min loss\" =  18.743021\n",
      "2018-08-29 09:17:16.113390 Test Step 990 \"loss\" =  19.542137\n",
      "2018-08-29 09:17:16.158525 Training Step 990 Finished Timing (Training: 0.908404, Test: 0.0838321) after 0.246272 seconds\n",
      "2018-08-29 09:17:16.158656 Training Step 990 \"min loss\" =  6.0506473\n",
      "2018-08-29 09:17:16.158717 Training Step 990 \"loss\" =  7.026204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:17:16.359875 Test Step 995 Finished\n",
      "2018-08-29 09:17:16.360022 Test Step 995 \"min loss\" =  18.743021\n",
      "2018-08-29 09:17:16.360092 Test Step 995 \"loss\" =  18.951494\n",
      "2018-08-29 09:17:16.406604 Training Step 995 Finished Timing (Training: 0.908419, Test: 0.0838223) after 0.247811 seconds\n",
      "2018-08-29 09:17:16.406750 Training Step 995 \"min loss\" =  5.908632\n",
      "2018-08-29 09:17:16.407474 Training Step 995 \"loss\" =  7.174879\n",
      "2018-08-29 09:17:16.608503 Test Step 1000 Finished\n",
      "2018-08-29 09:17:16.608668 Test Step 1000 \"min loss\" =  18.743021\n",
      "2018-08-29 09:17:16.609267 Test Step 1000 \"loss\" =  19.574663\n",
      "2018-08-29 09:17:16.655132 Training Step 1000 Finished Timing (Training: 0.908375, Test: 0.0837944) after 0.247131 seconds\n",
      "2018-08-29 09:17:16.655286 Training Step 1000 \"min loss\" =  5.908632\n",
      "2018-08-29 09:17:16.656190 Training Step 1000 \"loss\" =  6.5866575\n",
      "2018-08-29 09:17:16.857086 Test Step 1005 Finished\n",
      "2018-08-29 09:17:16.857237 Test Step 1005 \"min loss\" =  18.743021\n",
      "2018-08-29 09:17:16.858044 Test Step 1005 \"loss\" =  19.407267\n",
      "2018-08-29 09:17:16.903611 Training Step 1005 Finished Timing (Training: 0.911275, Test: 0.0843676) after 0.247119 seconds\n",
      "2018-08-29 09:17:16.903761 Training Step 1005 \"min loss\" =  5.908632\n",
      "2018-08-29 09:17:16.903825 Training Step 1005 \"loss\" =  6.5856123\n",
      "2018-08-29 09:17:17.105312 Test Step 1010 Finished\n",
      "2018-08-29 09:17:17.105480 Test Step 1010 \"min loss\" =  17.800083\n",
      "2018-08-29 09:17:17.105550 Test Step 1010 \"loss\" =  17.800083\n",
      "2018-08-29 09:17:17.151610 Training Step 1010 Finished Timing (Training: 0.910432, Test: 0.0836879) after 0.247695 seconds\n",
      "2018-08-29 09:17:17.151754 Training Step 1010 \"min loss\" =  5.908632\n",
      "2018-08-29 09:17:17.151833 Training Step 1010 \"loss\" =  6.035717\n",
      "2018-08-29 09:17:17.353454 Test Step 1015 Finished\n",
      "2018-08-29 09:17:17.353631 Test Step 1015 \"min loss\" =  17.800083\n",
      "2018-08-29 09:17:17.353748 Test Step 1015 \"loss\" =  19.916677\n",
      "2018-08-29 09:17:17.399988 Training Step 1015 Finished Timing (Training: 0.910093, Test: 0.0833328) after 0.246871 seconds\n",
      "2018-08-29 09:17:17.400513 Training Step 1015 \"min loss\" =  5.662116\n",
      "2018-08-29 09:17:17.400658 Training Step 1015 \"loss\" =  7.0644183\n",
      "2018-08-29 09:17:17.602344 Test Step 1020 Finished\n",
      "2018-08-29 09:17:17.602494 Test Step 1020 \"min loss\" =  17.800083\n",
      "2018-08-29 09:17:17.603161 Test Step 1020 \"loss\" =  20.92802\n",
      "2018-08-29 09:17:17.648770 Training Step 1020 Finished Timing (Training: 0.909753, Test: 0.0835334) after 0.247978 seconds\n",
      "2018-08-29 09:17:17.648922 Training Step 1020 \"min loss\" =  5.662116\n",
      "2018-08-29 09:17:17.649011 Training Step 1020 \"loss\" =  6.4424887\n",
      "2018-08-29 09:17:17.849945 Test Step 1025 Finished\n",
      "2018-08-29 09:17:17.850091 Test Step 1025 \"min loss\" =  17.800083\n",
      "2018-08-29 09:17:17.850158 Test Step 1025 \"loss\" =  19.25545\n",
      "2018-08-29 09:17:17.895806 Training Step 1025 Finished Timing (Training: 0.910018, Test: 0.0833226) after 0.246709 seconds\n",
      "2018-08-29 09:17:17.895925 Training Step 1025 \"min loss\" =  5.662116\n",
      "2018-08-29 09:17:17.896002 Training Step 1025 \"loss\" =  6.5647507\n",
      "2018-08-29 09:17:18.097341 Test Step 1030 Finished\n",
      "2018-08-29 09:17:18.097505 Test Step 1030 \"min loss\" =  17.800083\n",
      "2018-08-29 09:17:18.097573 Test Step 1030 \"loss\" =  19.586533\n",
      "2018-08-29 09:17:18.143252 Training Step 1030 Finished Timing (Training: 0.909526, Test: 0.0833282) after 0.246179 seconds\n",
      "2018-08-29 09:17:18.143382 Training Step 1030 \"min loss\" =  5.662116\n",
      "2018-08-29 09:17:18.143440 Training Step 1030 \"loss\" =  6.0786667\n",
      "2018-08-29 09:17:18.344913 Test Step 1035 Finished\n",
      "2018-08-29 09:17:18.345631 Test Step 1035 \"min loss\" =  17.800083\n",
      "2018-08-29 09:17:18.345709 Test Step 1035 \"loss\" =  19.850742\n",
      "2018-08-29 09:17:18.391184 Training Step 1035 Finished Timing (Training: 0.909662, Test: 0.083247) after 0.247664 seconds\n",
      "2018-08-29 09:17:18.391805 Training Step 1035 \"min loss\" =  5.662116\n",
      "2018-08-29 09:17:18.391873 Training Step 1035 \"loss\" =  6.122358\n",
      "2018-08-29 09:17:18.592614 Test Step 1040 Finished\n",
      "2018-08-29 09:17:18.592760 Test Step 1040 \"min loss\" =  17.800083\n",
      "2018-08-29 09:17:18.593451 Test Step 1040 \"loss\" =  18.959013\n",
      "2018-08-29 09:17:18.638808 Training Step 1040 Finished Timing (Training: 0.909395, Test: 0.0833038) after 0.24684 seconds\n",
      "2018-08-29 09:17:18.639335 Training Step 1040 \"min loss\" =  5.662116\n",
      "2018-08-29 09:17:18.639413 Training Step 1040 \"loss\" =  6.8924294\n",
      "2018-08-29 09:17:18.840368 Test Step 1045 Finished\n",
      "2018-08-29 09:17:18.840536 Test Step 1045 \"min loss\" =  17.800083\n",
      "2018-08-29 09:17:18.841464 Test Step 1045 \"loss\" =  18.445467\n",
      "2018-08-29 09:17:18.887505 Training Step 1045 Finished Timing (Training: 0.909341, Test: 0.0832935) after 0.247992 seconds\n",
      "2018-08-29 09:17:18.887686 Training Step 1045 \"min loss\" =  5.662116\n",
      "2018-08-29 09:17:18.888144 Training Step 1045 \"loss\" =  6.2445498\n",
      "2018-08-29 09:17:19.090049 Test Step 1050 Finished\n",
      "2018-08-29 09:17:19.090720 Test Step 1050 \"min loss\" =  17.800083\n",
      "2018-08-29 09:17:19.091100 Test Step 1050 \"loss\" =  19.564108\n",
      "2018-08-29 09:17:19.136746 Training Step 1050 Finished Timing (Training: 0.909124, Test: 0.0833226) after 0.248456 seconds\n",
      "2018-08-29 09:17:19.136880 Training Step 1050 \"min loss\" =  5.662116\n",
      "2018-08-29 09:17:19.137587 Training Step 1050 \"loss\" =  6.043111\n",
      "2018-08-29 09:17:19.337511 Test Step 1055 Finished\n",
      "2018-08-29 09:17:19.337650 Test Step 1055 \"min loss\" =  17.800083\n",
      "2018-08-29 09:17:19.337731 Test Step 1055 \"loss\" =  19.162579\n",
      "2018-08-29 09:17:19.382519 Training Step 1055 Finished Timing (Training: 0.909243, Test: 0.083305) after 0.24453 seconds\n",
      "2018-08-29 09:17:19.382649 Training Step 1055 \"min loss\" =  5.662116\n",
      "2018-08-29 09:17:19.383319 Training Step 1055 \"loss\" =  6.1450977\n",
      "2018-08-29 09:17:19.583670 Test Step 1060 Finished\n",
      "2018-08-29 09:17:19.583814 Test Step 1060 \"min loss\" =  17.800083\n",
      "2018-08-29 09:17:19.584625 Test Step 1060 \"loss\" =  18.885763\n",
      "2018-08-29 09:17:19.629908 Training Step 1060 Finished Timing (Training: 0.90905, Test: 0.0833229) after 0.246119 seconds\n",
      "2018-08-29 09:17:19.630109 Training Step 1060 \"min loss\" =  5.662116\n",
      "2018-08-29 09:17:19.630809 Training Step 1060 \"loss\" =  6.4226975\n",
      "2018-08-29 09:17:19.831852 Test Step 1065 Finished\n",
      "2018-08-29 09:17:19.832011 Test Step 1065 \"min loss\" =  17.800083\n",
      "2018-08-29 09:17:19.832080 Test Step 1065 \"loss\" =  19.80253\n",
      "2018-08-29 09:17:19.877089 Training Step 1065 Finished Timing (Training: 0.909085, Test: 0.0833088) after 0.245712 seconds\n",
      "2018-08-29 09:17:19.877254 Training Step 1065 \"min loss\" =  5.662116\n",
      "2018-08-29 09:17:19.878006 Training Step 1065 \"loss\" =  6.4895787\n",
      "2018-08-29 09:17:20.078991 Test Step 1070 Finished\n",
      "2018-08-29 09:17:20.079125 Test Step 1070 \"min loss\" =  17.800083\n",
      "2018-08-29 09:17:20.079195 Test Step 1070 \"loss\" =  19.61802\n",
      "2018-08-29 09:17:20.125257 Training Step 1070 Finished Timing (Training: 0.908875, Test: 0.0833551) after 0.247006 seconds\n",
      "2018-08-29 09:17:20.125802 Training Step 1070 \"min loss\" =  5.4693847\n",
      "2018-08-29 09:17:20.125886 Training Step 1070 \"loss\" =  5.4693847\n",
      "2018-08-29 09:17:20.327215 Test Step 1075 Finished\n",
      "2018-08-29 09:17:20.327833 Test Step 1075 \"min loss\" =  17.800083\n",
      "2018-08-29 09:17:20.328430 Test Step 1075 \"loss\" =  18.260073\n",
      "2018-08-29 09:17:20.373627 Training Step 1075 Finished Timing (Training: 0.908733, Test: 0.0833689) after 0.247637 seconds\n",
      "2018-08-29 09:17:20.373778 Training Step 1075 \"min loss\" =  5.4693847\n",
      "2018-08-29 09:17:20.373848 Training Step 1075 \"loss\" =  6.5072665\n",
      "2018-08-29 09:17:20.574773 Test Step 1080 Finished\n",
      "2018-08-29 09:17:20.574953 Test Step 1080 \"min loss\" =  17.800083\n",
      "2018-08-29 09:17:20.575023 Test Step 1080 \"loss\" =  18.586952\n",
      "2018-08-29 09:17:20.620130 Training Step 1080 Finished Timing (Training: 0.908878, Test: 0.0835445) after 0.246192 seconds\n",
      "2018-08-29 09:17:20.620277 Training Step 1080 \"min loss\" =  5.4693847\n",
      "2018-08-29 09:17:20.621017 Training Step 1080 \"loss\" =  6.3009915\n",
      "2018-08-29 09:17:20.822191 Test Step 1085 Finished\n",
      "2018-08-29 09:17:20.822352 Test Step 1085 \"min loss\" =  17.800083\n",
      "2018-08-29 09:17:20.823445 Test Step 1085 \"loss\" =  19.183912\n",
      "2018-08-29 09:17:20.868442 Training Step 1085 Finished Timing (Training: 0.908831, Test: 0.083478) after 0.247332 seconds\n",
      "2018-08-29 09:17:20.868639 Training Step 1085 \"min loss\" =  5.4693847\n",
      "2018-08-29 09:17:20.869612 Training Step 1085 \"loss\" =  5.8009415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:17:21.069940 Test Step 1090 Finished\n",
      "2018-08-29 09:17:21.070101 Test Step 1090 \"min loss\" =  17.800083\n",
      "2018-08-29 09:17:21.070745 Test Step 1090 \"loss\" =  19.363619\n",
      "2018-08-29 09:17:21.115686 Training Step 1090 Finished Timing (Training: 0.908679, Test: 0.0835044) after 0.24574 seconds\n",
      "2018-08-29 09:17:21.116283 Training Step 1090 \"min loss\" =  5.4693847\n",
      "2018-08-29 09:17:21.116711 Training Step 1090 \"loss\" =  6.264105\n",
      "2018-08-29 09:17:21.317325 Test Step 1095 Finished\n",
      "2018-08-29 09:17:21.317502 Test Step 1095 \"min loss\" =  17.800083\n",
      "2018-08-29 09:17:21.317570 Test Step 1095 \"loss\" =  19.134089\n",
      "2018-08-29 09:17:21.363859 Training Step 1095 Finished Timing (Training: 0.908518, Test: 0.083456) after 0.246692 seconds\n",
      "2018-08-29 09:17:21.364000 Training Step 1095 \"min loss\" =  5.4693847\n",
      "2018-08-29 09:17:21.364065 Training Step 1095 \"loss\" =  5.617114\n",
      "2018-08-29 09:17:21.564438 Test Step 1100 Finished\n",
      "2018-08-29 09:17:21.565004 Test Step 1100 \"min loss\" =  17.800083\n",
      "2018-08-29 09:17:21.565393 Test Step 1100 \"loss\" =  19.497627\n",
      "2018-08-29 09:17:21.610913 Training Step 1100 Finished Timing (Training: 0.908561, Test: 0.0834202) after 0.246767 seconds\n",
      "2018-08-29 09:17:21.611077 Training Step 1100 \"min loss\" =  5.4693847\n",
      "2018-08-29 09:17:21.611862 Training Step 1100 \"loss\" =  5.967629\n",
      "2018-08-29 09:17:21.812959 Test Step 1105 Finished\n",
      "2018-08-29 09:17:21.813109 Test Step 1105 \"min loss\" =  17.800083\n",
      "2018-08-29 09:17:21.813184 Test Step 1105 \"loss\" =  18.886572\n",
      "2018-08-29 09:17:21.858075 Training Step 1105 Finished Timing (Training: 0.914666, Test: 0.0839838) after 0.245825 seconds\n",
      "2018-08-29 09:17:21.858230 Training Step 1105 \"min loss\" =  5.4693847\n",
      "2018-08-29 09:17:21.858986 Training Step 1105 \"loss\" =  6.1820893\n",
      "2018-08-29 09:17:22.059408 Test Step 1110 Finished\n",
      "2018-08-29 09:17:22.059584 Test Step 1110 \"min loss\" =  17.800083\n",
      "2018-08-29 09:17:22.060605 Test Step 1110 \"loss\" =  17.89584\n",
      "2018-08-29 09:17:22.105884 Training Step 1110 Finished Timing (Training: 0.909936, Test: 0.0834333) after 0.246247 seconds\n",
      "2018-08-29 09:17:22.106036 Training Step 1110 \"min loss\" =  5.4693847\n",
      "2018-08-29 09:17:22.106938 Training Step 1110 \"loss\" =  6.404056\n",
      "2018-08-29 09:17:22.307429 Test Step 1115 Finished\n",
      "2018-08-29 09:17:22.307563 Test Step 1115 \"min loss\" =  17.800083\n",
      "2018-08-29 09:17:22.307628 Test Step 1115 \"loss\" =  19.187931\n",
      "2018-08-29 09:17:22.353402 Training Step 1115 Finished Timing (Training: 0.908441, Test: 0.0832523) after 0.245933 seconds\n",
      "2018-08-29 09:17:22.353549 Training Step 1115 \"min loss\" =  5.4693847\n",
      "2018-08-29 09:17:22.353613 Training Step 1115 \"loss\" =  6.302181\n",
      "2018-08-29 09:17:22.556130 Test Step 1120 Finished\n",
      "2018-08-29 09:17:22.556277 Test Step 1120 \"min loss\" =  17.700176\n",
      "2018-08-29 09:17:22.556346 Test Step 1120 \"loss\" =  17.700176\n",
      "2018-08-29 09:17:22.602061 Training Step 1120 Finished Timing (Training: 0.909377, Test: 0.0832364) after 0.248336 seconds\n",
      "2018-08-29 09:17:22.602222 Training Step 1120 \"min loss\" =  5.4693847\n",
      "2018-08-29 09:17:22.602292 Training Step 1120 \"loss\" =  6.0607324\n",
      "2018-08-29 09:17:22.803618 Test Step 1125 Finished\n",
      "2018-08-29 09:17:22.803846 Test Step 1125 \"min loss\" =  17.700176\n",
      "2018-08-29 09:17:22.804953 Test Step 1125 \"loss\" =  18.572603\n",
      "2018-08-29 09:17:22.850460 Training Step 1125 Finished Timing (Training: 0.909053, Test: 0.0832279) after 0.248083 seconds\n",
      "2018-08-29 09:17:22.850603 Training Step 1125 \"min loss\" =  5.4693847\n",
      "2018-08-29 09:17:22.850690 Training Step 1125 \"loss\" =  6.09001\n",
      "2018-08-29 09:17:23.051901 Test Step 1130 Finished\n",
      "2018-08-29 09:17:23.052109 Test Step 1130 \"min loss\" =  17.700176\n",
      "2018-08-29 09:17:23.052241 Test Step 1130 \"loss\" =  19.6554\n",
      "2018-08-29 09:17:23.098287 Training Step 1130 Finished Timing (Training: 0.909576, Test: 0.0834299) after 0.247507 seconds\n",
      "2018-08-29 09:17:23.098427 Training Step 1130 \"min loss\" =  5.280218\n",
      "2018-08-29 09:17:23.098541 Training Step 1130 \"loss\" =  6.333351\n",
      "2018-08-29 09:17:23.299797 Test Step 1135 Finished\n",
      "2018-08-29 09:17:23.300490 Test Step 1135 \"min loss\" =  17.700176\n",
      "2018-08-29 09:17:23.300886 Test Step 1135 \"loss\" =  18.148855\n",
      "2018-08-29 09:17:23.345961 Training Step 1135 Finished Timing (Training: 0.909359, Test: 0.0836272) after 0.247339 seconds\n",
      "2018-08-29 09:17:23.346090 Training Step 1135 \"min loss\" =  5.2685084\n",
      "2018-08-29 09:17:23.346165 Training Step 1135 \"loss\" =  5.7719784\n",
      "2018-08-29 09:17:23.547392 Test Step 1140 Finished\n",
      "2018-08-29 09:17:23.547585 Test Step 1140 \"min loss\" =  17.700176\n",
      "2018-08-29 09:17:23.547695 Test Step 1140 \"loss\" =  17.896511\n",
      "2018-08-29 09:17:23.593129 Training Step 1140 Finished Timing (Training: 0.909516, Test: 0.0836287) after 0.246888 seconds\n",
      "2018-08-29 09:17:23.593251 Training Step 1140 \"min loss\" =  5.2685084\n",
      "2018-08-29 09:17:23.593717 Training Step 1140 \"loss\" =  5.9882503\n",
      "2018-08-29 09:17:23.795644 Test Step 1145 Finished\n",
      "2018-08-29 09:17:23.796211 Test Step 1145 \"min loss\" =  17.700176\n",
      "2018-08-29 09:17:23.796576 Test Step 1145 \"loss\" =  18.23754\n",
      "2018-08-29 09:17:23.841567 Training Step 1145 Finished Timing (Training: 0.909227, Test: 0.0837497) after 0.247488 seconds\n",
      "2018-08-29 09:17:23.842085 Training Step 1145 \"min loss\" =  5.2685084\n",
      "2018-08-29 09:17:23.842329 Training Step 1145 \"loss\" =  6.215401\n",
      "2018-08-29 09:17:24.042647 Test Step 1150 Finished\n",
      "2018-08-29 09:17:24.043280 Test Step 1150 \"min loss\" =  17.700176\n",
      "2018-08-29 09:17:24.043360 Test Step 1150 \"loss\" =  17.852392\n",
      "2018-08-29 09:17:24.089079 Training Step 1150 Finished Timing (Training: 0.909182, Test: 0.0836427) after 0.246645 seconds\n",
      "2018-08-29 09:17:24.089278 Training Step 1150 \"min loss\" =  5.2685084\n",
      "2018-08-29 09:17:24.089391 Training Step 1150 \"loss\" =  6.5866227\n",
      "2018-08-29 09:17:24.290155 Test Step 1155 Finished\n",
      "2018-08-29 09:17:24.290344 Test Step 1155 \"min loss\" =  17.700176\n",
      "2018-08-29 09:17:24.290464 Test Step 1155 \"loss\" =  19.856506\n",
      "2018-08-29 09:17:24.336317 Training Step 1155 Finished Timing (Training: 0.909272, Test: 0.083598) after 0.246787 seconds\n",
      "2018-08-29 09:17:24.336460 Training Step 1155 \"min loss\" =  5.2685084\n",
      "2018-08-29 09:17:24.337230 Training Step 1155 \"loss\" =  5.379021\n",
      "2018-08-29 09:17:24.537918 Test Step 1160 Finished\n",
      "2018-08-29 09:17:24.538064 Test Step 1160 \"min loss\" =  17.700176\n",
      "2018-08-29 09:17:24.538163 Test Step 1160 \"loss\" =  20.364813\n",
      "2018-08-29 09:17:24.584696 Training Step 1160 Finished Timing (Training: 0.908826, Test: 0.0836404) after 0.246731 seconds\n",
      "2018-08-29 09:17:24.584851 Training Step 1160 \"min loss\" =  5.2685084\n",
      "2018-08-29 09:17:24.585601 Training Step 1160 \"loss\" =  6.7466025\n",
      "2018-08-29 09:17:24.786461 Test Step 1165 Finished\n",
      "2018-08-29 09:17:24.786601 Test Step 1165 \"min loss\" =  17.700176\n",
      "2018-08-29 09:17:24.787414 Test Step 1165 \"loss\" =  19.062483\n",
      "2018-08-29 09:17:24.832418 Training Step 1165 Finished Timing (Training: 0.908561, Test: 0.0837042) after 0.246284 seconds\n",
      "2018-08-29 09:17:24.832564 Training Step 1165 \"min loss\" =  5.2685084\n",
      "2018-08-29 09:17:24.832670 Training Step 1165 \"loss\" =  6.2120404\n",
      "2018-08-29 09:17:25.034157 Test Step 1170 Finished\n",
      "2018-08-29 09:17:25.034335 Test Step 1170 \"min loss\" =  17.700176\n",
      "2018-08-29 09:17:25.034404 Test Step 1170 \"loss\" =  18.02397\n",
      "2018-08-29 09:17:25.080858 Training Step 1170 Finished Timing (Training: 0.908671, Test: 0.0836217) after 0.248092 seconds\n",
      "2018-08-29 09:17:25.081436 Training Step 1170 \"min loss\" =  5.2685084\n",
      "2018-08-29 09:17:25.081510 Training Step 1170 \"loss\" =  6.298725\n",
      "2018-08-29 09:17:25.283781 Test Step 1175 Finished\n",
      "2018-08-29 09:17:25.283935 Test Step 1175 \"min loss\" =  17.700176\n",
      "2018-08-29 09:17:25.284008 Test Step 1175 \"loss\" =  18.368694\n",
      "2018-08-29 09:17:25.330087 Training Step 1175 Finished Timing (Training: 0.908786, Test: 0.0835657) after 0.24788 seconds\n",
      "2018-08-29 09:17:25.330242 Training Step 1175 \"min loss\" =  5.2685084\n",
      "2018-08-29 09:17:25.330311 Training Step 1175 \"loss\" =  6.083996\n",
      "2018-08-29 09:17:25.532301 Test Step 1180 Finished\n",
      "2018-08-29 09:17:25.532965 Test Step 1180 \"min loss\" =  17.700176\n",
      "2018-08-29 09:17:25.533045 Test Step 1180 \"loss\" =  18.58963\n",
      "2018-08-29 09:17:25.577991 Training Step 1180 Finished Timing (Training: 0.908763, Test: 0.0836558) after 0.247189 seconds\n",
      "2018-08-29 09:17:25.578131 Training Step 1180 \"min loss\" =  5.2685084\n",
      "2018-08-29 09:17:25.578199 Training Step 1180 \"loss\" =  6.1084323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:17:25.778645 Test Step 1185 Finished\n",
      "2018-08-29 09:17:25.779327 Test Step 1185 \"min loss\" =  17.700176\n",
      "2018-08-29 09:17:25.779727 Test Step 1185 \"loss\" =  17.872036\n",
      "2018-08-29 09:17:25.825245 Training Step 1185 Finished Timing (Training: 0.908909, Test: 0.0835998) after 0.246967 seconds\n",
      "2018-08-29 09:17:25.825379 Training Step 1185 \"min loss\" =  5.2685084\n",
      "2018-08-29 09:17:25.825447 Training Step 1185 \"loss\" =  5.8589215\n",
      "2018-08-29 09:17:26.026640 Test Step 1190 Finished\n",
      "2018-08-29 09:17:26.026798 Test Step 1190 \"min loss\" =  17.700176\n",
      "2018-08-29 09:17:26.027331 Test Step 1190 \"loss\" =  18.32497\n",
      "2018-08-29 09:17:26.072330 Training Step 1190 Finished Timing (Training: 0.909006, Test: 0.0836696) after 0.246794 seconds\n",
      "2018-08-29 09:17:26.072477 Training Step 1190 \"min loss\" =  5.2685084\n",
      "2018-08-29 09:17:26.072554 Training Step 1190 \"loss\" =  5.4683857\n",
      "2018-08-29 09:17:26.273432 Test Step 1195 Finished\n",
      "2018-08-29 09:17:26.273598 Test Step 1195 \"min loss\" =  17.700176\n",
      "2018-08-29 09:17:26.273707 Test Step 1195 \"loss\" =  18.401611\n",
      "2018-08-29 09:17:26.320185 Training Step 1195 Finished Timing (Training: 0.909014, Test: 0.0837287) after 0.247513 seconds\n",
      "2018-08-29 09:17:26.320377 Training Step 1195 \"min loss\" =  5.073512\n",
      "2018-08-29 09:17:26.320982 Training Step 1195 \"loss\" =  5.8049793\n",
      "2018-08-29 09:17:26.522045 Test Step 1200 Finished\n",
      "2018-08-29 09:17:26.522191 Test Step 1200 \"min loss\" =  17.700176\n",
      "2018-08-29 09:17:26.522263 Test Step 1200 \"loss\" =  18.841713\n",
      "2018-08-29 09:17:26.568586 Training Step 1200 Finished Timing (Training: 0.90897, Test: 0.0836957) after 0.247479 seconds\n",
      "2018-08-29 09:17:26.569212 Training Step 1200 \"min loss\" =  5.073512\n",
      "2018-08-29 09:17:26.569503 Training Step 1200 \"loss\" =  5.7242913\n",
      "2018-08-29 09:17:26.771337 Test Step 1205 Finished\n",
      "2018-08-29 09:17:26.771486 Test Step 1205 \"min loss\" =  17.700176\n",
      "2018-08-29 09:17:26.771557 Test Step 1205 \"loss\" =  18.474749\n",
      "2018-08-29 09:17:26.816682 Training Step 1205 Finished Timing (Training: 0.912717, Test: 0.0859342) after 0.246855 seconds\n",
      "2018-08-29 09:17:26.816843 Training Step 1205 \"min loss\" =  5.073512\n",
      "2018-08-29 09:17:26.817542 Training Step 1205 \"loss\" =  5.8652954\n",
      "2018-08-29 09:17:27.018153 Test Step 1210 Finished\n",
      "2018-08-29 09:17:27.018306 Test Step 1210 \"min loss\" =  17.700176\n",
      "2018-08-29 09:17:27.018967 Test Step 1210 \"loss\" =  18.561676\n",
      "2018-08-29 09:17:27.064311 Training Step 1210 Finished Timing (Training: 0.910228, Test: 0.0847697) after 0.246617 seconds\n",
      "2018-08-29 09:17:27.064458 Training Step 1210 \"min loss\" =  5.062984\n",
      "2018-08-29 09:17:27.064524 Training Step 1210 \"loss\" =  6.0565963\n",
      "2018-08-29 09:17:27.265363 Test Step 1215 Finished\n",
      "2018-08-29 09:17:27.265498 Test Step 1215 \"min loss\" =  17.700176\n",
      "2018-08-29 09:17:27.266328 Test Step 1215 \"loss\" =  18.265673\n",
      "2018-08-29 09:17:27.312515 Training Step 1215 Finished Timing (Training: 0.910217, Test: 0.0840953) after 0.247782 seconds\n",
      "2018-08-29 09:17:27.313023 Training Step 1215 \"min loss\" =  5.062984\n",
      "2018-08-29 09:17:27.313360 Training Step 1215 \"loss\" =  6.127809\n",
      "2018-08-29 09:17:27.513729 Test Step 1220 Finished\n",
      "2018-08-29 09:17:27.514300 Test Step 1220 \"min loss\" =  17.700176\n",
      "2018-08-29 09:17:27.514371 Test Step 1220 \"loss\" =  18.240509\n",
      "2018-08-29 09:17:27.560496 Training Step 1220 Finished Timing (Training: 0.909245, Test: 0.0836877) after 0.246902 seconds\n",
      "2018-08-29 09:17:27.560666 Training Step 1220 \"min loss\" =  5.062984\n",
      "2018-08-29 09:17:27.560736 Training Step 1220 \"loss\" =  5.412525\n",
      "2018-08-29 09:17:27.762803 Test Step 1225 Finished\n",
      "2018-08-29 09:17:27.763395 Test Step 1225 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:27.763473 Test Step 1225 \"loss\" =  17.686457\n",
      "2018-08-29 09:17:27.809065 Training Step 1225 Finished Timing (Training: 0.910051, Test: 0.0833945) after 0.248238 seconds\n",
      "2018-08-29 09:17:27.809214 Training Step 1225 \"min loss\" =  5.062984\n",
      "2018-08-29 09:17:27.809277 Training Step 1225 \"loss\" =  6.0774064\n",
      "2018-08-29 09:17:28.010601 Test Step 1230 Finished\n",
      "2018-08-29 09:17:28.011066 Test Step 1230 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:28.011133 Test Step 1230 \"loss\" =  18.730742\n",
      "2018-08-29 09:17:28.056578 Training Step 1230 Finished Timing (Training: 0.90986, Test: 0.083711) after 0.247222 seconds\n",
      "2018-08-29 09:17:28.056727 Training Step 1230 \"min loss\" =  4.94026\n",
      "2018-08-29 09:17:28.057423 Training Step 1230 \"loss\" =  6.06234\n",
      "2018-08-29 09:17:28.258643 Test Step 1235 Finished\n",
      "2018-08-29 09:17:28.258815 Test Step 1235 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:28.258887 Test Step 1235 \"loss\" =  19.415709\n",
      "2018-08-29 09:17:28.304984 Training Step 1235 Finished Timing (Training: 0.909835, Test: 0.0837345) after 0.247169 seconds\n",
      "2018-08-29 09:17:28.305152 Training Step 1235 \"min loss\" =  4.94026\n",
      "2018-08-29 09:17:28.305226 Training Step 1235 \"loss\" =  6.060843\n",
      "2018-08-29 09:17:28.508280 Test Step 1240 Finished\n",
      "2018-08-29 09:17:28.508434 Test Step 1240 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:28.509334 Test Step 1240 \"loss\" =  18.362135\n",
      "2018-08-29 09:17:28.555010 Training Step 1240 Finished Timing (Training: 0.909784, Test: 0.0837078) after 0.249681 seconds\n",
      "2018-08-29 09:17:28.555229 Training Step 1240 \"min loss\" =  4.94026\n",
      "2018-08-29 09:17:28.555349 Training Step 1240 \"loss\" =  5.3151555\n",
      "2018-08-29 09:17:28.756072 Test Step 1245 Finished\n",
      "2018-08-29 09:17:28.756237 Test Step 1245 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:28.756928 Test Step 1245 \"loss\" =  18.233341\n",
      "2018-08-29 09:17:28.802305 Training Step 1245 Finished Timing (Training: 0.909855, Test: 0.0835812) after 0.246821 seconds\n",
      "2018-08-29 09:17:28.802452 Training Step 1245 \"min loss\" =  4.94026\n",
      "2018-08-29 09:17:28.802522 Training Step 1245 \"loss\" =  5.706561\n",
      "2018-08-29 09:17:29.003765 Test Step 1250 Finished\n",
      "2018-08-29 09:17:29.004308 Test Step 1250 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:29.005108 Test Step 1250 \"loss\" =  19.3076\n",
      "2018-08-29 09:17:29.050427 Training Step 1250 Finished Timing (Training: 0.909462, Test: 0.083691) after 0.247754 seconds\n",
      "2018-08-29 09:17:29.050600 Training Step 1250 \"min loss\" =  4.94026\n",
      "2018-08-29 09:17:29.050669 Training Step 1250 \"loss\" =  5.858271\n",
      "2018-08-29 09:17:29.251557 Test Step 1255 Finished\n",
      "2018-08-29 09:17:29.252043 Test Step 1255 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:29.252366 Test Step 1255 \"loss\" =  18.34834\n",
      "2018-08-29 09:17:29.297457 Training Step 1255 Finished Timing (Training: 0.909451, Test: 0.0836026) after 0.246027 seconds\n",
      "2018-08-29 09:17:29.297932 Training Step 1255 \"min loss\" =  4.94026\n",
      "2018-08-29 09:17:29.298394 Training Step 1255 \"loss\" =  5.5954776\n",
      "2018-08-29 09:17:29.499768 Test Step 1260 Finished\n",
      "2018-08-29 09:17:29.500310 Test Step 1260 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:29.500575 Test Step 1260 \"loss\" =  19.02761\n",
      "2018-08-29 09:17:29.545785 Training Step 1260 Finished Timing (Training: 0.909342, Test: 0.0835314) after 0.246986 seconds\n",
      "2018-08-29 09:17:29.545912 Training Step 1260 \"min loss\" =  4.94026\n",
      "2018-08-29 09:17:29.546427 Training Step 1260 \"loss\" =  4.9969063\n",
      "2018-08-29 09:17:29.746816 Test Step 1265 Finished\n",
      "2018-08-29 09:17:29.746947 Test Step 1265 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:29.747730 Test Step 1265 \"loss\" =  19.481031\n",
      "2018-08-29 09:17:29.792847 Training Step 1265 Finished Timing (Training: 0.909214, Test: 0.0836545) after 0.246336 seconds\n",
      "2018-08-29 09:17:29.793052 Training Step 1265 \"min loss\" =  4.9162765\n",
      "2018-08-29 09:17:29.793175 Training Step 1265 \"loss\" =  5.7848153\n",
      "2018-08-29 09:17:29.994497 Test Step 1270 Finished\n",
      "2018-08-29 09:17:29.994650 Test Step 1270 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:29.994715 Test Step 1270 \"loss\" =  18.86276\n",
      "2018-08-29 09:17:30.040545 Training Step 1270 Finished Timing (Training: 0.909379, Test: 0.083617) after 0.246717 seconds\n",
      "2018-08-29 09:17:30.040700 Training Step 1270 \"min loss\" =  4.9162765\n",
      "2018-08-29 09:17:30.041365 Training Step 1270 \"loss\" =  5.402179\n",
      "2018-08-29 09:17:30.242083 Test Step 1275 Finished\n",
      "2018-08-29 09:17:30.242885 Test Step 1275 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:30.243426 Test Step 1275 \"loss\" =  18.137146\n",
      "2018-08-29 09:17:30.289378 Training Step 1275 Finished Timing (Training: 0.909176, Test: 0.0835266) after 0.247894 seconds\n",
      "2018-08-29 09:17:30.289541 Training Step 1275 \"min loss\" =  4.9162765\n",
      "2018-08-29 09:17:30.290252 Training Step 1275 \"loss\" =  5.419986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:17:30.490479 Test Step 1280 Finished\n",
      "2018-08-29 09:17:30.490631 Test Step 1280 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:30.491380 Test Step 1280 \"loss\" =  17.93677\n",
      "2018-08-29 09:17:30.536762 Training Step 1280 Finished Timing (Training: 0.909046, Test: 0.0835046) after 0.2462 seconds\n",
      "2018-08-29 09:17:30.536904 Training Step 1280 \"min loss\" =  4.9162765\n",
      "2018-08-29 09:17:30.537587 Training Step 1280 \"loss\" =  5.3593383\n",
      "2018-08-29 09:17:30.738993 Test Step 1285 Finished\n",
      "2018-08-29 09:17:30.739126 Test Step 1285 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:30.739246 Test Step 1285 \"loss\" =  18.679148\n",
      "2018-08-29 09:17:30.785693 Training Step 1285 Finished Timing (Training: 0.909177, Test: 0.083501) after 0.247999 seconds\n",
      "2018-08-29 09:17:30.785837 Training Step 1285 \"min loss\" =  4.7840314\n",
      "2018-08-29 09:17:30.786364 Training Step 1285 \"loss\" =  5.044713\n",
      "2018-08-29 09:17:30.986810 Test Step 1290 Finished\n",
      "2018-08-29 09:17:30.987523 Test Step 1290 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:30.987929 Test Step 1290 \"loss\" =  18.35114\n",
      "2018-08-29 09:17:31.033694 Training Step 1290 Finished Timing (Training: 0.909022, Test: 0.0834834) after 0.247244 seconds\n",
      "2018-08-29 09:17:31.033891 Training Step 1290 \"min loss\" =  4.7840314\n",
      "2018-08-29 09:17:31.034005 Training Step 1290 \"loss\" =  5.307575\n",
      "2018-08-29 09:17:31.235207 Test Step 1295 Finished\n",
      "2018-08-29 09:17:31.235352 Test Step 1295 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:31.235932 Test Step 1295 \"loss\" =  18.691277\n",
      "2018-08-29 09:17:31.281199 Training Step 1295 Finished Timing (Training: 0.908833, Test: 0.0834692) after 0.245831 seconds\n",
      "2018-08-29 09:17:31.281333 Training Step 1295 \"min loss\" =  4.7840314\n",
      "2018-08-29 09:17:31.282007 Training Step 1295 \"loss\" =  5.1359987\n",
      "2018-08-29 09:17:31.482315 Test Step 1300 Finished\n",
      "2018-08-29 09:17:31.482451 Test Step 1300 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:31.483501 Test Step 1300 \"loss\" =  18.552832\n",
      "2018-08-29 09:17:31.529053 Training Step 1300 Finished Timing (Training: 0.908665, Test: 0.083425) after 0.246908 seconds\n",
      "2018-08-29 09:17:31.529710 Training Step 1300 \"min loss\" =  4.7840314\n",
      "2018-08-29 09:17:31.529807 Training Step 1300 \"loss\" =  5.822686\n",
      "2018-08-29 09:17:31.730805 Test Step 1305 Finished\n",
      "2018-08-29 09:17:31.730945 Test Step 1305 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:31.731699 Test Step 1305 \"loss\" =  18.278618\n",
      "2018-08-29 09:17:31.777058 Training Step 1305 Finished Timing (Training: 0.912668, Test: 0.0832086) after 0.246579 seconds\n",
      "2018-08-29 09:17:31.777225 Training Step 1305 \"min loss\" =  4.7840314\n",
      "2018-08-29 09:17:31.777886 Training Step 1305 \"loss\" =  5.6847672\n",
      "2018-08-29 09:17:31.979045 Test Step 1310 Finished\n",
      "2018-08-29 09:17:31.979186 Test Step 1310 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:31.979256 Test Step 1310 \"loss\" =  18.733227\n",
      "2018-08-29 09:17:32.025383 Training Step 1310 Finished Timing (Training: 0.910147, Test: 0.0829417) after 0.247355 seconds\n",
      "2018-08-29 09:17:32.025525 Training Step 1310 \"min loss\" =  4.6826677\n",
      "2018-08-29 09:17:32.025589 Training Step 1310 \"loss\" =  4.6826677\n",
      "2018-08-29 09:17:32.227269 Test Step 1315 Finished\n",
      "2018-08-29 09:17:32.227937 Test Step 1315 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:32.228265 Test Step 1315 \"loss\" =  18.957409\n",
      "2018-08-29 09:17:32.273515 Training Step 1315 Finished Timing (Training: 0.908486, Test: 0.0833676) after 0.246618 seconds\n",
      "2018-08-29 09:17:32.273632 Training Step 1315 \"min loss\" =  4.6561127\n",
      "2018-08-29 09:17:32.273697 Training Step 1315 \"loss\" =  5.863198\n",
      "2018-08-29 09:17:32.475461 Test Step 1320 Finished\n",
      "2018-08-29 09:17:32.476100 Test Step 1320 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:32.476181 Test Step 1320 \"loss\" =  19.281982\n",
      "2018-08-29 09:17:32.521830 Training Step 1320 Finished Timing (Training: 0.90782, Test: 0.0832102) after 0.246982 seconds\n",
      "2018-08-29 09:17:32.521972 Training Step 1320 \"min loss\" =  4.6561127\n",
      "2018-08-29 09:17:32.522639 Training Step 1320 \"loss\" =  5.43284\n",
      "2018-08-29 09:17:32.723391 Test Step 1325 Finished\n",
      "2018-08-29 09:17:32.723534 Test Step 1325 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:32.723605 Test Step 1325 \"loss\" =  18.957941\n",
      "2018-08-29 09:17:32.768718 Training Step 1325 Finished Timing (Training: 0.908458, Test: 0.0831681) after 0.245775 seconds\n",
      "2018-08-29 09:17:32.768847 Training Step 1325 \"min loss\" =  4.6561127\n",
      "2018-08-29 09:17:32.768955 Training Step 1325 \"loss\" =  5.4423113\n",
      "2018-08-29 09:17:32.968976 Test Step 1330 Finished\n",
      "2018-08-29 09:17:32.969171 Test Step 1330 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:32.969248 Test Step 1330 \"loss\" =  19.665419\n",
      "2018-08-29 09:17:33.014321 Training Step 1330 Finished Timing (Training: 0.909103, Test: 0.0834243) after 0.245282 seconds\n",
      "2018-08-29 09:17:33.014465 Training Step 1330 \"min loss\" =  4.6561127\n",
      "2018-08-29 09:17:33.014527 Training Step 1330 \"loss\" =  5.1539555\n",
      "2018-08-29 09:17:33.215865 Test Step 1335 Finished\n",
      "2018-08-29 09:17:33.216008 Test Step 1335 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:33.216076 Test Step 1335 \"loss\" =  20.07165\n",
      "2018-08-29 09:17:33.262102 Training Step 1335 Finished Timing (Training: 0.909315, Test: 0.0834371) after 0.247499 seconds\n",
      "2018-08-29 09:17:33.262501 Training Step 1335 \"min loss\" =  4.6561127\n",
      "2018-08-29 09:17:33.262566 Training Step 1335 \"loss\" =  5.189917\n",
      "2018-08-29 09:17:33.463054 Test Step 1340 Finished\n",
      "2018-08-29 09:17:33.463593 Test Step 1340 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:33.463845 Test Step 1340 \"loss\" =  19.921871\n",
      "2018-08-29 09:17:33.509409 Training Step 1340 Finished Timing (Training: 0.909141, Test: 0.0834934) after 0.246767 seconds\n",
      "2018-08-29 09:17:33.509546 Training Step 1340 \"min loss\" =  4.6561127\n",
      "2018-08-29 09:17:33.509611 Training Step 1340 \"loss\" =  5.7318683\n",
      "2018-08-29 09:17:33.710668 Test Step 1345 Finished\n",
      "2018-08-29 09:17:33.710820 Test Step 1345 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:33.710898 Test Step 1345 \"loss\" =  19.545643\n",
      "2018-08-29 09:17:33.755556 Training Step 1345 Finished Timing (Training: 0.909622, Test: 0.0835444) after 0.245864 seconds\n",
      "2018-08-29 09:17:33.755684 Training Step 1345 \"min loss\" =  4.6561127\n",
      "2018-08-29 09:17:33.755759 Training Step 1345 \"loss\" =  5.3929467\n",
      "2018-08-29 09:17:33.957896 Test Step 1350 Finished\n",
      "2018-08-29 09:17:33.958704 Test Step 1350 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:33.958804 Test Step 1350 \"loss\" =  20.416288\n",
      "2018-08-29 09:17:34.004775 Training Step 1350 Finished Timing (Training: 0.909157, Test: 0.0834103) after 0.247842 seconds\n",
      "2018-08-29 09:17:34.004904 Training Step 1350 \"min loss\" =  4.6561127\n",
      "2018-08-29 09:17:34.004969 Training Step 1350 \"loss\" =  5.1135764\n",
      "2018-08-29 09:17:34.206134 Test Step 1355 Finished\n",
      "2018-08-29 09:17:34.206266 Test Step 1355 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:34.206332 Test Step 1355 \"loss\" =  21.256369\n",
      "2018-08-29 09:17:34.252493 Training Step 1355 Finished Timing (Training: 0.909232, Test: 0.083416) after 0.2464 seconds\n",
      "2018-08-29 09:17:34.253079 Training Step 1355 \"min loss\" =  4.6561127\n",
      "2018-08-29 09:17:34.253390 Training Step 1355 \"loss\" =  5.5577474\n",
      "2018-08-29 09:17:34.453962 Test Step 1360 Finished\n",
      "2018-08-29 09:17:34.454102 Test Step 1360 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:34.454211 Test Step 1360 \"loss\" =  19.472998\n",
      "2018-08-29 09:17:34.500540 Training Step 1360 Finished Timing (Training: 0.909343, Test: 0.0834421) after 0.247061 seconds\n",
      "2018-08-29 09:17:34.500725 Training Step 1360 \"min loss\" =  4.6561127\n",
      "2018-08-29 09:17:34.500792 Training Step 1360 \"loss\" =  5.9904613\n",
      "2018-08-29 09:17:34.702965 Test Step 1365 Finished\n",
      "2018-08-29 09:17:34.703156 Test Step 1365 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:34.703310 Test Step 1365 \"loss\" =  18.195742\n",
      "2018-08-29 09:17:34.749076 Training Step 1365 Finished Timing (Training: 0.909412, Test: 0.0834083) after 0.247387 seconds\n",
      "2018-08-29 09:17:34.749223 Training Step 1365 \"min loss\" =  4.6561127\n",
      "2018-08-29 09:17:34.749803 Training Step 1365 \"loss\" =  5.80247\n",
      "2018-08-29 09:17:34.950843 Test Step 1370 Finished\n",
      "2018-08-29 09:17:34.951542 Test Step 1370 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:34.951820 Test Step 1370 \"loss\" =  18.967184\n",
      "2018-08-29 09:17:34.997389 Training Step 1370 Finished Timing (Training: 0.909087, Test: 0.0833294) after 0.246624 seconds\n",
      "2018-08-29 09:17:34.997835 Training Step 1370 \"min loss\" =  4.6561127\n",
      "2018-08-29 09:17:34.997959 Training Step 1370 \"loss\" =  5.1882725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:17:35.198624 Test Step 1375 Finished\n",
      "2018-08-29 09:17:35.198845 Test Step 1375 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:35.198967 Test Step 1375 \"loss\" =  18.389374\n",
      "2018-08-29 09:17:35.245043 Training Step 1375 Finished Timing (Training: 0.909267, Test: 0.0833221) after 0.246943 seconds\n",
      "2018-08-29 09:17:35.245215 Training Step 1375 \"min loss\" =  4.6561127\n",
      "2018-08-29 09:17:35.245334 Training Step 1375 \"loss\" =  4.9599857\n",
      "2018-08-29 09:17:35.446286 Test Step 1380 Finished\n",
      "2018-08-29 09:17:35.446434 Test Step 1380 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:35.446517 Test Step 1380 \"loss\" =  18.133743\n",
      "2018-08-29 09:17:35.492087 Training Step 1380 Finished Timing (Training: 0.909357, Test: 0.0833029) after 0.246622 seconds\n",
      "2018-08-29 09:17:35.492245 Training Step 1380 \"min loss\" =  4.6561127\n",
      "2018-08-29 09:17:35.492314 Training Step 1380 \"loss\" =  5.0700865\n",
      "2018-08-29 09:17:35.692703 Test Step 1385 Finished\n",
      "2018-08-29 09:17:35.692849 Test Step 1385 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:35.693410 Test Step 1385 \"loss\" =  18.018532\n",
      "2018-08-29 09:17:35.738841 Training Step 1385 Finished Timing (Training: 0.909376, Test: 0.0833769) after 0.246445 seconds\n",
      "2018-08-29 09:17:35.738972 Training Step 1385 \"min loss\" =  4.6561127\n",
      "2018-08-29 09:17:35.739582 Training Step 1385 \"loss\" =  4.9885845\n",
      "2018-08-29 09:17:35.939899 Test Step 1390 Finished\n",
      "2018-08-29 09:17:35.940096 Test Step 1390 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:35.941133 Test Step 1390 \"loss\" =  18.009956\n",
      "2018-08-29 09:17:35.986354 Training Step 1390 Finished Timing (Training: 0.909205, Test: 0.0833786) after 0.246637 seconds\n",
      "2018-08-29 09:17:35.986505 Training Step 1390 \"min loss\" =  4.6561127\n",
      "2018-08-29 09:17:35.986572 Training Step 1390 \"loss\" =  4.9684267\n",
      "2018-08-29 09:17:36.188312 Test Step 1395 Finished\n",
      "2018-08-29 09:17:36.188462 Test Step 1395 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:36.188530 Test Step 1395 \"loss\" =  18.25885\n",
      "2018-08-29 09:17:36.234545 Training Step 1395 Finished Timing (Training: 0.909315, Test: 0.0834396) after 0.247492 seconds\n",
      "2018-08-29 09:17:36.234762 Training Step 1395 \"min loss\" =  4.6561127\n",
      "2018-08-29 09:17:36.235485 Training Step 1395 \"loss\" =  5.495711\n",
      "2018-08-29 09:17:36.436347 Test Step 1400 Finished\n",
      "2018-08-29 09:17:36.436497 Test Step 1400 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:36.436567 Test Step 1400 \"loss\" =  19.371792\n",
      "2018-08-29 09:17:36.482579 Training Step 1400 Finished Timing (Training: 0.909279, Test: 0.0834135) after 0.246923 seconds\n",
      "2018-08-29 09:17:36.482722 Training Step 1400 \"min loss\" =  4.6561127\n",
      "2018-08-29 09:17:36.483541 Training Step 1400 \"loss\" =  5.0633125\n",
      "2018-08-29 09:17:36.685042 Test Step 1405 Finished\n",
      "2018-08-29 09:17:36.685194 Test Step 1405 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:36.685267 Test Step 1405 \"loss\" =  20.467525\n",
      "2018-08-29 09:17:36.730230 Training Step 1405 Finished Timing (Training: 0.912275, Test: 0.0863302) after 0.246598 seconds\n",
      "2018-08-29 09:17:36.730375 Training Step 1405 \"min loss\" =  4.6561127\n",
      "2018-08-29 09:17:36.730445 Training Step 1405 \"loss\" =  5.4557786\n",
      "2018-08-29 09:17:36.930449 Test Step 1410 Finished\n",
      "2018-08-29 09:17:36.930591 Test Step 1410 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:36.931164 Test Step 1410 \"loss\" =  19.408342\n",
      "2018-08-29 09:17:36.976432 Training Step 1410 Finished Timing (Training: 0.912392, Test: 0.0845796) after 0.24589 seconds\n",
      "2018-08-29 09:17:36.976568 Training Step 1410 \"min loss\" =  4.6561127\n",
      "2018-08-29 09:17:36.976655 Training Step 1410 \"loss\" =  5.4842825\n",
      "2018-08-29 09:17:37.177195 Test Step 1415 Finished\n",
      "2018-08-29 09:17:37.177761 Test Step 1415 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:37.178037 Test Step 1415 \"loss\" =  18.43559\n",
      "2018-08-29 09:17:37.223376 Training Step 1415 Finished Timing (Training: 0.911374, Test: 0.0848921) after 0.246633 seconds\n",
      "2018-08-29 09:17:37.223514 Training Step 1415 \"min loss\" =  4.4662237\n",
      "2018-08-29 09:17:37.223581 Training Step 1415 \"loss\" =  5.1838484\n",
      "2018-08-29 09:17:37.424527 Test Step 1420 Finished\n",
      "2018-08-29 09:17:37.425168 Test Step 1420 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:37.425244 Test Step 1420 \"loss\" =  18.20122\n",
      "2018-08-29 09:17:37.470597 Training Step 1420 Finished Timing (Training: 0.91084, Test: 0.0844501) after 0.246171 seconds\n",
      "2018-08-29 09:17:37.471092 Training Step 1420 \"min loss\" =  4.4662237\n",
      "2018-08-29 09:17:37.471162 Training Step 1420 \"loss\" =  4.9620214\n",
      "2018-08-29 09:17:37.671372 Test Step 1425 Finished\n",
      "2018-08-29 09:17:37.671512 Test Step 1425 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:37.672108 Test Step 1425 \"loss\" =  17.926857\n",
      "2018-08-29 09:17:37.717319 Training Step 1425 Finished Timing (Training: 0.910286, Test: 0.0841676) after 0.245802 seconds\n",
      "2018-08-29 09:17:37.717451 Training Step 1425 \"min loss\" =  4.4662237\n",
      "2018-08-29 09:17:37.718152 Training Step 1425 \"loss\" =  5.3502774\n",
      "2018-08-29 09:17:37.918569 Test Step 1430 Finished\n",
      "2018-08-29 09:17:37.918767 Test Step 1430 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:37.918888 Test Step 1430 \"loss\" =  18.186178\n",
      "2018-08-29 09:17:37.965229 Training Step 1430 Finished Timing (Training: 0.910037, Test: 0.0842321) after 0.246753 seconds\n",
      "2018-08-29 09:17:37.965422 Training Step 1430 \"min loss\" =  4.4662237\n",
      "2018-08-29 09:17:37.965572 Training Step 1430 \"loss\" =  4.8663015\n",
      "2018-08-29 09:17:38.167883 Test Step 1435 Finished\n",
      "2018-08-29 09:17:38.168040 Test Step 1435 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:38.168911 Test Step 1435 \"loss\" =  17.950413\n",
      "2018-08-29 09:17:38.214569 Training Step 1435 Finished Timing (Training: 0.908475, Test: 0.0845193) after 0.247442 seconds\n",
      "2018-08-29 09:17:38.214700 Training Step 1435 \"min loss\" =  4.4662237\n",
      "2018-08-29 09:17:38.215257 Training Step 1435 \"loss\" =  5.1244392\n",
      "2018-08-29 09:17:38.419940 Test Step 1440 Finished\n",
      "2018-08-29 09:17:38.420591 Test Step 1440 \"min loss\" =  17.686457\n",
      "2018-08-29 09:17:38.420692 Test Step 1440 \"loss\" =  18.252478\n",
      "2018-08-29 09:17:38.466292 Training Step 1440 Finished Timing (Training: 0.908707, Test: 0.0839989) after 0.250949 seconds\n",
      "2018-08-29 09:17:38.466437 Training Step 1440 \"min loss\" =  4.4662237\n",
      "2018-08-29 09:17:38.467585 Training Step 1440 \"loss\" =  5.1107183\n",
      "2018-08-29 09:17:38.669679 Test Step 1445 Finished\n",
      "2018-08-29 09:17:38.669828 Test Step 1445 \"min loss\" =  17.59922\n",
      "2018-08-29 09:17:38.670410 Test Step 1445 \"loss\" =  17.59922\n",
      "2018-08-29 09:17:38.715854 Training Step 1445 Finished Timing (Training: 0.90816, Test: 0.0841569) after 0.247716 seconds\n",
      "2018-08-29 09:17:38.715998 Training Step 1445 \"min loss\" =  4.4662237\n",
      "2018-08-29 09:17:38.716064 Training Step 1445 \"loss\" =  5.8934593\n",
      "2018-08-29 09:17:38.918279 Test Step 1450 Finished\n",
      "2018-08-29 09:17:38.918455 Test Step 1450 \"min loss\" =  17.59922\n",
      "2018-08-29 09:17:38.918576 Test Step 1450 \"loss\" =  19.16939\n",
      "2018-08-29 09:17:38.965124 Training Step 1450 Finished Timing (Training: 0.908302, Test: 0.0841877) after 0.248246 seconds\n",
      "2018-08-29 09:17:38.965648 Training Step 1450 \"min loss\" =  4.4662237\n",
      "2018-08-29 09:17:38.965768 Training Step 1450 \"loss\" =  5.2855177\n",
      "2018-08-29 09:17:39.167045 Test Step 1455 Finished\n",
      "2018-08-29 09:17:39.167185 Test Step 1455 \"min loss\" =  17.59922\n",
      "2018-08-29 09:17:39.167939 Test Step 1455 \"loss\" =  18.573664\n",
      "2018-08-29 09:17:39.212983 Training Step 1455 Finished Timing (Training: 0.908413, Test: 0.0840999) after 0.247073 seconds\n",
      "2018-08-29 09:17:39.213125 Training Step 1455 \"min loss\" =  4.4662237\n",
      "2018-08-29 09:17:39.213675 Training Step 1455 \"loss\" =  4.6822104\n",
      "2018-08-29 09:17:39.413918 Test Step 1460 Finished\n",
      "2018-08-29 09:17:39.414053 Test Step 1460 \"min loss\" =  17.59922\n",
      "2018-08-29 09:17:39.414837 Test Step 1460 \"loss\" =  18.210241\n",
      "2018-08-29 09:17:39.460326 Training Step 1460 Finished Timing (Training: 0.908476, Test: 0.0840471) after 0.246565 seconds\n",
      "2018-08-29 09:17:39.460497 Training Step 1460 \"min loss\" =  4.4662237\n",
      "2018-08-29 09:17:39.461126 Training Step 1460 \"loss\" =  5.2539325\n",
      "2018-08-29 09:17:39.662562 Test Step 1465 Finished\n",
      "2018-08-29 09:17:39.662737 Test Step 1465 \"min loss\" =  17.59922\n",
      "2018-08-29 09:17:39.662807 Test Step 1465 \"loss\" =  19.853424\n",
      "2018-08-29 09:17:39.709416 Training Step 1465 Finished Timing (Training: 0.908248, Test: 0.0839677) after 0.247523 seconds\n",
      "2018-08-29 09:17:39.709565 Training Step 1465 \"min loss\" =  4.4662237\n",
      "2018-08-29 09:17:39.709672 Training Step 1465 \"loss\" =  4.753419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:17:39.909898 Test Step 1470 Finished\n",
      "2018-08-29 09:17:39.910359 Test Step 1470 \"min loss\" =  17.59922\n",
      "2018-08-29 09:17:39.910425 Test Step 1470 \"loss\" =  18.219881\n",
      "2018-08-29 09:17:39.955756 Training Step 1470 Finished Timing (Training: 0.908463, Test: 0.0838746) after 0.245975 seconds\n",
      "2018-08-29 09:17:39.955889 Training Step 1470 \"min loss\" =  4.4662237\n",
      "2018-08-29 09:17:39.955955 Training Step 1470 \"loss\" =  4.7035623\n",
      "2018-08-29 09:17:40.157464 Test Step 1475 Finished\n",
      "2018-08-29 09:17:40.157650 Test Step 1475 \"min loss\" =  17.582926\n",
      "2018-08-29 09:17:40.157724 Test Step 1475 \"loss\" =  17.582926\n",
      "2018-08-29 09:17:40.202970 Training Step 1475 Finished Timing (Training: 0.908466, Test: 0.0839505) after 0.246002 seconds\n",
      "2018-08-29 09:17:40.203104 Training Step 1475 \"min loss\" =  4.4662237\n",
      "2018-08-29 09:17:40.203797 Training Step 1475 \"loss\" =  4.8456187\n",
      "2018-08-29 09:17:40.405096 Test Step 1480 Finished\n",
      "2018-08-29 09:17:40.405229 Test Step 1480 \"min loss\" =  17.582926\n",
      "2018-08-29 09:17:40.405301 Test Step 1480 \"loss\" =  20.825018\n",
      "2018-08-29 09:17:40.451525 Training Step 1480 Finished Timing (Training: 0.908338, Test: 0.0839999) after 0.247645 seconds\n",
      "2018-08-29 09:17:40.451663 Training Step 1480 \"min loss\" =  4.4662237\n",
      "2018-08-29 09:17:40.451742 Training Step 1480 \"loss\" =  4.732322\n",
      "2018-08-29 09:17:40.653729 Test Step 1485 Finished\n",
      "2018-08-29 09:17:40.653889 Test Step 1485 \"min loss\" =  17.582926\n",
      "2018-08-29 09:17:40.654846 Test Step 1485 \"loss\" =  19.642767\n",
      "2018-08-29 09:17:40.700253 Training Step 1485 Finished Timing (Training: 0.908001, Test: 0.0840406) after 0.246989 seconds\n",
      "2018-08-29 09:17:40.700407 Training Step 1485 \"min loss\" =  4.4662237\n",
      "2018-08-29 09:17:40.700475 Training Step 1485 \"loss\" =  5.839146\n",
      "2018-08-29 09:17:40.902115 Test Step 1490 Finished\n",
      "2018-08-29 09:17:40.902305 Test Step 1490 \"min loss\" =  17.582926\n",
      "2018-08-29 09:17:40.903296 Test Step 1490 \"loss\" =  19.182411\n",
      "2018-08-29 09:17:40.948196 Training Step 1490 Finished Timing (Training: 0.908137, Test: 0.0839859) after 0.247635 seconds\n",
      "2018-08-29 09:17:40.948359 Training Step 1490 \"min loss\" =  4.4662237\n",
      "2018-08-29 09:17:40.948454 Training Step 1490 \"loss\" =  5.0890083\n",
      "2018-08-29 09:17:41.150734 Test Step 1495 Finished\n",
      "2018-08-29 09:17:41.151367 Test Step 1495 \"min loss\" =  17.582926\n",
      "2018-08-29 09:17:41.151465 Test Step 1495 \"loss\" =  19.856081\n",
      "2018-08-29 09:17:41.196740 Training Step 1495 Finished Timing (Training: 0.908263, Test: 0.0840061) after 0.248178 seconds\n",
      "2018-08-29 09:17:41.196883 Training Step 1495 \"min loss\" =  4.4662237\n",
      "2018-08-29 09:17:41.196958 Training Step 1495 \"loss\" =  4.657023\n",
      "2018-08-29 09:17:41.398468 Test Step 1500 Finished\n",
      "2018-08-29 09:17:41.399167 Test Step 1500 \"min loss\" =  17.582926\n",
      "2018-08-29 09:17:41.399254 Test Step 1500 \"loss\" =  19.019194\n",
      "2018-08-29 09:17:41.444239 Training Step 1500 Finished Timing (Training: 0.908176, Test: 0.0840103) after 0.246078 seconds\n",
      "2018-08-29 09:17:41.444387 Training Step 1500 \"min loss\" =  4.4662237\n",
      "2018-08-29 09:17:41.445272 Training Step 1500 \"loss\" =  5.0881844\n",
      "2018-08-29 09:17:41.645846 Test Step 1505 Finished\n",
      "2018-08-29 09:17:41.645991 Test Step 1505 \"min loss\" =  17.582926\n",
      "2018-08-29 09:17:41.646800 Test Step 1505 \"loss\" =  18.492514\n",
      "2018-08-29 09:17:41.692086 Training Step 1505 Finished Timing (Training: 0.91168, Test: 0.0832007) after 0.246726 seconds\n",
      "2018-08-29 09:17:41.692231 Training Step 1505 \"min loss\" =  4.4662237\n",
      "2018-08-29 09:17:41.692307 Training Step 1505 \"loss\" =  4.595592\n",
      "2018-08-29 09:17:41.894307 Test Step 1510 Finished\n",
      "2018-08-29 09:17:41.894952 Test Step 1510 \"min loss\" =  17.582926\n",
      "2018-08-29 09:17:41.895076 Test Step 1510 \"loss\" =  18.180363\n",
      "2018-08-29 09:17:41.941253 Training Step 1510 Finished Timing (Training: 0.908448, Test: 0.0838354) after 0.247546 seconds\n",
      "2018-08-29 09:17:41.941416 Training Step 1510 \"min loss\" =  4.4662237\n",
      "2018-08-29 09:17:41.942003 Training Step 1510 \"loss\" =  4.9940853\n",
      "2018-08-29 09:17:42.143031 Test Step 1515 Finished\n",
      "2018-08-29 09:17:42.143209 Test Step 1515 \"min loss\" =  17.582926\n",
      "2018-08-29 09:17:42.143281 Test Step 1515 \"loss\" =  18.8125\n",
      "2018-08-29 09:17:42.189296 Training Step 1515 Finished Timing (Training: 0.909398, Test: 0.0838125) after 0.247201 seconds\n",
      "2018-08-29 09:17:42.189458 Training Step 1515 \"min loss\" =  4.4662237\n",
      "2018-08-29 09:17:42.189539 Training Step 1515 \"loss\" =  4.9517336\n",
      "2018-08-29 09:17:42.389905 Test Step 1520 Finished\n",
      "2018-08-29 09:17:42.390040 Test Step 1520 \"min loss\" =  17.582926\n",
      "2018-08-29 09:17:42.390107 Test Step 1520 \"loss\" =  18.496305\n",
      "2018-08-29 09:17:42.435930 Training Step 1520 Finished Timing (Training: 0.909461, Test: 0.0837678) after 0.2463 seconds\n",
      "2018-08-29 09:17:42.436077 Training Step 1520 \"min loss\" =  4.4662237\n",
      "2018-08-29 09:17:42.436156 Training Step 1520 \"loss\" =  4.9960847\n",
      "2018-08-29 09:17:42.636732 Test Step 1525 Finished\n",
      "2018-08-29 09:17:42.636865 Test Step 1525 \"min loss\" =  17.582926\n",
      "2018-08-29 09:17:42.636937 Test Step 1525 \"loss\" =  18.985132\n",
      "2018-08-29 09:17:42.682900 Training Step 1525 Finished Timing (Training: 0.909351, Test: 0.0838532) after 0.24665 seconds\n",
      "2018-08-29 09:17:42.683059 Training Step 1525 \"min loss\" =  4.230915\n",
      "2018-08-29 09:17:42.683683 Training Step 1525 \"loss\" =  5.500799\n",
      "2018-08-29 09:17:42.884321 Test Step 1530 Finished\n",
      "2018-08-29 09:17:42.885052 Test Step 1530 \"min loss\" =  17.582926\n",
      "2018-08-29 09:17:42.885149 Test Step 1530 \"loss\" =  19.186485\n",
      "2018-08-29 09:17:42.930400 Training Step 1530 Finished Timing (Training: 0.909253, Test: 0.0838383) after 0.246608 seconds\n",
      "2018-08-29 09:17:42.930543 Training Step 1530 \"min loss\" =  4.230915\n",
      "2018-08-29 09:17:42.931188 Training Step 1530 \"loss\" =  5.5723114\n",
      "2018-08-29 09:17:43.132348 Test Step 1535 Finished\n",
      "2018-08-29 09:17:43.132483 Test Step 1535 \"min loss\" =  17.582926\n",
      "2018-08-29 09:17:43.132545 Test Step 1535 \"loss\" =  20.986284\n",
      "2018-08-29 09:17:43.178402 Training Step 1535 Finished Timing (Training: 0.909052, Test: 0.0840889) after 0.246717 seconds\n",
      "2018-08-29 09:17:43.178534 Training Step 1535 \"min loss\" =  4.230915\n",
      "2018-08-29 09:17:43.178620 Training Step 1535 \"loss\" =  4.897037\n",
      "2018-08-29 09:17:43.379902 Test Step 1540 Finished\n",
      "2018-08-29 09:17:43.380028 Test Step 1540 \"min loss\" =  17.582926\n",
      "2018-08-29 09:17:43.380094 Test Step 1540 \"loss\" =  20.190617\n",
      "2018-08-29 09:17:43.426275 Training Step 1540 Finished Timing (Training: 0.909068, Test: 0.0840127) after 0.246346 seconds\n",
      "2018-08-29 09:17:43.426412 Training Step 1540 \"min loss\" =  4.230915\n",
      "2018-08-29 09:17:43.426531 Training Step 1540 \"loss\" =  4.762623\n",
      "2018-08-29 09:17:43.629603 Test Step 1545 Finished\n",
      "2018-08-29 09:17:43.630194 Test Step 1545 \"min loss\" =  17.582926\n",
      "2018-08-29 09:17:43.630485 Test Step 1545 \"loss\" =  18.993477\n",
      "2018-08-29 09:17:43.676779 Training Step 1545 Finished Timing (Training: 0.908658, Test: 0.0838928) after 0.248795 seconds\n",
      "2018-08-29 09:17:43.676922 Training Step 1545 \"min loss\" =  4.230915\n",
      "2018-08-29 09:17:43.677611 Training Step 1545 \"loss\" =  4.661341\n",
      "2018-08-29 09:17:43.879400 Test Step 1550 Finished\n",
      "2018-08-29 09:17:43.879990 Test Step 1550 \"min loss\" =  17.582926\n",
      "2018-08-29 09:17:43.880268 Test Step 1550 \"loss\" =  18.887106\n",
      "2018-08-29 09:17:43.925818 Training Step 1550 Finished Timing (Training: 0.908495, Test: 0.0837692) after 0.247609 seconds\n",
      "2018-08-29 09:17:43.925952 Training Step 1550 \"min loss\" =  4.230915\n",
      "2018-08-29 09:17:43.926853 Training Step 1550 \"loss\" =  5.0680275\n",
      "2018-08-29 09:17:44.127819 Test Step 1555 Finished\n",
      "2018-08-29 09:17:44.128040 Test Step 1555 \"min loss\" =  17.582926\n",
      "2018-08-29 09:17:44.128768 Test Step 1555 \"loss\" =  18.320408\n",
      "2018-08-29 09:17:44.174139 Training Step 1555 Finished Timing (Training: 0.908315, Test: 0.0838448) after 0.247201 seconds\n",
      "2018-08-29 09:17:44.174283 Training Step 1555 \"min loss\" =  4.230915\n",
      "2018-08-29 09:17:44.175008 Training Step 1555 \"loss\" =  5.439229\n",
      "2018-08-29 09:17:44.375075 Test Step 1560 Finished\n",
      "2018-08-29 09:17:44.375254 Test Step 1560 \"min loss\" =  17.582926\n",
      "2018-08-29 09:17:44.375328 Test Step 1560 \"loss\" =  19.10482\n",
      "2018-08-29 09:17:44.421287 Training Step 1560 Finished Timing (Training: 0.908535, Test: 0.0838143) after 0.246164 seconds\n",
      "2018-08-29 09:17:44.421444 Training Step 1560 \"min loss\" =  4.230915\n",
      "2018-08-29 09:17:44.421512 Training Step 1560 \"loss\" =  4.9805427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:17:44.622749 Test Step 1565 Finished\n",
      "2018-08-29 09:17:44.623440 Test Step 1565 \"min loss\" =  17.582926\n",
      "2018-08-29 09:17:44.623740 Test Step 1565 \"loss\" =  18.615833\n",
      "2018-08-29 09:17:44.668984 Training Step 1565 Finished Timing (Training: 0.908647, Test: 0.0837277) after 0.247375 seconds\n",
      "2018-08-29 09:17:44.669134 Training Step 1565 \"min loss\" =  4.230915\n",
      "2018-08-29 09:17:44.669844 Training Step 1565 \"loss\" =  5.100621\n",
      "2018-08-29 09:17:44.870134 Test Step 1570 Finished\n",
      "2018-08-29 09:17:44.870286 Test Step 1570 \"min loss\" =  17.582926\n",
      "2018-08-29 09:17:44.870351 Test Step 1570 \"loss\" =  18.806505\n",
      "2018-08-29 09:17:44.915155 Training Step 1570 Finished Timing (Training: 0.90884, Test: 0.0837039) after 0.24522 seconds\n",
      "2018-08-29 09:17:44.915298 Training Step 1570 \"min loss\" =  4.230915\n",
      "2018-08-29 09:17:44.916291 Training Step 1570 \"loss\" =  5.062074\n",
      "2018-08-29 09:17:45.117021 Test Step 1575 Finished\n",
      "2018-08-29 09:17:45.117181 Test Step 1575 \"min loss\" =  17.582926\n",
      "2018-08-29 09:17:45.118051 Test Step 1575 \"loss\" =  19.067564\n",
      "2018-08-29 09:17:45.163977 Training Step 1575 Finished Timing (Training: 0.908591, Test: 0.0836138) after 0.247436 seconds\n",
      "2018-08-29 09:17:45.164129 Training Step 1575 \"min loss\" =  4.230915\n",
      "2018-08-29 09:17:45.164199 Training Step 1575 \"loss\" =  5.3254128\n",
      "2018-08-29 09:17:45.364810 Test Step 1580 Finished\n",
      "2018-08-29 09:17:45.364966 Test Step 1580 \"min loss\" =  17.582926\n",
      "2018-08-29 09:17:45.365035 Test Step 1580 \"loss\" =  19.026896\n",
      "2018-08-29 09:17:45.410962 Training Step 1580 Finished Timing (Training: 0.908773, Test: 0.0837535) after 0.246676 seconds\n",
      "2018-08-29 09:17:45.411140 Training Step 1580 \"min loss\" =  4.230915\n",
      "2018-08-29 09:17:45.411213 Training Step 1580 \"loss\" =  4.699049\n",
      "2018-08-29 09:17:45.612634 Test Step 1585 Finished\n",
      "2018-08-29 09:17:45.612749 Test Step 1585 \"min loss\" =  17.49152\n",
      "2018-08-29 09:17:45.612815 Test Step 1585 \"loss\" =  17.49152\n",
      "2018-08-29 09:17:45.657610 Training Step 1585 Finished Timing (Training: 0.909125, Test: 0.083687) after 0.246314 seconds\n",
      "2018-08-29 09:17:45.657739 Training Step 1585 \"min loss\" =  4.230915\n",
      "2018-08-29 09:17:45.657841 Training Step 1585 \"loss\" =  5.090645\n",
      "2018-08-29 09:17:45.859640 Test Step 1590 Finished\n",
      "2018-08-29 09:17:45.859765 Test Step 1590 \"min loss\" =  17.49152\n",
      "2018-08-29 09:17:45.859832 Test Step 1590 \"loss\" =  17.686977\n",
      "2018-08-29 09:17:45.904592 Training Step 1590 Finished Timing (Training: 0.909474, Test: 0.0835985) after 0.246663 seconds\n",
      "2018-08-29 09:17:45.904737 Training Step 1590 \"min loss\" =  4.230915\n",
      "2018-08-29 09:17:45.904824 Training Step 1590 \"loss\" =  4.686366\n",
      "2018-08-29 09:17:46.107065 Test Step 1595 Finished\n",
      "2018-08-29 09:17:46.107214 Test Step 1595 \"min loss\" =  17.49152\n",
      "2018-08-29 09:17:46.108109 Test Step 1595 \"loss\" =  17.526642\n",
      "2018-08-29 09:17:46.153232 Training Step 1595 Finished Timing (Training: 0.909379, Test: 0.0836737) after 0.248304 seconds\n",
      "2018-08-29 09:17:46.153413 Training Step 1595 \"min loss\" =  4.230915\n",
      "2018-08-29 09:17:46.153542 Training Step 1595 \"loss\" =  4.599167\n",
      "2018-08-29 09:17:46.355083 Test Step 1600 Finished\n",
      "2018-08-29 09:17:46.355218 Test Step 1600 \"min loss\" =  17.49152\n",
      "2018-08-29 09:17:46.356067 Test Step 1600 \"loss\" =  18.556902\n",
      "2018-08-29 09:17:46.401424 Training Step 1600 Finished Timing (Training: 0.909304, Test: 0.0835953) after 0.247127 seconds\n",
      "2018-08-29 09:17:46.401617 Training Step 1600 \"min loss\" =  4.230915\n",
      "2018-08-29 09:17:46.401750 Training Step 1600 \"loss\" =  4.5906587\n",
      "2018-08-29 09:17:46.603013 Test Step 1605 Finished\n",
      "2018-08-29 09:17:46.603832 Test Step 1605 \"min loss\" =  17.49152\n",
      "2018-08-29 09:17:46.603931 Test Step 1605 \"loss\" =  18.928799\n",
      "2018-08-29 09:17:46.648956 Training Step 1605 Finished Timing (Training: 0.912243, Test: 0.0835058) after 0.246048 seconds\n",
      "2018-08-29 09:17:46.649120 Training Step 1605 \"min loss\" =  4.230915\n",
      "2018-08-29 09:17:46.649209 Training Step 1605 \"loss\" =  5.06335\n",
      "2018-08-29 09:17:46.849708 Test Step 1610 Finished\n",
      "2018-08-29 09:17:46.849851 Test Step 1610 \"min loss\" =  17.49152\n",
      "2018-08-29 09:17:46.849919 Test Step 1610 \"loss\" =  18.438763\n",
      "2018-08-29 09:17:46.894810 Training Step 1610 Finished Timing (Training: 0.912297, Test: 0.0842122) after 0.245517 seconds\n",
      "2018-08-29 09:17:46.894942 Training Step 1610 \"min loss\" =  4.230915\n",
      "2018-08-29 09:17:46.895041 Training Step 1610 \"loss\" =  4.6486087\n",
      "2018-08-29 09:17:47.096383 Test Step 1615 Finished\n",
      "2018-08-29 09:17:47.096861 Test Step 1615 \"min loss\" =  17.49152\n",
      "2018-08-29 09:17:47.097218 Test Step 1615 \"loss\" =  18.72299\n",
      "2018-08-29 09:17:47.142306 Training Step 1615 Finished Timing (Training: 0.910669, Test: 0.0837809) after 0.246448 seconds\n",
      "2018-08-29 09:17:47.142435 Training Step 1615 \"min loss\" =  4.2113023\n",
      "2018-08-29 09:17:47.142518 Training Step 1615 \"loss\" =  4.5661025\n",
      "2018-08-29 09:17:47.344280 Test Step 1620 Finished\n",
      "2018-08-29 09:17:47.344944 Test Step 1620 \"min loss\" =  17.49152\n",
      "2018-08-29 09:17:47.345054 Test Step 1620 \"loss\" =  17.964169\n",
      "2018-08-29 09:17:47.390117 Training Step 1620 Finished Timing (Training: 0.910112, Test: 0.0837343) after 0.246742 seconds\n",
      "2018-08-29 09:17:47.390263 Training Step 1620 \"min loss\" =  4.2113023\n",
      "2018-08-29 09:17:47.390337 Training Step 1620 \"loss\" =  4.961856\n",
      "2018-08-29 09:17:47.590703 Test Step 1625 Finished\n",
      "2018-08-29 09:17:47.590834 Test Step 1625 \"min loss\" =  17.49152\n",
      "2018-08-29 09:17:47.591528 Test Step 1625 \"loss\" =  18.213806\n",
      "2018-08-29 09:17:47.637088 Training Step 1625 Finished Timing (Training: 0.910064, Test: 0.083996) after 0.246664 seconds\n",
      "2018-08-29 09:17:47.637217 Training Step 1625 \"min loss\" =  4.2113023\n",
      "2018-08-29 09:17:47.637287 Training Step 1625 \"loss\" =  5.048613\n",
      "2018-08-29 09:17:47.839644 Test Step 1630 Finished\n",
      "2018-08-29 09:17:47.840217 Test Step 1630 \"min loss\" =  17.49152\n",
      "2018-08-29 09:17:47.840578 Test Step 1630 \"loss\" =  18.107136\n",
      "2018-08-29 09:17:47.886044 Training Step 1630 Finished Timing (Training: 0.909684, Test: 0.0841753) after 0.248677 seconds\n",
      "2018-08-29 09:17:47.886287 Training Step 1630 \"min loss\" =  4.2113023\n",
      "2018-08-29 09:17:47.886405 Training Step 1630 \"loss\" =  5.5546174\n",
      "2018-08-29 09:17:48.088012 Test Step 1635 Finished\n",
      "2018-08-29 09:17:48.088164 Test Step 1635 \"min loss\" =  17.49152\n",
      "2018-08-29 09:17:48.088231 Test Step 1635 \"loss\" =  19.293283\n",
      "2018-08-29 09:17:48.134143 Training Step 1635 Finished Timing (Training: 0.910321, Test: 0.0839599) after 0.247654 seconds\n",
      "2018-08-29 09:17:48.134704 Training Step 1635 \"min loss\" =  4.2113023\n",
      "2018-08-29 09:17:48.134781 Training Step 1635 \"loss\" =  4.729705\n",
      "2018-08-29 09:17:48.334969 Test Step 1640 Finished\n",
      "2018-08-29 09:17:48.335562 Test Step 1640 \"min loss\" =  17.49152\n",
      "2018-08-29 09:17:48.335634 Test Step 1640 \"loss\" =  19.422302\n",
      "2018-08-29 09:17:48.381024 Training Step 1640 Finished Timing (Training: 0.91038, Test: 0.0838491) after 0.246157 seconds\n",
      "2018-08-29 09:17:48.381151 Training Step 1640 \"min loss\" =  4.2113023\n",
      "2018-08-29 09:17:48.381210 Training Step 1640 \"loss\" =  5.149025\n",
      "2018-08-29 09:17:48.582633 Test Step 1645 Finished\n",
      "2018-08-29 09:17:48.582759 Test Step 1645 \"min loss\" =  17.49152\n",
      "2018-08-29 09:17:48.582824 Test Step 1645 \"loss\" =  17.703465\n",
      "2018-08-29 09:17:48.628508 Training Step 1645 Finished Timing (Training: 0.910896, Test: 0.083722) after 0.247219 seconds\n",
      "2018-08-29 09:17:48.628652 Training Step 1645 \"min loss\" =  4.2113023\n",
      "2018-08-29 09:17:48.628748 Training Step 1645 \"loss\" =  4.8074136\n",
      "2018-08-29 09:17:48.828454 Test Step 1650 Finished\n",
      "2018-08-29 09:17:48.828925 Test Step 1650 \"min loss\" =  17.49152\n",
      "2018-08-29 09:17:48.829520 Test Step 1650 \"loss\" =  19.190628\n",
      "2018-08-29 09:17:48.874930 Training Step 1650 Finished Timing (Training: 0.910763, Test: 0.0835928) after 0.246086 seconds\n",
      "2018-08-29 09:17:48.875061 Training Step 1650 \"min loss\" =  4.2113023\n",
      "2018-08-29 09:17:48.875752 Training Step 1650 \"loss\" =  4.740935\n",
      "2018-08-29 09:17:49.075922 Test Step 1655 Finished\n",
      "2018-08-29 09:17:49.076100 Test Step 1655 \"min loss\" =  17.49152\n",
      "2018-08-29 09:17:49.076170 Test Step 1655 \"loss\" =  19.77947\n",
      "2018-08-29 09:17:49.121358 Training Step 1655 Finished Timing (Training: 0.910766, Test: 0.0835349) after 0.245251 seconds\n",
      "2018-08-29 09:17:49.121504 Training Step 1655 \"min loss\" =  3.970532\n",
      "2018-08-29 09:17:49.121569 Training Step 1655 \"loss\" =  4.8376927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:17:49.323494 Test Step 1660 Finished\n",
      "2018-08-29 09:17:49.323650 Test Step 1660 \"min loss\" =  17.49152\n",
      "2018-08-29 09:17:49.323721 Test Step 1660 \"loss\" =  19.792217\n",
      "2018-08-29 09:17:49.368707 Training Step 1660 Finished Timing (Training: 0.91054, Test: 0.0837249) after 0.246213 seconds\n",
      "2018-08-29 09:17:49.368835 Training Step 1660 \"min loss\" =  3.970532\n",
      "2018-08-29 09:17:49.368900 Training Step 1660 \"loss\" =  4.6729093\n",
      "2018-08-29 09:17:49.568572 Test Step 1665 Finished\n",
      "2018-08-29 09:17:49.569242 Test Step 1665 \"min loss\" =  17.49152\n",
      "2018-08-29 09:17:49.569508 Test Step 1665 \"loss\" =  18.703129\n",
      "2018-08-29 09:17:49.615651 Training Step 1665 Finished Timing (Training: 0.910478, Test: 0.0836861) after 0.246659 seconds\n",
      "2018-08-29 09:17:49.615827 Training Step 1665 \"min loss\" =  3.970532\n",
      "2018-08-29 09:17:49.615949 Training Step 1665 \"loss\" =  4.816938\n",
      "2018-08-29 09:17:49.817833 Test Step 1670 Finished\n",
      "2018-08-29 09:17:49.818488 Test Step 1670 \"min loss\" =  17.49152\n",
      "2018-08-29 09:17:49.818747 Test Step 1670 \"loss\" =  18.637829\n",
      "2018-08-29 09:17:49.863657 Training Step 1670 Finished Timing (Training: 0.910397, Test: 0.0837532) after 0.247574 seconds\n",
      "2018-08-29 09:17:49.863801 Training Step 1670 \"min loss\" =  3.970532\n",
      "2018-08-29 09:17:49.863866 Training Step 1670 \"loss\" =  4.552886\n",
      "2018-08-29 09:17:50.062946 Test Step 1675 Finished\n",
      "2018-08-29 09:17:50.063123 Test Step 1675 \"min loss\" =  17.49152\n",
      "2018-08-29 09:17:50.063241 Test Step 1675 \"loss\" =  18.59011\n",
      "2018-08-29 09:17:50.109057 Training Step 1675 Finished Timing (Training: 0.910659, Test: 0.0836801) after 0.245108 seconds\n",
      "2018-08-29 09:17:50.109204 Training Step 1675 \"min loss\" =  3.970532\n",
      "2018-08-29 09:17:50.109281 Training Step 1675 \"loss\" =  4.5546665\n",
      "2018-08-29 09:17:50.310735 Test Step 1680 Finished\n",
      "2018-08-29 09:17:50.310865 Test Step 1680 \"min loss\" =  17.49152\n",
      "2018-08-29 09:17:50.310928 Test Step 1680 \"loss\" =  18.158384\n",
      "2018-08-29 09:17:50.357153 Training Step 1680 Finished Timing (Training: 0.910359, Test: 0.0836292) after 0.246961 seconds\n",
      "2018-08-29 09:17:50.357301 Training Step 1680 \"min loss\" =  3.970532\n",
      "2018-08-29 09:17:50.358032 Training Step 1680 \"loss\" =  4.555665\n",
      "2018-08-29 09:17:50.558688 Test Step 1685 Finished\n",
      "2018-08-29 09:17:50.559305 Test Step 1685 \"min loss\" =  17.329859\n",
      "2018-08-29 09:17:50.559381 Test Step 1685 \"loss\" =  17.329859\n",
      "2018-08-29 09:17:50.604675 Training Step 1685 Finished Timing (Training: 0.910278, Test: 0.0835497) after 0.246178 seconds\n",
      "2018-08-29 09:17:50.604813 Training Step 1685 \"min loss\" =  3.970532\n",
      "2018-08-29 09:17:50.604878 Training Step 1685 \"loss\" =  4.3319693\n",
      "2018-08-29 09:17:50.806676 Test Step 1690 Finished\n",
      "2018-08-29 09:17:50.806841 Test Step 1690 \"min loss\" =  17.329859\n",
      "2018-08-29 09:17:50.807476 Test Step 1690 \"loss\" =  18.074743\n",
      "2018-08-29 09:17:50.853044 Training Step 1690 Finished Timing (Training: 0.909992, Test: 0.0836124) after 0.24718 seconds\n",
      "2018-08-29 09:17:50.853167 Training Step 1690 \"min loss\" =  3.9201288\n",
      "2018-08-29 09:17:50.853932 Training Step 1690 \"loss\" =  3.9201288\n",
      "2018-08-29 09:17:51.055918 Test Step 1695 Finished\n",
      "2018-08-29 09:17:51.056453 Test Step 1695 \"min loss\" =  17.329859\n",
      "2018-08-29 09:17:51.056709 Test Step 1695 \"loss\" =  17.873083\n",
      "2018-08-29 09:17:51.102021 Training Step 1695 Finished Timing (Training: 0.909777, Test: 0.083696) after 0.247966 seconds\n",
      "2018-08-29 09:17:51.102163 Training Step 1695 \"min loss\" =  3.9201288\n",
      "2018-08-29 09:17:51.102227 Training Step 1695 \"loss\" =  4.779057\n",
      "2018-08-29 09:17:51.304447 Test Step 1700 Finished\n",
      "2018-08-29 09:17:51.304590 Test Step 1700 \"min loss\" =  17.329859\n",
      "2018-08-29 09:17:51.304708 Test Step 1700 \"loss\" =  17.510363\n",
      "2018-08-29 09:17:51.351059 Training Step 1700 Finished Timing (Training: 0.909448, Test: 0.0836795) after 0.247681 seconds\n",
      "2018-08-29 09:17:51.351190 Training Step 1700 \"min loss\" =  3.9201288\n",
      "2018-08-29 09:17:51.351241 Training Step 1700 \"loss\" =  4.5806293\n",
      "2018-08-29 09:17:51.560445 Test Step 1705 Finished\n",
      "2018-08-29 09:17:51.560591 Test Step 1705 \"min loss\" =  17.329859\n",
      "2018-08-29 09:17:51.560676 Test Step 1705 \"loss\" =  17.43079\n",
      "2018-08-29 09:17:51.606857 Training Step 1705 Finished Timing (Training: 0.912983, Test: 0.0806004) after 0.25554 seconds\n",
      "2018-08-29 09:17:51.607001 Training Step 1705 \"min loss\" =  3.9201288\n",
      "2018-08-29 09:17:51.607722 Training Step 1705 \"loss\" =  4.6404147\n",
      "2018-08-29 09:17:51.808072 Test Step 1710 Finished\n",
      "2018-08-29 09:17:51.808611 Test Step 1710 \"min loss\" =  17.329859\n",
      "2018-08-29 09:17:51.808854 Test Step 1710 \"loss\" =  17.773539\n",
      "2018-08-29 09:17:51.854096 Training Step 1710 Finished Timing (Training: 0.910635, Test: 0.081812) after 0.246276 seconds\n",
      "2018-08-29 09:17:51.854242 Training Step 1710 \"min loss\" =  3.9201288\n",
      "2018-08-29 09:17:51.854307 Training Step 1710 \"loss\" =  4.6389074\n",
      "2018-08-29 09:17:52.054704 Test Step 1715 Finished\n",
      "2018-08-29 09:17:52.055358 Test Step 1715 \"min loss\" =  17.329859\n",
      "2018-08-29 09:17:52.055642 Test Step 1715 \"loss\" =  18.435907\n",
      "2018-08-29 09:17:52.100467 Training Step 1715 Finished Timing (Training: 0.909909, Test: 0.0821438) after 0.245277 seconds\n",
      "2018-08-29 09:17:52.100616 Training Step 1715 \"min loss\" =  3.9201288\n",
      "2018-08-29 09:17:52.100681 Training Step 1715 \"loss\" =  4.318747\n",
      "2018-08-29 09:17:52.301783 Test Step 1720 Finished\n",
      "2018-08-29 09:17:52.301956 Test Step 1720 \"min loss\" =  17.329859\n",
      "2018-08-29 09:17:52.302029 Test Step 1720 \"loss\" =  18.283386\n",
      "2018-08-29 09:17:52.346649 Training Step 1720 Finished Timing (Training: 0.909878, Test: 0.0825482) after 0.244967 seconds\n",
      "2018-08-29 09:17:52.346766 Training Step 1720 \"min loss\" =  3.9201288\n",
      "2018-08-29 09:17:52.346851 Training Step 1720 \"loss\" =  4.5663314\n",
      "2018-08-29 09:17:52.546407 Test Step 1725 Finished\n",
      "2018-08-29 09:17:52.546537 Test Step 1725 \"min loss\" =  17.329859\n",
      "2018-08-29 09:17:52.546605 Test Step 1725 \"loss\" =  18.912052\n",
      "2018-08-29 09:17:52.591523 Training Step 1725 Finished Timing (Training: 0.910753, Test: 0.0826926) after 0.244588 seconds\n",
      "2018-08-29 09:17:52.591662 Training Step 1725 \"min loss\" =  3.9201288\n",
      "2018-08-29 09:17:52.592186 Training Step 1725 \"loss\" =  4.8645372\n",
      "2018-08-29 09:17:52.792433 Test Step 1730 Finished\n",
      "2018-08-29 09:17:52.792585 Test Step 1730 \"min loss\" =  17.329859\n",
      "2018-08-29 09:17:52.793469 Test Step 1730 \"loss\" =  18.178839\n",
      "2018-08-29 09:17:52.838262 Training Step 1730 Finished Timing (Training: 0.910125, Test: 0.0827818) after 0.245479 seconds\n",
      "2018-08-29 09:17:52.838405 Training Step 1730 \"min loss\" =  3.9201288\n",
      "2018-08-29 09:17:52.839324 Training Step 1730 \"loss\" =  4.2645345\n",
      "2018-08-29 09:17:53.040288 Test Step 1735 Finished\n",
      "2018-08-29 09:17:53.040470 Test Step 1735 \"min loss\" =  17.329859\n",
      "2018-08-29 09:17:53.040540 Test Step 1735 \"loss\" =  17.723743\n",
      "2018-08-29 09:17:53.085576 Training Step 1735 Finished Timing (Training: 0.909881, Test: 0.0830237) after 0.245973 seconds\n",
      "2018-08-29 09:17:53.085764 Training Step 1735 \"min loss\" =  3.9201288\n",
      "2018-08-29 09:17:53.085836 Training Step 1735 \"loss\" =  4.5106864\n",
      "2018-08-29 09:17:53.285907 Test Step 1740 Finished\n",
      "2018-08-29 09:17:53.286080 Test Step 1740 \"min loss\" =  17.317165\n",
      "2018-08-29 09:17:53.286810 Test Step 1740 \"loss\" =  17.317165\n",
      "2018-08-29 09:17:53.331889 Training Step 1740 Finished Timing (Training: 0.909764, Test: 0.0831433) after 0.245972 seconds\n",
      "2018-08-29 09:17:53.332037 Training Step 1740 \"min loss\" =  3.9201288\n",
      "2018-08-29 09:17:53.332133 Training Step 1740 \"loss\" =  4.1723733\n",
      "2018-08-29 09:17:53.533921 Test Step 1745 Finished\n",
      "2018-08-29 09:17:53.534103 Test Step 1745 \"min loss\" =  17.317165\n",
      "2018-08-29 09:17:53.534942 Test Step 1745 \"loss\" =  18.466112\n",
      "2018-08-29 09:17:53.580339 Training Step 1745 Finished Timing (Training: 0.908967, Test: 0.0834036) after 0.246834 seconds\n",
      "2018-08-29 09:17:53.580714 Training Step 1745 \"min loss\" =  3.9201288\n",
      "2018-08-29 09:17:53.580999 Training Step 1745 \"loss\" =  4.36451\n",
      "2018-08-29 09:17:53.781673 Test Step 1750 Finished\n",
      "2018-08-29 09:17:53.781890 Test Step 1750 \"min loss\" =  17.317165\n",
      "2018-08-29 09:17:53.782006 Test Step 1750 \"loss\" =  17.603779\n",
      "2018-08-29 09:17:53.827382 Training Step 1750 Finished Timing (Training: 0.909126, Test: 0.0835021) after 0.2463 seconds\n",
      "2018-08-29 09:17:53.827528 Training Step 1750 \"min loss\" =  3.8544781\n",
      "2018-08-29 09:17:53.827615 Training Step 1750 \"loss\" =  4.398537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:17:54.029485 Test Step 1755 Finished\n",
      "2018-08-29 09:17:54.029633 Test Step 1755 \"min loss\" =  17.317165\n",
      "2018-08-29 09:17:54.029694 Test Step 1755 \"loss\" =  18.943209\n",
      "2018-08-29 09:17:54.075782 Training Step 1755 Finished Timing (Training: 0.908723, Test: 0.0836676) after 0.247213 seconds\n",
      "2018-08-29 09:17:54.075925 Training Step 1755 \"min loss\" =  3.8544781\n",
      "2018-08-29 09:17:54.076516 Training Step 1755 \"loss\" =  4.307262\n",
      "2018-08-29 09:17:54.276948 Test Step 1760 Finished\n",
      "2018-08-29 09:17:54.277083 Test Step 1760 \"min loss\" =  17.317165\n",
      "2018-08-29 09:17:54.277826 Test Step 1760 \"loss\" =  17.985615\n",
      "2018-08-29 09:17:54.323164 Training Step 1760 Finished Timing (Training: 0.908711, Test: 0.0835654) after 0.246565 seconds\n",
      "2018-08-29 09:17:54.323319 Training Step 1760 \"min loss\" =  3.8544781\n",
      "2018-08-29 09:17:54.324125 Training Step 1760 \"loss\" =  4.7087693\n",
      "2018-08-29 09:17:54.524350 Test Step 1765 Finished\n",
      "2018-08-29 09:17:54.524971 Test Step 1765 \"min loss\" =  17.317165\n",
      "2018-08-29 09:17:54.525064 Test Step 1765 \"loss\" =  17.830404\n",
      "2018-08-29 09:17:54.571389 Training Step 1765 Finished Timing (Training: 0.908598, Test: 0.0835231) after 0.247154 seconds\n",
      "2018-08-29 09:17:54.571555 Training Step 1765 \"min loss\" =  3.8544781\n",
      "2018-08-29 09:17:54.571645 Training Step 1765 \"loss\" =  4.6723895\n",
      "2018-08-29 09:17:54.774330 Test Step 1770 Finished\n",
      "2018-08-29 09:17:54.774463 Test Step 1770 \"min loss\" =  17.317165\n",
      "2018-08-29 09:17:54.774531 Test Step 1770 \"loss\" =  17.58666\n",
      "2018-08-29 09:17:54.820483 Training Step 1770 Finished Timing (Training: 0.908508, Test: 0.0834931) after 0.248086 seconds\n",
      "2018-08-29 09:17:54.820712 Training Step 1770 \"min loss\" =  3.8544781\n",
      "2018-08-29 09:17:54.820832 Training Step 1770 \"loss\" =  4.509325\n",
      "2018-08-29 09:17:55.023509 Test Step 1775 Finished\n",
      "2018-08-29 09:17:55.024086 Test Step 1775 \"min loss\" =  17.317165\n",
      "2018-08-29 09:17:55.024440 Test Step 1775 \"loss\" =  17.525185\n",
      "2018-08-29 09:17:55.069630 Training Step 1775 Finished Timing (Training: 0.908533, Test: 0.0834237) after 0.248278 seconds\n",
      "2018-08-29 09:17:55.069780 Training Step 1775 \"min loss\" =  3.8544781\n",
      "2018-08-29 09:17:55.070414 Training Step 1775 \"loss\" =  4.3448477\n",
      "2018-08-29 09:17:55.271056 Test Step 1780 Finished\n",
      "2018-08-29 09:17:55.271578 Test Step 1780 \"min loss\" =  17.317165\n",
      "2018-08-29 09:17:55.271670 Test Step 1780 \"loss\" =  17.471142\n",
      "2018-08-29 09:17:55.316901 Training Step 1780 Finished Timing (Training: 0.908504, Test: 0.0833319) after 0.245997 seconds\n",
      "2018-08-29 09:17:55.317033 Training Step 1780 \"min loss\" =  3.8544781\n",
      "2018-08-29 09:17:55.317095 Training Step 1780 \"loss\" =  4.5387225\n",
      "2018-08-29 09:17:55.518144 Test Step 1785 Finished\n",
      "2018-08-29 09:17:55.518300 Test Step 1785 \"min loss\" =  17.317165\n",
      "2018-08-29 09:17:55.519105 Test Step 1785 \"loss\" =  18.610209\n",
      "2018-08-29 09:17:55.564382 Training Step 1785 Finished Timing (Training: 0.908627, Test: 0.0832732) after 0.247208 seconds\n",
      "2018-08-29 09:17:55.564527 Training Step 1785 \"min loss\" =  3.8544781\n",
      "2018-08-29 09:17:55.564685 Training Step 1785 \"loss\" =  4.1932416\n",
      "2018-08-29 09:17:55.766823 Test Step 1790 Finished\n",
      "2018-08-29 09:17:55.766980 Test Step 1790 \"min loss\" =  17.317165\n",
      "2018-08-29 09:17:55.767538 Test Step 1790 \"loss\" =  17.789732\n",
      "2018-08-29 09:17:55.813296 Training Step 1790 Finished Timing (Training: 0.908668, Test: 0.0833993) after 0.248473 seconds\n",
      "2018-08-29 09:17:55.813762 Training Step 1790 \"min loss\" =  3.8544781\n",
      "2018-08-29 09:17:55.814001 Training Step 1790 \"loss\" =  4.3078966\n",
      "2018-08-29 09:17:56.014261 Test Step 1795 Finished\n",
      "2018-08-29 09:17:56.014437 Test Step 1795 \"min loss\" =  17.317165\n",
      "2018-08-29 09:17:56.015072 Test Step 1795 \"loss\" =  17.633236\n",
      "2018-08-29 09:17:56.060340 Training Step 1795 Finished Timing (Training: 0.908701, Test: 0.0834168) after 0.246255 seconds\n",
      "2018-08-29 09:17:56.060489 Training Step 1795 \"min loss\" =  3.8544781\n",
      "2018-08-29 09:17:56.061164 Training Step 1795 \"loss\" =  4.40948\n",
      "2018-08-29 09:17:56.261757 Test Step 1800 Finished\n",
      "2018-08-29 09:17:56.261977 Test Step 1800 \"min loss\" =  17.317165\n",
      "2018-08-29 09:17:56.262101 Test Step 1800 \"loss\" =  18.962889\n",
      "2018-08-29 09:17:56.307557 Training Step 1800 Finished Timing (Training: 0.908756, Test: 0.0834178) after 0.246061 seconds\n",
      "2018-08-29 09:17:56.307704 Training Step 1800 \"min loss\" =  3.8544781\n",
      "2018-08-29 09:17:56.308354 Training Step 1800 \"loss\" =  4.2245426\n",
      "2018-08-29 09:17:56.509569 Test Step 1805 Finished\n",
      "2018-08-29 09:17:56.509747 Test Step 1805 \"min loss\" =  17.317165\n",
      "2018-08-29 09:17:56.510772 Test Step 1805 \"loss\" =  18.248493\n",
      "2018-08-29 09:17:56.556098 Training Step 1805 Finished Timing (Training: 0.906836, Test: 0.086987) after 0.247654 seconds\n",
      "2018-08-29 09:17:56.556290 Training Step 1805 \"min loss\" =  3.8544781\n",
      "2018-08-29 09:17:56.557291 Training Step 1805 \"loss\" =  4.3750935\n",
      "2018-08-29 09:17:56.757359 Test Step 1810 Finished\n",
      "2018-08-29 09:17:56.757509 Test Step 1810 \"min loss\" =  17.317165\n",
      "2018-08-29 09:17:56.757582 Test Step 1810 \"loss\" =  17.971334\n",
      "2018-08-29 09:17:56.803048 Training Step 1810 Finished Timing (Training: 0.908034, Test: 0.0853861) after 0.245569 seconds\n",
      "2018-08-29 09:17:56.803179 Training Step 1810 \"min loss\" =  3.8544781\n",
      "2018-08-29 09:17:56.803270 Training Step 1810 \"loss\" =  4.5572524\n",
      "2018-08-29 09:17:57.004030 Test Step 1815 Finished\n",
      "2018-08-29 09:17:57.004689 Test Step 1815 \"min loss\" =  17.317165\n",
      "2018-08-29 09:17:57.005110 Test Step 1815 \"loss\" =  18.531721\n",
      "2018-08-29 09:17:57.050068 Training Step 1815 Finished Timing (Training: 0.90783, Test: 0.084621) after 0.245933 seconds\n",
      "2018-08-29 09:17:57.050218 Training Step 1815 \"min loss\" =  3.8544781\n",
      "2018-08-29 09:17:57.050293 Training Step 1815 \"loss\" =  5.1351585\n",
      "2018-08-29 09:17:57.250725 Test Step 1820 Finished\n",
      "2018-08-29 09:17:57.250876 Test Step 1820 \"min loss\" =  17.317165\n",
      "2018-08-29 09:17:57.252159 Test Step 1820 \"loss\" =  18.31313\n",
      "2018-08-29 09:17:57.297513 Training Step 1820 Finished Timing (Training: 0.907936, Test: 0.0843098) after 0.247133 seconds\n",
      "2018-08-29 09:17:57.297679 Training Step 1820 \"min loss\" =  3.8544781\n",
      "2018-08-29 09:17:57.298306 Training Step 1820 \"loss\" =  4.026104\n",
      "2018-08-29 09:17:57.499222 Test Step 1825 Finished\n",
      "2018-08-29 09:17:57.499836 Test Step 1825 \"min loss\" =  17.317165\n",
      "2018-08-29 09:17:57.500087 Test Step 1825 \"loss\" =  17.93267\n",
      "2018-08-29 09:17:57.545011 Training Step 1825 Finished Timing (Training: 0.907674, Test: 0.0841324) after 0.24603 seconds\n",
      "2018-08-29 09:17:57.545153 Training Step 1825 \"min loss\" =  3.8544781\n",
      "2018-08-29 09:17:57.545227 Training Step 1825 \"loss\" =  4.3920264\n",
      "2018-08-29 09:17:57.747308 Test Step 1830 Finished\n",
      "2018-08-29 09:17:57.747476 Test Step 1830 \"min loss\" =  17.317165\n",
      "2018-08-29 09:17:57.747959 Test Step 1830 \"loss\" =  18.228888\n",
      "2018-08-29 09:17:57.793536 Training Step 1830 Finished Timing (Training: 0.907825, Test: 0.0840215) after 0.247331 seconds\n",
      "2018-08-29 09:17:57.794076 Training Step 1830 \"min loss\" =  3.8544781\n",
      "2018-08-29 09:17:57.794598 Training Step 1830 \"loss\" =  4.2635007\n",
      "2018-08-29 09:17:57.994866 Test Step 1835 Finished\n",
      "2018-08-29 09:17:57.995007 Test Step 1835 \"min loss\" =  17.317165\n",
      "2018-08-29 09:17:57.995566 Test Step 1835 \"loss\" =  17.878605\n",
      "2018-08-29 09:17:58.040669 Training Step 1835 Finished Timing (Training: 0.907632, Test: 0.0839923) after 0.245543 seconds\n",
      "2018-08-29 09:17:58.040798 Training Step 1835 \"min loss\" =  3.8544781\n",
      "2018-08-29 09:17:58.041265 Training Step 1835 \"loss\" =  4.435531\n",
      "2018-08-29 09:17:58.242579 Test Step 1840 Finished\n",
      "2018-08-29 09:17:58.243295 Test Step 1840 \"min loss\" =  17.317165\n",
      "2018-08-29 09:17:58.243402 Test Step 1840 \"loss\" =  18.132153\n",
      "2018-08-29 09:17:58.288505 Training Step 1840 Finished Timing (Training: 0.907861, Test: 0.0839829) after 0.247158 seconds\n",
      "2018-08-29 09:17:58.289067 Training Step 1840 \"min loss\" =  3.8544781\n",
      "2018-08-29 09:17:58.289128 Training Step 1840 \"loss\" =  4.382955\n",
      "2018-08-29 09:17:58.489045 Test Step 1845 Finished\n",
      "2018-08-29 09:17:58.489177 Test Step 1845 \"min loss\" =  17.317165\n",
      "2018-08-29 09:17:58.489775 Test Step 1845 \"loss\" =  17.792706\n",
      "2018-08-29 09:17:58.535172 Training Step 1845 Finished Timing (Training: 0.908221, Test: 0.0838232) after 0.245943 seconds\n",
      "2018-08-29 09:17:58.535321 Training Step 1845 \"min loss\" =  3.8544781\n",
      "2018-08-29 09:17:58.535412 Training Step 1845 \"loss\" =  4.8602443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:17:58.736639 Test Step 1850 Finished\n",
      "2018-08-29 09:17:58.736782 Test Step 1850 \"min loss\" =  17.317165\n",
      "2018-08-29 09:17:58.736858 Test Step 1850 \"loss\" =  18.629341\n",
      "2018-08-29 09:17:58.782323 Training Step 1850 Finished Timing (Training: 0.908237, Test: 0.0837157) after 0.246026 seconds\n",
      "2018-08-29 09:17:58.782443 Training Step 1850 \"min loss\" =  3.7255967\n",
      "2018-08-29 09:17:58.782525 Training Step 1850 \"loss\" =  4.1938553\n",
      "2018-08-29 09:17:58.984024 Test Step 1855 Finished\n",
      "2018-08-29 09:17:58.984164 Test Step 1855 \"min loss\" =  16.456541\n",
      "2018-08-29 09:17:58.984233 Test Step 1855 \"loss\" =  16.456541\n",
      "2018-08-29 09:17:59.030168 Training Step 1855 Finished Timing (Training: 0.90867, Test: 0.0837907) after 0.247555 seconds\n",
      "2018-08-29 09:17:59.030308 Training Step 1855 \"min loss\" =  3.7255967\n",
      "2018-08-29 09:17:59.031128 Training Step 1855 \"loss\" =  4.0074034\n",
      "2018-08-29 09:17:59.231695 Test Step 1860 Finished\n",
      "2018-08-29 09:17:59.231832 Test Step 1860 \"min loss\" =  16.456541\n",
      "2018-08-29 09:17:59.231904 Test Step 1860 \"loss\" =  17.15391\n",
      "2018-08-29 09:17:59.277676 Training Step 1860 Finished Timing (Training: 0.908705, Test: 0.0837653) after 0.246462 seconds\n",
      "2018-08-29 09:17:59.277806 Training Step 1860 \"min loss\" =  3.7255967\n",
      "2018-08-29 09:17:59.278458 Training Step 1860 \"loss\" =  4.3443584\n",
      "2018-08-29 09:17:59.479709 Test Step 1865 Finished\n",
      "2018-08-29 09:17:59.479891 Test Step 1865 \"min loss\" =  16.456541\n",
      "2018-08-29 09:17:59.479962 Test Step 1865 \"loss\" =  17.687193\n",
      "2018-08-29 09:17:59.525048 Training Step 1865 Finished Timing (Training: 0.908876, Test: 0.0837578) after 0.246412 seconds\n",
      "2018-08-29 09:17:59.525241 Training Step 1865 \"min loss\" =  3.7255967\n",
      "2018-08-29 09:17:59.525312 Training Step 1865 \"loss\" =  4.632974\n",
      "2018-08-29 09:17:59.727486 Test Step 1870 Finished\n",
      "2018-08-29 09:17:59.727634 Test Step 1870 \"min loss\" =  16.456541\n",
      "2018-08-29 09:17:59.728205 Test Step 1870 \"loss\" =  18.896759\n",
      "2018-08-29 09:17:59.773832 Training Step 1870 Finished Timing (Training: 0.90905, Test: 0.0836815) after 0.248419 seconds\n",
      "2018-08-29 09:17:59.773983 Training Step 1870 \"min loss\" =  3.7255967\n",
      "2018-08-29 09:17:59.774049 Training Step 1870 \"loss\" =  4.89167\n",
      "2018-08-29 09:17:59.975476 Test Step 1875 Finished\n",
      "2018-08-29 09:17:59.976097 Test Step 1875 \"min loss\" =  16.456541\n",
      "2018-08-29 09:17:59.976418 Test Step 1875 \"loss\" =  17.291327\n",
      "2018-08-29 09:18:00.022574 Training Step 1875 Finished Timing (Training: 0.908976, Test: 0.0836291) after 0.247534 seconds\n",
      "2018-08-29 09:18:00.022719 Training Step 1875 \"min loss\" =  3.7255967\n",
      "2018-08-29 09:18:00.023530 Training Step 1875 \"loss\" =  4.206115\n",
      "2018-08-29 09:18:00.224161 Test Step 1880 Finished\n",
      "2018-08-29 09:18:00.224854 Test Step 1880 \"min loss\" =  16.456541\n",
      "2018-08-29 09:18:00.224967 Test Step 1880 \"loss\" =  18.904402\n",
      "2018-08-29 09:18:00.270804 Training Step 1880 Finished Timing (Training: 0.908848, Test: 0.0836292) after 0.246856 seconds\n",
      "2018-08-29 09:18:00.270980 Training Step 1880 \"min loss\" =  3.7255967\n",
      "2018-08-29 09:18:00.271521 Training Step 1880 \"loss\" =  4.5218062\n",
      "2018-08-29 09:18:00.471605 Test Step 1885 Finished\n",
      "2018-08-29 09:18:00.472149 Test Step 1885 \"min loss\" =  16.456541\n",
      "2018-08-29 09:18:00.472220 Test Step 1885 \"loss\" =  18.201834\n",
      "2018-08-29 09:18:00.517114 Training Step 1885 Finished Timing (Training: 0.908865, Test: 0.0835769) after 0.245035 seconds\n",
      "2018-08-29 09:18:00.517258 Training Step 1885 \"min loss\" =  3.7255967\n",
      "2018-08-29 09:18:00.517338 Training Step 1885 \"loss\" =  4.45543\n",
      "2018-08-29 09:18:00.718370 Test Step 1890 Finished\n",
      "2018-08-29 09:18:00.718546 Test Step 1890 \"min loss\" =  16.456541\n",
      "2018-08-29 09:18:00.719454 Test Step 1890 \"loss\" =  16.821432\n",
      "2018-08-29 09:18:00.765142 Training Step 1890 Finished Timing (Training: 0.908915, Test: 0.0835268) after 0.247713 seconds\n",
      "2018-08-29 09:18:00.765287 Training Step 1890 \"min loss\" =  3.7255967\n",
      "2018-08-29 09:18:00.765354 Training Step 1890 \"loss\" =  4.2517805\n",
      "2018-08-29 09:18:00.967416 Test Step 1895 Finished\n",
      "2018-08-29 09:18:00.967671 Test Step 1895 \"min loss\" =  16.456541\n",
      "2018-08-29 09:18:00.967798 Test Step 1895 \"loss\" =  16.801424\n",
      "2018-08-29 09:18:01.014239 Training Step 1895 Finished Timing (Training: 0.90881, Test: 0.0836722) after 0.248806 seconds\n",
      "2018-08-29 09:18:01.014367 Training Step 1895 \"min loss\" =  3.7255967\n",
      "2018-08-29 09:18:01.015127 Training Step 1895 \"loss\" =  4.000722\n",
      "2018-08-29 09:18:01.216942 Test Step 1900 Finished\n",
      "2018-08-29 09:18:01.217091 Test Step 1900 \"min loss\" =  16.456541\n",
      "2018-08-29 09:18:01.217150 Test Step 1900 \"loss\" =  17.700817\n",
      "2018-08-29 09:18:01.263116 Training Step 1900 Finished Timing (Training: 0.908631, Test: 0.0837601) after 0.247902 seconds\n",
      "2018-08-29 09:18:01.263268 Training Step 1900 \"min loss\" =  3.7255967\n",
      "2018-08-29 09:18:01.263354 Training Step 1900 \"loss\" =  4.4210896\n",
      "2018-08-29 09:18:01.464789 Test Step 1905 Finished\n",
      "2018-08-29 09:18:01.464931 Test Step 1905 \"min loss\" =  16.456541\n",
      "2018-08-29 09:18:01.465925 Test Step 1905 \"loss\" =  17.52239\n",
      "2018-08-29 09:18:01.511168 Training Step 1905 Finished Timing (Training: 0.912722, Test: 0.0822127) after 0.247719 seconds\n",
      "2018-08-29 09:18:01.511332 Training Step 1905 \"min loss\" =  3.7255967\n",
      "2018-08-29 09:18:01.512024 Training Step 1905 \"loss\" =  4.2020693\n",
      "2018-08-29 09:18:01.712848 Test Step 1910 Finished\n",
      "2018-08-29 09:18:01.713405 Test Step 1910 \"min loss\" =  16.456541\n",
      "2018-08-29 09:18:01.713559 Test Step 1910 \"loss\" =  17.738543\n",
      "2018-08-29 09:18:01.758772 Training Step 1910 Finished Timing (Training: 0.911333, Test: 0.0825025) after 0.246657 seconds\n",
      "2018-08-29 09:18:01.758910 Training Step 1910 \"min loss\" =  3.7255967\n",
      "2018-08-29 09:18:01.758977 Training Step 1910 \"loss\" =  4.090001\n",
      "2018-08-29 09:18:01.961166 Test Step 1915 Finished\n",
      "2018-08-29 09:18:01.961298 Test Step 1915 \"min loss\" =  16.456541\n",
      "2018-08-29 09:18:01.961382 Test Step 1915 \"loss\" =  16.771471\n",
      "2018-08-29 09:18:02.007808 Training Step 1915 Finished Timing (Training: 0.912715, Test: 0.0823498) after 0.248742 seconds\n",
      "2018-08-29 09:18:02.007958 Training Step 1915 \"min loss\" =  3.7255967\n",
      "2018-08-29 09:18:02.008621 Training Step 1915 \"loss\" =  4.2397394\n",
      "2018-08-29 09:18:02.210950 Test Step 1920 Finished\n",
      "2018-08-29 09:18:02.211118 Test Step 1920 \"min loss\" =  16.456541\n",
      "2018-08-29 09:18:02.211190 Test Step 1920 \"loss\" =  17.338123\n",
      "2018-08-29 09:18:02.256183 Training Step 1920 Finished Timing (Training: 0.911793, Test: 0.0823451) after 0.24659 seconds\n",
      "2018-08-29 09:18:02.256314 Training Step 1920 \"min loss\" =  3.7255967\n",
      "2018-08-29 09:18:02.256827 Training Step 1920 \"loss\" =  4.032635\n",
      "2018-08-29 09:18:02.457431 Test Step 1925 Finished\n",
      "2018-08-29 09:18:02.457564 Test Step 1925 \"min loss\" =  16.456541\n",
      "2018-08-29 09:18:02.458132 Test Step 1925 \"loss\" =  17.460043\n",
      "2018-08-29 09:18:02.503220 Training Step 1925 Finished Timing (Training: 0.911374, Test: 0.0824288) after 0.246313 seconds\n",
      "2018-08-29 09:18:02.503764 Training Step 1925 \"min loss\" =  3.7161436\n",
      "2018-08-29 09:18:02.504240 Training Step 1925 \"loss\" =  4.283167\n",
      "2018-08-29 09:18:02.704989 Test Step 1930 Finished\n",
      "2018-08-29 09:18:02.705125 Test Step 1930 \"min loss\" =  16.456541\n",
      "2018-08-29 09:18:02.705900 Test Step 1930 \"loss\" =  16.768852\n",
      "2018-08-29 09:18:02.751191 Training Step 1930 Finished Timing (Training: 0.910814, Test: 0.0823624) after 0.246842 seconds\n",
      "2018-08-29 09:18:02.751327 Training Step 1930 \"min loss\" =  3.7161436\n",
      "2018-08-29 09:18:02.751399 Training Step 1930 \"loss\" =  3.8417687\n",
      "2018-08-29 09:18:02.952340 Test Step 1935 Finished\n",
      "2018-08-29 09:18:02.952506 Test Step 1935 \"min loss\" =  16.456541\n",
      "2018-08-29 09:18:02.953465 Test Step 1935 \"loss\" =  17.056944\n",
      "2018-08-29 09:18:02.998738 Training Step 1935 Finished Timing (Training: 0.910116, Test: 0.0825058) after 0.246378 seconds\n",
      "2018-08-29 09:18:02.998890 Training Step 1935 \"min loss\" =  3.7161436\n",
      "2018-08-29 09:18:02.998956 Training Step 1935 \"loss\" =  4.3820815\n",
      "2018-08-29 09:18:03.199622 Test Step 1940 Finished\n",
      "2018-08-29 09:18:03.200201 Test Step 1940 \"min loss\" =  16.456541\n",
      "2018-08-29 09:18:03.200315 Test Step 1940 \"loss\" =  18.172672\n",
      "2018-08-29 09:18:03.245790 Training Step 1940 Finished Timing (Training: 0.910037, Test: 0.0826194) after 0.24675 seconds\n",
      "2018-08-29 09:18:03.245935 Training Step 1940 \"min loss\" =  3.7161436\n",
      "2018-08-29 09:18:03.246593 Training Step 1940 \"loss\" =  4.167882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:18:03.446069 Test Step 1945 Finished\n",
      "2018-08-29 09:18:03.446206 Test Step 1945 \"min loss\" =  16.456541\n",
      "2018-08-29 09:18:03.446902 Test Step 1945 \"loss\" =  18.335808\n",
      "2018-08-29 09:18:03.491903 Training Step 1945 Finished Timing (Training: 0.909997, Test: 0.0826236) after 0.245225 seconds\n",
      "2018-08-29 09:18:03.492021 Training Step 1945 \"min loss\" =  3.7161436\n",
      "2018-08-29 09:18:03.492075 Training Step 1945 \"loss\" =  4.303908\n",
      "2018-08-29 09:18:03.694518 Test Step 1950 Finished\n",
      "2018-08-29 09:18:03.695076 Test Step 1950 \"min loss\" =  16.456541\n",
      "2018-08-29 09:18:03.695255 Test Step 1950 \"loss\" =  17.432417\n",
      "2018-08-29 09:18:03.740932 Training Step 1950 Finished Timing (Training: 0.909637, Test: 0.0829047) after 0.247932 seconds\n",
      "2018-08-29 09:18:03.741067 Training Step 1950 \"min loss\" =  3.5346596\n",
      "2018-08-29 09:18:03.741136 Training Step 1950 \"loss\" =  3.960867\n",
      "2018-08-29 09:18:03.941927 Test Step 1955 Finished\n",
      "2018-08-29 09:18:03.942068 Test Step 1955 \"min loss\" =  16.456541\n",
      "2018-08-29 09:18:03.942827 Test Step 1955 \"loss\" =  18.088566\n",
      "2018-08-29 09:18:03.988567 Training Step 1955 Finished Timing (Training: 0.909551, Test: 0.0830702) after 0.247343 seconds\n",
      "2018-08-29 09:18:03.988726 Training Step 1955 \"min loss\" =  3.5346596\n",
      "2018-08-29 09:18:03.988800 Training Step 1955 \"loss\" =  4.197344\n",
      "2018-08-29 09:18:04.188846 Test Step 1960 Finished\n",
      "2018-08-29 09:18:04.188976 Test Step 1960 \"min loss\" =  16.456541\n",
      "2018-08-29 09:18:04.189823 Test Step 1960 \"loss\" =  18.087555\n",
      "2018-08-29 09:18:04.235519 Training Step 1960 Finished Timing (Training: 0.909625, Test: 0.0830583) after 0.246625 seconds\n",
      "2018-08-29 09:18:04.235662 Training Step 1960 \"min loss\" =  3.5346596\n",
      "2018-08-29 09:18:04.235726 Training Step 1960 \"loss\" =  4.3360243\n",
      "2018-08-29 09:18:04.436128 Test Step 1965 Finished\n",
      "2018-08-29 09:18:04.436302 Test Step 1965 \"min loss\" =  16.456541\n",
      "2018-08-29 09:18:04.436932 Test Step 1965 \"loss\" =  18.47627\n",
      "2018-08-29 09:18:04.482163 Training Step 1965 Finished Timing (Training: 0.909791, Test: 0.0830789) after 0.246363 seconds\n",
      "2018-08-29 09:18:04.482298 Training Step 1965 \"min loss\" =  3.5346596\n",
      "2018-08-29 09:18:04.483006 Training Step 1965 \"loss\" =  4.2207584\n",
      "2018-08-29 09:18:04.683337 Test Step 1970 Finished\n",
      "2018-08-29 09:18:04.683912 Test Step 1970 \"min loss\" =  16.456541\n",
      "2018-08-29 09:18:04.683985 Test Step 1970 \"loss\" =  17.794699\n",
      "2018-08-29 09:18:04.729705 Training Step 1970 Finished Timing (Training: 0.909586, Test: 0.0830758) after 0.246211 seconds\n",
      "2018-08-29 09:18:04.730248 Training Step 1970 \"min loss\" =  3.5346596\n",
      "2018-08-29 09:18:04.730612 Training Step 1970 \"loss\" =  4.014505\n",
      "2018-08-29 09:18:04.931812 Test Step 1975 Finished\n",
      "2018-08-29 09:18:04.931968 Test Step 1975 \"min loss\" =  16.456541\n",
      "2018-08-29 09:18:04.932634 Test Step 1975 \"loss\" =  18.28074\n",
      "2018-08-29 09:18:04.977982 Training Step 1975 Finished Timing (Training: 0.909451, Test: 0.083066) after 0.24727 seconds\n",
      "2018-08-29 09:18:04.978115 Training Step 1975 \"min loss\" =  3.5346596\n",
      "2018-08-29 09:18:04.978180 Training Step 1975 \"loss\" =  3.9073882\n",
      "2018-08-29 09:18:05.180129 Test Step 1980 Finished\n",
      "2018-08-29 09:18:05.180280 Test Step 1980 \"min loss\" =  16.456541\n",
      "2018-08-29 09:18:05.181332 Test Step 1980 \"loss\" =  17.605492\n",
      "2018-08-29 09:18:05.226624 Training Step 1980 Finished Timing (Training: 0.909324, Test: 0.083165) after 0.248362 seconds\n",
      "2018-08-29 09:18:05.226769 Training Step 1980 \"min loss\" =  3.5346596\n",
      "2018-08-29 09:18:05.227461 Training Step 1980 \"loss\" =  3.950192\n",
      "2018-08-29 09:18:05.429523 Test Step 1985 Finished\n",
      "2018-08-29 09:18:05.430331 Test Step 1985 \"min loss\" =  16.456541\n",
      "2018-08-29 09:18:05.430519 Test Step 1985 \"loss\" =  16.853111\n",
      "2018-08-29 09:18:05.476165 Training Step 1985 Finished Timing (Training: 0.909137, Test: 0.0831802) after 0.248101 seconds\n",
      "2018-08-29 09:18:05.476319 Training Step 1985 \"min loss\" =  3.5346596\n",
      "2018-08-29 09:18:05.476977 Training Step 1985 \"loss\" =  3.9461884\n",
      "2018-08-29 09:18:05.679036 Test Step 1990 Finished\n",
      "2018-08-29 09:18:05.679166 Test Step 1990 \"min loss\" =  16.456541\n",
      "2018-08-29 09:18:05.679275 Test Step 1990 \"loss\" =  18.621197\n",
      "2018-08-29 09:18:05.724168 Training Step 1990 Finished Timing (Training: 0.909162, Test: 0.0832971) after 0.24709 seconds\n",
      "2018-08-29 09:18:05.724345 Training Step 1990 \"min loss\" =  3.5346596\n",
      "2018-08-29 09:18:05.724446 Training Step 1990 \"loss\" =  3.806817\n",
      "2018-08-29 09:18:05.926354 Test Step 1995 Finished\n",
      "2018-08-29 09:18:05.926495 Test Step 1995 \"min loss\" =  16.456541\n",
      "2018-08-29 09:18:05.927223 Test Step 1995 \"loss\" =  18.350998\n",
      "2018-08-29 09:18:05.972399 Training Step 1995 Finished Timing (Training: 0.908948, Test: 0.0832765) after 0.246292 seconds\n",
      "2018-08-29 09:18:05.972541 Training Step 1995 \"min loss\" =  3.5346596\n",
      "2018-08-29 09:18:05.973255 Training Step 1995 \"loss\" =  3.6116679\n",
      "2018-08-29 09:18:06.174383 Test Step 2000 Finished\n",
      "2018-08-29 09:18:06.174538 Test Step 2000 \"min loss\" =  16.456541\n",
      "2018-08-29 09:18:06.174621 Test Step 2000 \"loss\" =  16.81161\n",
      "2018-08-29 09:18:06.221497 Training Step 2000 Finished Timing (Training: 0.909048, Test: 0.0833034) after 0.248153 seconds\n",
      "2018-08-29 09:18:06.221643 Training Step 2000 \"min loss\" =  3.5346596\n",
      "2018-08-29 09:18:06.221712 Training Step 2000 \"loss\" =  3.8103852\n",
      "2018-08-29 09:18:06.422887 Test Step 2005 Finished\n",
      "2018-08-29 09:18:06.423046 Test Step 2005 \"min loss\" =  16.456541\n",
      "2018-08-29 09:18:06.423126 Test Step 2005 \"loss\" =  17.669098\n",
      "2018-08-29 09:18:06.475670 Training Step 2005 Finished Timing (Training: 0.913316, Test: 0.0808247) after 0.253872 seconds\n",
      "2018-08-29 09:18:06.475802 Training Step 2005 \"min loss\" =  3.5346596\n",
      "2018-08-29 09:18:06.475867 Training Step 2005 \"loss\" =  3.7878578\n",
      "2018-08-29 09:18:06.676696 Test Step 2010 Finished\n",
      "2018-08-29 09:18:06.676865 Test Step 2010 \"min loss\" =  16.456541\n",
      "2018-08-29 09:18:06.676937 Test Step 2010 \"loss\" =  17.33699\n",
      "2018-08-29 09:18:06.722635 Training Step 2010 Finished Timing (Training: 0.910765, Test: 0.0832117) after 0.245794 seconds\n",
      "2018-08-29 09:18:06.722779 Training Step 2010 \"min loss\" =  3.5346596\n",
      "2018-08-29 09:18:06.723467 Training Step 2010 \"loss\" =  3.8523407\n",
      "2018-08-29 09:18:06.923758 Test Step 2015 Finished\n",
      "2018-08-29 09:18:06.924327 Test Step 2015 \"min loss\" =  16.282578\n",
      "2018-08-29 09:18:06.924579 Test Step 2015 \"loss\" =  16.282578\n",
      "2018-08-29 09:18:06.969848 Training Step 2015 Finished Timing (Training: 0.910051, Test: 0.0831075) after 0.246288 seconds\n",
      "2018-08-29 09:18:06.969993 Training Step 2015 \"min loss\" =  3.5346596\n",
      "2018-08-29 09:18:06.970050 Training Step 2015 \"loss\" =  4.0304823\n",
      "2018-08-29 09:18:07.172968 Test Step 2020 Finished\n",
      "2018-08-29 09:18:07.173576 Test Step 2020 \"min loss\" =  16.282578\n",
      "2018-08-29 09:18:07.174109 Test Step 2020 \"loss\" =  17.736645\n",
      "2018-08-29 09:18:07.218975 Training Step 2020 Finished Timing (Training: 0.909536, Test: 0.0837714) after 0.248846 seconds\n",
      "2018-08-29 09:18:07.219126 Training Step 2020 \"min loss\" =  3.5346596\n",
      "2018-08-29 09:18:07.219214 Training Step 2020 \"loss\" =  4.1796184\n",
      "2018-08-29 09:18:07.420232 Test Step 2025 Finished\n",
      "2018-08-29 09:18:07.420938 Test Step 2025 \"min loss\" =  16.282578\n",
      "2018-08-29 09:18:07.421337 Test Step 2025 \"loss\" =  17.149704\n",
      "2018-08-29 09:18:07.466631 Training Step 2025 Finished Timing (Training: 0.908951, Test: 0.0837712) after 0.246509 seconds\n",
      "2018-08-29 09:18:07.466777 Training Step 2025 \"min loss\" =  3.5133085\n",
      "2018-08-29 09:18:07.466838 Training Step 2025 \"loss\" =  3.6858587\n",
      "2018-08-29 09:18:07.667781 Test Step 2030 Finished\n",
      "2018-08-29 09:18:07.668393 Test Step 2030 \"min loss\" =  16.282578\n",
      "2018-08-29 09:18:07.669005 Test Step 2030 \"loss\" =  17.359602\n",
      "2018-08-29 09:18:07.714433 Training Step 2030 Finished Timing (Training: 0.908601, Test: 0.0839404) after 0.247509 seconds\n",
      "2018-08-29 09:18:07.714604 Training Step 2030 \"min loss\" =  3.5133085\n",
      "2018-08-29 09:18:07.714728 Training Step 2030 \"loss\" =  4.246675\n",
      "2018-08-29 09:18:07.916098 Test Step 2035 Finished\n",
      "2018-08-29 09:18:07.916604 Test Step 2035 \"min loss\" =  16.282578\n",
      "2018-08-29 09:18:07.917074 Test Step 2035 \"loss\" =  18.01835\n",
      "2018-08-29 09:18:07.962309 Training Step 2035 Finished Timing (Training: 0.90804, Test: 0.0839073) after 0.246287 seconds\n",
      "2018-08-29 09:18:07.962473 Training Step 2035 \"min loss\" =  3.5133085\n",
      "2018-08-29 09:18:07.963382 Training Step 2035 \"loss\" =  4.0226803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:18:08.164780 Test Step 2040 Finished\n",
      "2018-08-29 09:18:08.164940 Test Step 2040 \"min loss\" =  16.282578\n",
      "2018-08-29 09:18:08.166051 Test Step 2040 \"loss\" =  16.932407\n",
      "2018-08-29 09:18:08.211953 Training Step 2040 Finished Timing (Training: 0.90735, Test: 0.0838154) after 0.248046 seconds\n",
      "2018-08-29 09:18:08.212584 Training Step 2040 \"min loss\" =  3.5133085\n",
      "2018-08-29 09:18:08.212648 Training Step 2040 \"loss\" =  4.0306573\n",
      "2018-08-29 09:18:08.414089 Test Step 2045 Finished\n",
      "2018-08-29 09:18:08.414669 Test Step 2045 \"min loss\" =  16.282578\n",
      "2018-08-29 09:18:08.415059 Test Step 2045 \"loss\" =  16.785484\n",
      "2018-08-29 09:18:08.460236 Training Step 2045 Finished Timing (Training: 0.907523, Test: 0.0837739) after 0.24749 seconds\n",
      "2018-08-29 09:18:08.460370 Training Step 2045 \"min loss\" =  3.5133085\n",
      "2018-08-29 09:18:08.460880 Training Step 2045 \"loss\" =  4.2619505\n",
      "2018-08-29 09:18:08.662109 Test Step 2050 Finished\n",
      "2018-08-29 09:18:08.662243 Test Step 2050 \"min loss\" =  16.126656\n",
      "2018-08-29 09:18:08.662294 Test Step 2050 \"loss\" =  16.126656\n",
      "2018-08-29 09:18:08.707635 Training Step 2050 Finished Timing (Training: 0.907896, Test: 0.0837313) after 0.246349 seconds\n",
      "2018-08-29 09:18:08.707792 Training Step 2050 \"min loss\" =  3.5133085\n",
      "2018-08-29 09:18:08.707845 Training Step 2050 \"loss\" =  3.8075051\n",
      "2018-08-29 09:18:08.908145 Test Step 2055 Finished\n",
      "2018-08-29 09:18:08.908287 Test Step 2055 \"min loss\" =  16.126656\n",
      "2018-08-29 09:18:08.908339 Test Step 2055 \"loss\" =  16.249733\n",
      "2018-08-29 09:18:08.953297 Training Step 2055 Finished Timing (Training: 0.908331, Test: 0.0838347) after 0.245385 seconds\n",
      "2018-08-29 09:18:08.953431 Training Step 2055 \"min loss\" =  3.5057356\n",
      "2018-08-29 09:18:08.953483 Training Step 2055 \"loss\" =  4.2225003\n",
      "2018-08-29 09:18:09.153986 Test Step 2060 Finished\n",
      "2018-08-29 09:18:09.154158 Test Step 2060 \"min loss\" =  16.126656\n",
      "2018-08-29 09:18:09.154236 Test Step 2060 \"loss\" =  16.540222\n",
      "2018-08-29 09:18:09.199516 Training Step 2060 Finished Timing (Training: 0.908815, Test: 0.0837781) after 0.245938 seconds\n",
      "2018-08-29 09:18:09.199667 Training Step 2060 \"min loss\" =  3.5057356\n",
      "2018-08-29 09:18:09.199726 Training Step 2060 \"loss\" =  3.713774\n",
      "2018-08-29 09:18:09.400228 Test Step 2065 Finished\n",
      "2018-08-29 09:18:09.400790 Test Step 2065 \"min loss\" =  16.126656\n",
      "2018-08-29 09:18:09.400936 Test Step 2065 \"loss\" =  17.14987\n",
      "2018-08-29 09:18:09.446216 Training Step 2065 Finished Timing (Training: 0.909129, Test: 0.0836658) after 0.246425 seconds\n",
      "2018-08-29 09:18:09.446674 Training Step 2065 \"min loss\" =  3.5057356\n",
      "2018-08-29 09:18:09.446787 Training Step 2065 \"loss\" =  3.9833431\n",
      "2018-08-29 09:18:09.649845 Test Step 2070 Finished\n",
      "2018-08-29 09:18:09.650060 Test Step 2070 \"min loss\" =  16.126656\n",
      "2018-08-29 09:18:09.650143 Test Step 2070 \"loss\" =  16.75047\n",
      "2018-08-29 09:18:09.696504 Training Step 2070 Finished Timing (Training: 0.909132, Test: 0.0835713) after 0.249583 seconds\n",
      "2018-08-29 09:18:09.696690 Training Step 2070 \"min loss\" =  3.5057356\n",
      "2018-08-29 09:18:09.696778 Training Step 2070 \"loss\" =  3.8275707\n",
      "2018-08-29 09:18:09.898199 Test Step 2075 Finished\n",
      "2018-08-29 09:18:09.898337 Test Step 2075 \"min loss\" =  16.126656\n",
      "2018-08-29 09:18:09.898423 Test Step 2075 \"loss\" =  17.114958\n",
      "2018-08-29 09:18:09.944523 Training Step 2075 Finished Timing (Training: 0.909069, Test: 0.0835022) after 0.246965 seconds\n",
      "2018-08-29 09:18:09.945060 Training Step 2075 \"min loss\" =  3.5057356\n",
      "2018-08-29 09:18:09.945167 Training Step 2075 \"loss\" =  4.1521506\n",
      "2018-08-29 09:18:10.145701 Test Step 2080 Finished\n",
      "2018-08-29 09:18:10.145848 Test Step 2080 \"min loss\" =  16.126656\n",
      "2018-08-29 09:18:10.145913 Test Step 2080 \"loss\" =  17.289125\n",
      "2018-08-29 09:18:10.191253 Training Step 2080 Finished Timing (Training: 0.9092, Test: 0.0835665) after 0.245998 seconds\n",
      "2018-08-29 09:18:10.191383 Training Step 2080 \"min loss\" =  3.430434\n",
      "2018-08-29 09:18:10.191447 Training Step 2080 \"loss\" =  3.7662444\n",
      "2018-08-29 09:18:10.393796 Test Step 2085 Finished\n",
      "2018-08-29 09:18:10.394309 Test Step 2085 \"min loss\" =  16.126656\n",
      "2018-08-29 09:18:10.394539 Test Step 2085 \"loss\" =  17.810774\n",
      "2018-08-29 09:18:10.439826 Training Step 2085 Finished Timing (Training: 0.908973, Test: 0.0836706) after 0.247401 seconds\n",
      "2018-08-29 09:18:10.439954 Training Step 2085 \"min loss\" =  3.430434\n",
      "2018-08-29 09:18:10.440015 Training Step 2085 \"loss\" =  3.7705739\n",
      "2018-08-29 09:18:10.640466 Test Step 2090 Finished\n",
      "2018-08-29 09:18:10.640654 Test Step 2090 \"min loss\" =  16.126656\n",
      "2018-08-29 09:18:10.640754 Test Step 2090 \"loss\" =  17.313877\n",
      "2018-08-29 09:18:10.687138 Training Step 2090 Finished Timing (Training: 0.909209, Test: 0.0836774) after 0.247016 seconds\n",
      "2018-08-29 09:18:10.687265 Training Step 2090 \"min loss\" =  3.430434\n",
      "2018-08-29 09:18:10.687827 Training Step 2090 \"loss\" =  3.9142678\n",
      "2018-08-29 09:18:10.888290 Test Step 2095 Finished\n",
      "2018-08-29 09:18:10.888857 Test Step 2095 \"min loss\" =  16.126656\n",
      "2018-08-29 09:18:10.889008 Test Step 2095 \"loss\" =  16.657913\n",
      "2018-08-29 09:18:10.934341 Training Step 2095 Finished Timing (Training: 0.909201, Test: 0.0836996) after 0.246402 seconds\n",
      "2018-08-29 09:18:10.934548 Training Step 2095 \"min loss\" =  3.430434\n",
      "2018-08-29 09:18:10.934624 Training Step 2095 \"loss\" =  4.1329756\n",
      "2018-08-29 09:18:11.136310 Test Step 2100 Finished\n",
      "2018-08-29 09:18:11.136514 Test Step 2100 \"min loss\" =  16.126656\n",
      "2018-08-29 09:18:11.136665 Test Step 2100 \"loss\" =  16.132141\n",
      "2018-08-29 09:18:11.183086 Training Step 2100 Finished Timing (Training: 0.909233, Test: 0.0836825) after 0.247578 seconds\n",
      "2018-08-29 09:18:11.183245 Training Step 2100 \"min loss\" =  3.430434\n",
      "2018-08-29 09:18:11.183309 Training Step 2100 \"loss\" =  4.172333\n",
      "2018-08-29 09:18:11.384331 Test Step 2105 Finished\n",
      "2018-08-29 09:18:11.384513 Test Step 2105 \"min loss\" =  16.126656\n",
      "2018-08-29 09:18:11.384584 Test Step 2105 \"loss\" =  17.333853\n",
      "2018-08-29 09:18:11.430448 Training Step 2105 Finished Timing (Training: 0.915153, Test: 0.0832612) after 0.246193 seconds\n",
      "2018-08-29 09:18:11.430578 Training Step 2105 \"min loss\" =  3.430434\n",
      "2018-08-29 09:18:11.431456 Training Step 2105 \"loss\" =  3.8076453\n",
      "2018-08-29 09:18:11.632627 Test Step 2110 Finished\n",
      "2018-08-29 09:18:11.632780 Test Step 2110 \"min loss\" =  16.126656\n",
      "2018-08-29 09:18:11.632847 Test Step 2110 \"loss\" =  16.715853\n",
      "2018-08-29 09:18:11.679612 Training Step 2110 Finished Timing (Training: 0.910428, Test: 0.0829877) after 0.248035 seconds\n",
      "2018-08-29 09:18:11.679781 Training Step 2110 \"min loss\" =  3.430434\n",
      "2018-08-29 09:18:11.679909 Training Step 2110 \"loss\" =  3.6961207\n",
      "2018-08-29 09:18:11.881007 Test Step 2115 Finished\n",
      "2018-08-29 09:18:11.881151 Test Step 2115 \"min loss\" =  16.126656\n",
      "2018-08-29 09:18:11.881231 Test Step 2115 \"loss\" =  17.160704\n",
      "2018-08-29 09:18:11.927189 Training Step 2115 Finished Timing (Training: 0.910539, Test: 0.0830163) after 0.247155 seconds\n",
      "2018-08-29 09:18:11.927330 Training Step 2115 \"min loss\" =  3.430434\n",
      "2018-08-29 09:18:11.927403 Training Step 2115 \"loss\" =  3.850016\n",
      "2018-08-29 09:18:12.127765 Test Step 2120 Finished\n",
      "2018-08-29 09:18:12.127893 Test Step 2120 \"min loss\" =  16.126656\n",
      "2018-08-29 09:18:12.127958 Test Step 2120 \"loss\" =  16.698418\n",
      "2018-08-29 09:18:12.173611 Training Step 2120 Finished Timing (Training: 0.910721, Test: 0.0830224) after 0.246122 seconds\n",
      "2018-08-29 09:18:12.173798 Training Step 2120 \"min loss\" =  3.430434\n",
      "2018-08-29 09:18:12.173921 Training Step 2120 \"loss\" =  4.112226\n",
      "2018-08-29 09:18:12.376934 Test Step 2125 Finished\n",
      "2018-08-29 09:18:12.377089 Test Step 2125 \"min loss\" =  16.126656\n",
      "2018-08-29 09:18:12.377158 Test Step 2125 \"loss\" =  18.169384\n",
      "2018-08-29 09:18:12.424541 Training Step 2125 Finished Timing (Training: 0.911369, Test: 0.0829763) after 0.250487 seconds\n",
      "2018-08-29 09:18:12.424703 Training Step 2125 \"min loss\" =  3.271017\n",
      "2018-08-29 09:18:12.425221 Training Step 2125 \"loss\" =  3.271017\n",
      "2018-08-29 09:18:12.626035 Test Step 2130 Finished\n",
      "2018-08-29 09:18:12.626204 Test Step 2130 \"min loss\" =  16.126656\n",
      "2018-08-29 09:18:12.626946 Test Step 2130 \"loss\" =  17.213154\n",
      "2018-08-29 09:18:12.672948 Training Step 2130 Finished Timing (Training: 0.910897, Test: 0.0831802) after 0.247637 seconds\n",
      "2018-08-29 09:18:12.673155 Training Step 2130 \"min loss\" =  3.271017\n",
      "2018-08-29 09:18:12.674021 Training Step 2130 \"loss\" =  4.0976768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:18:12.875390 Test Step 2135 Finished\n",
      "2018-08-29 09:18:12.875889 Test Step 2135 \"min loss\" =  16.126656\n",
      "2018-08-29 09:18:12.876109 Test Step 2135 \"loss\" =  17.122423\n",
      "2018-08-29 09:18:12.921472 Training Step 2135 Finished Timing (Training: 0.910087, Test: 0.0832548) after 0.246892 seconds\n",
      "2018-08-29 09:18:12.921619 Training Step 2135 \"min loss\" =  3.271017\n",
      "2018-08-29 09:18:12.921686 Training Step 2135 \"loss\" =  4.0473223\n",
      "2018-08-29 09:18:13.123732 Test Step 2140 Finished\n",
      "2018-08-29 09:18:13.123862 Test Step 2140 \"min loss\" =  16.126656\n",
      "2018-08-29 09:18:13.123922 Test Step 2140 \"loss\" =  17.74731\n",
      "2018-08-29 09:18:13.170672 Training Step 2140 Finished Timing (Training: 0.910741, Test: 0.0831233) after 0.248887 seconds\n",
      "2018-08-29 09:18:13.170802 Training Step 2140 \"min loss\" =  3.271017\n",
      "2018-08-29 09:18:13.171537 Training Step 2140 \"loss\" =  4.0654106\n",
      "2018-08-29 09:18:13.373019 Test Step 2145 Finished\n",
      "2018-08-29 09:18:13.373235 Test Step 2145 \"min loss\" =  16.126656\n",
      "2018-08-29 09:18:13.373993 Test Step 2145 \"loss\" =  16.532476\n",
      "2018-08-29 09:18:13.420002 Training Step 2145 Finished Timing (Training: 0.909854, Test: 0.0834027) after 0.2476 seconds\n",
      "2018-08-29 09:18:13.420150 Training Step 2145 \"min loss\" =  3.271017\n",
      "2018-08-29 09:18:13.420228 Training Step 2145 \"loss\" =  3.7249174\n",
      "2018-08-29 09:18:13.620787 Test Step 2150 Finished\n",
      "2018-08-29 09:18:13.620918 Test Step 2150 \"min loss\" =  16.126656\n",
      "2018-08-29 09:18:13.620990 Test Step 2150 \"loss\" =  17.445017\n",
      "2018-08-29 09:18:13.666776 Training Step 2150 Finished Timing (Training: 0.91002, Test: 0.0833768) after 0.246464 seconds\n",
      "2018-08-29 09:18:13.666924 Training Step 2150 \"min loss\" =  3.271017\n",
      "2018-08-29 09:18:13.667001 Training Step 2150 \"loss\" =  3.7567008\n",
      "2018-08-29 09:18:13.867550 Test Step 2155 Finished\n",
      "2018-08-29 09:18:13.867694 Test Step 2155 \"min loss\" =  16.126656\n",
      "2018-08-29 09:18:13.868246 Test Step 2155 \"loss\" =  16.750328\n",
      "2018-08-29 09:18:13.913848 Training Step 2155 Finished Timing (Training: 0.910023, Test: 0.0833166) after 0.246088 seconds\n",
      "2018-08-29 09:18:13.914086 Training Step 2155 \"min loss\" =  3.271017\n",
      "2018-08-29 09:18:13.914230 Training Step 2155 \"loss\" =  3.7232757\n",
      "2018-08-29 09:18:14.117592 Test Step 2160 Finished\n",
      "2018-08-29 09:18:14.118372 Test Step 2160 \"min loss\" =  16.126656\n",
      "2018-08-29 09:18:14.118711 Test Step 2160 \"loss\" =  17.897947\n",
      "2018-08-29 09:18:14.163754 Training Step 2160 Finished Timing (Training: 0.909982, Test: 0.0833018) after 0.249383 seconds\n",
      "2018-08-29 09:18:14.163902 Training Step 2160 \"min loss\" =  3.271017\n",
      "2018-08-29 09:18:14.164516 Training Step 2160 \"loss\" =  4.303915\n",
      "2018-08-29 09:18:14.365930 Test Step 2165 Finished\n",
      "2018-08-29 09:18:14.366143 Test Step 2165 \"min loss\" =  16.126656\n",
      "2018-08-29 09:18:14.366264 Test Step 2165 \"loss\" =  17.850033\n",
      "2018-08-29 09:18:14.411365 Training Step 2165 Finished Timing (Training: 0.909834, Test: 0.0833901) after 0.246267 seconds\n",
      "2018-08-29 09:18:14.411534 Training Step 2165 \"min loss\" =  3.271017\n",
      "2018-08-29 09:18:14.412546 Training Step 2165 \"loss\" =  3.9349847\n",
      "2018-08-29 09:18:14.613195 Test Step 2170 Finished\n",
      "2018-08-29 09:18:14.613851 Test Step 2170 \"min loss\" =  16.126656\n",
      "2018-08-29 09:18:14.613928 Test Step 2170 \"loss\" =  16.525751\n",
      "2018-08-29 09:18:14.659802 Training Step 2170 Finished Timing (Training: 0.909652, Test: 0.0832924) after 0.246626 seconds\n",
      "2018-08-29 09:18:14.660309 Training Step 2170 \"min loss\" =  3.271017\n",
      "2018-08-29 09:18:14.660713 Training Step 2170 \"loss\" =  3.75992\n",
      "2018-08-29 09:18:14.861292 Test Step 2175 Finished\n",
      "2018-08-29 09:18:14.861472 Test Step 2175 \"min loss\" =  16.126656\n",
      "2018-08-29 09:18:14.862331 Test Step 2175 \"loss\" =  17.741657\n",
      "2018-08-29 09:18:14.908710 Training Step 2175 Finished Timing (Training: 0.909403, Test: 0.0832798) after 0.247915 seconds\n",
      "2018-08-29 09:18:14.908857 Training Step 2175 \"min loss\" =  3.271017\n",
      "2018-08-29 09:18:14.909553 Training Step 2175 \"loss\" =  4.151397\n",
      "2018-08-29 09:18:15.109994 Test Step 2180 Finished\n",
      "2018-08-29 09:18:15.110592 Test Step 2180 \"min loss\" =  16.126656\n",
      "2018-08-29 09:18:15.110693 Test Step 2180 \"loss\" =  17.04225\n",
      "2018-08-29 09:18:15.156180 Training Step 2180 Finished Timing (Training: 0.9094, Test: 0.0832876) after 0.246506 seconds\n",
      "2018-08-29 09:18:15.156314 Training Step 2180 \"min loss\" =  3.271017\n",
      "2018-08-29 09:18:15.156986 Training Step 2180 \"loss\" =  3.7154455\n",
      "2018-08-29 09:18:15.357721 Test Step 2185 Finished\n",
      "2018-08-29 09:18:15.357853 Test Step 2185 \"min loss\" =  16.126656\n",
      "2018-08-29 09:18:15.358409 Test Step 2185 \"loss\" =  16.59333\n",
      "2018-08-29 09:18:15.403770 Training Step 2185 Finished Timing (Training: 0.909397, Test: 0.0832133) after 0.246676 seconds\n",
      "2018-08-29 09:18:15.403901 Training Step 2185 \"min loss\" =  3.271017\n",
      "2018-08-29 09:18:15.404013 Training Step 2185 \"loss\" =  3.6267982\n",
      "2018-08-29 09:18:15.605647 Test Step 2190 Finished\n",
      "2018-08-29 09:18:15.605815 Test Step 2190 \"min loss\" =  16.126656\n",
      "2018-08-29 09:18:15.605888 Test Step 2190 \"loss\" =  17.218908\n",
      "2018-08-29 09:18:15.650742 Training Step 2190 Finished Timing (Training: 0.909674, Test: 0.0831915) after 0.246642 seconds\n",
      "2018-08-29 09:18:15.650885 Training Step 2190 \"min loss\" =  3.271017\n",
      "2018-08-29 09:18:15.651448 Training Step 2190 \"loss\" =  3.766605\n",
      "2018-08-29 09:18:15.852368 Test Step 2195 Finished\n",
      "2018-08-29 09:18:15.852525 Test Step 2195 \"min loss\" =  16.126656\n",
      "2018-08-29 09:18:15.853157 Test Step 2195 \"loss\" =  17.18046\n",
      "2018-08-29 09:18:15.898426 Training Step 2195 Finished Timing (Training: 0.909564, Test: 0.0831693) after 0.246201 seconds\n",
      "2018-08-29 09:18:15.898573 Training Step 2195 \"min loss\" =  3.271017\n",
      "2018-08-29 09:18:15.898648 Training Step 2195 \"loss\" =  3.762982\n",
      "2018-08-29 09:18:16.100742 Test Step 2200 Finished\n",
      "2018-08-29 09:18:16.101408 Test Step 2200 \"min loss\" =  16.126656\n",
      "2018-08-29 09:18:16.101680 Test Step 2200 \"loss\" =  16.77441\n",
      "2018-08-29 09:18:16.147411 Training Step 2200 Finished Timing (Training: 0.909491, Test: 0.083188) after 0.247974 seconds\n",
      "2018-08-29 09:18:16.147551 Training Step 2200 \"min loss\" =  3.271017\n",
      "2018-08-29 09:18:16.147656 Training Step 2200 \"loss\" =  3.5908487\n",
      "2018-08-29 09:18:16.348770 Test Step 2205 Finished\n",
      "2018-08-29 09:18:16.348907 Test Step 2205 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:16.349464 Test Step 2205 \"loss\" =  15.324853\n",
      "2018-08-29 09:18:16.394960 Training Step 2205 Finished Timing (Training: 0.912724, Test: 0.0840057) after 0.247182 seconds\n",
      "2018-08-29 09:18:16.395105 Training Step 2205 \"min loss\" =  3.271017\n",
      "2018-08-29 09:18:16.395842 Training Step 2205 \"loss\" =  3.7484016\n",
      "2018-08-29 09:18:16.597348 Test Step 2210 Finished\n",
      "2018-08-29 09:18:16.597524 Test Step 2210 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:16.597607 Test Step 2210 \"loss\" =  16.136276\n",
      "2018-08-29 09:18:16.643803 Training Step 2210 Finished Timing (Training: 0.910599, Test: 0.0844266) after 0.247557 seconds\n",
      "2018-08-29 09:18:16.643955 Training Step 2210 \"min loss\" =  3.271017\n",
      "2018-08-29 09:18:16.644021 Training Step 2210 \"loss\" =  3.522006\n",
      "2018-08-29 09:18:16.845275 Test Step 2215 Finished\n",
      "2018-08-29 09:18:16.845440 Test Step 2215 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:16.845998 Test Step 2215 \"loss\" =  15.658804\n",
      "2018-08-29 09:18:16.891343 Training Step 2215 Finished Timing (Training: 0.911133, Test: 0.0840214) after 0.247243 seconds\n",
      "2018-08-29 09:18:16.891481 Training Step 2215 \"min loss\" =  3.271017\n",
      "2018-08-29 09:18:16.891960 Training Step 2215 \"loss\" =  3.7033803\n",
      "2018-08-29 09:18:17.093180 Test Step 2220 Finished\n",
      "2018-08-29 09:18:17.093324 Test Step 2220 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:17.093950 Test Step 2220 \"loss\" =  15.762058\n",
      "2018-08-29 09:18:17.139355 Training Step 2220 Finished Timing (Training: 0.910649, Test: 0.0838218) after 0.247022 seconds\n",
      "2018-08-29 09:18:17.139494 Training Step 2220 \"min loss\" =  3.271017\n",
      "2018-08-29 09:18:17.139555 Training Step 2220 \"loss\" =  3.5220585\n",
      "2018-08-29 09:18:17.342559 Test Step 2225 Finished\n",
      "2018-08-29 09:18:17.342702 Test Step 2225 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:17.343276 Test Step 2225 \"loss\" =  16.054071\n",
      "2018-08-29 09:18:17.388809 Training Step 2225 Finished Timing (Training: 0.909941, Test: 0.0837755) after 0.248485 seconds\n",
      "2018-08-29 09:18:17.389326 Training Step 2225 \"min loss\" =  3.2240639\n",
      "2018-08-29 09:18:17.389773 Training Step 2225 \"loss\" =  3.2240639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:18:17.590926 Test Step 2230 Finished\n",
      "2018-08-29 09:18:17.591081 Test Step 2230 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:17.591133 Test Step 2230 \"loss\" =  16.009153\n",
      "2018-08-29 09:18:17.636370 Training Step 2230 Finished Timing (Training: 0.91012, Test: 0.0837308) after 0.246517 seconds\n",
      "2018-08-29 09:18:17.636496 Training Step 2230 \"min loss\" =  3.2240639\n",
      "2018-08-29 09:18:17.636547 Training Step 2230 \"loss\" =  4.168446\n",
      "2018-08-29 09:18:17.838205 Test Step 2235 Finished\n",
      "2018-08-29 09:18:17.838348 Test Step 2235 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:17.838398 Test Step 2235 \"loss\" =  16.508394\n",
      "2018-08-29 09:18:17.883576 Training Step 2235 Finished Timing (Training: 0.91028, Test: 0.0841359) after 0.246957 seconds\n",
      "2018-08-29 09:18:17.883717 Training Step 2235 \"min loss\" =  3.2240639\n",
      "2018-08-29 09:18:17.883765 Training Step 2235 \"loss\" =  3.599259\n",
      "2018-08-29 09:18:18.084947 Test Step 2240 Finished\n",
      "2018-08-29 09:18:18.085079 Test Step 2240 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:18.085160 Test Step 2240 \"loss\" =  16.611946\n",
      "2018-08-29 09:18:18.130333 Training Step 2240 Finished Timing (Training: 0.910739, Test: 0.0840846) after 0.246494 seconds\n",
      "2018-08-29 09:18:18.130743 Training Step 2240 \"min loss\" =  3.2240639\n",
      "2018-08-29 09:18:18.130829 Training Step 2240 \"loss\" =  3.8266182\n",
      "2018-08-29 09:18:18.332747 Test Step 2245 Finished\n",
      "2018-08-29 09:18:18.333296 Test Step 2245 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:18.333670 Test Step 2245 \"loss\" =  16.502663\n",
      "2018-08-29 09:18:18.379521 Training Step 2245 Finished Timing (Training: 0.91018, Test: 0.0843236) after 0.248591 seconds\n",
      "2018-08-29 09:18:18.380130 Training Step 2245 \"min loss\" =  3.2240639\n",
      "2018-08-29 09:18:18.380691 Training Step 2245 \"loss\" =  3.6308768\n",
      "2018-08-29 09:18:18.582755 Test Step 2250 Finished\n",
      "2018-08-29 09:18:18.583289 Test Step 2250 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:18.583631 Test Step 2250 \"loss\" =  16.689127\n",
      "2018-08-29 09:18:18.629279 Training Step 2250 Finished Timing (Training: 0.909608, Test: 0.0842524) after 0.248049 seconds\n",
      "2018-08-29 09:18:18.629723 Training Step 2250 \"min loss\" =  3.2240639\n",
      "2018-08-29 09:18:18.630083 Training Step 2250 \"loss\" =  3.6239686\n",
      "2018-08-29 09:18:18.831368 Test Step 2255 Finished\n",
      "2018-08-29 09:18:18.831889 Test Step 2255 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:18.832240 Test Step 2255 \"loss\" =  18.29005\n",
      "2018-08-29 09:18:18.877628 Training Step 2255 Finished Timing (Training: 0.909397, Test: 0.0841402) after 0.24719 seconds\n",
      "2018-08-29 09:18:18.878158 Training Step 2255 \"min loss\" =  3.2240639\n",
      "2018-08-29 09:18:18.878517 Training Step 2255 \"loss\" =  3.772419\n",
      "2018-08-29 09:18:19.080086 Test Step 2260 Finished\n",
      "2018-08-29 09:18:19.080225 Test Step 2260 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:19.080274 Test Step 2260 \"loss\" =  17.286575\n",
      "2018-08-29 09:18:19.126233 Training Step 2260 Finished Timing (Training: 0.909413, Test: 0.0841467) after 0.247349 seconds\n",
      "2018-08-29 09:18:19.126399 Training Step 2260 \"min loss\" =  3.2240639\n",
      "2018-08-29 09:18:19.126449 Training Step 2260 \"loss\" =  3.7259529\n",
      "2018-08-29 09:18:19.328143 Test Step 2265 Finished\n",
      "2018-08-29 09:18:19.328281 Test Step 2265 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:19.328333 Test Step 2265 \"loss\" =  16.943703\n",
      "2018-08-29 09:18:19.373318 Training Step 2265 Finished Timing (Training: 0.909613, Test: 0.0842612) after 0.246806 seconds\n",
      "2018-08-29 09:18:19.373455 Training Step 2265 \"min loss\" =  3.2240639\n",
      "2018-08-29 09:18:19.373503 Training Step 2265 \"loss\" =  3.8866313\n",
      "2018-08-29 09:18:19.575876 Test Step 2270 Finished\n",
      "2018-08-29 09:18:19.576084 Test Step 2270 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:19.576209 Test Step 2270 \"loss\" =  16.792295\n",
      "2018-08-29 09:18:19.621687 Training Step 2270 Finished Timing (Training: 0.9098, Test: 0.0842916) after 0.248113 seconds\n",
      "2018-08-29 09:18:19.621881 Training Step 2270 \"min loss\" =  3.2240639\n",
      "2018-08-29 09:18:19.622425 Training Step 2270 \"loss\" =  3.5384295\n",
      "2018-08-29 09:18:19.823656 Test Step 2275 Finished\n",
      "2018-08-29 09:18:19.823793 Test Step 2275 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:19.824722 Test Step 2275 \"loss\" =  16.261927\n",
      "2018-08-29 09:18:19.869827 Training Step 2275 Finished Timing (Training: 0.909649, Test: 0.0842938) after 0.247317 seconds\n",
      "2018-08-29 09:18:19.869950 Training Step 2275 \"min loss\" =  3.2240639\n",
      "2018-08-29 09:18:19.870001 Training Step 2275 \"loss\" =  3.7764106\n",
      "2018-08-29 09:18:20.070469 Test Step 2280 Finished\n",
      "2018-08-29 09:18:20.070627 Test Step 2280 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:20.070695 Test Step 2280 \"loss\" =  16.203957\n",
      "2018-08-29 09:18:20.116781 Training Step 2280 Finished Timing (Training: 0.90965, Test: 0.0842549) after 0.246702 seconds\n",
      "2018-08-29 09:18:20.116907 Training Step 2280 \"min loss\" =  3.2240639\n",
      "2018-08-29 09:18:20.116979 Training Step 2280 \"loss\" =  3.7189546\n",
      "2018-08-29 09:18:20.318828 Test Step 2285 Finished\n",
      "2018-08-29 09:18:20.318998 Test Step 2285 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:20.319806 Test Step 2285 \"loss\" =  17.787388\n",
      "2018-08-29 09:18:20.365701 Training Step 2285 Finished Timing (Training: 0.909667, Test: 0.0841886) after 0.248641 seconds\n",
      "2018-08-29 09:18:20.365867 Training Step 2285 \"min loss\" =  3.2240639\n",
      "2018-08-29 09:18:20.366592 Training Step 2285 \"loss\" =  3.815937\n",
      "2018-08-29 09:18:20.568395 Test Step 2290 Finished\n",
      "2018-08-29 09:18:20.568544 Test Step 2290 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:20.569433 Test Step 2290 \"loss\" =  17.044868\n",
      "2018-08-29 09:18:20.615111 Training Step 2290 Finished Timing (Training: 0.909478, Test: 0.0840929) after 0.248178 seconds\n",
      "2018-08-29 09:18:20.615601 Training Step 2290 \"min loss\" =  3.2240639\n",
      "2018-08-29 09:18:20.615675 Training Step 2290 \"loss\" =  3.8025796\n",
      "2018-08-29 09:18:20.817865 Test Step 2295 Finished\n",
      "2018-08-29 09:18:20.818493 Test Step 2295 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:20.818847 Test Step 2295 \"loss\" =  16.72569\n",
      "2018-08-29 09:18:20.864397 Training Step 2295 Finished Timing (Training: 0.909385, Test: 0.0840622) after 0.248216 seconds\n",
      "2018-08-29 09:18:20.864532 Training Step 2295 \"min loss\" =  3.2240639\n",
      "2018-08-29 09:18:20.865158 Training Step 2295 \"loss\" =  3.8172913\n",
      "2018-08-29 09:18:21.066195 Test Step 2300 Finished\n",
      "2018-08-29 09:18:21.066767 Test Step 2300 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:21.066997 Test Step 2300 \"loss\" =  16.913765\n",
      "2018-08-29 09:18:21.112490 Training Step 2300 Finished Timing (Training: 0.909336, Test: 0.0840215) after 0.247247 seconds\n",
      "2018-08-29 09:18:21.112629 Training Step 2300 \"min loss\" =  3.2240639\n",
      "2018-08-29 09:18:21.112698 Training Step 2300 \"loss\" =  3.9354348\n",
      "2018-08-29 09:18:21.315196 Test Step 2305 Finished\n",
      "2018-08-29 09:18:21.315384 Test Step 2305 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:21.315973 Test Step 2305 \"loss\" =  16.999128\n",
      "2018-08-29 09:18:21.361816 Training Step 2305 Finished Timing (Training: 0.911489, Test: 0.0836085) after 0.248291 seconds\n",
      "2018-08-29 09:18:21.362008 Training Step 2305 \"min loss\" =  3.2240639\n",
      "2018-08-29 09:18:21.362519 Training Step 2305 \"loss\" =  3.5713913\n",
      "2018-08-29 09:18:21.565415 Test Step 2310 Finished\n",
      "2018-08-29 09:18:21.565572 Test Step 2310 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:21.566168 Test Step 2310 \"loss\" =  15.464065\n",
      "2018-08-29 09:18:21.611843 Training Step 2310 Finished Timing (Training: 0.908142, Test: 0.0847101) after 0.248928 seconds\n",
      "2018-08-29 09:18:21.612022 Training Step 2310 \"min loss\" =  3.2240639\n",
      "2018-08-29 09:18:21.612103 Training Step 2310 \"loss\" =  3.880009\n",
      "2018-08-29 09:18:21.814716 Test Step 2315 Finished\n",
      "2018-08-29 09:18:21.815150 Test Step 2315 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:21.815221 Test Step 2315 \"loss\" =  16.80736\n",
      "2018-08-29 09:18:21.860947 Training Step 2315 Finished Timing (Training: 0.90868, Test: 0.0839537) after 0.247787 seconds\n",
      "2018-08-29 09:18:21.861319 Training Step 2315 \"min loss\" =  3.2240639\n",
      "2018-08-29 09:18:21.861610 Training Step 2315 \"loss\" =  3.8395526\n",
      "2018-08-29 09:18:22.064195 Test Step 2320 Finished\n",
      "2018-08-29 09:18:22.064383 Test Step 2320 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:22.064453 Test Step 2320 \"loss\" =  15.965428\n",
      "2018-08-29 09:18:22.109692 Training Step 2320 Finished Timing (Training: 0.909542, Test: 0.0838044) after 0.247994 seconds\n",
      "2018-08-29 09:18:22.109892 Training Step 2320 \"min loss\" =  3.2240639\n",
      "2018-08-29 09:18:22.110026 Training Step 2320 \"loss\" =  3.813836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:18:22.312770 Test Step 2325 Finished\n",
      "2018-08-29 09:18:22.312927 Test Step 2325 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:22.312999 Test Step 2325 \"loss\" =  16.346071\n",
      "2018-08-29 09:18:22.359270 Training Step 2325 Finished Timing (Training: 0.909985, Test: 0.0835817) after 0.2491 seconds\n",
      "2018-08-29 09:18:22.359421 Training Step 2325 \"min loss\" =  3.2240639\n",
      "2018-08-29 09:18:22.359492 Training Step 2325 \"loss\" =  3.6693504\n",
      "2018-08-29 09:18:22.562072 Test Step 2330 Finished\n",
      "2018-08-29 09:18:22.562251 Test Step 2330 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:22.562993 Test Step 2330 \"loss\" =  16.032858\n",
      "2018-08-29 09:18:22.608889 Training Step 2330 Finished Timing (Training: 0.910031, Test: 0.0833033) after 0.249307 seconds\n",
      "2018-08-29 09:18:22.609019 Training Step 2330 \"min loss\" =  3.2240639\n",
      "2018-08-29 09:18:22.609590 Training Step 2330 \"loss\" =  3.895008\n",
      "2018-08-29 09:18:22.811192 Test Step 2335 Finished\n",
      "2018-08-29 09:18:22.811363 Test Step 2335 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:22.811431 Test Step 2335 \"loss\" =  16.978107\n",
      "2018-08-29 09:18:22.857822 Training Step 2335 Finished Timing (Training: 0.910331, Test: 0.0833012) after 0.24814 seconds\n",
      "2018-08-29 09:18:22.858016 Training Step 2335 \"min loss\" =  3.1915739\n",
      "2018-08-29 09:18:22.858602 Training Step 2335 \"loss\" =  4.1562057\n",
      "2018-08-29 09:18:23.060076 Test Step 2340 Finished\n",
      "2018-08-29 09:18:23.060713 Test Step 2340 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:23.061118 Test Step 2340 \"loss\" =  17.739733\n",
      "2018-08-29 09:18:23.106651 Training Step 2340 Finished Timing (Training: 0.910104, Test: 0.083208) after 0.247934 seconds\n",
      "2018-08-29 09:18:23.106796 Training Step 2340 \"min loss\" =  3.1448083\n",
      "2018-08-29 09:18:23.106863 Training Step 2340 \"loss\" =  3.596761\n",
      "2018-08-29 09:18:23.309103 Test Step 2345 Finished\n",
      "2018-08-29 09:18:23.309292 Test Step 2345 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:23.310082 Test Step 2345 \"loss\" =  16.35841\n",
      "2018-08-29 09:18:23.355791 Training Step 2345 Finished Timing (Training: 0.909626, Test: 0.0833073) after 0.248049 seconds\n",
      "2018-08-29 09:18:23.355941 Training Step 2345 \"min loss\" =  3.1448083\n",
      "2018-08-29 09:18:23.356011 Training Step 2345 \"loss\" =  3.9280362\n",
      "2018-08-29 09:18:23.557558 Test Step 2350 Finished\n",
      "2018-08-29 09:18:23.557697 Test Step 2350 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:23.558308 Test Step 2350 \"loss\" =  17.675913\n",
      "2018-08-29 09:18:23.603869 Training Step 2350 Finished Timing (Training: 0.909915, Test: 0.0832561) after 0.247787 seconds\n",
      "2018-08-29 09:18:23.604363 Training Step 2350 \"min loss\" =  3.1448083\n",
      "2018-08-29 09:18:23.604680 Training Step 2350 \"loss\" =  3.9393508\n",
      "2018-08-29 09:18:23.806148 Test Step 2355 Finished\n",
      "2018-08-29 09:18:23.806728 Test Step 2355 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:23.806972 Test Step 2355 \"loss\" =  17.446598\n",
      "2018-08-29 09:18:23.852529 Training Step 2355 Finished Timing (Training: 0.909659, Test: 0.0832378) after 0.247546 seconds\n",
      "2018-08-29 09:18:23.852738 Training Step 2355 \"min loss\" =  3.1448083\n",
      "2018-08-29 09:18:23.853520 Training Step 2355 \"loss\" =  3.935278\n",
      "2018-08-29 09:18:24.055340 Test Step 2360 Finished\n",
      "2018-08-29 09:18:24.055518 Test Step 2360 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:24.055630 Test Step 2360 \"loss\" =  17.066505\n",
      "2018-08-29 09:18:24.101586 Training Step 2360 Finished Timing (Training: 0.909357, Test: 0.0832222) after 0.247529 seconds\n",
      "2018-08-29 09:18:24.101733 Training Step 2360 \"min loss\" =  3.1448083\n",
      "2018-08-29 09:18:24.102341 Training Step 2360 \"loss\" =  3.8894691\n",
      "2018-08-29 09:18:24.304185 Test Step 2365 Finished\n",
      "2018-08-29 09:18:24.304856 Test Step 2365 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:24.304932 Test Step 2365 \"loss\" =  16.995516\n",
      "2018-08-29 09:18:24.350586 Training Step 2365 Finished Timing (Training: 0.909337, Test: 0.083223) after 0.247952 seconds\n",
      "2018-08-29 09:18:24.350753 Training Step 2365 \"min loss\" =  3.1448083\n",
      "2018-08-29 09:18:24.351627 Training Step 2365 \"loss\" =  4.267648\n",
      "2018-08-29 09:18:24.553810 Test Step 2370 Finished\n",
      "2018-08-29 09:18:24.553956 Test Step 2370 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:24.554031 Test Step 2370 \"loss\" =  16.50117\n",
      "2018-08-29 09:18:24.600444 Training Step 2370 Finished Timing (Training: 0.909239, Test: 0.0831781) after 0.248707 seconds\n",
      "2018-08-29 09:18:24.600590 Training Step 2370 \"min loss\" =  3.005411\n",
      "2018-08-29 09:18:24.600670 Training Step 2370 \"loss\" =  3.6176307\n",
      "2018-08-29 09:18:24.803301 Test Step 2375 Finished\n",
      "2018-08-29 09:18:24.803437 Test Step 2375 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:24.804136 Test Step 2375 \"loss\" =  16.03178\n",
      "2018-08-29 09:18:24.849798 Training Step 2375 Finished Timing (Training: 0.909145, Test: 0.0832571) after 0.248362 seconds\n",
      "2018-08-29 09:18:24.850304 Training Step 2375 \"min loss\" =  3.005411\n",
      "2018-08-29 09:18:24.850387 Training Step 2375 \"loss\" =  3.6369517\n",
      "2018-08-29 09:18:25.051739 Test Step 2380 Finished\n",
      "2018-08-29 09:18:25.052263 Test Step 2380 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:25.052339 Test Step 2380 \"loss\" =  16.378448\n",
      "2018-08-29 09:18:25.097587 Training Step 2380 Finished Timing (Training: 0.909155, Test: 0.0832726) after 0.246728 seconds\n",
      "2018-08-29 09:18:25.097802 Training Step 2380 \"min loss\" =  3.005411\n",
      "2018-08-29 09:18:25.098328 Training Step 2380 \"loss\" =  3.7693927\n",
      "2018-08-29 09:18:25.300502 Test Step 2385 Finished\n",
      "2018-08-29 09:18:25.300672 Test Step 2385 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:25.301281 Test Step 2385 \"loss\" =  15.850915\n",
      "2018-08-29 09:18:25.346808 Training Step 2385 Finished Timing (Training: 0.909037, Test: 0.0833175) after 0.248303 seconds\n",
      "2018-08-29 09:18:25.346944 Training Step 2385 \"min loss\" =  3.005411\n",
      "2018-08-29 09:18:25.347014 Training Step 2385 \"loss\" =  3.3172436\n",
      "2018-08-29 09:18:25.549522 Test Step 2390 Finished\n",
      "2018-08-29 09:18:25.550302 Test Step 2390 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:25.550377 Test Step 2390 \"loss\" =  17.120749\n",
      "2018-08-29 09:18:25.595957 Training Step 2390 Finished Timing (Training: 0.908963, Test: 0.0833218) after 0.248444 seconds\n",
      "2018-08-29 09:18:25.596357 Training Step 2390 \"min loss\" =  3.005411\n",
      "2018-08-29 09:18:25.596889 Training Step 2390 \"loss\" =  3.557251\n",
      "2018-08-29 09:18:25.798484 Test Step 2395 Finished\n",
      "2018-08-29 09:18:25.798626 Test Step 2395 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:25.799479 Test Step 2395 \"loss\" =  17.328695\n",
      "2018-08-29 09:18:25.844996 Training Step 2395 Finished Timing (Training: 0.908847, Test: 0.0832562) after 0.247617 seconds\n",
      "2018-08-29 09:18:25.845126 Training Step 2395 \"min loss\" =  3.005411\n",
      "2018-08-29 09:18:25.845194 Training Step 2395 \"loss\" =  3.2717187\n",
      "2018-08-29 09:18:26.048324 Test Step 2400 Finished\n",
      "2018-08-29 09:18:26.048491 Test Step 2400 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:26.049417 Test Step 2400 \"loss\" =  16.643112\n",
      "2018-08-29 09:18:26.094579 Training Step 2400 Finished Timing (Training: 0.90885, Test: 0.0833416) after 0.249304 seconds\n",
      "2018-08-29 09:18:26.094706 Training Step 2400 \"min loss\" =  3.005411\n",
      "2018-08-29 09:18:26.094785 Training Step 2400 \"loss\" =  3.42096\n",
      "2018-08-29 09:18:26.296446 Test Step 2405 Finished\n",
      "2018-08-29 09:18:26.296628 Test Step 2405 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:26.296707 Test Step 2405 \"loss\" =  17.193577\n",
      "2018-08-29 09:18:26.343963 Training Step 2405 Finished Timing (Training: 0.914593, Test: 0.0838555) after 0.249049 seconds\n",
      "2018-08-29 09:18:26.344163 Training Step 2405 \"min loss\" =  3.005411\n",
      "2018-08-29 09:18:26.344293 Training Step 2405 \"loss\" =  3.4526298\n",
      "2018-08-29 09:18:26.548355 Test Step 2410 Finished\n",
      "2018-08-29 09:18:26.548518 Test Step 2410 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:26.548591 Test Step 2410 \"loss\" =  16.783981\n",
      "2018-08-29 09:18:26.595703 Training Step 2410 Finished Timing (Training: 0.912491, Test: 0.0850204) after 0.25128 seconds\n",
      "2018-08-29 09:18:26.595891 Training Step 2410 \"min loss\" =  3.005411\n",
      "2018-08-29 09:18:26.596621 Training Step 2410 \"loss\" =  3.3576977\n",
      "2018-08-29 09:18:26.798360 Test Step 2415 Finished\n",
      "2018-08-29 09:18:26.798524 Test Step 2415 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:26.798582 Test Step 2415 \"loss\" =  16.763012\n",
      "2018-08-29 09:18:26.843595 Training Step 2415 Finished Timing (Training: 0.911388, Test: 0.0843439) after 0.246284 seconds\n",
      "2018-08-29 09:18:26.843733 Training Step 2415 \"min loss\" =  3.005411\n",
      "2018-08-29 09:18:26.844533 Training Step 2415 \"loss\" =  3.3979208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:18:27.046063 Test Step 2420 Finished\n",
      "2018-08-29 09:18:27.046239 Test Step 2420 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:27.047125 Test Step 2420 \"loss\" =  17.122313\n",
      "2018-08-29 09:18:27.092871 Training Step 2420 Finished Timing (Training: 0.910149, Test: 0.083836) after 0.248233 seconds\n",
      "2018-08-29 09:18:27.093021 Training Step 2420 \"min loss\" =  3.005411\n",
      "2018-08-29 09:18:27.093963 Training Step 2420 \"loss\" =  3.5117617\n",
      "2018-08-29 09:18:27.296160 Test Step 2425 Finished\n",
      "2018-08-29 09:18:27.296819 Test Step 2425 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:27.297083 Test Step 2425 \"loss\" =  16.32226\n",
      "2018-08-29 09:18:27.342178 Training Step 2425 Finished Timing (Training: 0.909166, Test: 0.0836988) after 0.247465 seconds\n",
      "2018-08-29 09:18:27.342322 Training Step 2425 \"min loss\" =  3.005411\n",
      "2018-08-29 09:18:27.342966 Training Step 2425 \"loss\" =  3.391407\n",
      "2018-08-29 09:18:27.544358 Test Step 2430 Finished\n",
      "2018-08-29 09:18:27.544511 Test Step 2430 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:27.544583 Test Step 2430 \"loss\" =  16.245737\n",
      "2018-08-29 09:18:27.590871 Training Step 2430 Finished Timing (Training: 0.908833, Test: 0.0836532) after 0.247813 seconds\n",
      "2018-08-29 09:18:27.591023 Training Step 2430 \"min loss\" =  3.005411\n",
      "2018-08-29 09:18:27.591094 Training Step 2430 \"loss\" =  3.5717418\n",
      "2018-08-29 09:18:27.793371 Test Step 2435 Finished\n",
      "2018-08-29 09:18:27.794043 Test Step 2435 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:27.794124 Test Step 2435 \"loss\" =  16.621294\n",
      "2018-08-29 09:18:27.840108 Training Step 2435 Finished Timing (Training: 0.908784, Test: 0.0834863) after 0.248929 seconds\n",
      "2018-08-29 09:18:27.840237 Training Step 2435 \"min loss\" =  2.9983435\n",
      "2018-08-29 09:18:27.840322 Training Step 2435 \"loss\" =  3.625776\n",
      "2018-08-29 09:18:28.043947 Test Step 2440 Finished\n",
      "2018-08-29 09:18:28.044110 Test Step 2440 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:28.044795 Test Step 2440 \"loss\" =  16.127876\n",
      "2018-08-29 09:18:28.090587 Training Step 2440 Finished Timing (Training: 0.908173, Test: 0.0837039) after 0.248742 seconds\n",
      "2018-08-29 09:18:28.090717 Training Step 2440 \"min loss\" =  2.9983435\n",
      "2018-08-29 09:18:28.090800 Training Step 2440 \"loss\" =  3.5431156\n",
      "2018-08-29 09:18:28.294162 Test Step 2445 Finished\n",
      "2018-08-29 09:18:28.294310 Test Step 2445 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:28.294868 Test Step 2445 \"loss\" =  17.402452\n",
      "2018-08-29 09:18:28.340457 Training Step 2445 Finished Timing (Training: 0.9079, Test: 0.0838414) after 0.248359 seconds\n",
      "2018-08-29 09:18:28.340621 Training Step 2445 \"min loss\" =  2.9983435\n",
      "2018-08-29 09:18:28.340691 Training Step 2445 \"loss\" =  3.2094302\n",
      "2018-08-29 09:18:28.541630 Test Step 2450 Finished\n",
      "2018-08-29 09:18:28.542188 Test Step 2450 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:28.542278 Test Step 2450 \"loss\" =  15.618938\n",
      "2018-08-29 09:18:28.587521 Training Step 2450 Finished Timing (Training: 0.908281, Test: 0.0838424) after 0.246752 seconds\n",
      "2018-08-29 09:18:28.587659 Training Step 2450 \"min loss\" =  2.9983435\n",
      "2018-08-29 09:18:28.588376 Training Step 2450 \"loss\" =  3.209139\n",
      "2018-08-29 09:18:28.789334 Test Step 2455 Finished\n",
      "2018-08-29 09:18:28.789953 Test Step 2455 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:28.790027 Test Step 2455 \"loss\" =  16.46238\n",
      "2018-08-29 09:18:28.835762 Training Step 2455 Finished Timing (Training: 0.90843, Test: 0.0837633) after 0.247285 seconds\n",
      "2018-08-29 09:18:28.835911 Training Step 2455 \"min loss\" =  2.9983435\n",
      "2018-08-29 09:18:28.835973 Training Step 2455 \"loss\" =  3.3295443\n",
      "2018-08-29 09:18:29.039360 Test Step 2460 Finished\n",
      "2018-08-29 09:18:29.039535 Test Step 2460 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:29.040408 Test Step 2460 \"loss\" =  16.712515\n",
      "2018-08-29 09:18:29.086117 Training Step 2460 Finished Timing (Training: 0.908585, Test: 0.0836591) after 0.250056 seconds\n",
      "2018-08-29 09:18:29.086293 Training Step 2460 \"min loss\" =  2.9983435\n",
      "2018-08-29 09:18:29.087134 Training Step 2460 \"loss\" =  3.780148\n",
      "2018-08-29 09:18:29.289317 Test Step 2465 Finished\n",
      "2018-08-29 09:18:29.289993 Test Step 2465 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:29.290281 Test Step 2465 \"loss\" =  16.053965\n",
      "2018-08-29 09:18:29.335680 Training Step 2465 Finished Timing (Training: 0.908301, Test: 0.0836565) after 0.247798 seconds\n",
      "2018-08-29 09:18:29.335817 Training Step 2465 \"min loss\" =  2.9983435\n",
      "2018-08-29 09:18:29.335885 Training Step 2465 \"loss\" =  3.3038278\n",
      "2018-08-29 09:18:29.538072 Test Step 2470 Finished\n",
      "2018-08-29 09:18:29.538632 Test Step 2470 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:29.538706 Test Step 2470 \"loss\" =  15.391902\n",
      "2018-08-29 09:18:29.584374 Training Step 2470 Finished Timing (Training: 0.90861, Test: 0.0836154) after 0.248395 seconds\n",
      "2018-08-29 09:18:29.584527 Training Step 2470 \"min loss\" =  2.9983435\n",
      "2018-08-29 09:18:29.585274 Training Step 2470 \"loss\" =  3.5966847\n",
      "2018-08-29 09:18:29.787609 Test Step 2475 Finished\n",
      "2018-08-29 09:18:29.787751 Test Step 2475 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:29.788366 Test Step 2475 \"loss\" =  15.701531\n",
      "2018-08-29 09:18:29.834016 Training Step 2475 Finished Timing (Training: 0.908702, Test: 0.0835367) after 0.248629 seconds\n",
      "2018-08-29 09:18:29.834170 Training Step 2475 \"min loss\" =  2.9983435\n",
      "2018-08-29 09:18:29.834658 Training Step 2475 \"loss\" =  3.8210177\n",
      "2018-08-29 09:18:30.036774 Test Step 2480 Finished\n",
      "2018-08-29 09:18:30.037004 Test Step 2480 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:30.037538 Test Step 2480 \"loss\" =  17.069065\n",
      "2018-08-29 09:18:30.082925 Training Step 2480 Finished Timing (Training: 0.908702, Test: 0.0835151) after 0.247825 seconds\n",
      "2018-08-29 09:18:30.083417 Training Step 2480 \"min loss\" =  2.9983435\n",
      "2018-08-29 09:18:30.083493 Training Step 2480 \"loss\" =  3.2705972\n",
      "2018-08-29 09:18:30.286567 Test Step 2485 Finished\n",
      "2018-08-29 09:18:30.286707 Test Step 2485 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:30.287331 Test Step 2485 \"loss\" =  16.625727\n",
      "2018-08-29 09:18:30.332900 Training Step 2485 Finished Timing (Training: 0.908683, Test: 0.0835061) after 0.24884 seconds\n",
      "2018-08-29 09:18:30.333058 Training Step 2485 \"min loss\" =  2.9983435\n",
      "2018-08-29 09:18:30.333761 Training Step 2485 \"loss\" =  3.1575208\n",
      "2018-08-29 09:18:30.535204 Test Step 2490 Finished\n",
      "2018-08-29 09:18:30.535914 Test Step 2490 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:30.536072 Test Step 2490 \"loss\" =  16.237417\n",
      "2018-08-29 09:18:30.582069 Training Step 2490 Finished Timing (Training: 0.908678, Test: 0.0834439) after 0.247916 seconds\n",
      "2018-08-29 09:18:30.582664 Training Step 2490 \"min loss\" =  2.9983435\n",
      "2018-08-29 09:18:30.583171 Training Step 2490 \"loss\" =  3.1395507\n",
      "2018-08-29 09:18:30.785681 Test Step 2495 Finished\n",
      "2018-08-29 09:18:30.786247 Test Step 2495 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:30.786391 Test Step 2495 \"loss\" =  15.820778\n",
      "2018-08-29 09:18:30.832069 Training Step 2495 Finished Timing (Training: 0.908612, Test: 0.0834645) after 0.248716 seconds\n",
      "2018-08-29 09:18:30.832553 Training Step 2495 \"min loss\" =  2.9983435\n",
      "2018-08-29 09:18:30.832675 Training Step 2495 \"loss\" =  3.5151656\n",
      "2018-08-29 09:18:31.034613 Test Step 2500 Finished\n",
      "2018-08-29 09:18:31.034761 Test Step 2500 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:31.034827 Test Step 2500 \"loss\" =  15.868775\n",
      "2018-08-29 09:18:31.081502 Training Step 2500 Finished Timing (Training: 0.90869, Test: 0.0835737) after 0.248733 seconds\n",
      "2018-08-29 09:18:31.081636 Training Step 2500 \"min loss\" =  2.9983435\n",
      "2018-08-29 09:18:31.082192 Training Step 2500 \"loss\" =  3.2061298\n",
      "2018-08-29 09:18:31.284922 Test Step 2505 Finished\n",
      "2018-08-29 09:18:31.285664 Test Step 2505 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:31.285973 Test Step 2505 \"loss\" =  16.022936\n",
      "2018-08-29 09:18:31.331756 Training Step 2505 Finished Timing (Training: 0.910993, Test: 0.0832572) after 0.249448 seconds\n",
      "2018-08-29 09:18:31.331890 Training Step 2505 \"min loss\" =  2.9983435\n",
      "2018-08-29 09:18:31.332387 Training Step 2505 \"loss\" =  3.6510444\n",
      "2018-08-29 09:18:31.533318 Test Step 2510 Finished\n",
      "2018-08-29 09:18:31.533446 Test Step 2510 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:31.533520 Test Step 2510 \"loss\" =  16.012144\n",
      "2018-08-29 09:18:31.580657 Training Step 2510 Finished Timing (Training: 0.911516, Test: 0.0825903) after 0.247713 seconds\n",
      "2018-08-29 09:18:31.580806 Training Step 2510 \"min loss\" =  2.9983435\n",
      "2018-08-29 09:18:31.581518 Training Step 2510 \"loss\" =  3.3747547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:18:31.784790 Test Step 2515 Finished\n",
      "2018-08-29 09:18:31.785402 Test Step 2515 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:31.786008 Test Step 2515 \"loss\" =  17.085577\n",
      "2018-08-29 09:18:31.831617 Training Step 2515 Finished Timing (Training: 0.908937, Test: 0.0826531) after 0.249385 seconds\n",
      "2018-08-29 09:18:31.832170 Training Step 2515 \"min loss\" =  2.9983435\n",
      "2018-08-29 09:18:31.832705 Training Step 2515 \"loss\" =  3.296479\n",
      "2018-08-29 09:18:32.033975 Test Step 2520 Finished\n",
      "2018-08-29 09:18:32.034119 Test Step 2520 \"min loss\" =  15.324853\n",
      "2018-08-29 09:18:32.034185 Test Step 2520 \"loss\" =  16.528002\n",
      "2018-08-29 09:18:32.080511 Training Step 2520 Finished Timing (Training: 0.907974, Test: 0.0828145) after 0.2474 seconds\n",
      "2018-08-29 09:18:32.080689 Training Step 2520 \"min loss\" =  2.9983435\n",
      "2018-08-29 09:18:32.080765 Training Step 2520 \"loss\" =  3.6475706\n",
      "2018-08-29 09:18:32.282655 Test Step 2525 Finished\n",
      "2018-08-29 09:18:32.283488 Test Step 2525 \"min loss\" =  15.1211405\n",
      "2018-08-29 09:18:32.283636 Test Step 2525 \"loss\" =  15.1211405\n",
      "2018-08-29 09:18:32.329515 Training Step 2525 Finished Timing (Training: 0.907911, Test: 0.0829876) after 0.248662 seconds\n",
      "2018-08-29 09:18:32.329657 Training Step 2525 \"min loss\" =  2.9983435\n",
      "2018-08-29 09:18:32.330284 Training Step 2525 \"loss\" =  3.3067458\n",
      "2018-08-29 09:18:32.532082 Test Step 2530 Finished\n",
      "2018-08-29 09:18:32.532616 Test Step 2530 \"min loss\" =  15.1211405\n",
      "2018-08-29 09:18:32.532914 Test Step 2530 \"loss\" =  16.156557\n",
      "2018-08-29 09:18:32.578573 Training Step 2530 Finished Timing (Training: 0.907683, Test: 0.0831917) after 0.248199 seconds\n",
      "2018-08-29 09:18:32.578752 Training Step 2530 \"min loss\" =  2.9983435\n",
      "2018-08-29 09:18:32.579394 Training Step 2530 \"loss\" =  3.0640028\n",
      "2018-08-29 09:18:32.781089 Test Step 2535 Finished\n",
      "2018-08-29 09:18:32.781212 Test Step 2535 \"min loss\" =  15.1211405\n",
      "2018-08-29 09:18:32.781273 Test Step 2535 \"loss\" =  16.108303\n",
      "2018-08-29 09:18:32.827517 Training Step 2535 Finished Timing (Training: 0.907316, Test: 0.0831246) after 0.247316 seconds\n",
      "2018-08-29 09:18:32.827643 Training Step 2535 \"min loss\" =  2.9983435\n",
      "2018-08-29 09:18:32.827708 Training Step 2535 \"loss\" =  3.2244136\n",
      "2018-08-29 09:18:33.029810 Test Step 2540 Finished\n",
      "2018-08-29 09:18:33.030548 Test Step 2540 \"min loss\" =  15.1211405\n",
      "2018-08-29 09:18:33.030650 Test Step 2540 \"loss\" =  15.895459\n",
      "2018-08-29 09:18:33.076528 Training Step 2540 Finished Timing (Training: 0.907889, Test: 0.0831256) after 0.248732 seconds\n",
      "2018-08-29 09:18:33.076756 Training Step 2540 \"min loss\" =  2.9983435\n",
      "2018-08-29 09:18:33.077459 Training Step 2540 \"loss\" =  3.3860614\n",
      "2018-08-29 09:18:33.278855 Test Step 2545 Finished\n",
      "2018-08-29 09:18:33.279579 Test Step 2545 \"min loss\" =  15.1211405\n",
      "2018-08-29 09:18:33.279649 Test Step 2545 \"loss\" =  16.112335\n",
      "2018-08-29 09:18:33.324695 Training Step 2545 Finished Timing (Training: 0.907841, Test: 0.0831463) after 0.246803 seconds\n",
      "2018-08-29 09:18:33.324822 Training Step 2545 \"min loss\" =  2.9983435\n",
      "2018-08-29 09:18:33.324882 Training Step 2545 \"loss\" =  3.3237503\n",
      "2018-08-29 09:18:33.526660 Test Step 2550 Finished\n",
      "2018-08-29 09:18:33.527178 Test Step 2550 \"min loss\" =  15.1211405\n",
      "2018-08-29 09:18:33.527487 Test Step 2550 \"loss\" =  15.7702\n",
      "2018-08-29 09:18:33.572811 Training Step 2550 Finished Timing (Training: 0.907821, Test: 0.083139) after 0.246753 seconds\n",
      "2018-08-29 09:18:33.572968 Training Step 2550 \"min loss\" =  2.9983435\n",
      "2018-08-29 09:18:33.573453 Training Step 2550 \"loss\" =  3.4877608\n",
      "2018-08-29 09:18:33.775388 Test Step 2555 Finished\n",
      "2018-08-29 09:18:33.775512 Test Step 2555 \"min loss\" =  15.1211405\n",
      "2018-08-29 09:18:33.776362 Test Step 2555 \"loss\" =  16.36958\n",
      "2018-08-29 09:18:33.821919 Training Step 2555 Finished Timing (Training: 0.907613, Test: 0.0834908) after 0.248378 seconds\n",
      "2018-08-29 09:18:33.822068 Training Step 2555 \"min loss\" =  2.9983435\n",
      "2018-08-29 09:18:33.822134 Training Step 2555 \"loss\" =  3.2943008\n",
      "2018-08-29 09:18:34.023984 Test Step 2560 Finished\n",
      "2018-08-29 09:18:34.024187 Test Step 2560 \"min loss\" =  15.1211405\n",
      "2018-08-29 09:18:34.025425 Test Step 2560 \"loss\" =  15.944592\n",
      "2018-08-29 09:18:34.070444 Training Step 2560 Finished Timing (Training: 0.907432, Test: 0.0835528) after 0.247534 seconds\n",
      "2018-08-29 09:18:34.070572 Training Step 2560 \"min loss\" =  2.9983435\n",
      "2018-08-29 09:18:34.071175 Training Step 2560 \"loss\" =  3.1755226\n",
      "2018-08-29 09:18:34.272676 Test Step 2565 Finished\n",
      "2018-08-29 09:18:34.272812 Test Step 2565 \"min loss\" =  15.1211405\n",
      "2018-08-29 09:18:34.273678 Test Step 2565 \"loss\" =  15.840584\n",
      "2018-08-29 09:18:34.319698 Training Step 2565 Finished Timing (Training: 0.907354, Test: 0.0835861) after 0.248374 seconds\n",
      "2018-08-29 09:18:34.319832 Training Step 2565 \"min loss\" =  2.9983435\n",
      "2018-08-29 09:18:34.320687 Training Step 2565 \"loss\" =  3.4357061\n",
      "2018-08-29 09:18:34.522192 Test Step 2570 Finished\n",
      "2018-08-29 09:18:34.522776 Test Step 2570 \"min loss\" =  15.1211405\n",
      "2018-08-29 09:18:34.523143 Test Step 2570 \"loss\" =  15.485199\n",
      "2018-08-29 09:18:34.568528 Training Step 2570 Finished Timing (Training: 0.907383, Test: 0.0835714) after 0.247712 seconds\n",
      "2018-08-29 09:18:34.568767 Training Step 2570 \"min loss\" =  2.9983435\n",
      "2018-08-29 09:18:34.568889 Training Step 2570 \"loss\" =  3.4844368\n",
      "2018-08-29 09:18:34.771210 Test Step 2575 Finished\n",
      "2018-08-29 09:18:34.771413 Test Step 2575 \"min loss\" =  15.1211405\n",
      "2018-08-29 09:18:34.771487 Test Step 2575 \"loss\" =  15.19941\n",
      "2018-08-29 09:18:34.817556 Training Step 2575 Finished Timing (Training: 0.907629, Test: 0.0835674) after 0.248093 seconds\n",
      "2018-08-29 09:18:34.817699 Training Step 2575 \"min loss\" =  2.9983435\n",
      "2018-08-29 09:18:34.817771 Training Step 2575 \"loss\" =  3.379731\n",
      "2018-08-29 09:18:35.020527 Test Step 2580 Finished\n",
      "2018-08-29 09:18:35.021084 Test Step 2580 \"min loss\" =  15.1211405\n",
      "2018-08-29 09:18:35.021333 Test Step 2580 \"loss\" =  15.444418\n",
      "2018-08-29 09:18:35.066490 Training Step 2580 Finished Timing (Training: 0.907877, Test: 0.0835627) after 0.248629 seconds\n",
      "2018-08-29 09:18:35.066694 Training Step 2580 \"min loss\" =  2.9983435\n",
      "2018-08-29 09:18:35.066827 Training Step 2580 \"loss\" =  3.5848627\n",
      "2018-08-29 09:18:35.268880 Test Step 2585 Finished\n",
      "2018-08-29 09:18:35.269034 Test Step 2585 \"min loss\" =  15.1211405\n",
      "2018-08-29 09:18:35.269740 Test Step 2585 \"loss\" =  15.958026\n",
      "2018-08-29 09:18:35.315356 Training Step 2585 Finished Timing (Training: 0.908074, Test: 0.0835112) after 0.24842 seconds\n",
      "2018-08-29 09:18:35.315510 Training Step 2585 \"min loss\" =  2.9983435\n",
      "2018-08-29 09:18:35.316029 Training Step 2585 \"loss\" =  3.1882675\n",
      "2018-08-29 09:18:35.517998 Test Step 2590 Finished\n",
      "2018-08-29 09:18:35.518145 Test Step 2590 \"min loss\" =  15.1211405\n",
      "2018-08-29 09:18:35.519022 Test Step 2590 \"loss\" =  16.439112\n",
      "2018-08-29 09:18:35.564975 Training Step 2590 Finished Timing (Training: 0.908161, Test: 0.0834704) after 0.248864 seconds\n",
      "2018-08-29 09:18:35.565118 Training Step 2590 \"min loss\" =  2.9830575\n",
      "2018-08-29 09:18:35.565185 Training Step 2590 \"loss\" =  3.5259726\n",
      "2018-08-29 09:18:35.766540 Test Step 2595 Finished\n",
      "2018-08-29 09:18:35.766692 Test Step 2595 \"min loss\" =  15.1211405\n",
      "2018-08-29 09:18:35.766767 Test Step 2595 \"loss\" =  16.206877\n",
      "2018-08-29 09:18:35.811942 Training Step 2595 Finished Timing (Training: 0.908452, Test: 0.0834789) after 0.246669 seconds\n",
      "2018-08-29 09:18:35.812143 Training Step 2595 \"min loss\" =  2.9830575\n",
      "2018-08-29 09:18:35.812282 Training Step 2595 \"loss\" =  3.3879254\n",
      "2018-08-29 09:18:36.014192 Test Step 2600 Finished\n",
      "2018-08-29 09:18:36.014864 Test Step 2600 \"min loss\" =  15.1211405\n",
      "2018-08-29 09:18:36.014966 Test Step 2600 \"loss\" =  15.892834\n",
      "2018-08-29 09:18:36.060827 Training Step 2600 Finished Timing (Training: 0.9085, Test: 0.0835531) after 0.248397 seconds\n",
      "2018-08-29 09:18:36.061349 Training Step 2600 \"min loss\" =  2.9830575\n",
      "2018-08-29 09:18:36.061422 Training Step 2600 \"loss\" =  3.075228\n",
      "2018-08-29 09:18:36.263089 Test Step 2605 Finished\n",
      "2018-08-29 09:18:36.263778 Test Step 2605 \"min loss\" =  15.1211405\n",
      "2018-08-29 09:18:36.264027 Test Step 2605 \"loss\" =  16.588537\n",
      "2018-08-29 09:18:36.309183 Training Step 2605 Finished Timing (Training: 0.912076, Test: 0.0836637) after 0.247669 seconds\n",
      "2018-08-29 09:18:36.309342 Training Step 2605 \"min loss\" =  2.9830575\n",
      "2018-08-29 09:18:36.309426 Training Step 2605 \"loss\" =  3.336087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:18:36.511982 Test Step 2610 Finished\n",
      "2018-08-29 09:18:36.512116 Test Step 2610 \"min loss\" =  15.1211405\n",
      "2018-08-29 09:18:36.513046 Test Step 2610 \"loss\" =  16.103699\n",
      "2018-08-29 09:18:36.558256 Training Step 2610 Finished Timing (Training: 0.90932, Test: 0.083469) after 0.24776 seconds\n",
      "2018-08-29 09:18:36.558394 Training Step 2610 \"min loss\" =  2.9830575\n",
      "2018-08-29 09:18:36.559046 Training Step 2610 \"loss\" =  3.6508517\n",
      "2018-08-29 09:18:36.760549 Test Step 2615 Finished\n",
      "2018-08-29 09:18:36.760728 Test Step 2615 \"min loss\" =  15.1211405\n",
      "2018-08-29 09:18:36.760800 Test Step 2615 \"loss\" =  16.765633\n",
      "2018-08-29 09:18:36.806919 Training Step 2615 Finished Timing (Training: 0.909412, Test: 0.0834527) after 0.247292 seconds\n",
      "2018-08-29 09:18:36.807053 Training Step 2615 \"min loss\" =  2.9830575\n",
      "2018-08-29 09:18:36.807119 Training Step 2615 \"loss\" =  3.290182\n",
      "2018-08-29 09:18:37.009512 Test Step 2620 Finished\n",
      "2018-08-29 09:18:37.010116 Test Step 2620 \"min loss\" =  15.1211405\n",
      "2018-08-29 09:18:37.010186 Test Step 2620 \"loss\" =  15.697497\n",
      "2018-08-29 09:18:37.055403 Training Step 2620 Finished Timing (Training: 0.909184, Test: 0.0835185) after 0.247348 seconds\n",
      "2018-08-29 09:18:37.056042 Training Step 2620 \"min loss\" =  2.918257\n",
      "2018-08-29 09:18:37.056123 Training Step 2620 \"loss\" =  2.918257\n",
      "2018-08-29 09:18:37.258891 Test Step 2625 Finished\n",
      "2018-08-29 09:18:37.259596 Test Step 2625 \"min loss\" =  15.1211405\n",
      "2018-08-29 09:18:37.259728 Test Step 2625 \"loss\" =  15.489871\n",
      "2018-08-29 09:18:37.306456 Training Step 2625 Finished Timing (Training: 0.908204, Test: 0.0834745) after 0.249285 seconds\n",
      "2018-08-29 09:18:37.306958 Training Step 2625 \"min loss\" =  2.918257\n",
      "2018-08-29 09:18:37.307035 Training Step 2625 \"loss\" =  3.4238284\n",
      "2018-08-29 09:18:37.508081 Test Step 2630 Finished\n",
      "2018-08-29 09:18:37.508213 Test Step 2630 \"min loss\" =  15.1211405\n",
      "2018-08-29 09:18:37.508276 Test Step 2630 \"loss\" =  17.058876\n",
      "2018-08-29 09:18:37.554447 Training Step 2630 Finished Timing (Training: 0.908508, Test: 0.0833423) after 0.247322 seconds\n",
      "2018-08-29 09:18:37.554594 Training Step 2630 \"min loss\" =  2.918257\n",
      "2018-08-29 09:18:37.555285 Training Step 2630 \"loss\" =  3.5757577\n",
      "2018-08-29 09:18:37.756757 Test Step 2635 Finished\n",
      "2018-08-29 09:18:37.756964 Test Step 2635 \"min loss\" =  15.1211405\n",
      "2018-08-29 09:18:37.757035 Test Step 2635 \"loss\" =  16.261581\n",
      "2018-08-29 09:18:37.803635 Training Step 2635 Finished Timing (Training: 0.908758, Test: 0.083484) after 0.248242 seconds\n",
      "2018-08-29 09:18:37.803853 Training Step 2635 \"min loss\" =  2.918257\n",
      "2018-08-29 09:18:37.804526 Training Step 2635 \"loss\" =  3.0570781\n",
      "2018-08-29 09:18:38.006179 Test Step 2640 Finished\n",
      "2018-08-29 09:18:38.006382 Test Step 2640 \"min loss\" =  15.1211405\n",
      "2018-08-29 09:18:38.006506 Test Step 2640 \"loss\" =  15.207115\n",
      "2018-08-29 09:18:38.053226 Training Step 2640 Finished Timing (Training: 0.90873, Test: 0.0834193) after 0.248528 seconds\n",
      "2018-08-29 09:18:38.053381 Training Step 2640 \"min loss\" =  2.918257\n",
      "2018-08-29 09:18:38.054077 Training Step 2640 \"loss\" =  3.2957327\n",
      "2018-08-29 09:18:38.256419 Test Step 2645 Finished\n",
      "2018-08-29 09:18:38.256594 Test Step 2645 \"min loss\" =  15.1211405\n",
      "2018-08-29 09:18:38.256707 Test Step 2645 \"loss\" =  16.981953\n",
      "2018-08-29 09:18:38.303264 Training Step 2645 Finished Timing (Training: 0.908759, Test: 0.0833592) after 0.248405 seconds\n",
      "2018-08-29 09:18:38.303429 Training Step 2645 \"min loss\" =  2.8128088\n",
      "2018-08-29 09:18:38.303501 Training Step 2645 \"loss\" =  3.1944404\n",
      "2018-08-29 09:18:38.504935 Test Step 2650 Finished\n",
      "2018-08-29 09:18:38.505404 Test Step 2650 \"min loss\" =  15.1211405\n",
      "2018-08-29 09:18:38.505480 Test Step 2650 \"loss\" =  16.785465\n",
      "2018-08-29 09:18:38.551606 Training Step 2650 Finished Timing (Training: 0.908657, Test: 0.0834923) after 0.248021 seconds\n",
      "2018-08-29 09:18:38.552069 Training Step 2650 \"min loss\" =  2.8128088\n",
      "2018-08-29 09:18:38.552147 Training Step 2650 \"loss\" =  3.527465\n",
      "2018-08-29 09:18:38.754252 Test Step 2655 Finished\n",
      "2018-08-29 09:18:38.754394 Test Step 2655 \"min loss\" =  15.1211405\n",
      "2018-08-29 09:18:38.754456 Test Step 2655 \"loss\" =  16.666582\n",
      "2018-08-29 09:18:38.801121 Training Step 2655 Finished Timing (Training: 0.90839, Test: 0.0834) after 0.248192 seconds\n",
      "2018-08-29 09:18:38.801532 Training Step 2655 \"min loss\" =  2.8128088\n",
      "2018-08-29 09:18:38.801850 Training Step 2655 \"loss\" =  3.4471292\n",
      "2018-08-29 09:18:39.003332 Test Step 2660 Finished\n",
      "2018-08-29 09:18:39.004054 Test Step 2660 \"min loss\" =  15.1211405\n",
      "2018-08-29 09:18:39.004665 Test Step 2660 \"loss\" =  15.525836\n",
      "2018-08-29 09:18:39.050438 Training Step 2660 Finished Timing (Training: 0.908251, Test: 0.0833819) after 0.248307 seconds\n",
      "2018-08-29 09:18:39.050599 Training Step 2660 \"min loss\" =  2.8128088\n",
      "2018-08-29 09:18:39.050687 Training Step 2660 \"loss\" =  3.2621686\n",
      "2018-08-29 09:18:39.253724 Test Step 2665 Finished\n",
      "2018-08-29 09:18:39.253924 Test Step 2665 \"min loss\" =  14.987309\n",
      "2018-08-29 09:18:39.253999 Test Step 2665 \"loss\" =  14.987309\n",
      "2018-08-29 09:18:39.300268 Training Step 2665 Finished Timing (Training: 0.908707, Test: 0.0833292) after 0.249441 seconds\n",
      "2018-08-29 09:18:39.300491 Training Step 2665 \"min loss\" =  2.8128088\n",
      "2018-08-29 09:18:39.301283 Training Step 2665 \"loss\" =  3.2804253\n",
      "2018-08-29 09:18:39.503051 Test Step 2670 Finished\n",
      "2018-08-29 09:18:39.503201 Test Step 2670 \"min loss\" =  14.987309\n",
      "2018-08-29 09:18:39.503269 Test Step 2670 \"loss\" =  15.344961\n",
      "2018-08-29 09:18:39.548320 Training Step 2670 Finished Timing (Training: 0.908745, Test: 0.0834276) after 0.246902 seconds\n",
      "2018-08-29 09:18:39.548467 Training Step 2670 \"min loss\" =  2.8128088\n",
      "2018-08-29 09:18:39.548536 Training Step 2670 \"loss\" =  3.5256732\n",
      "2018-08-29 09:18:39.750223 Test Step 2675 Finished\n",
      "2018-08-29 09:18:39.750412 Test Step 2675 \"min loss\" =  14.777432\n",
      "2018-08-29 09:18:39.750973 Test Step 2675 \"loss\" =  14.777432\n",
      "2018-08-29 09:18:39.796521 Training Step 2675 Finished Timing (Training: 0.90873, Test: 0.0835698) after 0.247906 seconds\n",
      "2018-08-29 09:18:39.796667 Training Step 2675 \"min loss\" =  2.8128088\n",
      "2018-08-29 09:18:39.796732 Training Step 2675 \"loss\" =  3.2206607\n",
      "2018-08-29 09:18:39.999968 Test Step 2680 Finished\n",
      "2018-08-29 09:18:40.000138 Test Step 2680 \"min loss\" =  14.777432\n",
      "2018-08-29 09:18:40.000868 Test Step 2680 \"loss\" =  15.892724\n",
      "2018-08-29 09:18:40.046737 Training Step 2680 Finished Timing (Training: 0.908816, Test: 0.0836376) after 0.249924 seconds\n",
      "2018-08-29 09:18:40.046897 Training Step 2680 \"min loss\" =  2.8128088\n",
      "2018-08-29 09:18:40.047565 Training Step 2680 \"loss\" =  3.496514\n",
      "2018-08-29 09:18:40.249951 Test Step 2685 Finished\n",
      "2018-08-29 09:18:40.250175 Test Step 2685 \"min loss\" =  14.777432\n",
      "2018-08-29 09:18:40.250284 Test Step 2685 \"loss\" =  16.746464\n",
      "2018-08-29 09:18:40.295714 Training Step 2685 Finished Timing (Training: 0.908766, Test: 0.0836449) after 0.247414 seconds\n",
      "2018-08-29 09:18:40.295915 Training Step 2685 \"min loss\" =  2.7978077\n",
      "2018-08-29 09:18:40.296536 Training Step 2685 \"loss\" =  3.4816444\n",
      "2018-08-29 09:18:40.498974 Test Step 2690 Finished\n",
      "2018-08-29 09:18:40.499495 Test Step 2690 \"min loss\" =  14.777432\n",
      "2018-08-29 09:18:40.499561 Test Step 2690 \"loss\" =  16.897589\n",
      "2018-08-29 09:18:40.545202 Training Step 2690 Finished Timing (Training: 0.90883, Test: 0.083623) after 0.248504 seconds\n",
      "2018-08-29 09:18:40.545386 Training Step 2690 \"min loss\" =  2.7978077\n",
      "2018-08-29 09:18:40.546079 Training Step 2690 \"loss\" =  3.455324\n",
      "2018-08-29 09:18:40.749233 Test Step 2695 Finished\n",
      "2018-08-29 09:18:40.749399 Test Step 2695 \"min loss\" =  14.777432\n",
      "2018-08-29 09:18:40.749470 Test Step 2695 \"loss\" =  15.561116\n",
      "2018-08-29 09:18:40.795522 Training Step 2695 Finished Timing (Training: 0.908616, Test: 0.0836635) after 0.24895 seconds\n",
      "2018-08-29 09:18:40.795669 Training Step 2695 \"min loss\" =  2.7978077\n",
      "2018-08-29 09:18:40.796171 Training Step 2695 \"loss\" =  3.3138022\n",
      "2018-08-29 09:18:40.999166 Test Step 2700 Finished\n",
      "2018-08-29 09:18:40.999319 Test Step 2700 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:41.000097 Test Step 2700 \"loss\" =  14.759122\n",
      "2018-08-29 09:18:41.045388 Training Step 2700 Finished Timing (Training: 0.908569, Test: 0.0836383) after 0.248668 seconds\n",
      "2018-08-29 09:18:41.045516 Training Step 2700 \"min loss\" =  2.7978077\n",
      "2018-08-29 09:18:41.045598 Training Step 2700 \"loss\" =  2.976705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:18:41.246912 Test Step 2705 Finished\n",
      "2018-08-29 09:18:41.247063 Test Step 2705 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:41.247754 Test Step 2705 \"loss\" =  16.509775\n",
      "2018-08-29 09:18:41.293331 Training Step 2705 Finished Timing (Training: 0.911511, Test: 0.0838042) after 0.247638 seconds\n",
      "2018-08-29 09:18:41.293811 Training Step 2705 \"min loss\" =  2.7978077\n",
      "2018-08-29 09:18:41.293881 Training Step 2705 \"loss\" =  3.359636\n",
      "2018-08-29 09:18:41.496305 Test Step 2710 Finished\n",
      "2018-08-29 09:18:41.496556 Test Step 2710 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:41.496665 Test Step 2710 \"loss\" =  15.250388\n",
      "2018-08-29 09:18:41.542415 Training Step 2710 Finished Timing (Training: 0.910035, Test: 0.0835324) after 0.248053 seconds\n",
      "2018-08-29 09:18:41.542591 Training Step 2710 \"min loss\" =  2.7978077\n",
      "2018-08-29 09:18:41.542658 Training Step 2710 \"loss\" =  3.0741875\n",
      "2018-08-29 09:18:41.744067 Test Step 2715 Finished\n",
      "2018-08-29 09:18:41.744238 Test Step 2715 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:41.744839 Test Step 2715 \"loss\" =  14.96444\n",
      "2018-08-29 09:18:41.790753 Training Step 2715 Finished Timing (Training: 0.910659, Test: 0.0834225) after 0.248016 seconds\n",
      "2018-08-29 09:18:41.790914 Training Step 2715 \"min loss\" =  2.7978077\n",
      "2018-08-29 09:18:41.791434 Training Step 2715 \"loss\" =  3.165341\n",
      "2018-08-29 09:18:41.993372 Test Step 2720 Finished\n",
      "2018-08-29 09:18:41.993518 Test Step 2720 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:41.993593 Test Step 2720 \"loss\" =  16.59361\n",
      "2018-08-29 09:18:42.039523 Training Step 2720 Finished Timing (Training: 0.910869, Test: 0.0835814) after 0.248007 seconds\n",
      "2018-08-29 09:18:42.039689 Training Step 2720 \"min loss\" =  2.7978077\n",
      "2018-08-29 09:18:42.040590 Training Step 2720 \"loss\" =  3.110763\n",
      "2018-08-29 09:18:42.241941 Test Step 2725 Finished\n",
      "2018-08-29 09:18:42.242095 Test Step 2725 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:42.243002 Test Step 2725 \"loss\" =  16.10701\n",
      "2018-08-29 09:18:42.288886 Training Step 2725 Finished Timing (Training: 0.909917, Test: 0.0833371) after 0.248159 seconds\n",
      "2018-08-29 09:18:42.289020 Training Step 2725 \"min loss\" =  2.7978077\n",
      "2018-08-29 09:18:42.289091 Training Step 2725 \"loss\" =  2.8866956\n",
      "2018-08-29 09:18:42.492128 Test Step 2730 Finished\n",
      "2018-08-29 09:18:42.492821 Test Step 2730 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:42.493216 Test Step 2730 \"loss\" =  16.825045\n",
      "2018-08-29 09:18:42.538807 Training Step 2730 Finished Timing (Training: 0.908431, Test: 0.0837613) after 0.248313 seconds\n",
      "2018-08-29 09:18:42.539305 Training Step 2730 \"min loss\" =  2.7978077\n",
      "2018-08-29 09:18:42.539905 Training Step 2730 \"loss\" =  3.4192107\n",
      "2018-08-29 09:18:42.741705 Test Step 2735 Finished\n",
      "2018-08-29 09:18:42.741841 Test Step 2735 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:42.741906 Test Step 2735 \"loss\" =  15.860406\n",
      "2018-08-29 09:18:42.788971 Training Step 2735 Finished Timing (Training: 0.907651, Test: 0.0838345) after 0.248658 seconds\n",
      "2018-08-29 09:18:42.789136 Training Step 2735 \"min loss\" =  2.7978077\n",
      "2018-08-29 09:18:42.790055 Training Step 2735 \"loss\" =  3.4592607\n",
      "2018-08-29 09:18:42.993371 Test Step 2740 Finished\n",
      "2018-08-29 09:18:42.993528 Test Step 2740 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:42.993604 Test Step 2740 \"loss\" =  15.173767\n",
      "2018-08-29 09:18:43.039705 Training Step 2740 Finished Timing (Training: 0.907584, Test: 0.0840372) after 0.249257 seconds\n",
      "2018-08-29 09:18:43.039844 Training Step 2740 \"min loss\" =  2.7978077\n",
      "2018-08-29 09:18:43.040830 Training Step 2740 \"loss\" =  3.0850594\n",
      "2018-08-29 09:18:43.242241 Test Step 2745 Finished\n",
      "2018-08-29 09:18:43.242376 Test Step 2745 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:43.242448 Test Step 2745 \"loss\" =  16.026325\n",
      "2018-08-29 09:18:43.287991 Training Step 2745 Finished Timing (Training: 0.90775, Test: 0.0838498) after 0.246485 seconds\n",
      "2018-08-29 09:18:43.288120 Training Step 2745 \"min loss\" =  2.7665315\n",
      "2018-08-29 09:18:43.288211 Training Step 2745 \"loss\" =  2.7665315\n",
      "2018-08-29 09:18:43.490672 Test Step 2750 Finished\n",
      "2018-08-29 09:18:43.490848 Test Step 2750 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:43.490922 Test Step 2750 \"loss\" =  15.596954\n",
      "2018-08-29 09:18:43.537695 Training Step 2750 Finished Timing (Training: 0.908095, Test: 0.0837184) after 0.248509 seconds\n",
      "2018-08-29 09:18:43.538151 Training Step 2750 \"min loss\" =  2.7665315\n",
      "2018-08-29 09:18:43.538223 Training Step 2750 \"loss\" =  3.3347075\n",
      "2018-08-29 09:18:43.741016 Test Step 2755 Finished\n",
      "2018-08-29 09:18:43.741265 Test Step 2755 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:43.741379 Test Step 2755 \"loss\" =  16.198536\n",
      "2018-08-29 09:18:43.786742 Training Step 2755 Finished Timing (Training: 0.908071, Test: 0.0837389) after 0.247533 seconds\n",
      "2018-08-29 09:18:43.787228 Training Step 2755 \"min loss\" =  2.7665315\n",
      "2018-08-29 09:18:43.787437 Training Step 2755 \"loss\" =  3.2944999\n",
      "2018-08-29 09:18:43.988967 Test Step 2760 Finished\n",
      "2018-08-29 09:18:43.989491 Test Step 2760 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:43.989563 Test Step 2760 \"loss\" =  16.380247\n",
      "2018-08-29 09:18:44.035266 Training Step 2760 Finished Timing (Training: 0.908042, Test: 0.0838146) after 0.247345 seconds\n",
      "2018-08-29 09:18:44.035410 Training Step 2760 \"min loss\" =  2.7665315\n",
      "2018-08-29 09:18:44.036162 Training Step 2760 \"loss\" =  3.5206242\n",
      "2018-08-29 09:18:44.236239 Test Step 2765 Finished\n",
      "2018-08-29 09:18:44.236766 Test Step 2765 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:44.236847 Test Step 2765 \"loss\" =  15.373804\n",
      "2018-08-29 09:18:44.282405 Training Step 2765 Finished Timing (Training: 0.908248, Test: 0.0837003) after 0.246146 seconds\n",
      "2018-08-29 09:18:44.282554 Training Step 2765 \"min loss\" =  2.7665315\n",
      "2018-08-29 09:18:44.283327 Training Step 2765 \"loss\" =  2.9590318\n",
      "2018-08-29 09:18:44.485072 Test Step 2770 Finished\n",
      "2018-08-29 09:18:44.485590 Test Step 2770 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:44.485917 Test Step 2770 \"loss\" =  16.021202\n",
      "2018-08-29 09:18:44.531780 Training Step 2770 Finished Timing (Training: 0.908185, Test: 0.0836801) after 0.248349 seconds\n",
      "2018-08-29 09:18:44.531974 Training Step 2770 \"min loss\" =  2.7665315\n",
      "2018-08-29 09:18:44.532097 Training Step 2770 \"loss\" =  3.2283487\n",
      "2018-08-29 09:18:44.733851 Test Step 2775 Finished\n",
      "2018-08-29 09:18:44.733990 Test Step 2775 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:44.734548 Test Step 2775 \"loss\" =  16.085754\n",
      "2018-08-29 09:18:44.780136 Training Step 2775 Finished Timing (Training: 0.908363, Test: 0.0836951) after 0.247907 seconds\n",
      "2018-08-29 09:18:44.780269 Training Step 2775 \"min loss\" =  2.7662406\n",
      "2018-08-29 09:18:44.780824 Training Step 2775 \"loss\" =  2.7662406\n",
      "2018-08-29 09:18:44.981795 Test Step 2780 Finished\n",
      "2018-08-29 09:18:44.981928 Test Step 2780 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:44.982659 Test Step 2780 \"loss\" =  16.941578\n",
      "2018-08-29 09:18:45.028417 Training Step 2780 Finished Timing (Training: 0.908368, Test: 0.0836331) after 0.247301 seconds\n",
      "2018-08-29 09:18:45.028583 Training Step 2780 \"min loss\" =  2.7662406\n",
      "2018-08-29 09:18:45.028701 Training Step 2780 \"loss\" =  3.1316438\n",
      "2018-08-29 09:18:45.231853 Test Step 2785 Finished\n",
      "2018-08-29 09:18:45.232059 Test Step 2785 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:45.232180 Test Step 2785 \"loss\" =  15.604446\n",
      "2018-08-29 09:18:45.278405 Training Step 2785 Finished Timing (Training: 0.90841, Test: 0.0836226) after 0.248609 seconds\n",
      "2018-08-29 09:18:45.278622 Training Step 2785 \"min loss\" =  2.7662406\n",
      "2018-08-29 09:18:45.278753 Training Step 2785 \"loss\" =  3.4070518\n",
      "2018-08-29 09:18:45.481507 Test Step 2790 Finished\n",
      "2018-08-29 09:18:45.482173 Test Step 2790 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:45.482479 Test Step 2790 \"loss\" =  15.3602705\n",
      "2018-08-29 09:18:45.527709 Training Step 2790 Finished Timing (Training: 0.908531, Test: 0.0835875) after 0.248818 seconds\n",
      "2018-08-29 09:18:45.527864 Training Step 2790 \"min loss\" =  2.7662406\n",
      "2018-08-29 09:18:45.527933 Training Step 2790 \"loss\" =  3.0825572\n",
      "2018-08-29 09:18:45.730237 Test Step 2795 Finished\n",
      "2018-08-29 09:18:45.730425 Test Step 2795 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:45.730546 Test Step 2795 \"loss\" =  15.394921\n",
      "2018-08-29 09:18:45.776366 Training Step 2795 Finished Timing (Training: 0.908558, Test: 0.0836261) after 0.247475 seconds\n",
      "2018-08-29 09:18:45.776554 Training Step 2795 \"min loss\" =  2.7662406\n",
      "2018-08-29 09:18:45.776734 Training Step 2795 \"loss\" =  3.2334564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:18:45.979742 Test Step 2800 Finished\n",
      "2018-08-29 09:18:45.979902 Test Step 2800 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:45.980593 Test Step 2800 \"loss\" =  15.80858\n",
      "2018-08-29 09:18:46.026075 Training Step 2800 Finished Timing (Training: 0.908598, Test: 0.0835994) after 0.249171 seconds\n",
      "2018-08-29 09:18:46.026241 Training Step 2800 \"min loss\" =  2.7662406\n",
      "2018-08-29 09:18:46.026934 Training Step 2800 \"loss\" =  3.046973\n",
      "2018-08-29 09:18:46.228570 Test Step 2805 Finished\n",
      "2018-08-29 09:18:46.228743 Test Step 2805 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:46.229652 Test Step 2805 \"loss\" =  15.497961\n",
      "2018-08-29 09:18:46.274852 Training Step 2805 Finished Timing (Training: 0.911401, Test: 0.083712) after 0.247688 seconds\n",
      "2018-08-29 09:18:46.274993 Training Step 2805 \"min loss\" =  2.7662406\n",
      "2018-08-29 09:18:46.275059 Training Step 2805 \"loss\" =  2.8841865\n",
      "2018-08-29 09:18:46.477458 Test Step 2810 Finished\n",
      "2018-08-29 09:18:46.478014 Test Step 2810 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:46.478127 Test Step 2810 \"loss\" =  15.876051\n",
      "2018-08-29 09:18:46.523859 Training Step 2810 Finished Timing (Training: 0.90859, Test: 0.0837128) after 0.247858 seconds\n",
      "2018-08-29 09:18:46.524409 Training Step 2810 \"min loss\" =  2.7662406\n",
      "2018-08-29 09:18:46.524789 Training Step 2810 \"loss\" =  2.935991\n",
      "2018-08-29 09:18:46.726925 Test Step 2815 Finished\n",
      "2018-08-29 09:18:46.727075 Test Step 2815 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:46.727146 Test Step 2815 \"loss\" =  16.200432\n",
      "2018-08-29 09:18:46.772420 Training Step 2815 Finished Timing (Training: 0.908447, Test: 0.0838961) after 0.247023 seconds\n",
      "2018-08-29 09:18:46.772576 Training Step 2815 \"min loss\" =  2.7662406\n",
      "2018-08-29 09:18:46.773056 Training Step 2815 \"loss\" =  3.278569\n",
      "2018-08-29 09:18:46.974912 Test Step 2820 Finished\n",
      "2018-08-29 09:18:46.975071 Test Step 2820 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:46.975139 Test Step 2820 \"loss\" =  15.805816\n",
      "2018-08-29 09:18:47.021489 Training Step 2820 Finished Timing (Training: 0.908533, Test: 0.0838756) after 0.248353 seconds\n",
      "2018-08-29 09:18:47.021637 Training Step 2820 \"min loss\" =  2.7662406\n",
      "2018-08-29 09:18:47.021703 Training Step 2820 \"loss\" =  2.9095\n",
      "2018-08-29 09:18:47.224770 Test Step 2825 Finished\n",
      "2018-08-29 09:18:47.224915 Test Step 2825 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:47.225699 Test Step 2825 \"loss\" =  15.409586\n",
      "2018-08-29 09:18:47.271893 Training Step 2825 Finished Timing (Training: 0.908545, Test: 0.0836913) after 0.249344 seconds\n",
      "2018-08-29 09:18:47.272023 Training Step 2825 \"min loss\" =  2.7223103\n",
      "2018-08-29 09:18:47.273112 Training Step 2825 \"loss\" =  2.9953382\n",
      "2018-08-29 09:18:47.474547 Test Step 2830 Finished\n",
      "2018-08-29 09:18:47.474724 Test Step 2830 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:47.474801 Test Step 2830 \"loss\" =  14.879899\n",
      "2018-08-29 09:18:47.521355 Training Step 2830 Finished Timing (Training: 0.908562, Test: 0.0836139) after 0.247815 seconds\n",
      "2018-08-29 09:18:47.521548 Training Step 2830 \"min loss\" =  2.7223103\n",
      "2018-08-29 09:18:47.521670 Training Step 2830 \"loss\" =  3.1824775\n",
      "2018-08-29 09:18:47.724896 Test Step 2835 Finished\n",
      "2018-08-29 09:18:47.725046 Test Step 2835 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:47.725625 Test Step 2835 \"loss\" =  16.279875\n",
      "2018-08-29 09:18:47.771227 Training Step 2835 Finished Timing (Training: 0.908507, Test: 0.0835255) after 0.248521 seconds\n",
      "2018-08-29 09:18:47.771371 Training Step 2835 \"min loss\" =  2.7223103\n",
      "2018-08-29 09:18:47.771906 Training Step 2835 \"loss\" =  2.8794258\n",
      "2018-08-29 09:18:47.974069 Test Step 2840 Finished\n",
      "2018-08-29 09:18:47.974198 Test Step 2840 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:47.974970 Test Step 2840 \"loss\" =  16.176785\n",
      "2018-08-29 09:18:48.020401 Training Step 2840 Finished Timing (Training: 0.908391, Test: 0.0835294) after 0.247991 seconds\n",
      "2018-08-29 09:18:48.020966 Training Step 2840 \"min loss\" =  2.718061\n",
      "2018-08-29 09:18:48.021088 Training Step 2840 \"loss\" =  2.718061\n",
      "2018-08-29 09:18:48.224075 Test Step 2845 Finished\n",
      "2018-08-29 09:18:48.224275 Test Step 2845 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:48.224385 Test Step 2845 \"loss\" =  15.469339\n",
      "2018-08-29 09:18:48.269839 Training Step 2845 Finished Timing (Training: 0.908812, Test: 0.0834321) after 0.248617 seconds\n",
      "2018-08-29 09:18:48.270034 Training Step 2845 \"min loss\" =  2.718061\n",
      "2018-08-29 09:18:48.270652 Training Step 2845 \"loss\" =  3.0630856\n",
      "2018-08-29 09:18:48.472436 Test Step 2850 Finished\n",
      "2018-08-29 09:18:48.472927 Test Step 2850 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:48.473256 Test Step 2850 \"loss\" =  16.333595\n",
      "2018-08-29 09:18:48.518813 Training Step 2850 Finished Timing (Training: 0.908772, Test: 0.083367) after 0.247724 seconds\n",
      "2018-08-29 09:18:48.518937 Training Step 2850 \"min loss\" =  2.718061\n",
      "2018-08-29 09:18:48.519004 Training Step 2850 \"loss\" =  3.064095\n",
      "2018-08-29 09:18:48.721660 Test Step 2855 Finished\n",
      "2018-08-29 09:18:48.721841 Test Step 2855 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:48.721912 Test Step 2855 \"loss\" =  14.984157\n",
      "2018-08-29 09:18:48.768290 Training Step 2855 Finished Timing (Training: 0.908584, Test: 0.0833363) after 0.248535 seconds\n",
      "2018-08-29 09:18:48.768456 Training Step 2855 \"min loss\" =  2.718061\n",
      "2018-08-29 09:18:48.768521 Training Step 2855 \"loss\" =  2.9784458\n",
      "2018-08-29 09:18:48.970767 Test Step 2860 Finished\n",
      "2018-08-29 09:18:48.970913 Test Step 2860 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:48.970982 Test Step 2860 \"loss\" =  15.237385\n",
      "2018-08-29 09:18:49.017360 Training Step 2860 Finished Timing (Training: 0.909074, Test: 0.0833002) after 0.248761 seconds\n",
      "2018-08-29 09:18:49.017530 Training Step 2860 \"min loss\" =  2.718061\n",
      "2018-08-29 09:18:49.018033 Training Step 2860 \"loss\" =  3.134246\n",
      "2018-08-29 09:18:49.219302 Test Step 2865 Finished\n",
      "2018-08-29 09:18:49.219459 Test Step 2865 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:49.219542 Test Step 2865 \"loss\" =  15.601933\n",
      "2018-08-29 09:18:49.265238 Training Step 2865 Finished Timing (Training: 0.909331, Test: 0.0832829) after 0.247125 seconds\n",
      "2018-08-29 09:18:49.265715 Training Step 2865 \"min loss\" =  2.718061\n",
      "2018-08-29 09:18:49.265967 Training Step 2865 \"loss\" =  2.880926\n",
      "2018-08-29 09:18:49.467391 Test Step 2870 Finished\n",
      "2018-08-29 09:18:49.467998 Test Step 2870 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:49.468074 Test Step 2870 \"loss\" =  15.184093\n",
      "2018-08-29 09:18:49.513838 Training Step 2870 Finished Timing (Training: 0.909215, Test: 0.0832676) after 0.247788 seconds\n",
      "2018-08-29 09:18:49.513984 Training Step 2870 \"min loss\" =  2.718061\n",
      "2018-08-29 09:18:49.514063 Training Step 2870 \"loss\" =  2.9858766\n",
      "2018-08-29 09:18:49.717826 Test Step 2875 Finished\n",
      "2018-08-29 09:18:49.717961 Test Step 2875 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:49.718027 Test Step 2875 \"loss\" =  16.048878\n",
      "2018-08-29 09:18:49.764042 Training Step 2875 Finished Timing (Training: 0.909046, Test: 0.0833449) after 0.248309 seconds\n",
      "2018-08-29 09:18:49.764175 Training Step 2875 \"min loss\" =  2.718061\n",
      "2018-08-29 09:18:49.764542 Training Step 2875 \"loss\" =  3.1648357\n",
      "2018-08-29 09:18:49.965720 Test Step 2880 Finished\n",
      "2018-08-29 09:18:49.965905 Test Step 2880 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:49.965975 Test Step 2880 \"loss\" =  15.557729\n",
      "2018-08-29 09:18:50.010937 Training Step 2880 Finished Timing (Training: 0.90928, Test: 0.083343) after 0.246307 seconds\n",
      "2018-08-29 09:18:50.011068 Training Step 2880 \"min loss\" =  2.718061\n",
      "2018-08-29 09:18:50.011751 Training Step 2880 \"loss\" =  2.8605354\n",
      "2018-08-29 09:18:50.212988 Test Step 2885 Finished\n",
      "2018-08-29 09:18:50.213572 Test Step 2885 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:50.213685 Test Step 2885 \"loss\" =  17.023443\n",
      "2018-08-29 09:18:50.259271 Training Step 2885 Finished Timing (Training: 0.90916, Test: 0.0833848) after 0.247431 seconds\n",
      "2018-08-29 09:18:50.259410 Training Step 2885 \"min loss\" =  2.718061\n",
      "2018-08-29 09:18:50.260028 Training Step 2885 \"loss\" =  3.217877\n",
      "2018-08-29 09:18:50.460812 Test Step 2890 Finished\n",
      "2018-08-29 09:18:50.460946 Test Step 2890 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:50.461518 Test Step 2890 \"loss\" =  15.840645\n",
      "2018-08-29 09:18:50.507044 Training Step 2890 Finished Timing (Training: 0.909187, Test: 0.083355) after 0.246778 seconds\n",
      "2018-08-29 09:18:50.507173 Training Step 2890 \"min loss\" =  2.718061\n",
      "2018-08-29 09:18:50.508192 Training Step 2890 \"loss\" =  2.8837755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:18:50.710010 Test Step 2895 Finished\n",
      "2018-08-29 09:18:50.710651 Test Step 2895 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:50.710750 Test Step 2895 \"loss\" =  15.834386\n",
      "2018-08-29 09:18:50.756002 Training Step 2895 Finished Timing (Training: 0.909104, Test: 0.0833198) after 0.247408 seconds\n",
      "2018-08-29 09:18:50.756146 Training Step 2895 \"min loss\" =  2.718061\n",
      "2018-08-29 09:18:50.756226 Training Step 2895 \"loss\" =  3.088166\n",
      "2018-08-29 09:18:50.957644 Test Step 2900 Finished\n",
      "2018-08-29 09:18:50.958287 Test Step 2900 \"min loss\" =  14.759122\n",
      "2018-08-29 09:18:50.958362 Test Step 2900 \"loss\" =  16.037142\n",
      "2018-08-29 09:18:51.004191 Training Step 2900 Finished Timing (Training: 0.909143, Test: 0.0834261) after 0.247873 seconds\n",
      "2018-08-29 09:18:51.004325 Training Step 2900 \"min loss\" =  2.692394\n",
      "2018-08-29 09:18:51.005150 Training Step 2900 \"loss\" =  3.098348\n",
      "2018-08-29 09:18:51.206490 Test Step 2905 Finished\n",
      "2018-08-29 09:18:51.207113 Test Step 2905 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:51.207189 Test Step 2905 \"loss\" =  14.378064\n",
      "2018-08-29 09:18:51.252255 Training Step 2905 Finished Timing (Training: 0.913848, Test: 0.0828925) after 0.247016 seconds\n",
      "2018-08-29 09:18:51.252386 Training Step 2905 \"min loss\" =  2.6894233\n",
      "2018-08-29 09:18:51.253283 Training Step 2905 \"loss\" =  3.0679536\n",
      "2018-08-29 09:18:51.454746 Test Step 2910 Finished\n",
      "2018-08-29 09:18:51.455424 Test Step 2910 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:51.455719 Test Step 2910 \"loss\" =  14.392617\n",
      "2018-08-29 09:18:51.501513 Training Step 2910 Finished Timing (Training: 0.910816, Test: 0.083049) after 0.248118 seconds\n",
      "2018-08-29 09:18:51.501672 Training Step 2910 \"min loss\" =  2.6894233\n",
      "2018-08-29 09:18:51.501738 Training Step 2910 \"loss\" =  3.0079775\n",
      "2018-08-29 09:18:51.704484 Test Step 2915 Finished\n",
      "2018-08-29 09:18:51.704636 Test Step 2915 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:51.705645 Test Step 2915 \"loss\" =  15.174621\n",
      "2018-08-29 09:18:51.750651 Training Step 2915 Finished Timing (Training: 0.910835, Test: 0.0828691) after 0.248833 seconds\n",
      "2018-08-29 09:18:51.751109 Training Step 2915 \"min loss\" =  2.6894233\n",
      "2018-08-29 09:18:51.751177 Training Step 2915 \"loss\" =  3.0437677\n",
      "2018-08-29 09:18:51.952526 Test Step 2920 Finished\n",
      "2018-08-29 09:18:51.952680 Test Step 2920 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:51.953340 Test Step 2920 \"loss\" =  15.601987\n",
      "2018-08-29 09:18:51.998840 Training Step 2920 Finished Timing (Training: 0.910262, Test: 0.0828537) after 0.247155 seconds\n",
      "2018-08-29 09:18:51.998990 Training Step 2920 \"min loss\" =  2.6894233\n",
      "2018-08-29 09:18:51.999679 Training Step 2920 \"loss\" =  2.837867\n",
      "2018-08-29 09:18:52.201335 Test Step 2925 Finished\n",
      "2018-08-29 09:18:52.201498 Test Step 2925 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:52.202673 Test Step 2925 \"loss\" =  15.0185585\n",
      "2018-08-29 09:18:52.248058 Training Step 2925 Finished Timing (Training: 0.90946, Test: 0.0830493) after 0.248296 seconds\n",
      "2018-08-29 09:18:52.248686 Training Step 2925 \"min loss\" =  2.6894233\n",
      "2018-08-29 09:18:52.248947 Training Step 2925 \"loss\" =  2.8981338\n",
      "2018-08-29 09:18:52.450674 Test Step 2930 Finished\n",
      "2018-08-29 09:18:52.450844 Test Step 2930 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:52.451425 Test Step 2930 \"loss\" =  15.511608\n",
      "2018-08-29 09:18:52.496724 Training Step 2930 Finished Timing (Training: 0.909436, Test: 0.0830731) after 0.247675 seconds\n",
      "2018-08-29 09:18:52.496869 Training Step 2930 \"min loss\" =  2.6894233\n",
      "2018-08-29 09:18:52.496937 Training Step 2930 \"loss\" =  2.9053366\n",
      "2018-08-29 09:18:52.697925 Test Step 2935 Finished\n",
      "2018-08-29 09:18:52.698599 Test Step 2935 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:52.698894 Test Step 2935 \"loss\" =  15.480592\n",
      "2018-08-29 09:18:52.744526 Training Step 2935 Finished Timing (Training: 0.909532, Test: 0.0830897) after 0.24751 seconds\n",
      "2018-08-29 09:18:52.744990 Training Step 2935 \"min loss\" =  2.672835\n",
      "2018-08-29 09:18:52.745297 Training Step 2935 \"loss\" =  3.0345364\n",
      "2018-08-29 09:18:52.948114 Test Step 2940 Finished\n",
      "2018-08-29 09:18:52.948310 Test Step 2940 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:52.949523 Test Step 2940 \"loss\" =  15.521502\n",
      "2018-08-29 09:18:52.994698 Training Step 2940 Finished Timing (Training: 0.909272, Test: 0.0830344) after 0.249243 seconds\n",
      "2018-08-29 09:18:52.994846 Training Step 2940 \"min loss\" =  2.672835\n",
      "2018-08-29 09:18:52.995441 Training Step 2940 \"loss\" =  3.476513\n",
      "2018-08-29 09:18:53.197416 Test Step 2945 Finished\n",
      "2018-08-29 09:18:53.197659 Test Step 2945 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:53.198204 Test Step 2945 \"loss\" =  14.543553\n",
      "2018-08-29 09:18:53.244618 Training Step 2945 Finished Timing (Training: 0.909176, Test: 0.0831808) after 0.249064 seconds\n",
      "2018-08-29 09:18:53.244766 Training Step 2945 \"min loss\" =  2.672835\n",
      "2018-08-29 09:18:53.244835 Training Step 2945 \"loss\" =  2.9786217\n",
      "2018-08-29 09:18:53.446714 Test Step 2950 Finished\n",
      "2018-08-29 09:18:53.446896 Test Step 2950 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:53.446988 Test Step 2950 \"loss\" =  15.267655\n",
      "2018-08-29 09:18:53.493401 Training Step 2950 Finished Timing (Training: 0.909301, Test: 0.0831362) after 0.248481 seconds\n",
      "2018-08-29 09:18:53.493549 Training Step 2950 \"min loss\" =  2.672835\n",
      "2018-08-29 09:18:53.493617 Training Step 2950 \"loss\" =  3.119538\n",
      "2018-08-29 09:18:53.697410 Test Step 2955 Finished\n",
      "2018-08-29 09:18:53.698059 Test Step 2955 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:53.698330 Test Step 2955 \"loss\" =  15.444271\n",
      "2018-08-29 09:18:53.743494 Training Step 2955 Finished Timing (Training: 0.9088, Test: 0.083436) after 0.248701 seconds\n",
      "2018-08-29 09:18:53.743620 Training Step 2955 \"min loss\" =  2.672835\n",
      "2018-08-29 09:18:53.744343 Training Step 2955 \"loss\" =  3.1331174\n",
      "2018-08-29 09:18:53.945338 Test Step 2960 Finished\n",
      "2018-08-29 09:18:53.945480 Test Step 2960 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:53.945550 Test Step 2960 \"loss\" =  14.60098\n",
      "2018-08-29 09:18:53.991625 Training Step 2960 Finished Timing (Training: 0.908739, Test: 0.0834538) after 0.247144 seconds\n",
      "2018-08-29 09:18:53.991776 Training Step 2960 \"min loss\" =  2.6595137\n",
      "2018-08-29 09:18:53.992435 Training Step 2960 \"loss\" =  2.6595137\n",
      "2018-08-29 09:18:54.194706 Test Step 2965 Finished\n",
      "2018-08-29 09:18:54.194877 Test Step 2965 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:54.195587 Test Step 2965 \"loss\" =  15.318897\n",
      "2018-08-29 09:18:54.241143 Training Step 2965 Finished Timing (Training: 0.908795, Test: 0.083405) after 0.2486 seconds\n",
      "2018-08-29 09:18:54.241344 Training Step 2965 \"min loss\" =  2.6595137\n",
      "2018-08-29 09:18:54.241449 Training Step 2965 \"loss\" =  2.8410237\n",
      "2018-08-29 09:18:54.443629 Test Step 2970 Finished\n",
      "2018-08-29 09:18:54.444360 Test Step 2970 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:54.444484 Test Step 2970 \"loss\" =  15.887117\n",
      "2018-08-29 09:18:54.489785 Training Step 2970 Finished Timing (Training: 0.908815, Test: 0.083406) after 0.247814 seconds\n",
      "2018-08-29 09:18:54.490315 Training Step 2970 \"min loss\" =  2.6595137\n",
      "2018-08-29 09:18:54.490437 Training Step 2970 \"loss\" =  2.788459\n",
      "2018-08-29 09:18:54.693636 Test Step 2975 Finished\n",
      "2018-08-29 09:18:54.693873 Test Step 2975 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:54.694014 Test Step 2975 \"loss\" =  15.735456\n",
      "2018-08-29 09:18:54.739580 Training Step 2975 Finished Timing (Training: 0.908666, Test: 0.0834833) after 0.24815 seconds\n",
      "2018-08-29 09:18:54.739740 Training Step 2975 \"min loss\" =  2.6595137\n",
      "2018-08-29 09:18:54.740411 Training Step 2975 \"loss\" =  2.9446461\n",
      "2018-08-29 09:18:54.941738 Test Step 2980 Finished\n",
      "2018-08-29 09:18:54.941877 Test Step 2980 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:54.941953 Test Step 2980 \"loss\" =  15.838278\n",
      "2018-08-29 09:18:54.988079 Training Step 2980 Finished Timing (Training: 0.90855, Test: 0.0834448) after 0.247154 seconds\n",
      "2018-08-29 09:18:54.988251 Training Step 2980 \"min loss\" =  2.6595137\n",
      "2018-08-29 09:18:54.988336 Training Step 2980 \"loss\" =  3.1238954\n",
      "2018-08-29 09:18:55.190246 Test Step 2985 Finished\n",
      "2018-08-29 09:18:55.190403 Test Step 2985 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:55.190508 Test Step 2985 \"loss\" =  15.932369\n",
      "2018-08-29 09:18:55.237040 Training Step 2985 Finished Timing (Training: 0.908545, Test: 0.0834436) after 0.248612 seconds\n",
      "2018-08-29 09:18:55.237637 Training Step 2985 \"min loss\" =  2.6595137\n",
      "2018-08-29 09:18:55.237759 Training Step 2985 \"loss\" =  2.8119676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:18:55.441338 Test Step 2990 Finished\n",
      "2018-08-29 09:18:55.441976 Test Step 2990 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:55.442097 Test Step 2990 \"loss\" =  15.69081\n",
      "2018-08-29 09:18:55.487675 Training Step 2990 Finished Timing (Training: 0.908489, Test: 0.083512) after 0.24978 seconds\n",
      "2018-08-29 09:18:55.487842 Training Step 2990 \"min loss\" =  2.6595137\n",
      "2018-08-29 09:18:55.487957 Training Step 2990 \"loss\" =  2.7332287\n",
      "2018-08-29 09:18:55.689879 Test Step 2995 Finished\n",
      "2018-08-29 09:18:55.690061 Test Step 2995 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:55.690129 Test Step 2995 \"loss\" =  14.689369\n",
      "2018-08-29 09:18:55.735282 Training Step 2995 Finished Timing (Training: 0.908664, Test: 0.0835986) after 0.247242 seconds\n",
      "2018-08-29 09:18:55.735430 Training Step 2995 \"min loss\" =  2.6555865\n",
      "2018-08-29 09:18:55.735493 Training Step 2995 \"loss\" =  2.6555865\n",
      "2018-08-29 09:18:55.937912 Test Step 3000 Finished\n",
      "2018-08-29 09:18:55.938071 Test Step 3000 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:55.939160 Test Step 3000 \"loss\" =  14.473232\n",
      "2018-08-29 09:18:55.985083 Training Step 3000 Finished Timing (Training: 0.90865, Test: 0.0836031) after 0.249495 seconds\n",
      "2018-08-29 09:18:55.985283 Training Step 3000 \"min loss\" =  2.6555865\n",
      "2018-08-29 09:18:55.986458 Training Step 3000 \"loss\" =  3.2176566\n",
      "2018-08-29 09:18:56.188487 Test Step 3005 Finished\n",
      "2018-08-29 09:18:56.188659 Test Step 3005 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:56.189756 Test Step 3005 \"loss\" =  14.936037\n",
      "2018-08-29 09:18:56.235516 Training Step 3005 Finished Timing (Training: 0.909506, Test: 0.0831786) after 0.248582 seconds\n",
      "2018-08-29 09:18:56.235661 Training Step 3005 \"min loss\" =  2.6555865\n",
      "2018-08-29 09:18:56.235720 Training Step 3005 \"loss\" =  2.8069222\n",
      "2018-08-29 09:18:56.438998 Test Step 3010 Finished\n",
      "2018-08-29 09:18:56.439196 Test Step 3010 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:56.439930 Test Step 3010 \"loss\" =  14.538867\n",
      "2018-08-29 09:18:56.486309 Training Step 3010 Finished Timing (Training: 0.907964, Test: 0.0831299) after 0.249811 seconds\n",
      "2018-08-29 09:18:56.486470 Training Step 3010 \"min loss\" =  2.6555865\n",
      "2018-08-29 09:18:56.487135 Training Step 3010 \"loss\" =  3.0160942\n",
      "2018-08-29 09:18:56.690417 Test Step 3015 Finished\n",
      "2018-08-29 09:18:56.690902 Test Step 3015 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:56.691208 Test Step 3015 \"loss\" =  14.654831\n",
      "2018-08-29 09:18:56.736873 Training Step 3015 Finished Timing (Training: 0.906985, Test: 0.0832814) after 0.248925 seconds\n",
      "2018-08-29 09:18:56.737004 Training Step 3015 \"min loss\" =  2.5827403\n",
      "2018-08-29 09:18:56.737072 Training Step 3015 \"loss\" =  2.8264544\n",
      "2018-08-29 09:18:56.941431 Test Step 3020 Finished\n",
      "2018-08-29 09:18:56.941568 Test Step 3020 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:56.942100 Test Step 3020 \"loss\" =  15.517052\n",
      "2018-08-29 09:18:56.988467 Training Step 3020 Finished Timing (Training: 0.907585, Test: 0.0836679) after 0.251264 seconds\n",
      "2018-08-29 09:18:56.988661 Training Step 3020 \"min loss\" =  2.5827403\n",
      "2018-08-29 09:18:56.988731 Training Step 3020 \"loss\" =  2.6802652\n",
      "2018-08-29 09:18:57.190794 Test Step 3025 Finished\n",
      "2018-08-29 09:18:57.190962 Test Step 3025 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:57.191539 Test Step 3025 \"loss\" =  14.981468\n",
      "2018-08-29 09:18:57.237230 Training Step 3025 Finished Timing (Training: 0.908274, Test: 0.0837529) after 0.248419 seconds\n",
      "2018-08-29 09:18:57.237371 Training Step 3025 \"min loss\" =  2.5827403\n",
      "2018-08-29 09:18:57.237462 Training Step 3025 \"loss\" =  3.1604936\n",
      "2018-08-29 09:18:57.439535 Test Step 3030 Finished\n",
      "2018-08-29 09:18:57.439726 Test Step 3030 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:57.439847 Test Step 3030 \"loss\" =  14.830103\n",
      "2018-08-29 09:18:57.485907 Training Step 3030 Finished Timing (Training: 0.908421, Test: 0.0840114) after 0.248357 seconds\n",
      "2018-08-29 09:18:57.486063 Training Step 3030 \"min loss\" =  2.5827403\n",
      "2018-08-29 09:18:57.486136 Training Step 3030 \"loss\" =  3.0314076\n",
      "2018-08-29 09:18:57.689498 Test Step 3035 Finished\n",
      "2018-08-29 09:18:57.689676 Test Step 3035 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:57.690305 Test Step 3035 \"loss\" =  15.750071\n",
      "2018-08-29 09:18:57.735664 Training Step 3035 Finished Timing (Training: 0.908658, Test: 0.084126) after 0.249406 seconds\n",
      "2018-08-29 09:18:57.735874 Training Step 3035 \"min loss\" =  2.5761757\n",
      "2018-08-29 09:18:57.736025 Training Step 3035 \"loss\" =  2.772982\n",
      "2018-08-29 09:18:57.938590 Test Step 3040 Finished\n",
      "2018-08-29 09:18:57.938770 Test Step 3040 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:57.939760 Test Step 3040 \"loss\" =  15.102581\n",
      "2018-08-29 09:18:57.985469 Training Step 3040 Finished Timing (Training: 0.908694, Test: 0.084045) after 0.249297 seconds\n",
      "2018-08-29 09:18:57.985620 Training Step 3040 \"min loss\" =  2.5761757\n",
      "2018-08-29 09:18:57.985688 Training Step 3040 \"loss\" =  2.7951286\n",
      "2018-08-29 09:18:58.188988 Test Step 3045 Finished\n",
      "2018-08-29 09:18:58.189732 Test Step 3045 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:58.190352 Test Step 3045 \"loss\" =  14.900684\n",
      "2018-08-29 09:18:58.235999 Training Step 3045 Finished Timing (Training: 0.90874, Test: 0.083866) after 0.250217 seconds\n",
      "2018-08-29 09:18:58.236154 Training Step 3045 \"min loss\" =  2.5761757\n",
      "2018-08-29 09:18:58.237062 Training Step 3045 \"loss\" =  2.9438617\n",
      "2018-08-29 09:18:58.439656 Test Step 3050 Finished\n",
      "2018-08-29 09:18:58.439864 Test Step 3050 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:58.439985 Test Step 3050 \"loss\" =  14.86637\n",
      "2018-08-29 09:18:58.486323 Training Step 3050 Finished Timing (Training: 0.908624, Test: 0.0838286) after 0.248599 seconds\n",
      "2018-08-29 09:18:58.486483 Training Step 3050 \"min loss\" =  2.5761757\n",
      "2018-08-29 09:18:58.486603 Training Step 3050 \"loss\" =  2.7820456\n",
      "2018-08-29 09:18:58.689271 Test Step 3055 Finished\n",
      "2018-08-29 09:18:58.689823 Test Step 3055 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:58.690492 Test Step 3055 \"loss\" =  14.989837\n",
      "2018-08-29 09:18:58.736087 Training Step 3055 Finished Timing (Training: 0.90864, Test: 0.0838414) after 0.249339 seconds\n",
      "2018-08-29 09:18:58.736666 Training Step 3055 \"min loss\" =  2.5761757\n",
      "2018-08-29 09:18:58.737193 Training Step 3055 \"loss\" =  2.9888222\n",
      "2018-08-29 09:18:58.939270 Test Step 3060 Finished\n",
      "2018-08-29 09:18:58.939447 Test Step 3060 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:58.940461 Test Step 3060 \"loss\" =  15.197917\n",
      "2018-08-29 09:18:58.986016 Training Step 3060 Finished Timing (Training: 0.908395, Test: 0.083758) after 0.248417 seconds\n",
      "2018-08-29 09:18:58.986186 Training Step 3060 \"min loss\" =  2.52755\n",
      "2018-08-29 09:18:58.987097 Training Step 3060 \"loss\" =  2.7386034\n",
      "2018-08-29 09:18:59.190131 Test Step 3065 Finished\n",
      "2018-08-29 09:18:59.190290 Test Step 3065 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:59.191432 Test Step 3065 \"loss\" =  16.316729\n",
      "2018-08-29 09:18:59.237215 Training Step 3065 Finished Timing (Training: 0.908145, Test: 0.0836203) after 0.249586 seconds\n",
      "2018-08-29 09:18:59.237722 Training Step 3065 \"min loss\" =  2.52755\n",
      "2018-08-29 09:18:59.238512 Training Step 3065 \"loss\" =  3.1685748\n",
      "2018-08-29 09:18:59.440855 Test Step 3070 Finished\n",
      "2018-08-29 09:18:59.441015 Test Step 3070 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:59.441612 Test Step 3070 \"loss\" =  15.445343\n",
      "2018-08-29 09:18:59.487086 Training Step 3070 Finished Timing (Training: 0.908022, Test: 0.0836702) after 0.248441 seconds\n",
      "2018-08-29 09:18:59.487240 Training Step 3070 \"min loss\" =  2.52755\n",
      "2018-08-29 09:18:59.487954 Training Step 3070 \"loss\" =  2.7148314\n",
      "2018-08-29 09:18:59.689471 Test Step 3075 Finished\n",
      "2018-08-29 09:18:59.690106 Test Step 3075 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:59.690181 Test Step 3075 \"loss\" =  15.840166\n",
      "2018-08-29 09:18:59.736922 Training Step 3075 Finished Timing (Training: 0.908078, Test: 0.0836714) after 0.24881 seconds\n",
      "2018-08-29 09:18:59.737069 Training Step 3075 \"min loss\" =  2.52755\n",
      "2018-08-29 09:18:59.737191 Training Step 3075 \"loss\" =  3.1976426\n",
      "2018-08-29 09:18:59.940851 Test Step 3080 Finished\n",
      "2018-08-29 09:18:59.941024 Test Step 3080 \"min loss\" =  14.378064\n",
      "2018-08-29 09:18:59.941107 Test Step 3080 \"loss\" =  15.48279\n",
      "2018-08-29 09:18:59.987865 Training Step 3080 Finished Timing (Training: 0.908033, Test: 0.0836325) after 0.250585 seconds\n",
      "2018-08-29 09:18:59.988005 Training Step 3080 \"min loss\" =  2.52755\n",
      "2018-08-29 09:18:59.988698 Training Step 3080 \"loss\" =  2.8457658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:19:00.197155 Test Step 3085 Finished\n",
      "2018-08-29 09:19:00.197377 Test Step 3085 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:00.197459 Test Step 3085 \"loss\" =  14.68649\n",
      "2018-08-29 09:19:00.242713 Training Step 3085 Finished Timing (Training: 0.906895, Test: 0.0849508) after 0.253923 seconds\n",
      "2018-08-29 09:19:00.242856 Training Step 3085 \"min loss\" =  2.52755\n",
      "2018-08-29 09:19:00.243709 Training Step 3085 \"loss\" =  2.9824326\n",
      "2018-08-29 09:19:00.445093 Test Step 3090 Finished\n",
      "2018-08-29 09:19:00.445224 Test Step 3090 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:00.445292 Test Step 3090 \"loss\" =  15.359444\n",
      "2018-08-29 09:19:00.490309 Training Step 3090 Finished Timing (Training: 0.907099, Test: 0.0848823) after 0.246499 seconds\n",
      "2018-08-29 09:19:00.490452 Training Step 3090 \"min loss\" =  2.52755\n",
      "2018-08-29 09:19:00.491287 Training Step 3090 \"loss\" =  2.782881\n",
      "2018-08-29 09:19:00.693255 Test Step 3095 Finished\n",
      "2018-08-29 09:19:00.693848 Test Step 3095 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:00.694351 Test Step 3095 \"loss\" =  15.492547\n",
      "2018-08-29 09:19:00.739933 Training Step 3095 Finished Timing (Training: 0.907049, Test: 0.084823) after 0.24836 seconds\n",
      "2018-08-29 09:19:00.740065 Training Step 3095 \"min loss\" =  2.499562\n",
      "2018-08-29 09:19:00.740794 Training Step 3095 \"loss\" =  3.0314348\n",
      "2018-08-29 09:19:00.942228 Test Step 3100 Finished\n",
      "2018-08-29 09:19:00.942361 Test Step 3100 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:00.942428 Test Step 3100 \"loss\" =  15.281128\n",
      "2018-08-29 09:19:00.987543 Training Step 3100 Finished Timing (Training: 0.907228, Test: 0.0847423) after 0.24641 seconds\n",
      "2018-08-29 09:19:00.987676 Training Step 3100 \"min loss\" =  2.499562\n",
      "2018-08-29 09:19:00.988256 Training Step 3100 \"loss\" =  3.0107038\n",
      "2018-08-29 09:19:01.190520 Test Step 3105 Finished\n",
      "2018-08-29 09:19:01.190705 Test Step 3105 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:01.191537 Test Step 3105 \"loss\" =  15.371812\n",
      "2018-08-29 09:19:01.237045 Training Step 3105 Finished Timing (Training: 0.910522, Test: 0.0836771) after 0.248282 seconds\n",
      "2018-08-29 09:19:01.237200 Training Step 3105 \"min loss\" =  2.499562\n",
      "2018-08-29 09:19:01.237270 Training Step 3105 \"loss\" =  2.8413901\n",
      "2018-08-29 09:19:01.439853 Test Step 3110 Finished\n",
      "2018-08-29 09:19:01.440083 Test Step 3110 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:01.441046 Test Step 3110 \"loss\" =  15.645822\n",
      "2018-08-29 09:19:01.486413 Training Step 3110 Finished Timing (Training: 0.90845, Test: 0.0850308) after 0.249065 seconds\n",
      "2018-08-29 09:19:01.486562 Training Step 3110 \"min loss\" =  2.499562\n",
      "2018-08-29 09:19:01.487218 Training Step 3110 \"loss\" =  2.8744078\n",
      "2018-08-29 09:19:01.688306 Test Step 3115 Finished\n",
      "2018-08-29 09:19:01.688459 Test Step 3115 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:01.688608 Test Step 3115 \"loss\" =  14.857948\n",
      "2018-08-29 09:19:01.735004 Training Step 3115 Finished Timing (Training: 0.908822, Test: 0.0844022) after 0.247691 seconds\n",
      "2018-08-29 09:19:01.735147 Training Step 3115 \"min loss\" =  2.499562\n",
      "2018-08-29 09:19:01.735220 Training Step 3115 \"loss\" =  2.7203374\n",
      "2018-08-29 09:19:01.937342 Test Step 3120 Finished\n",
      "2018-08-29 09:19:01.937482 Test Step 3120 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:01.938405 Test Step 3120 \"loss\" =  15.1263895\n",
      "2018-08-29 09:19:01.983533 Training Step 3120 Finished Timing (Training: 0.908422, Test: 0.0843092) after 0.247561 seconds\n",
      "2018-08-29 09:19:01.983689 Training Step 3120 \"min loss\" =  2.499562\n",
      "2018-08-29 09:19:01.983751 Training Step 3120 \"loss\" =  3.019976\n",
      "2018-08-29 09:19:02.186162 Test Step 3125 Finished\n",
      "2018-08-29 09:19:02.186698 Test Step 3125 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:02.187058 Test Step 3125 \"loss\" =  16.662312\n",
      "2018-08-29 09:19:02.232773 Training Step 3125 Finished Timing (Training: 0.908178, Test: 0.0838896) after 0.247967 seconds\n",
      "2018-08-29 09:19:02.232953 Training Step 3125 \"min loss\" =  2.499562\n",
      "2018-08-29 09:19:02.233490 Training Step 3125 \"loss\" =  2.9142992\n",
      "2018-08-29 09:19:02.434748 Test Step 3130 Finished\n",
      "2018-08-29 09:19:02.434908 Test Step 3130 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:02.434981 Test Step 3130 \"loss\" =  15.766515\n",
      "2018-08-29 09:19:02.481017 Training Step 3130 Finished Timing (Training: 0.90831, Test: 0.0843005) after 0.247442 seconds\n",
      "2018-08-29 09:19:02.481167 Training Step 3130 \"min loss\" =  2.499562\n",
      "2018-08-29 09:19:02.481868 Training Step 3130 \"loss\" =  2.8943915\n",
      "2018-08-29 09:19:02.684006 Test Step 3135 Finished\n",
      "2018-08-29 09:19:02.684682 Test Step 3135 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:02.685126 Test Step 3135 \"loss\" =  15.073398\n",
      "2018-08-29 09:19:02.730503 Training Step 3135 Finished Timing (Training: 0.907964, Test: 0.0843945) after 0.248544 seconds\n",
      "2018-08-29 09:19:02.731053 Training Step 3135 \"min loss\" =  2.499562\n",
      "2018-08-29 09:19:02.731124 Training Step 3135 \"loss\" =  3.1013608\n",
      "2018-08-29 09:19:02.933755 Test Step 3140 Finished\n",
      "2018-08-29 09:19:02.933906 Test Step 3140 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:02.933972 Test Step 3140 \"loss\" =  16.079933\n",
      "2018-08-29 09:19:02.979965 Training Step 3140 Finished Timing (Training: 0.908047, Test: 0.0843553) after 0.248755 seconds\n",
      "2018-08-29 09:19:02.980097 Training Step 3140 \"min loss\" =  2.499562\n",
      "2018-08-29 09:19:02.980779 Training Step 3140 \"loss\" =  2.734297\n",
      "2018-08-29 09:19:03.181721 Test Step 3145 Finished\n",
      "2018-08-29 09:19:03.181855 Test Step 3145 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:03.181925 Test Step 3145 \"loss\" =  15.413294\n",
      "2018-08-29 09:19:03.228534 Training Step 3145 Finished Timing (Training: 0.907993, Test: 0.0842133) after 0.247661 seconds\n",
      "2018-08-29 09:19:03.228773 Training Step 3145 \"min loss\" =  2.4403274\n",
      "2018-08-29 09:19:03.228911 Training Step 3145 \"loss\" =  2.6339302\n",
      "2018-08-29 09:19:03.431622 Test Step 3150 Finished\n",
      "2018-08-29 09:19:03.431764 Test Step 3150 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:03.431832 Test Step 3150 \"loss\" =  14.909748\n",
      "2018-08-29 09:19:03.477578 Training Step 3150 Finished Timing (Training: 0.908205, Test: 0.0840556) after 0.248511 seconds\n",
      "2018-08-29 09:19:03.477714 Training Step 3150 \"min loss\" =  2.4278975\n",
      "2018-08-29 09:19:03.478276 Training Step 3150 \"loss\" =  2.7310038\n",
      "2018-08-29 09:19:03.679786 Test Step 3155 Finished\n",
      "2018-08-29 09:19:03.680429 Test Step 3155 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:03.680506 Test Step 3155 \"loss\" =  15.442921\n",
      "2018-08-29 09:19:03.726194 Training Step 3155 Finished Timing (Training: 0.908294, Test: 0.0839669) after 0.247564 seconds\n",
      "2018-08-29 09:19:03.726664 Training Step 3155 \"min loss\" =  2.4278975\n",
      "2018-08-29 09:19:03.726734 Training Step 3155 \"loss\" =  2.9456038\n",
      "2018-08-29 09:19:03.928626 Test Step 3160 Finished\n",
      "2018-08-29 09:19:03.928783 Test Step 3160 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:03.929781 Test Step 3160 \"loss\" =  15.703878\n",
      "2018-08-29 09:19:03.974900 Training Step 3160 Finished Timing (Training: 0.908324, Test: 0.0838057) after 0.247724 seconds\n",
      "2018-08-29 09:19:03.975072 Training Step 3160 \"min loss\" =  2.4278975\n",
      "2018-08-29 09:19:03.975968 Training Step 3160 \"loss\" =  2.657126\n",
      "2018-08-29 09:19:04.177474 Test Step 3165 Finished\n",
      "2018-08-29 09:19:04.178003 Test Step 3165 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:04.178088 Test Step 3165 \"loss\" =  15.488771\n",
      "2018-08-29 09:19:04.224220 Training Step 3165 Finished Timing (Training: 0.908127, Test: 0.0837733) after 0.248134 seconds\n",
      "2018-08-29 09:19:04.224349 Training Step 3165 \"min loss\" =  2.4278975\n",
      "2018-08-29 09:19:04.225191 Training Step 3165 \"loss\" =  3.028773\n",
      "2018-08-29 09:19:04.427264 Test Step 3170 Finished\n",
      "2018-08-29 09:19:04.427411 Test Step 3170 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:04.428090 Test Step 3170 \"loss\" =  14.599215\n",
      "2018-08-29 09:19:04.473799 Training Step 3170 Finished Timing (Training: 0.907874, Test: 0.0836909) after 0.247851 seconds\n",
      "2018-08-29 09:19:04.473937 Training Step 3170 \"min loss\" =  2.3269844\n",
      "2018-08-29 09:19:04.474001 Training Step 3170 \"loss\" =  3.181739\n",
      "2018-08-29 09:19:04.675019 Test Step 3175 Finished\n",
      "2018-08-29 09:19:04.675179 Test Step 3175 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:04.675249 Test Step 3175 \"loss\" =  16.14261\n",
      "2018-08-29 09:19:04.720391 Training Step 3175 Finished Timing (Training: 0.908268, Test: 0.0836751) after 0.246269 seconds\n",
      "2018-08-29 09:19:04.720553 Training Step 3175 \"min loss\" =  2.3269844\n",
      "2018-08-29 09:19:04.721278 Training Step 3175 \"loss\" =  3.3005636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:19:04.922818 Test Step 3180 Finished\n",
      "2018-08-29 09:19:04.922962 Test Step 3180 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:04.923014 Test Step 3180 \"loss\" =  15.151738\n",
      "2018-08-29 09:19:04.969100 Training Step 3180 Finished Timing (Training: 0.908265, Test: 0.083622) after 0.247734 seconds\n",
      "2018-08-29 09:19:04.969236 Training Step 3180 \"min loss\" =  2.3269844\n",
      "2018-08-29 09:19:04.970027 Training Step 3180 \"loss\" =  2.7165363\n",
      "2018-08-29 09:19:05.172505 Test Step 3185 Finished\n",
      "2018-08-29 09:19:05.172701 Test Step 3185 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:05.172779 Test Step 3185 \"loss\" =  15.877099\n",
      "2018-08-29 09:19:05.217984 Training Step 3185 Finished Timing (Training: 0.908254, Test: 0.0837567) after 0.247784 seconds\n",
      "2018-08-29 09:19:05.218129 Training Step 3185 \"min loss\" =  2.3269844\n",
      "2018-08-29 09:19:05.218201 Training Step 3185 \"loss\" =  3.0121439\n",
      "2018-08-29 09:19:05.420114 Test Step 3190 Finished\n",
      "2018-08-29 09:19:05.420241 Test Step 3190 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:05.420310 Test Step 3190 \"loss\" =  15.94303\n",
      "2018-08-29 09:19:05.465441 Training Step 3190 Finished Timing (Training: 0.908546, Test: 0.0837667) after 0.247153 seconds\n",
      "2018-08-29 09:19:05.465574 Training Step 3190 \"min loss\" =  2.3269844\n",
      "2018-08-29 09:19:05.465641 Training Step 3190 \"loss\" =  2.9249861\n",
      "2018-08-29 09:19:05.667864 Test Step 3195 Finished\n",
      "2018-08-29 09:19:05.668008 Test Step 3195 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:05.669002 Test Step 3195 \"loss\" =  14.4784775\n",
      "2018-08-29 09:19:05.714592 Training Step 3195 Finished Timing (Training: 0.908622, Test: 0.0837603) after 0.248863 seconds\n",
      "2018-08-29 09:19:05.714754 Training Step 3195 \"min loss\" =  2.3269844\n",
      "2018-08-29 09:19:05.715656 Training Step 3195 \"loss\" =  2.9468453\n",
      "2018-08-29 09:19:05.917526 Test Step 3200 Finished\n",
      "2018-08-29 09:19:05.917691 Test Step 3200 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:05.918751 Test Step 3200 \"loss\" =  15.78191\n",
      "2018-08-29 09:19:05.964730 Training Step 3200 Finished Timing (Training: 0.908283, Test: 0.0837434) after 0.248559 seconds\n",
      "2018-08-29 09:19:05.964836 Training Step 3200 \"min loss\" =  2.3269844\n",
      "2018-08-29 09:19:05.964901 Training Step 3200 \"loss\" =  2.9569454\n",
      "2018-08-29 09:19:06.168332 Test Step 3205 Finished\n",
      "2018-08-29 09:19:06.168544 Test Step 3205 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:06.168671 Test Step 3205 \"loss\" =  15.330636\n",
      "2018-08-29 09:19:06.214979 Training Step 3205 Finished Timing (Training: 0.913018, Test: 0.0849897) after 0.248605 seconds\n",
      "2018-08-29 09:19:06.215120 Training Step 3205 \"min loss\" =  2.3269844\n",
      "2018-08-29 09:19:06.215186 Training Step 3205 \"loss\" =  2.723645\n",
      "2018-08-29 09:19:06.416912 Test Step 3210 Finished\n",
      "2018-08-29 09:19:06.417045 Test Step 3210 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:06.417110 Test Step 3210 \"loss\" =  15.673963\n",
      "2018-08-29 09:19:06.463240 Training Step 3210 Finished Timing (Training: 0.911984, Test: 0.0844559) after 0.247292 seconds\n",
      "2018-08-29 09:19:06.463391 Training Step 3210 \"min loss\" =  2.3269844\n",
      "2018-08-29 09:19:06.463459 Training Step 3210 \"loss\" =  2.5668023\n",
      "2018-08-29 09:19:06.665633 Test Step 3215 Finished\n",
      "2018-08-29 09:19:06.665766 Test Step 3215 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:06.665834 Test Step 3215 \"loss\" =  16.382612\n",
      "2018-08-29 09:19:06.712227 Training Step 3215 Finished Timing (Training: 0.910398, Test: 0.0846603) after 0.248664 seconds\n",
      "2018-08-29 09:19:06.712398 Training Step 3215 \"min loss\" =  2.3269844\n",
      "2018-08-29 09:19:06.712476 Training Step 3215 \"loss\" =  2.67671\n",
      "2018-08-29 09:19:06.914392 Test Step 3220 Finished\n",
      "2018-08-29 09:19:06.914941 Test Step 3220 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:06.915186 Test Step 3220 \"loss\" =  15.970851\n",
      "2018-08-29 09:19:06.960869 Training Step 3220 Finished Timing (Training: 0.910326, Test: 0.0844109) after 0.248295 seconds\n",
      "2018-08-29 09:19:06.961058 Training Step 3220 \"min loss\" =  2.3269844\n",
      "2018-08-29 09:19:06.961180 Training Step 3220 \"loss\" =  2.6825483\n",
      "2018-08-29 09:19:07.162838 Test Step 3225 Finished\n",
      "2018-08-29 09:19:07.162973 Test Step 3225 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:07.163044 Test Step 3225 \"loss\" =  16.445345\n",
      "2018-08-29 09:19:07.208034 Training Step 3225 Finished Timing (Training: 0.910865, Test: 0.0842808) after 0.246715 seconds\n",
      "2018-08-29 09:19:07.208173 Training Step 3225 \"min loss\" =  2.3269844\n",
      "2018-08-29 09:19:07.208270 Training Step 3225 \"loss\" =  2.6744666\n",
      "2018-08-29 09:19:07.409236 Test Step 3230 Finished\n",
      "2018-08-29 09:19:07.409405 Test Step 3230 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:07.409470 Test Step 3230 \"loss\" =  15.793171\n",
      "2018-08-29 09:19:07.455331 Training Step 3230 Finished Timing (Training: 0.910622, Test: 0.0841875) after 0.246979 seconds\n",
      "2018-08-29 09:19:07.455461 Training Step 3230 \"min loss\" =  2.3269844\n",
      "2018-08-29 09:19:07.455545 Training Step 3230 \"loss\" =  2.5293365\n",
      "2018-08-29 09:19:07.656992 Test Step 3235 Finished\n",
      "2018-08-29 09:19:07.657642 Test Step 3235 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:07.657809 Test Step 3235 \"loss\" =  16.195427\n",
      "2018-08-29 09:19:07.703146 Training Step 3235 Finished Timing (Training: 0.910744, Test: 0.0840903) after 0.24752 seconds\n",
      "2018-08-29 09:19:07.703319 Training Step 3235 \"min loss\" =  2.3269844\n",
      "2018-08-29 09:19:07.703407 Training Step 3235 \"loss\" =  2.8757386\n",
      "2018-08-29 09:19:07.906145 Test Step 3240 Finished\n",
      "2018-08-29 09:19:07.906384 Test Step 3240 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:07.906506 Test Step 3240 \"loss\" =  16.820803\n",
      "2018-08-29 09:19:07.952302 Training Step 3240 Finished Timing (Training: 0.910742, Test: 0.0839839) after 0.24818 seconds\n",
      "2018-08-29 09:19:07.952475 Training Step 3240 \"min loss\" =  2.3269844\n",
      "2018-08-29 09:19:07.953567 Training Step 3240 \"loss\" =  2.7666936\n",
      "2018-08-29 09:19:08.154194 Test Step 3245 Finished\n",
      "2018-08-29 09:19:08.154409 Test Step 3245 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:08.154539 Test Step 3245 \"loss\" =  17.70475\n",
      "2018-08-29 09:19:08.200705 Training Step 3245 Finished Timing (Training: 0.91025, Test: 0.0838055) after 0.24705 seconds\n",
      "2018-08-29 09:19:08.200843 Training Step 3245 \"min loss\" =  2.3269844\n",
      "2018-08-29 09:19:08.200918 Training Step 3245 \"loss\" =  2.6354928\n",
      "2018-08-29 09:19:08.402030 Test Step 3250 Finished\n",
      "2018-08-29 09:19:08.402546 Test Step 3250 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:08.402651 Test Step 3250 \"loss\" =  17.0538\n",
      "2018-08-29 09:19:08.448314 Training Step 3250 Finished Timing (Training: 0.910304, Test: 0.0837556) after 0.247308 seconds\n",
      "2018-08-29 09:19:08.448442 Training Step 3250 \"min loss\" =  2.3269844\n",
      "2018-08-29 09:19:08.449176 Training Step 3250 \"loss\" =  2.6088512\n",
      "2018-08-29 09:19:08.651631 Test Step 3255 Finished\n",
      "2018-08-29 09:19:08.651805 Test Step 3255 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:08.651875 Test Step 3255 \"loss\" =  16.891983\n",
      "2018-08-29 09:19:08.697111 Training Step 3255 Finished Timing (Training: 0.910235, Test: 0.0838088) after 0.247634 seconds\n",
      "2018-08-29 09:19:08.697282 Training Step 3255 \"min loss\" =  2.3269844\n",
      "2018-08-29 09:19:08.698383 Training Step 3255 \"loss\" =  2.8789744\n",
      "2018-08-29 09:19:08.899834 Test Step 3260 Finished\n",
      "2018-08-29 09:19:08.900409 Test Step 3260 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:08.900488 Test Step 3260 \"loss\" =  17.202162\n",
      "2018-08-29 09:19:08.945839 Training Step 3260 Finished Timing (Training: 0.909879, Test: 0.0837537) after 0.246812 seconds\n",
      "2018-08-29 09:19:08.945980 Training Step 3260 \"min loss\" =  2.3269844\n",
      "2018-08-29 09:19:08.946040 Training Step 3260 \"loss\" =  2.5571105\n",
      "2018-08-29 09:19:09.146957 Test Step 3265 Finished\n",
      "2018-08-29 09:19:09.147138 Test Step 3265 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:09.148066 Test Step 3265 \"loss\" =  16.32636\n",
      "2018-08-29 09:19:09.193588 Training Step 3265 Finished Timing (Training: 0.909875, Test: 0.083663) after 0.247461 seconds\n",
      "2018-08-29 09:19:09.193734 Training Step 3265 \"min loss\" =  2.3269844\n",
      "2018-08-29 09:19:09.193802 Training Step 3265 \"loss\" =  2.6744606\n",
      "2018-08-29 09:19:09.397226 Test Step 3270 Finished\n",
      "2018-08-29 09:19:09.397373 Test Step 3270 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:09.397447 Test Step 3270 \"loss\" =  16.752659\n",
      "2018-08-29 09:19:09.442657 Training Step 3270 Finished Timing (Training: 0.910003, Test: 0.0838104) after 0.248778 seconds\n",
      "2018-08-29 09:19:09.442807 Training Step 3270 \"min loss\" =  2.3269844\n",
      "2018-08-29 09:19:09.442877 Training Step 3270 \"loss\" =  3.266423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:19:09.646643 Test Step 3275 Finished\n",
      "2018-08-29 09:19:09.647114 Test Step 3275 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:09.647579 Test Step 3275 \"loss\" =  16.120165\n",
      "2018-08-29 09:19:09.693483 Training Step 3275 Finished Timing (Training: 0.909801, Test: 0.0837206) after 0.249271 seconds\n",
      "2018-08-29 09:19:09.693631 Training Step 3275 \"min loss\" =  2.3269844\n",
      "2018-08-29 09:19:09.694362 Training Step 3275 \"loss\" =  2.4987757\n",
      "2018-08-29 09:19:09.896496 Test Step 3280 Finished\n",
      "2018-08-29 09:19:09.897121 Test Step 3280 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:09.897191 Test Step 3280 \"loss\" =  16.087618\n",
      "2018-08-29 09:19:09.942204 Training Step 3280 Finished Timing (Training: 0.90967, Test: 0.0836165) after 0.246992 seconds\n",
      "2018-08-29 09:19:09.942333 Training Step 3280 \"min loss\" =  2.3269844\n",
      "2018-08-29 09:19:09.942947 Training Step 3280 \"loss\" =  2.4294832\n",
      "2018-08-29 09:19:10.144439 Test Step 3285 Finished\n",
      "2018-08-29 09:19:10.145135 Test Step 3285 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:10.145437 Test Step 3285 \"loss\" =  15.8877125\n",
      "2018-08-29 09:19:10.191182 Training Step 3285 Finished Timing (Training: 0.909577, Test: 0.083557) after 0.248131 seconds\n",
      "2018-08-29 09:19:10.191308 Training Step 3285 \"min loss\" =  2.3269844\n",
      "2018-08-29 09:19:10.191373 Training Step 3285 \"loss\" =  2.6086862\n",
      "2018-08-29 09:19:10.394794 Test Step 3290 Finished\n",
      "2018-08-29 09:19:10.395028 Test Step 3290 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:10.395161 Test Step 3290 \"loss\" =  15.774078\n",
      "2018-08-29 09:19:10.440972 Training Step 3290 Finished Timing (Training: 0.909454, Test: 0.0835288) after 0.248509 seconds\n",
      "2018-08-29 09:19:10.441121 Training Step 3290 \"min loss\" =  2.3269844\n",
      "2018-08-29 09:19:10.441860 Training Step 3290 \"loss\" =  2.8239894\n",
      "2018-08-29 09:19:10.643452 Test Step 3295 Finished\n",
      "2018-08-29 09:19:10.643714 Test Step 3295 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:10.643831 Test Step 3295 \"loss\" =  16.405598\n",
      "2018-08-29 09:19:10.690222 Training Step 3295 Finished Timing (Training: 0.909306, Test: 0.0835039) after 0.248274 seconds\n",
      "2018-08-29 09:19:10.690392 Training Step 3295 \"min loss\" =  2.3269844\n",
      "2018-08-29 09:19:10.690906 Training Step 3295 \"loss\" =  2.7437418\n",
      "2018-08-29 09:19:10.892563 Test Step 3300 Finished\n",
      "2018-08-29 09:19:10.892766 Test Step 3300 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:10.893562 Test Step 3300 \"loss\" =  15.308182\n",
      "2018-08-29 09:19:10.939111 Training Step 3300 Finished Timing (Training: 0.909196, Test: 0.0834644) after 0.247596 seconds\n",
      "2018-08-29 09:19:10.939283 Training Step 3300 \"min loss\" =  2.3269844\n",
      "2018-08-29 09:19:10.940080 Training Step 3300 \"loss\" =  2.9388683\n",
      "2018-08-29 09:19:11.142764 Test Step 3305 Finished\n",
      "2018-08-29 09:19:11.142927 Test Step 3305 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:11.143774 Test Step 3305 \"loss\" =  15.709348\n",
      "2018-08-29 09:19:11.189253 Training Step 3305 Finished Timing (Training: 0.911449, Test: 0.0839785) after 0.249093 seconds\n",
      "2018-08-29 09:19:11.189739 Training Step 3305 \"min loss\" =  2.3269844\n",
      "2018-08-29 09:19:11.189819 Training Step 3305 \"loss\" =  2.7007225\n",
      "2018-08-29 09:19:11.391539 Test Step 3310 Finished\n",
      "2018-08-29 09:19:11.392113 Test Step 3310 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:11.392244 Test Step 3310 \"loss\" =  15.92869\n",
      "2018-08-29 09:19:11.438112 Training Step 3310 Finished Timing (Training: 0.910344, Test: 0.0834084) after 0.247773 seconds\n",
      "2018-08-29 09:19:11.438253 Training Step 3310 \"min loss\" =  2.3269844\n",
      "2018-08-29 09:19:11.438325 Training Step 3310 \"loss\" =  2.7804615\n",
      "2018-08-29 09:19:11.640698 Test Step 3315 Finished\n",
      "2018-08-29 09:19:11.640859 Test Step 3315 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:11.640926 Test Step 3315 \"loss\" =  16.664513\n",
      "2018-08-29 09:19:11.687174 Training Step 3315 Finished Timing (Training: 0.908468, Test: 0.0839899) after 0.247887 seconds\n",
      "2018-08-29 09:19:11.687323 Training Step 3315 \"min loss\" =  2.3269844\n",
      "2018-08-29 09:19:11.687391 Training Step 3315 \"loss\" =  2.6200495\n",
      "2018-08-29 09:19:11.889557 Test Step 3320 Finished\n",
      "2018-08-29 09:19:11.889694 Test Step 3320 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:11.889756 Test Step 3320 \"loss\" =  16.833769\n",
      "2018-08-29 09:19:11.934884 Training Step 3320 Finished Timing (Training: 0.908897, Test: 0.083858) after 0.246456 seconds\n",
      "2018-08-29 09:19:11.935016 Training Step 3320 \"min loss\" =  2.3085248\n",
      "2018-08-29 09:19:11.935098 Training Step 3320 \"loss\" =  2.676742\n",
      "2018-08-29 09:19:12.137069 Test Step 3325 Finished\n",
      "2018-08-29 09:19:12.137203 Test Step 3325 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:12.137270 Test Step 3325 \"loss\" =  16.133997\n",
      "2018-08-29 09:19:12.183346 Training Step 3325 Finished Timing (Training: 0.908573, Test: 0.0844197) after 0.248173 seconds\n",
      "2018-08-29 09:19:12.183467 Training Step 3325 \"min loss\" =  2.3085248\n",
      "2018-08-29 09:19:12.183531 Training Step 3325 \"loss\" =  3.0391955\n",
      "2018-08-29 09:19:12.384652 Test Step 3330 Finished\n",
      "2018-08-29 09:19:12.384806 Test Step 3330 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:12.385621 Test Step 3330 \"loss\" =  16.177784\n",
      "2018-08-29 09:19:12.430973 Training Step 3330 Finished Timing (Training: 0.908302, Test: 0.084165) after 0.246448 seconds\n",
      "2018-08-29 09:19:12.431159 Training Step 3330 \"min loss\" =  2.3085248\n",
      "2018-08-29 09:19:12.431273 Training Step 3330 \"loss\" =  2.4388924\n",
      "2018-08-29 09:19:12.633959 Test Step 3335 Finished\n",
      "2018-08-29 09:19:12.634098 Test Step 3335 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:12.634171 Test Step 3335 \"loss\" =  15.797104\n",
      "2018-08-29 09:19:12.679739 Training Step 3335 Finished Timing (Training: 0.908774, Test: 0.0840255) after 0.248337 seconds\n",
      "2018-08-29 09:19:12.679874 Training Step 3335 \"min loss\" =  2.3085248\n",
      "2018-08-29 09:19:12.679973 Training Step 3335 \"loss\" =  2.4332924\n",
      "2018-08-29 09:19:12.881621 Test Step 3340 Finished\n",
      "2018-08-29 09:19:12.881761 Test Step 3340 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:12.881837 Test Step 3340 \"loss\" =  16.988558\n",
      "2018-08-29 09:19:12.927042 Training Step 3340 Finished Timing (Training: 0.909083, Test: 0.0839224) after 0.246272 seconds\n",
      "2018-08-29 09:19:12.927217 Training Step 3340 \"min loss\" =  2.3085248\n",
      "2018-08-29 09:19:12.927731 Training Step 3340 \"loss\" =  2.6571083\n",
      "2018-08-29 09:19:13.129464 Test Step 3345 Finished\n",
      "2018-08-29 09:19:13.129644 Test Step 3345 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:13.130650 Test Step 3345 \"loss\" =  16.494995\n",
      "2018-08-29 09:19:13.175956 Training Step 3345 Finished Timing (Training: 0.908641, Test: 0.0838858) after 0.247445 seconds\n",
      "2018-08-29 09:19:13.176102 Training Step 3345 \"min loss\" =  2.3085248\n",
      "2018-08-29 09:19:13.176162 Training Step 3345 \"loss\" =  2.5578494\n",
      "2018-08-29 09:19:13.378504 Test Step 3350 Finished\n",
      "2018-08-29 09:19:13.378632 Test Step 3350 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:13.378679 Test Step 3350 \"loss\" =  15.755682\n",
      "2018-08-29 09:19:13.423787 Training Step 3350 Finished Timing (Training: 0.909091, Test: 0.0837813) after 0.247118 seconds\n",
      "2018-08-29 09:19:13.423909 Training Step 3350 \"min loss\" =  2.3085248\n",
      "2018-08-29 09:19:13.423957 Training Step 3350 \"loss\" =  2.3938117\n",
      "2018-08-29 09:19:13.624571 Test Step 3355 Finished\n",
      "2018-08-29 09:19:13.624710 Test Step 3355 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:13.624769 Test Step 3355 \"loss\" =  14.858876\n",
      "2018-08-29 09:19:13.669906 Training Step 3355 Finished Timing (Training: 0.909544, Test: 0.0837766) after 0.245888 seconds\n",
      "2018-08-29 09:19:13.670044 Training Step 3355 \"min loss\" =  2.3085248\n",
      "2018-08-29 09:19:13.670091 Training Step 3355 \"loss\" =  2.5802655\n",
      "2018-08-29 09:19:13.870808 Test Step 3360 Finished\n",
      "2018-08-29 09:19:13.870963 Test Step 3360 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:13.871013 Test Step 3360 \"loss\" =  15.723636\n",
      "2018-08-29 09:19:13.916695 Training Step 3360 Finished Timing (Training: 0.909833, Test: 0.0838573) after 0.24654 seconds\n",
      "2018-08-29 09:19:13.916871 Training Step 3360 \"min loss\" =  2.3085248\n",
      "2018-08-29 09:19:13.916924 Training Step 3360 \"loss\" =  2.6034386\n",
      "2018-08-29 09:19:14.119466 Test Step 3365 Finished\n",
      "2018-08-29 09:19:14.119995 Test Step 3365 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:14.120326 Test Step 3365 \"loss\" =  15.807584\n",
      "2018-08-29 09:19:14.165573 Training Step 3365 Finished Timing (Training: 0.90973, Test: 0.0839448) after 0.248556 seconds\n",
      "2018-08-29 09:19:14.166002 Training Step 3365 \"min loss\" =  2.3085248\n",
      "2018-08-29 09:19:14.166336 Training Step 3365 \"loss\" =  2.9082441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:19:14.368100 Test Step 3370 Finished\n",
      "2018-08-29 09:19:14.368635 Test Step 3370 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:14.369021 Test Step 3370 \"loss\" =  15.310905\n",
      "2018-08-29 09:19:14.414463 Training Step 3370 Finished Timing (Training: 0.909529, Test: 0.0838829) after 0.247763 seconds\n",
      "2018-08-29 09:19:14.414909 Training Step 3370 \"min loss\" =  2.3085248\n",
      "2018-08-29 09:19:14.415253 Training Step 3370 \"loss\" =  2.6900392\n",
      "2018-08-29 09:19:14.616470 Test Step 3375 Finished\n",
      "2018-08-29 09:19:14.617026 Test Step 3375 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:14.617358 Test Step 3375 \"loss\" =  15.304484\n",
      "2018-08-29 09:19:14.663426 Training Step 3375 Finished Timing (Training: 0.909406, Test: 0.0838013) after 0.247829 seconds\n",
      "2018-08-29 09:19:14.663873 Training Step 3375 \"min loss\" =  2.3085248\n",
      "2018-08-29 09:19:14.664234 Training Step 3375 \"loss\" =  2.708951\n",
      "2018-08-29 09:19:14.865493 Test Step 3380 Finished\n",
      "2018-08-29 09:19:14.865635 Test Step 3380 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:14.865684 Test Step 3380 \"loss\" =  15.655208\n",
      "2018-08-29 09:19:14.910791 Training Step 3380 Finished Timing (Training: 0.909498, Test: 0.0837646) after 0.246197 seconds\n",
      "2018-08-29 09:19:14.910970 Training Step 3380 \"min loss\" =  2.3085248\n",
      "2018-08-29 09:19:14.911051 Training Step 3380 \"loss\" =  2.6009877\n",
      "2018-08-29 09:19:15.112273 Test Step 3385 Finished\n",
      "2018-08-29 09:19:15.112452 Test Step 3385 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:15.112546 Test Step 3385 \"loss\" =  15.520933\n",
      "2018-08-29 09:19:15.157752 Training Step 3385 Finished Timing (Training: 0.909656, Test: 0.0838071) after 0.246605 seconds\n",
      "2018-08-29 09:19:15.157882 Training Step 3385 \"min loss\" =  2.3085248\n",
      "2018-08-29 09:19:15.157945 Training Step 3385 \"loss\" =  2.6991696\n",
      "2018-08-29 09:19:15.360132 Test Step 3390 Finished\n",
      "2018-08-29 09:19:15.360266 Test Step 3390 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:15.360318 Test Step 3390 \"loss\" =  15.743557\n",
      "2018-08-29 09:19:15.405487 Training Step 3390 Finished Timing (Training: 0.909856, Test: 0.0838463) after 0.247473 seconds\n",
      "2018-08-29 09:19:15.405616 Training Step 3390 \"min loss\" =  2.3085248\n",
      "2018-08-29 09:19:15.405667 Training Step 3390 \"loss\" =  2.557398\n",
      "2018-08-29 09:19:15.606862 Test Step 3395 Finished\n",
      "2018-08-29 09:19:15.607004 Test Step 3395 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:15.607052 Test Step 3395 \"loss\" =  16.160683\n",
      "2018-08-29 09:19:15.652118 Training Step 3395 Finished Timing (Training: 0.910061, Test: 0.0838553) after 0.246384 seconds\n",
      "2018-08-29 09:19:15.652634 Training Step 3395 \"min loss\" =  2.2548485\n",
      "2018-08-29 09:19:15.652725 Training Step 3395 \"loss\" =  2.623945\n",
      "2018-08-29 09:19:15.854999 Test Step 3400 Finished\n",
      "2018-08-29 09:19:15.855655 Test Step 3400 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:15.856092 Test Step 3400 \"loss\" =  15.756465\n",
      "2018-08-29 09:19:15.901136 Training Step 3400 Finished Timing (Training: 0.909945, Test: 0.0838128) after 0.247932 seconds\n",
      "2018-08-29 09:19:15.901291 Training Step 3400 \"min loss\" =  2.2548485\n",
      "2018-08-29 09:19:15.901694 Training Step 3400 \"loss\" =  2.82826\n",
      "2018-08-29 09:19:16.103652 Test Step 3405 Finished\n",
      "2018-08-29 09:19:16.103798 Test Step 3405 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:16.103864 Test Step 3405 \"loss\" =  15.253559\n",
      "2018-08-29 09:19:16.150508 Training Step 3405 Finished Timing (Training: 0.911298, Test: 0.0829584) after 0.248731 seconds\n",
      "2018-08-29 09:19:16.150641 Training Step 3405 \"min loss\" =  2.2548485\n",
      "2018-08-29 09:19:16.151783 Training Step 3405 \"loss\" =  2.574871\n",
      "2018-08-29 09:19:16.353815 Test Step 3410 Finished\n",
      "2018-08-29 09:19:16.354342 Test Step 3410 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:16.354595 Test Step 3410 \"loss\" =  15.226266\n",
      "2018-08-29 09:19:16.400387 Training Step 3410 Finished Timing (Training: 0.908176, Test: 0.0844218) after 0.248513 seconds\n",
      "2018-08-29 09:19:16.400543 Training Step 3410 \"min loss\" =  2.2548485\n",
      "2018-08-29 09:19:16.401111 Training Step 3410 \"loss\" =  2.4769833\n",
      "2018-08-29 09:19:16.603291 Test Step 3415 Finished\n",
      "2018-08-29 09:19:16.603930 Test Step 3415 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:16.604005 Test Step 3415 \"loss\" =  15.2894945\n",
      "2018-08-29 09:19:16.650211 Training Step 3415 Finished Timing (Training: 0.90825, Test: 0.0836096) after 0.248954 seconds\n",
      "2018-08-29 09:19:16.650344 Training Step 3415 \"min loss\" =  2.2548485\n",
      "2018-08-29 09:19:16.650942 Training Step 3415 \"loss\" =  2.7539334\n",
      "2018-08-29 09:19:16.853139 Test Step 3420 Finished\n",
      "2018-08-29 09:19:16.853275 Test Step 3420 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:16.853839 Test Step 3420 \"loss\" =  15.244998\n",
      "2018-08-29 09:19:16.899286 Training Step 3420 Finished Timing (Training: 0.908345, Test: 0.0836286) after 0.248259 seconds\n",
      "2018-08-29 09:19:16.899769 Training Step 3420 \"min loss\" =  2.2548485\n",
      "2018-08-29 09:19:16.900000 Training Step 3420 \"loss\" =  2.5846643\n",
      "2018-08-29 09:19:17.101290 Test Step 3425 Finished\n",
      "2018-08-29 09:19:17.101862 Test Step 3425 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:17.101947 Test Step 3425 \"loss\" =  15.298442\n",
      "2018-08-29 09:19:17.147453 Training Step 3425 Finished Timing (Training: 0.908205, Test: 0.0837769) after 0.24737 seconds\n",
      "2018-08-29 09:19:17.147589 Training Step 3425 \"min loss\" =  2.2548485\n",
      "2018-08-29 09:19:17.148218 Training Step 3425 \"loss\" =  2.8406608\n",
      "2018-08-29 09:19:17.349135 Test Step 3430 Finished\n",
      "2018-08-29 09:19:17.349294 Test Step 3430 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:17.349364 Test Step 3430 \"loss\" =  15.226501\n",
      "2018-08-29 09:19:17.395821 Training Step 3430 Finished Timing (Training: 0.90792, Test: 0.084008) after 0.247516 seconds\n",
      "2018-08-29 09:19:17.396444 Training Step 3430 \"min loss\" =  2.2548485\n",
      "2018-08-29 09:19:17.396891 Training Step 3430 \"loss\" =  2.4728005\n",
      "2018-08-29 09:19:17.599249 Test Step 3435 Finished\n",
      "2018-08-29 09:19:17.599809 Test Step 3435 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:17.599883 Test Step 3435 \"loss\" =  15.228138\n",
      "2018-08-29 09:19:17.645826 Training Step 3435 Finished Timing (Training: 0.907592, Test: 0.0841004) after 0.248831 seconds\n",
      "2018-08-29 09:19:17.645988 Training Step 3435 \"min loss\" =  2.2548485\n",
      "2018-08-29 09:19:17.646655 Training Step 3435 \"loss\" =  2.703643\n",
      "2018-08-29 09:19:17.848006 Test Step 3440 Finished\n",
      "2018-08-29 09:19:17.848514 Test Step 3440 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:17.848660 Test Step 3440 \"loss\" =  15.220609\n",
      "2018-08-29 09:19:17.894102 Training Step 3440 Finished Timing (Training: 0.907831, Test: 0.0840086) after 0.247339 seconds\n",
      "2018-08-29 09:19:17.894276 Training Step 3440 \"min loss\" =  2.2548485\n",
      "2018-08-29 09:19:17.894883 Training Step 3440 \"loss\" =  2.5092964\n",
      "2018-08-29 09:19:18.097035 Test Step 3445 Finished\n",
      "2018-08-29 09:19:18.097190 Test Step 3445 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:18.097261 Test Step 3445 \"loss\" =  16.082508\n",
      "2018-08-29 09:19:18.143103 Training Step 3445 Finished Timing (Training: 0.907977, Test: 0.0839623) after 0.248049 seconds\n",
      "2018-08-29 09:19:18.143309 Training Step 3445 \"min loss\" =  2.2548485\n",
      "2018-08-29 09:19:18.143392 Training Step 3445 \"loss\" =  2.457122\n",
      "2018-08-29 09:19:18.345527 Test Step 3450 Finished\n",
      "2018-08-29 09:19:18.346092 Test Step 3450 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:18.346190 Test Step 3450 \"loss\" =  15.556599\n",
      "2018-08-29 09:19:18.392226 Training Step 3450 Finished Timing (Training: 0.908249, Test: 0.0838518) after 0.248307 seconds\n",
      "2018-08-29 09:19:18.392366 Training Step 3450 \"min loss\" =  2.2548485\n",
      "2018-08-29 09:19:18.393265 Training Step 3450 \"loss\" =  2.7642183\n",
      "2018-08-29 09:19:18.594665 Test Step 3455 Finished\n",
      "2018-08-29 09:19:18.595211 Test Step 3455 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:18.595551 Test Step 3455 \"loss\" =  15.284836\n",
      "2018-08-29 09:19:18.641498 Training Step 3455 Finished Timing (Training: 0.908029, Test: 0.0837639) after 0.247674 seconds\n",
      "2018-08-29 09:19:18.641644 Training Step 3455 \"min loss\" =  2.2548485\n",
      "2018-08-29 09:19:18.642414 Training Step 3455 \"loss\" =  2.3854263\n",
      "2018-08-29 09:19:18.844460 Test Step 3460 Finished\n",
      "2018-08-29 09:19:18.844651 Test Step 3460 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:18.844764 Test Step 3460 \"loss\" =  16.00696\n",
      "2018-08-29 09:19:18.891520 Training Step 3460 Finished Timing (Training: 0.908123, Test: 0.0836666) after 0.248769 seconds\n",
      "2018-08-29 09:19:18.891711 Training Step 3460 \"min loss\" =  2.2548485\n",
      "2018-08-29 09:19:18.891825 Training Step 3460 \"loss\" =  2.505614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:19:19.093960 Test Step 3465 Finished\n",
      "2018-08-29 09:19:19.094128 Test Step 3465 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:19.094210 Test Step 3465 \"loss\" =  15.842372\n",
      "2018-08-29 09:19:19.139354 Training Step 3465 Finished Timing (Training: 0.90852, Test: 0.0836521) after 0.247404 seconds\n",
      "2018-08-29 09:19:19.139502 Training Step 3465 \"min loss\" =  2.2548485\n",
      "2018-08-29 09:19:19.139568 Training Step 3465 \"loss\" =  2.4359152\n",
      "2018-08-29 09:19:19.343535 Test Step 3470 Finished\n",
      "2018-08-29 09:19:19.343715 Test Step 3470 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:19.343835 Test Step 3470 \"loss\" =  15.351645\n",
      "2018-08-29 09:19:19.389860 Training Step 3470 Finished Timing (Training: 0.908468, Test: 0.0835875) after 0.248584 seconds\n",
      "2018-08-29 09:19:19.390364 Training Step 3470 \"min loss\" =  2.2548485\n",
      "2018-08-29 09:19:19.390434 Training Step 3470 \"loss\" =  2.6049516\n",
      "2018-08-29 09:19:19.592089 Test Step 3475 Finished\n",
      "2018-08-29 09:19:19.592621 Test Step 3475 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:19.592708 Test Step 3475 \"loss\" =  16.02934\n",
      "2018-08-29 09:19:19.638439 Training Step 3475 Finished Timing (Training: 0.908527, Test: 0.0836158) after 0.247926 seconds\n",
      "2018-08-29 09:19:19.638583 Training Step 3475 \"min loss\" =  2.2548485\n",
      "2018-08-29 09:19:19.638649 Training Step 3475 \"loss\" =  2.5893135\n",
      "2018-08-29 09:19:19.841386 Test Step 3480 Finished\n",
      "2018-08-29 09:19:19.841875 Test Step 3480 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:19.842274 Test Step 3480 \"loss\" =  15.217281\n",
      "2018-08-29 09:19:19.887545 Training Step 3480 Finished Timing (Training: 0.908737, Test: 0.083572) after 0.24882 seconds\n",
      "2018-08-29 09:19:19.887669 Training Step 3480 \"min loss\" =  2.2548485\n",
      "2018-08-29 09:19:19.887727 Training Step 3480 \"loss\" =  2.487677\n",
      "2018-08-29 09:19:20.090881 Test Step 3485 Finished\n",
      "2018-08-29 09:19:20.091474 Test Step 3485 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:20.091548 Test Step 3485 \"loss\" =  15.997376\n",
      "2018-08-29 09:19:20.137089 Training Step 3485 Finished Timing (Training: 0.908561, Test: 0.0836348) after 0.247938 seconds\n",
      "2018-08-29 09:19:20.137239 Training Step 3485 \"min loss\" =  2.2548485\n",
      "2018-08-29 09:19:20.137307 Training Step 3485 \"loss\" =  2.6947625\n",
      "2018-08-29 09:19:20.339031 Test Step 3490 Finished\n",
      "2018-08-29 09:19:20.339191 Test Step 3490 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:20.340283 Test Step 3490 \"loss\" =  16.52088\n",
      "2018-08-29 09:19:20.385968 Training Step 3490 Finished Timing (Training: 0.90867, Test: 0.0835727) after 0.248561 seconds\n",
      "2018-08-29 09:19:20.386564 Training Step 3490 \"min loss\" =  2.1906898\n",
      "2018-08-29 09:19:20.386981 Training Step 3490 \"loss\" =  2.1906898\n",
      "2018-08-29 09:19:20.589099 Test Step 3495 Finished\n",
      "2018-08-29 09:19:20.589713 Test Step 3495 \"min loss\" =  14.378064\n",
      "2018-08-29 09:19:20.589787 Test Step 3495 \"loss\" =  15.149697\n",
      "2018-08-29 09:19:20.635282 Training Step 3495 Finished Timing (Training: 0.908727, Test: 0.0835073) after 0.248163 seconds\n",
      "2018-08-29 09:19:20.635427 Training Step 3495 \"min loss\" =  2.1906898\n",
      "2018-08-29 09:19:20.635490 Training Step 3495 \"loss\" =  2.592437\n",
      "2018-08-29 09:19:20.838786 Test Step 3500 Finished\n",
      "2018-08-29 09:19:20.839435 Test Step 3500 \"min loss\" =  14.116654\n",
      "2018-08-29 09:19:20.839906 Test Step 3500 \"loss\" =  14.116654\n",
      "2018-08-29 09:19:20.885005 Training Step 3500 Finished Timing (Training: 0.908673, Test: 0.0836367) after 0.249431 seconds\n",
      "2018-08-29 09:19:20.885134 Training Step 3500 \"min loss\" =  2.1906898\n",
      "2018-08-29 09:19:20.885214 Training Step 3500 \"loss\" =  2.4959264\n",
      "2018-08-29 09:19:21.087984 Test Step 3505 Finished\n",
      "2018-08-29 09:19:21.088111 Test Step 3505 \"min loss\" =  14.116654\n",
      "2018-08-29 09:19:21.088193 Test Step 3505 \"loss\" =  14.340576\n",
      "2018-08-29 09:19:21.134322 Training Step 3505 Finished Timing (Training: 0.915209, Test: 0.0835168) after 0.248269 seconds\n",
      "2018-08-29 09:19:21.134456 Training Step 3505 \"min loss\" =  2.1906898\n",
      "2018-08-29 09:19:21.134524 Training Step 3505 \"loss\" =  2.534574\n",
      "2018-08-29 09:19:21.338021 Test Step 3510 Finished\n",
      "2018-08-29 09:19:21.338277 Test Step 3510 \"min loss\" =  14.116654\n",
      "2018-08-29 09:19:21.338403 Test Step 3510 \"loss\" =  16.005756\n",
      "2018-08-29 09:19:21.384752 Training Step 3510 Finished Timing (Training: 0.911866, Test: 0.0835258) after 0.249004 seconds\n",
      "2018-08-29 09:19:21.384900 Training Step 3510 \"min loss\" =  2.1906898\n",
      "2018-08-29 09:19:21.385560 Training Step 3510 \"loss\" =  2.6355157\n",
      "2018-08-29 09:19:21.587047 Test Step 3515 Finished\n",
      "2018-08-29 09:19:21.587188 Test Step 3515 \"min loss\" =  14.116654\n",
      "2018-08-29 09:19:21.588075 Test Step 3515 \"loss\" =  15.35759\n",
      "2018-08-29 09:19:21.633165 Training Step 3515 Finished Timing (Training: 0.910488, Test: 0.0836626) after 0.247514 seconds\n",
      "2018-08-29 09:19:21.633301 Training Step 3515 \"min loss\" =  2.1906898\n",
      "2018-08-29 09:19:21.633370 Training Step 3515 \"loss\" =  2.843943\n",
      "2018-08-29 09:19:21.837278 Test Step 3520 Finished\n",
      "2018-08-29 09:19:21.837953 Test Step 3520 \"min loss\" =  14.116654\n",
      "2018-08-29 09:19:21.838294 Test Step 3520 \"loss\" =  15.034932\n",
      "2018-08-29 09:19:21.883184 Training Step 3520 Finished Timing (Training: 0.910271, Test: 0.0830477) after 0.248873 seconds\n",
      "2018-08-29 09:19:21.883309 Training Step 3520 \"min loss\" =  2.1906898\n",
      "2018-08-29 09:19:21.884127 Training Step 3520 \"loss\" =  2.6620674\n",
      "2018-08-29 09:19:22.085187 Test Step 3525 Finished\n",
      "2018-08-29 09:19:22.085338 Test Step 3525 \"min loss\" =  14.116654\n",
      "2018-08-29 09:19:22.086324 Test Step 3525 \"loss\" =  15.154815\n",
      "2018-08-29 09:19:22.131915 Training Step 3525 Finished Timing (Training: 0.909617, Test: 0.083145) after 0.247679 seconds\n",
      "2018-08-29 09:19:22.132052 Training Step 3525 \"min loss\" =  2.1906898\n",
      "2018-08-29 09:19:22.132615 Training Step 3525 \"loss\" =  2.8225982\n",
      "2018-08-29 09:19:22.334140 Test Step 3530 Finished\n",
      "2018-08-29 09:19:22.334292 Test Step 3530 \"min loss\" =  14.116654\n",
      "2018-08-29 09:19:22.334919 Test Step 3530 \"loss\" =  14.781054\n",
      "2018-08-29 09:19:22.380701 Training Step 3530 Finished Timing (Training: 0.90947, Test: 0.0830283) after 0.247488 seconds\n",
      "2018-08-29 09:19:22.380870 Training Step 3530 \"min loss\" =  2.1906898\n",
      "2018-08-29 09:19:22.380970 Training Step 3530 \"loss\" =  2.4401236\n",
      "2018-08-29 09:19:22.583652 Test Step 3535 Finished\n",
      "2018-08-29 09:19:22.583795 Test Step 3535 \"min loss\" =  14.116654\n",
      "2018-08-29 09:19:22.584488 Test Step 3535 \"loss\" =  14.309192\n",
      "2018-08-29 09:19:22.629601 Training Step 3535 Finished Timing (Training: 0.909737, Test: 0.0830577) after 0.248512 seconds\n",
      "2018-08-29 09:19:22.629746 Training Step 3535 \"min loss\" =  2.1906898\n",
      "2018-08-29 09:19:22.630482 Training Step 3535 \"loss\" =  2.223041\n",
      "2018-08-29 09:19:22.832807 Test Step 3540 Finished\n",
      "2018-08-29 09:19:22.833467 Test Step 3540 \"min loss\" =  14.116499\n",
      "2018-08-29 09:19:22.833568 Test Step 3540 \"loss\" =  14.116499\n",
      "2018-08-29 09:19:22.879028 Training Step 3540 Finished Timing (Training: 0.909244, Test: 0.0833292) after 0.2481 seconds\n",
      "2018-08-29 09:19:22.879204 Training Step 3540 \"min loss\" =  2.1906898\n",
      "2018-08-29 09:19:22.879858 Training Step 3540 \"loss\" =  2.4998424\n",
      "2018-08-29 09:19:23.081384 Test Step 3545 Finished\n",
      "2018-08-29 09:19:23.081528 Test Step 3545 \"min loss\" =  14.116499\n",
      "2018-08-29 09:19:23.081599 Test Step 3545 \"loss\" =  15.858141\n",
      "2018-08-29 09:19:23.127680 Training Step 3545 Finished Timing (Training: 0.909333, Test: 0.0832976) after 0.247288 seconds\n",
      "2018-08-29 09:19:23.127805 Training Step 3545 \"min loss\" =  2.1906898\n",
      "2018-08-29 09:19:23.128565 Training Step 3545 \"loss\" =  2.4979813\n",
      "2018-08-29 09:19:23.331117 Test Step 3550 Finished\n",
      "2018-08-29 09:19:23.331779 Test Step 3550 \"min loss\" =  14.116499\n",
      "2018-08-29 09:19:23.331889 Test Step 3550 \"loss\" =  15.112522\n",
      "2018-08-29 09:19:23.376995 Training Step 3550 Finished Timing (Training: 0.909356, Test: 0.0832264) after 0.248245 seconds\n",
      "2018-08-29 09:19:23.377213 Training Step 3550 \"min loss\" =  2.1906898\n",
      "2018-08-29 09:19:23.377331 Training Step 3550 \"loss\" =  2.309699\n",
      "2018-08-29 09:19:23.579288 Test Step 3555 Finished\n",
      "2018-08-29 09:19:23.579421 Test Step 3555 \"min loss\" =  14.116499\n",
      "2018-08-29 09:19:23.579485 Test Step 3555 \"loss\" =  14.91966\n",
      "2018-08-29 09:19:23.625616 Training Step 3555 Finished Timing (Training: 0.90935, Test: 0.0832122) after 0.248147 seconds\n",
      "2018-08-29 09:19:23.625760 Training Step 3555 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:23.626303 Training Step 3555 \"loss\" =  2.1787293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:19:23.828325 Test Step 3560 Finished\n",
      "2018-08-29 09:19:23.828929 Test Step 3560 \"min loss\" =  14.116499\n",
      "2018-08-29 09:19:23.829007 Test Step 3560 \"loss\" =  14.6795635\n",
      "2018-08-29 09:19:23.874819 Training Step 3560 Finished Timing (Training: 0.909337, Test: 0.0831505) after 0.248415 seconds\n",
      "2018-08-29 09:19:23.874976 Training Step 3560 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:23.875063 Training Step 3560 \"loss\" =  2.9730957\n",
      "2018-08-29 09:19:24.077965 Test Step 3565 Finished\n",
      "2018-08-29 09:19:24.078107 Test Step 3565 \"min loss\" =  14.116499\n",
      "2018-08-29 09:19:24.078193 Test Step 3565 \"loss\" =  14.372209\n",
      "2018-08-29 09:19:24.124685 Training Step 3565 Finished Timing (Training: 0.909668, Test: 0.0831828) after 0.249525 seconds\n",
      "2018-08-29 09:19:24.124811 Training Step 3565 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:24.124870 Training Step 3565 \"loss\" =  2.3864489\n",
      "2018-08-29 09:19:24.326682 Test Step 3570 Finished\n",
      "2018-08-29 09:19:24.326842 Test Step 3570 \"min loss\" =  14.116499\n",
      "2018-08-29 09:19:24.327511 Test Step 3570 \"loss\" =  14.8050165\n",
      "2018-08-29 09:19:24.373019 Training Step 3570 Finished Timing (Training: 0.909413, Test: 0.0832236) after 0.247163 seconds\n",
      "2018-08-29 09:19:24.373466 Training Step 3570 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:24.373858 Training Step 3570 \"loss\" =  2.5421972\n",
      "2018-08-29 09:19:24.576018 Test Step 3575 Finished\n",
      "2018-08-29 09:19:24.576169 Test Step 3575 \"min loss\" =  14.116499\n",
      "2018-08-29 09:19:24.576238 Test Step 3575 \"loss\" =  15.330027\n",
      "2018-08-29 09:19:24.622168 Training Step 3575 Finished Timing (Training: 0.909455, Test: 0.0833249) after 0.248195 seconds\n",
      "2018-08-29 09:19:24.622665 Training Step 3575 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:24.622740 Training Step 3575 \"loss\" =  2.6057348\n",
      "2018-08-29 09:19:24.825151 Test Step 3580 Finished\n",
      "2018-08-29 09:19:24.825302 Test Step 3580 \"min loss\" =  14.116499\n",
      "2018-08-29 09:19:24.825369 Test Step 3580 \"loss\" =  14.660416\n",
      "2018-08-29 09:19:24.870497 Training Step 3580 Finished Timing (Training: 0.909409, Test: 0.0834522) after 0.247197 seconds\n",
      "2018-08-29 09:19:24.870672 Training Step 3580 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:24.871378 Training Step 3580 \"loss\" =  2.8102365\n",
      "2018-08-29 09:19:25.072628 Test Step 3585 Finished\n",
      "2018-08-29 09:19:25.072762 Test Step 3585 \"min loss\" =  14.116499\n",
      "2018-08-29 09:19:25.072833 Test Step 3585 \"loss\" =  14.4912\n",
      "2018-08-29 09:19:25.119157 Training Step 3585 Finished Timing (Training: 0.909277, Test: 0.0834328) after 0.247682 seconds\n",
      "2018-08-29 09:19:25.119290 Training Step 3585 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:25.119358 Training Step 3585 \"loss\" =  2.6080194\n",
      "2018-08-29 09:19:25.322149 Test Step 3590 Finished\n",
      "2018-08-29 09:19:25.322279 Test Step 3590 \"min loss\" =  14.116499\n",
      "2018-08-29 09:19:25.323375 Test Step 3590 \"loss\" =  15.052385\n",
      "2018-08-29 09:19:25.369525 Training Step 3590 Finished Timing (Training: 0.908949, Test: 0.0835338) after 0.249336 seconds\n",
      "2018-08-29 09:19:25.369672 Training Step 3590 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:25.369740 Training Step 3590 \"loss\" =  2.36626\n",
      "2018-08-29 09:19:25.570867 Test Step 3595 Finished\n",
      "2018-08-29 09:19:25.571013 Test Step 3595 \"min loss\" =  14.116499\n",
      "2018-08-29 09:19:25.571080 Test Step 3595 \"loss\" =  15.048693\n",
      "2018-08-29 09:19:25.617216 Training Step 3595 Finished Timing (Training: 0.909247, Test: 0.0834858) after 0.247388 seconds\n",
      "2018-08-29 09:19:25.617364 Training Step 3595 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:25.617875 Training Step 3595 \"loss\" =  2.5260231\n",
      "2018-08-29 09:19:25.819348 Test Step 3600 Finished\n",
      "2018-08-29 09:19:25.819819 Test Step 3600 \"min loss\" =  14.116499\n",
      "2018-08-29 09:19:25.819954 Test Step 3600 \"loss\" =  14.678714\n",
      "2018-08-29 09:19:25.865550 Training Step 3600 Finished Timing (Training: 0.909277, Test: 0.0835074) after 0.247593 seconds\n",
      "2018-08-29 09:19:25.865709 Training Step 3600 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:25.866304 Training Step 3600 \"loss\" =  2.5426414\n",
      "2018-08-29 09:19:26.067643 Test Step 3605 Finished\n",
      "2018-08-29 09:19:26.067766 Test Step 3605 \"min loss\" =  14.116499\n",
      "2018-08-29 09:19:26.067849 Test Step 3605 \"loss\" =  14.850229\n",
      "2018-08-29 09:19:26.112930 Training Step 3605 Finished Timing (Training: 0.914656, Test: 0.0840456) after 0.246324 seconds\n",
      "2018-08-29 09:19:26.113514 Training Step 3605 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:26.113919 Training Step 3605 \"loss\" =  2.592489\n",
      "2018-08-29 09:19:26.315779 Test Step 3610 Finished\n",
      "2018-08-29 09:19:26.315998 Test Step 3610 \"min loss\" =  14.116499\n",
      "2018-08-29 09:19:26.316142 Test Step 3610 \"loss\" =  14.827538\n",
      "2018-08-29 09:19:26.362172 Training Step 3610 Finished Timing (Training: 0.912118, Test: 0.0838305) after 0.248124 seconds\n",
      "2018-08-29 09:19:26.362326 Training Step 3610 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:26.362417 Training Step 3610 \"loss\" =  2.610183\n",
      "2018-08-29 09:19:26.564946 Test Step 3615 Finished\n",
      "2018-08-29 09:19:26.565112 Test Step 3615 \"min loss\" =  14.116499\n",
      "2018-08-29 09:19:26.565678 Test Step 3615 \"loss\" =  16.161015\n",
      "2018-08-29 09:19:26.611199 Training Step 3615 Finished Timing (Training: 0.911527, Test: 0.0835287) after 0.248687 seconds\n",
      "2018-08-29 09:19:26.611439 Training Step 3615 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:26.611575 Training Step 3615 \"loss\" =  2.6025388\n",
      "2018-08-29 09:19:26.814535 Test Step 3620 Finished\n",
      "2018-08-29 09:19:26.814688 Test Step 3620 \"min loss\" =  14.116499\n",
      "2018-08-29 09:19:26.815472 Test Step 3620 \"loss\" =  15.511507\n",
      "2018-08-29 09:19:26.860880 Training Step 3620 Finished Timing (Training: 0.911256, Test: 0.0832514) after 0.249164 seconds\n",
      "2018-08-29 09:19:26.861026 Training Step 3620 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:26.861835 Training Step 3620 \"loss\" =  2.5971763\n",
      "2018-08-29 09:19:27.063414 Test Step 3625 Finished\n",
      "2018-08-29 09:19:27.064197 Test Step 3625 \"min loss\" =  14.116499\n",
      "2018-08-29 09:19:27.064300 Test Step 3625 \"loss\" =  14.808881\n",
      "2018-08-29 09:19:27.109922 Training Step 3625 Finished Timing (Training: 0.910384, Test: 0.0835602) after 0.247981 seconds\n",
      "2018-08-29 09:19:27.110115 Training Step 3625 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:27.110184 Training Step 3625 \"loss\" =  2.5405252\n",
      "2018-08-29 09:19:27.311909 Test Step 3630 Finished\n",
      "2018-08-29 09:19:27.312569 Test Step 3630 \"min loss\" =  14.116499\n",
      "2018-08-29 09:19:27.312891 Test Step 3630 \"loss\" =  14.4786625\n",
      "2018-08-29 09:19:27.358360 Training Step 3630 Finished Timing (Training: 0.909836, Test: 0.0838193) after 0.248094 seconds\n",
      "2018-08-29 09:19:27.358864 Training Step 3630 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:27.358936 Training Step 3630 \"loss\" =  2.6049197\n",
      "2018-08-29 09:19:27.561155 Test Step 3635 Finished\n",
      "2018-08-29 09:19:27.561764 Test Step 3635 \"min loss\" =  14.116499\n",
      "2018-08-29 09:19:27.562206 Test Step 3635 \"loss\" =  14.286589\n",
      "2018-08-29 09:19:27.608137 Training Step 3635 Finished Timing (Training: 0.909809, Test: 0.0836988) after 0.249112 seconds\n",
      "2018-08-29 09:19:27.608289 Training Step 3635 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:27.608374 Training Step 3635 \"loss\" =  2.6236663\n",
      "2018-08-29 09:19:27.809923 Test Step 3640 Finished\n",
      "2018-08-29 09:19:27.810136 Test Step 3640 \"min loss\" =  14.116499\n",
      "2018-08-29 09:19:27.810240 Test Step 3640 \"loss\" =  14.425559\n",
      "2018-08-29 09:19:27.856540 Training Step 3640 Finished Timing (Training: 0.910247, Test: 0.0836916) after 0.248097 seconds\n",
      "2018-08-29 09:19:27.856726 Training Step 3640 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:27.856828 Training Step 3640 \"loss\" =  2.4221122\n",
      "2018-08-29 09:19:28.057381 Test Step 3645 Finished\n",
      "2018-08-29 09:19:28.058041 Test Step 3645 \"min loss\" =  14.116499\n",
      "2018-08-29 09:19:28.058136 Test Step 3645 \"loss\" =  14.480055\n",
      "2018-08-29 09:19:28.104395 Training Step 3645 Finished Timing (Training: 0.910424, Test: 0.0836202) after 0.24747 seconds\n",
      "2018-08-29 09:19:28.104541 Training Step 3645 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:28.104630 Training Step 3645 \"loss\" =  2.5172012\n",
      "2018-08-29 09:19:28.307682 Test Step 3650 Finished\n",
      "2018-08-29 09:19:28.307895 Test Step 3650 \"min loss\" =  14.116499\n",
      "2018-08-29 09:19:28.308017 Test Step 3650 \"loss\" =  15.055249\n",
      "2018-08-29 09:19:28.353474 Training Step 3650 Finished Timing (Training: 0.910115, Test: 0.0838198) after 0.24784 seconds\n",
      "2018-08-29 09:19:28.353651 Training Step 3650 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:28.354148 Training Step 3650 \"loss\" =  2.6915138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:19:28.555302 Test Step 3655 Finished\n",
      "2018-08-29 09:19:28.555465 Test Step 3655 \"min loss\" =  14.116499\n",
      "2018-08-29 09:19:28.556371 Test Step 3655 \"loss\" =  14.755426\n",
      "2018-08-29 09:19:28.603539 Training Step 3655 Finished Timing (Training: 0.909965, Test: 0.0836393) after 0.249312 seconds\n",
      "2018-08-29 09:19:28.603676 Training Step 3655 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:28.604392 Training Step 3655 \"loss\" =  2.2423892\n",
      "2018-08-29 09:19:28.806939 Test Step 3660 Finished\n",
      "2018-08-29 09:19:28.807154 Test Step 3660 \"min loss\" =  14.116499\n",
      "2018-08-29 09:19:28.807982 Test Step 3660 \"loss\" =  14.807343\n",
      "2018-08-29 09:19:28.853164 Training Step 3660 Finished Timing (Training: 0.909777, Test: 0.0836522) after 0.248682 seconds\n",
      "2018-08-29 09:19:28.853313 Training Step 3660 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:28.853385 Training Step 3660 \"loss\" =  2.4003344\n",
      "2018-08-29 09:19:29.055762 Test Step 3665 Finished\n",
      "2018-08-29 09:19:29.055930 Test Step 3665 \"min loss\" =  14.116499\n",
      "2018-08-29 09:19:29.056506 Test Step 3665 \"loss\" =  14.535732\n",
      "2018-08-29 09:19:29.102157 Training Step 3665 Finished Timing (Training: 0.909889, Test: 0.083681) after 0.248681 seconds\n",
      "2018-08-29 09:19:29.102336 Training Step 3665 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:29.102446 Training Step 3665 \"loss\" =  2.8153968\n",
      "2018-08-29 09:19:29.305997 Test Step 3670 Finished\n",
      "2018-08-29 09:19:29.306255 Test Step 3670 \"min loss\" =  14.116499\n",
      "2018-08-29 09:19:29.307284 Test Step 3670 \"loss\" =  14.373587\n",
      "2018-08-29 09:19:29.353104 Training Step 3670 Finished Timing (Training: 0.90922, Test: 0.0838082) after 0.249329 seconds\n",
      "2018-08-29 09:19:29.353233 Training Step 3670 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:29.353957 Training Step 3670 \"loss\" =  2.3820763\n",
      "2018-08-29 09:19:29.556700 Test Step 3675 Finished\n",
      "2018-08-29 09:19:29.556848 Test Step 3675 \"min loss\" =  14.116499\n",
      "2018-08-29 09:19:29.557464 Test Step 3675 \"loss\" =  15.048403\n",
      "2018-08-29 09:19:29.603392 Training Step 3675 Finished Timing (Training: 0.909159, Test: 0.0837632) after 0.24903 seconds\n",
      "2018-08-29 09:19:29.603524 Training Step 3675 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:29.604241 Training Step 3675 \"loss\" =  2.2864323\n",
      "2018-08-29 09:19:29.806889 Test Step 3680 Finished\n",
      "2018-08-29 09:19:29.807026 Test Step 3680 \"min loss\" =  14.116499\n",
      "2018-08-29 09:19:29.807104 Test Step 3680 \"loss\" =  14.829085\n",
      "2018-08-29 09:19:29.853893 Training Step 3680 Finished Timing (Training: 0.909243, Test: 0.0838098) after 0.249576 seconds\n",
      "2018-08-29 09:19:29.854020 Training Step 3680 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:29.854735 Training Step 3680 \"loss\" =  2.41744\n",
      "2018-08-29 09:19:30.055692 Test Step 3685 Finished\n",
      "2018-08-29 09:19:30.056225 Test Step 3685 \"min loss\" =  14.116499\n",
      "2018-08-29 09:19:30.056368 Test Step 3685 \"loss\" =  14.361509\n",
      "2018-08-29 09:19:30.101924 Training Step 3685 Finished Timing (Training: 0.909269, Test: 0.0837662) after 0.247101 seconds\n",
      "2018-08-29 09:19:30.102082 Training Step 3685 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:30.102571 Training Step 3685 \"loss\" =  2.2495768\n",
      "2018-08-29 09:19:30.304232 Test Step 3690 Finished\n",
      "2018-08-29 09:19:30.304899 Test Step 3690 \"min loss\" =  14.116499\n",
      "2018-08-29 09:19:30.304981 Test Step 3690 \"loss\" =  14.519275\n",
      "2018-08-29 09:19:30.350597 Training Step 3690 Finished Timing (Training: 0.909209, Test: 0.083722) after 0.247926 seconds\n",
      "2018-08-29 09:19:30.350739 Training Step 3690 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:30.351239 Training Step 3690 \"loss\" =  2.375434\n",
      "2018-08-29 09:19:30.551984 Test Step 3695 Finished\n",
      "2018-08-29 09:19:30.552120 Test Step 3695 \"min loss\" =  14.116499\n",
      "2018-08-29 09:19:30.552703 Test Step 3695 \"loss\" =  14.139152\n",
      "2018-08-29 09:19:30.598215 Training Step 3695 Finished Timing (Training: 0.909228, Test: 0.0836387) after 0.246885 seconds\n",
      "2018-08-29 09:19:30.598351 Training Step 3695 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:30.598846 Training Step 3695 \"loss\" =  2.4481342\n",
      "2018-08-29 09:19:30.800502 Test Step 3700 Finished\n",
      "2018-08-29 09:19:30.800657 Test Step 3700 \"min loss\" =  13.860678\n",
      "2018-08-29 09:19:30.800731 Test Step 3700 \"loss\" =  13.860678\n",
      "2018-08-29 09:19:30.847475 Training Step 3700 Finished Timing (Training: 0.909018, Test: 0.0836005) after 0.248143 seconds\n",
      "2018-08-29 09:19:30.847603 Training Step 3700 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:30.848310 Training Step 3700 \"loss\" =  2.370487\n",
      "2018-08-29 09:19:31.050518 Test Step 3705 Finished\n",
      "2018-08-29 09:19:31.050672 Test Step 3705 \"min loss\" =  13.860678\n",
      "2018-08-29 09:19:31.050744 Test Step 3705 \"loss\" =  14.893\n",
      "2018-08-29 09:19:31.097017 Training Step 3705 Finished Timing (Training: 0.912157, Test: 0.0864549) after 0.24823 seconds\n",
      "2018-08-29 09:19:31.097162 Training Step 3705 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:31.097805 Training Step 3705 \"loss\" =  2.751087\n",
      "2018-08-29 09:19:31.299337 Test Step 3710 Finished\n",
      "2018-08-29 09:19:31.299467 Test Step 3710 \"min loss\" =  13.860678\n",
      "2018-08-29 09:19:31.299531 Test Step 3710 \"loss\" =  15.467465\n",
      "2018-08-29 09:19:31.346335 Training Step 3710 Finished Timing (Training: 0.910088, Test: 0.0842282) after 0.248026 seconds\n",
      "2018-08-29 09:19:31.346508 Training Step 3710 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:31.346583 Training Step 3710 \"loss\" =  2.2032986\n",
      "2018-08-29 09:19:31.548999 Test Step 3715 Finished\n",
      "2018-08-29 09:19:31.549134 Test Step 3715 \"min loss\" =  13.860678\n",
      "2018-08-29 09:19:31.549682 Test Step 3715 \"loss\" =  15.820175\n",
      "2018-08-29 09:19:31.595427 Training Step 3715 Finished Timing (Training: 0.910307, Test: 0.0837534) after 0.248299 seconds\n",
      "2018-08-29 09:19:31.595556 Training Step 3715 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:31.595620 Training Step 3715 \"loss\" =  2.4728365\n",
      "2018-08-29 09:19:31.797679 Test Step 3720 Finished\n",
      "2018-08-29 09:19:31.798227 Test Step 3720 \"min loss\" =  13.860678\n",
      "2018-08-29 09:19:31.798303 Test Step 3720 \"loss\" =  14.345984\n",
      "2018-08-29 09:19:31.843894 Training Step 3720 Finished Timing (Training: 0.909881, Test: 0.0836918) after 0.247245 seconds\n",
      "2018-08-29 09:19:31.844038 Training Step 3720 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:31.844149 Training Step 3720 \"loss\" =  2.4706154\n",
      "2018-08-29 09:19:32.047786 Test Step 3725 Finished\n",
      "2018-08-29 09:19:32.047906 Test Step 3725 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:32.048698 Test Step 3725 \"loss\" =  13.799004\n",
      "2018-08-29 09:19:32.093702 Training Step 3725 Finished Timing (Training: 0.909765, Test: 0.0836194) after 0.249036 seconds\n",
      "2018-08-29 09:19:32.093826 Training Step 3725 \"min loss\" =  2.1787293\n",
      "2018-08-29 09:19:32.093881 Training Step 3725 \"loss\" =  2.7598498\n",
      "2018-08-29 09:19:32.296364 Test Step 3730 Finished\n",
      "2018-08-29 09:19:32.296575 Test Step 3730 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:32.297527 Test Step 3730 \"loss\" =  14.436706\n",
      "2018-08-29 09:19:32.342999 Training Step 3730 Finished Timing (Training: 0.909688, Test: 0.0835139) after 0.249039 seconds\n",
      "2018-08-29 09:19:32.343150 Training Step 3730 \"min loss\" =  2.1547477\n",
      "2018-08-29 09:19:32.344085 Training Step 3730 \"loss\" =  2.2287464\n",
      "2018-08-29 09:19:32.546794 Test Step 3735 Finished\n",
      "2018-08-29 09:19:32.546936 Test Step 3735 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:32.547008 Test Step 3735 \"loss\" =  14.346869\n",
      "2018-08-29 09:19:32.592429 Training Step 3735 Finished Timing (Training: 0.909875, Test: 0.0834236) after 0.248233 seconds\n",
      "2018-08-29 09:19:32.592970 Training Step 3735 \"min loss\" =  2.1547477\n",
      "2018-08-29 09:19:32.593194 Training Step 3735 \"loss\" =  2.2516954\n",
      "2018-08-29 09:19:32.794444 Test Step 3740 Finished\n",
      "2018-08-29 09:19:32.794577 Test Step 3740 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:32.795369 Test Step 3740 \"loss\" =  13.815199\n",
      "2018-08-29 09:19:32.841020 Training Step 3740 Finished Timing (Training: 0.909747, Test: 0.0832461) after 0.247713 seconds\n",
      "2018-08-29 09:19:32.841166 Training Step 3740 \"min loss\" =  2.1168003\n",
      "2018-08-29 09:19:32.841241 Training Step 3740 \"loss\" =  2.6210384\n",
      "2018-08-29 09:19:33.043571 Test Step 3745 Finished\n",
      "2018-08-29 09:19:33.043710 Test Step 3745 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:33.043786 Test Step 3745 \"loss\" =  14.6477585\n",
      "2018-08-29 09:19:33.088827 Training Step 3745 Finished Timing (Training: 0.909694, Test: 0.0832218) after 0.24623 seconds\n",
      "2018-08-29 09:19:33.088970 Training Step 3745 \"min loss\" =  2.1168003\n",
      "2018-08-29 09:19:33.089040 Training Step 3745 \"loss\" =  2.4417837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:19:33.291323 Test Step 3750 Finished\n",
      "2018-08-29 09:19:33.291502 Test Step 3750 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:33.292352 Test Step 3750 \"loss\" =  14.743791\n",
      "2018-08-29 09:19:33.337985 Training Step 3750 Finished Timing (Training: 0.90923, Test: 0.0834541) after 0.247973 seconds\n",
      "2018-08-29 09:19:33.338138 Training Step 3750 \"min loss\" =  2.1168003\n",
      "2018-08-29 09:19:33.338207 Training Step 3750 \"loss\" =  2.4468236\n",
      "2018-08-29 09:19:33.541447 Test Step 3755 Finished\n",
      "2018-08-29 09:19:33.541620 Test Step 3755 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:33.542340 Test Step 3755 \"loss\" =  14.139577\n",
      "2018-08-29 09:19:33.587793 Training Step 3755 Finished Timing (Training: 0.909077, Test: 0.0834345) after 0.24852 seconds\n",
      "2018-08-29 09:19:33.587920 Training Step 3755 \"min loss\" =  2.082714\n",
      "2018-08-29 09:19:33.587984 Training Step 3755 \"loss\" =  2.3895035\n",
      "2018-08-29 09:19:33.791604 Test Step 3760 Finished\n",
      "2018-08-29 09:19:33.791761 Test Step 3760 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:33.791835 Test Step 3760 \"loss\" =  14.383922\n",
      "2018-08-29 09:19:33.837285 Training Step 3760 Finished Timing (Training: 0.909132, Test: 0.0835918) after 0.248613 seconds\n",
      "2018-08-29 09:19:33.837413 Training Step 3760 \"min loss\" =  2.082714\n",
      "2018-08-29 09:19:33.838085 Training Step 3760 \"loss\" =  2.3521028\n",
      "2018-08-29 09:19:34.041815 Test Step 3765 Finished\n",
      "2018-08-29 09:19:34.041966 Test Step 3765 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:34.042784 Test Step 3765 \"loss\" =  14.640584\n",
      "2018-08-29 09:19:34.088184 Training Step 3765 Finished Timing (Training: 0.909098, Test: 0.0835482) after 0.250012 seconds\n",
      "2018-08-29 09:19:34.088327 Training Step 3765 \"min loss\" =  2.082714\n",
      "2018-08-29 09:19:34.088398 Training Step 3765 \"loss\" =  2.517691\n",
      "2018-08-29 09:19:34.290755 Test Step 3770 Finished\n",
      "2018-08-29 09:19:34.290898 Test Step 3770 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:34.290961 Test Step 3770 \"loss\" =  14.581451\n",
      "2018-08-29 09:19:34.337118 Training Step 3770 Finished Timing (Training: 0.909135, Test: 0.0835666) after 0.248627 seconds\n",
      "2018-08-29 09:19:34.337262 Training Step 3770 \"min loss\" =  2.082714\n",
      "2018-08-29 09:19:34.337320 Training Step 3770 \"loss\" =  2.3494256\n",
      "2018-08-29 09:19:34.539709 Test Step 3775 Finished\n",
      "2018-08-29 09:19:34.539859 Test Step 3775 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:34.540752 Test Step 3775 \"loss\" =  15.163609\n",
      "2018-08-29 09:19:34.586343 Training Step 3775 Finished Timing (Training: 0.909223, Test: 0.0834676) after 0.248941 seconds\n",
      "2018-08-29 09:19:34.586473 Training Step 3775 \"min loss\" =  2.082714\n",
      "2018-08-29 09:19:34.586536 Training Step 3775 \"loss\" =  2.4230247\n",
      "2018-08-29 09:19:34.789365 Test Step 3780 Finished\n",
      "2018-08-29 09:19:34.789517 Test Step 3780 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:34.789588 Test Step 3780 \"loss\" =  14.946675\n",
      "2018-08-29 09:19:34.837034 Training Step 3780 Finished Timing (Training: 0.909256, Test: 0.0835195) after 0.249537 seconds\n",
      "2018-08-29 09:19:34.837254 Training Step 3780 \"min loss\" =  2.082714\n",
      "2018-08-29 09:19:34.837329 Training Step 3780 \"loss\" =  2.482022\n",
      "2018-08-29 09:19:35.038796 Test Step 3785 Finished\n",
      "2018-08-29 09:19:35.038935 Test Step 3785 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:35.039039 Test Step 3785 \"loss\" =  14.745136\n",
      "2018-08-29 09:19:35.085366 Training Step 3785 Finished Timing (Training: 0.909313, Test: 0.0834789) after 0.247957 seconds\n",
      "2018-08-29 09:19:35.085493 Training Step 3785 \"min loss\" =  2.082714\n",
      "2018-08-29 09:19:35.085572 Training Step 3785 \"loss\" =  2.6994946\n",
      "2018-08-29 09:19:35.286556 Test Step 3790 Finished\n",
      "2018-08-29 09:19:35.286730 Test Step 3790 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:35.287458 Test Step 3790 \"loss\" =  14.377257\n",
      "2018-08-29 09:19:35.332861 Training Step 3790 Finished Timing (Training: 0.909415, Test: 0.0834778) after 0.247208 seconds\n",
      "2018-08-29 09:19:35.333338 Training Step 3790 \"min loss\" =  2.082714\n",
      "2018-08-29 09:19:35.333603 Training Step 3790 \"loss\" =  2.767074\n",
      "2018-08-29 09:19:35.534538 Test Step 3795 Finished\n",
      "2018-08-29 09:19:35.535107 Test Step 3795 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:35.535182 Test Step 3795 \"loss\" =  15.262809\n",
      "2018-08-29 09:19:35.580694 Training Step 3795 Finished Timing (Training: 0.909428, Test: 0.0834577) after 0.246806 seconds\n",
      "2018-08-29 09:19:35.580845 Training Step 3795 \"min loss\" =  2.082714\n",
      "2018-08-29 09:19:35.580906 Training Step 3795 \"loss\" =  2.5943322\n",
      "2018-08-29 09:19:35.782876 Test Step 3800 Finished\n",
      "2018-08-29 09:19:35.783054 Test Step 3800 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:35.783743 Test Step 3800 \"loss\" =  14.600039\n",
      "2018-08-29 09:19:35.828979 Training Step 3800 Finished Timing (Training: 0.909544, Test: 0.0834387) after 0.247991 seconds\n",
      "2018-08-29 09:19:35.829119 Training Step 3800 \"min loss\" =  2.082714\n",
      "2018-08-29 09:19:35.829761 Training Step 3800 \"loss\" =  2.540409\n",
      "2018-08-29 09:19:36.031682 Test Step 3805 Finished\n",
      "2018-08-29 09:19:36.031902 Test Step 3805 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:36.032455 Test Step 3805 \"loss\" =  15.049829\n",
      "2018-08-29 09:19:36.077667 Training Step 3805 Finished Timing (Training: 0.90967, Test: 0.0856128) after 0.24782 seconds\n",
      "2018-08-29 09:19:36.078232 Training Step 3805 \"min loss\" =  2.082714\n",
      "2018-08-29 09:19:36.078576 Training Step 3805 \"loss\" =  2.2622654\n",
      "2018-08-29 09:19:36.281123 Test Step 3810 Finished\n",
      "2018-08-29 09:19:36.281296 Test Step 3810 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:36.282313 Test Step 3810 \"loss\" =  14.399037\n",
      "2018-08-29 09:19:36.327873 Training Step 3810 Finished Timing (Training: 0.907495, Test: 0.0854363) after 0.249208 seconds\n",
      "2018-08-29 09:19:36.328028 Training Step 3810 \"min loss\" =  2.082714\n",
      "2018-08-29 09:19:36.328127 Training Step 3810 \"loss\" =  2.4463506\n",
      "2018-08-29 09:19:36.530962 Test Step 3815 Finished\n",
      "2018-08-29 09:19:36.531673 Test Step 3815 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:36.531768 Test Step 3815 \"loss\" =  13.984651\n",
      "2018-08-29 09:19:36.577605 Training Step 3815 Finished Timing (Training: 0.907136, Test: 0.0848712) after 0.248211 seconds\n",
      "2018-08-29 09:19:36.578084 Training Step 3815 \"min loss\" =  2.082714\n",
      "2018-08-29 09:19:36.578155 Training Step 3815 \"loss\" =  2.133858\n",
      "2018-08-29 09:19:36.779915 Test Step 3820 Finished\n",
      "2018-08-29 09:19:36.780410 Test Step 3820 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:36.780560 Test Step 3820 \"loss\" =  14.750331\n",
      "2018-08-29 09:19:36.826371 Training Step 3820 Finished Timing (Training: 0.907464, Test: 0.0846143) after 0.247639 seconds\n",
      "2018-08-29 09:19:36.826912 Training Step 3820 \"min loss\" =  2.082714\n",
      "2018-08-29 09:19:36.827071 Training Step 3820 \"loss\" =  2.2369435\n",
      "2018-08-29 09:19:37.029365 Test Step 3825 Finished\n",
      "2018-08-29 09:19:37.029518 Test Step 3825 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:37.030086 Test Step 3825 \"loss\" =  15.505985\n",
      "2018-08-29 09:19:37.075812 Training Step 3825 Finished Timing (Training: 0.907636, Test: 0.0843956) after 0.248579 seconds\n",
      "2018-08-29 09:19:37.075950 Training Step 3825 \"min loss\" =  2.082714\n",
      "2018-08-29 09:19:37.076013 Training Step 3825 \"loss\" =  2.424889\n",
      "2018-08-29 09:19:37.279298 Test Step 3830 Finished\n",
      "2018-08-29 09:19:37.279482 Test Step 3830 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:37.279561 Test Step 3830 \"loss\" =  15.194567\n",
      "2018-08-29 09:19:37.324820 Training Step 3830 Finished Timing (Training: 0.907935, Test: 0.084683) after 0.248289 seconds\n",
      "2018-08-29 09:19:37.324972 Training Step 3830 \"min loss\" =  2.082714\n",
      "2018-08-29 09:19:37.325636 Training Step 3830 \"loss\" =  2.3285744\n",
      "2018-08-29 09:19:37.527658 Test Step 3835 Finished\n",
      "2018-08-29 09:19:37.527809 Test Step 3835 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:37.527892 Test Step 3835 \"loss\" =  14.377158\n",
      "2018-08-29 09:19:37.572972 Training Step 3835 Finished Timing (Training: 0.908423, Test: 0.0845177) after 0.247244 seconds\n",
      "2018-08-29 09:19:37.573106 Training Step 3835 \"min loss\" =  2.082714\n",
      "2018-08-29 09:19:37.573178 Training Step 3835 \"loss\" =  2.3430793\n",
      "2018-08-29 09:19:37.775061 Test Step 3840 Finished\n",
      "2018-08-29 09:19:37.775754 Test Step 3840 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:37.775974 Test Step 3840 \"loss\" =  15.507805\n",
      "2018-08-29 09:19:37.821103 Training Step 3840 Finished Timing (Training: 0.908735, Test: 0.084412) after 0.24784 seconds\n",
      "2018-08-29 09:19:37.821231 Training Step 3840 \"min loss\" =  2.0689483\n",
      "2018-08-29 09:19:37.821295 Training Step 3840 \"loss\" =  2.4875658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:19:38.024348 Test Step 3845 Finished\n",
      "2018-08-29 09:19:38.025000 Test Step 3845 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:38.025125 Test Step 3845 \"loss\" =  14.911091\n",
      "2018-08-29 09:19:38.071262 Training Step 3845 Finished Timing (Training: 0.908748, Test: 0.0842472) after 0.249884 seconds\n",
      "2018-08-29 09:19:38.071415 Training Step 3845 \"min loss\" =  2.0689483\n",
      "2018-08-29 09:19:38.071541 Training Step 3845 \"loss\" =  2.843621\n",
      "2018-08-29 09:19:38.272754 Test Step 3850 Finished\n",
      "2018-08-29 09:19:38.273386 Test Step 3850 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:38.273655 Test Step 3850 \"loss\" =  15.199386\n",
      "2018-08-29 09:19:38.319868 Training Step 3850 Finished Timing (Training: 0.90893, Test: 0.0841731) after 0.248195 seconds\n",
      "2018-08-29 09:19:38.320049 Training Step 3850 \"min loss\" =  2.0689483\n",
      "2018-08-29 09:19:38.320121 Training Step 3850 \"loss\" =  2.4389248\n",
      "2018-08-29 09:19:38.521339 Test Step 3855 Finished\n",
      "2018-08-29 09:19:38.521483 Test Step 3855 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:38.521547 Test Step 3855 \"loss\" =  14.800071\n",
      "2018-08-29 09:19:38.567580 Training Step 3855 Finished Timing (Training: 0.909176, Test: 0.0839806) after 0.246475 seconds\n",
      "2018-08-29 09:19:38.567736 Training Step 3855 \"min loss\" =  2.0689483\n",
      "2018-08-29 09:19:38.568649 Training Step 3855 \"loss\" =  2.3938987\n",
      "2018-08-29 09:19:38.769880 Test Step 3860 Finished\n",
      "2018-08-29 09:19:38.770665 Test Step 3860 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:38.770766 Test Step 3860 \"loss\" =  16.227303\n",
      "2018-08-29 09:19:38.817028 Training Step 3860 Finished Timing (Training: 0.909157, Test: 0.0838399) after 0.248265 seconds\n",
      "2018-08-29 09:19:38.817158 Training Step 3860 \"min loss\" =  2.0689483\n",
      "2018-08-29 09:19:38.817227 Training Step 3860 \"loss\" =  2.3987834\n",
      "2018-08-29 09:19:39.018965 Test Step 3865 Finished\n",
      "2018-08-29 09:19:39.019098 Test Step 3865 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:39.020003 Test Step 3865 \"loss\" =  16.222725\n",
      "2018-08-29 09:19:39.065634 Training Step 3865 Finished Timing (Training: 0.909046, Test: 0.0837852) after 0.247477 seconds\n",
      "2018-08-29 09:19:39.065780 Training Step 3865 \"min loss\" =  2.0689483\n",
      "2018-08-29 09:19:39.066606 Training Step 3865 \"loss\" =  2.2256691\n",
      "2018-08-29 09:19:39.268272 Test Step 3870 Finished\n",
      "2018-08-29 09:19:39.268434 Test Step 3870 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:39.269197 Test Step 3870 \"loss\" =  15.706607\n",
      "2018-08-29 09:19:39.314933 Training Step 3870 Finished Timing (Training: 0.908757, Test: 0.0837746) after 0.248232 seconds\n",
      "2018-08-29 09:19:39.315083 Training Step 3870 \"min loss\" =  2.0689483\n",
      "2018-08-29 09:19:39.315152 Training Step 3870 \"loss\" =  2.4371774\n",
      "2018-08-29 09:19:39.519222 Test Step 3875 Finished\n",
      "2018-08-29 09:19:39.519378 Test Step 3875 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:39.519497 Test Step 3875 \"loss\" =  16.763653\n",
      "2018-08-29 09:19:39.565615 Training Step 3875 Finished Timing (Training: 0.908518, Test: 0.0838283) after 0.249506 seconds\n",
      "2018-08-29 09:19:39.565766 Training Step 3875 \"min loss\" =  2.0689483\n",
      "2018-08-29 09:19:39.566543 Training Step 3875 \"loss\" =  2.2336001\n",
      "2018-08-29 09:19:39.769606 Test Step 3880 Finished\n",
      "2018-08-29 09:19:39.769774 Test Step 3880 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:39.769847 Test Step 3880 \"loss\" =  14.755969\n",
      "2018-08-29 09:19:39.815910 Training Step 3880 Finished Timing (Training: 0.908497, Test: 0.0837485) after 0.249269 seconds\n",
      "2018-08-29 09:19:39.816057 Training Step 3880 \"min loss\" =  2.0689483\n",
      "2018-08-29 09:19:39.816849 Training Step 3880 \"loss\" =  2.6007023\n",
      "2018-08-29 09:19:40.019304 Test Step 3885 Finished\n",
      "2018-08-29 09:19:40.019835 Test Step 3885 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:40.019902 Test Step 3885 \"loss\" =  14.387322\n",
      "2018-08-29 09:19:40.065622 Training Step 3885 Finished Timing (Training: 0.908481, Test: 0.0836556) after 0.24868 seconds\n",
      "2018-08-29 09:19:40.065776 Training Step 3885 \"min loss\" =  2.0689483\n",
      "2018-08-29 09:19:40.065844 Training Step 3885 \"loss\" =  2.4661424\n",
      "2018-08-29 09:19:40.268324 Test Step 3890 Finished\n",
      "2018-08-29 09:19:40.268456 Test Step 3890 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:40.268516 Test Step 3890 \"loss\" =  14.2882805\n",
      "2018-08-29 09:19:40.314919 Training Step 3890 Finished Timing (Training: 0.908502, Test: 0.0836347) after 0.248991 seconds\n",
      "2018-08-29 09:19:40.315531 Training Step 3890 \"min loss\" =  2.0689483\n",
      "2018-08-29 09:19:40.315828 Training Step 3890 \"loss\" =  2.5229657\n",
      "2018-08-29 09:19:40.517292 Test Step 3895 Finished\n",
      "2018-08-29 09:19:40.517435 Test Step 3895 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:40.518149 Test Step 3895 \"loss\" =  14.408709\n",
      "2018-08-29 09:19:40.563530 Training Step 3895 Finished Timing (Training: 0.908412, Test: 0.0836148) after 0.24761 seconds\n",
      "2018-08-29 09:19:40.563675 Training Step 3895 \"min loss\" =  2.0689483\n",
      "2018-08-29 09:19:40.563743 Training Step 3895 \"loss\" =  2.3685203\n",
      "2018-08-29 09:19:40.767288 Test Step 3900 Finished\n",
      "2018-08-29 09:19:40.767454 Test Step 3900 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:40.767530 Test Step 3900 \"loss\" =  15.016444\n",
      "2018-08-29 09:19:40.812918 Training Step 3900 Finished Timing (Training: 0.908667, Test: 0.0836264) after 0.249082 seconds\n",
      "2018-08-29 09:19:40.813078 Training Step 3900 \"min loss\" =  2.0689483\n",
      "2018-08-29 09:19:40.813796 Training Step 3900 \"loss\" =  2.2228713\n",
      "2018-08-29 09:19:41.015218 Test Step 3905 Finished\n",
      "2018-08-29 09:19:41.015367 Test Step 3905 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:41.015438 Test Step 3905 \"loss\" =  15.171791\n",
      "2018-08-29 09:19:41.060738 Training Step 3905 Finished Timing (Training: 0.914786, Test: 0.0838485) after 0.246855 seconds\n",
      "2018-08-29 09:19:41.060884 Training Step 3905 \"min loss\" =  2.0689483\n",
      "2018-08-29 09:19:41.060952 Training Step 3905 \"loss\" =  2.27132\n",
      "2018-08-29 09:19:41.263989 Test Step 3910 Finished\n",
      "2018-08-29 09:19:41.264144 Test Step 3910 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:41.265064 Test Step 3910 \"loss\" =  15.295264\n",
      "2018-08-29 09:19:41.310812 Training Step 3910 Finished Timing (Training: 0.912122, Test: 0.0832687) after 0.249774 seconds\n",
      "2018-08-29 09:19:41.310957 Training Step 3910 \"min loss\" =  2.0689483\n",
      "2018-08-29 09:19:41.311023 Training Step 3910 \"loss\" =  2.2968102\n",
      "2018-08-29 09:19:41.511940 Test Step 3915 Finished\n",
      "2018-08-29 09:19:41.512099 Test Step 3915 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:41.512165 Test Step 3915 \"loss\" =  15.060845\n",
      "2018-08-29 09:19:41.558795 Training Step 3915 Finished Timing (Training: 0.911535, Test: 0.0829977) after 0.247692 seconds\n",
      "2018-08-29 09:19:41.558935 Training Step 3915 \"min loss\" =  2.0689483\n",
      "2018-08-29 09:19:41.559001 Training Step 3915 \"loss\" =  2.21429\n",
      "2018-08-29 09:19:41.760558 Test Step 3920 Finished\n",
      "2018-08-29 09:19:41.761218 Test Step 3920 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:41.761329 Test Step 3920 \"loss\" =  14.6262665\n",
      "2018-08-29 09:19:41.807481 Training Step 3920 Finished Timing (Training: 0.911156, Test: 0.0833603) after 0.2484 seconds\n",
      "2018-08-29 09:19:41.807939 Training Step 3920 \"min loss\" =  2.0358503\n",
      "2018-08-29 09:19:41.808018 Training Step 3920 \"loss\" =  2.287237\n",
      "2018-08-29 09:19:42.011452 Test Step 3925 Finished\n",
      "2018-08-29 09:19:42.011615 Test Step 3925 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:42.011687 Test Step 3925 \"loss\" =  14.004254\n",
      "2018-08-29 09:19:42.056795 Training Step 3925 Finished Timing (Training: 0.911343, Test: 0.0831755) after 0.2483 seconds\n",
      "2018-08-29 09:19:42.057480 Training Step 3925 \"min loss\" =  2.0358503\n",
      "2018-08-29 09:19:42.057549 Training Step 3925 \"loss\" =  2.5148795\n",
      "2018-08-29 09:19:42.260955 Test Step 3930 Finished\n",
      "2018-08-29 09:19:42.261180 Test Step 3930 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:42.261769 Test Step 3930 \"loss\" =  15.131354\n",
      "2018-08-29 09:19:42.306901 Training Step 3930 Finished Timing (Training: 0.910225, Test: 0.0837191) after 0.248827 seconds\n",
      "2018-08-29 09:19:42.307461 Training Step 3930 \"min loss\" =  2.035497\n",
      "2018-08-29 09:19:42.307780 Training Step 3930 \"loss\" =  2.4725337\n",
      "2018-08-29 09:19:42.510436 Test Step 3935 Finished\n",
      "2018-08-29 09:19:42.510582 Test Step 3935 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:42.510658 Test Step 3935 \"loss\" =  15.415609\n",
      "2018-08-29 09:19:42.557003 Training Step 3935 Finished Timing (Training: 0.909798, Test: 0.0835762) after 0.249141 seconds\n",
      "2018-08-29 09:19:42.557143 Training Step 3935 \"min loss\" =  2.035497\n",
      "2018-08-29 09:19:42.557234 Training Step 3935 \"loss\" =  2.335334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:19:42.759327 Test Step 3940 Finished\n",
      "2018-08-29 09:19:42.759872 Test Step 3940 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:42.759960 Test Step 3940 \"loss\" =  14.842424\n",
      "2018-08-29 09:19:42.805034 Training Step 3940 Finished Timing (Training: 0.909643, Test: 0.0835244) after 0.246721 seconds\n",
      "2018-08-29 09:19:42.805180 Training Step 3940 \"min loss\" =  2.035497\n",
      "2018-08-29 09:19:42.805729 Training Step 3940 \"loss\" =  2.1821573\n",
      "2018-08-29 09:19:43.007566 Test Step 3945 Finished\n",
      "2018-08-29 09:19:43.007754 Test Step 3945 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:43.007832 Test Step 3945 \"loss\" =  14.848202\n",
      "2018-08-29 09:19:43.053828 Training Step 3945 Finished Timing (Training: 0.909599, Test: 0.0836014) after 0.247571 seconds\n",
      "2018-08-29 09:19:43.054304 Training Step 3945 \"min loss\" =  2.035497\n",
      "2018-08-29 09:19:43.054380 Training Step 3945 \"loss\" =  2.3197439\n",
      "2018-08-29 09:19:43.257050 Test Step 3950 Finished\n",
      "2018-08-29 09:19:43.257603 Test Step 3950 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:43.257676 Test Step 3950 \"loss\" =  14.623789\n",
      "2018-08-29 09:19:43.303505 Training Step 3950 Finished Timing (Training: 0.909212, Test: 0.0835817) after 0.248356 seconds\n",
      "2018-08-29 09:19:43.303637 Training Step 3950 \"min loss\" =  2.035497\n",
      "2018-08-29 09:19:43.304306 Training Step 3950 \"loss\" =  2.0925586\n",
      "2018-08-29 09:19:43.505079 Test Step 3955 Finished\n",
      "2018-08-29 09:19:43.505222 Test Step 3955 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:43.505291 Test Step 3955 \"loss\" =  15.1532345\n",
      "2018-08-29 09:19:43.550355 Training Step 3955 Finished Timing (Training: 0.909501, Test: 0.0834468) after 0.245813 seconds\n",
      "2018-08-29 09:19:43.550509 Training Step 3955 \"min loss\" =  1.9879682\n",
      "2018-08-29 09:19:43.550584 Training Step 3955 \"loss\" =  1.9879682\n",
      "2018-08-29 09:19:43.752728 Test Step 3960 Finished\n",
      "2018-08-29 09:19:43.753237 Test Step 3960 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:43.753452 Test Step 3960 \"loss\" =  16.298323\n",
      "2018-08-29 09:19:43.798937 Training Step 3960 Finished Timing (Training: 0.90954, Test: 0.0834477) after 0.248262 seconds\n",
      "2018-08-29 09:19:43.799074 Training Step 3960 \"min loss\" =  1.9879682\n",
      "2018-08-29 09:19:43.799153 Training Step 3960 \"loss\" =  2.4440289\n",
      "2018-08-29 09:19:44.000885 Test Step 3965 Finished\n",
      "2018-08-29 09:19:44.001069 Test Step 3965 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:44.001141 Test Step 3965 \"loss\" =  15.122969\n",
      "2018-08-29 09:19:44.047309 Training Step 3965 Finished Timing (Training: 0.909892, Test: 0.0834246) after 0.248073 seconds\n",
      "2018-08-29 09:19:44.047454 Training Step 3965 \"min loss\" =  1.9879682\n",
      "2018-08-29 09:19:44.047516 Training Step 3965 \"loss\" =  2.1632683\n",
      "2018-08-29 09:19:44.251109 Test Step 3970 Finished\n",
      "2018-08-29 09:19:44.251800 Test Step 3970 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:44.252230 Test Step 3970 \"loss\" =  14.740856\n",
      "2018-08-29 09:19:44.297601 Training Step 3970 Finished Timing (Training: 0.909679, Test: 0.0833553) after 0.24909 seconds\n",
      "2018-08-29 09:19:44.297770 Training Step 3970 \"min loss\" =  1.9496381\n",
      "2018-08-29 09:19:44.298700 Training Step 3970 \"loss\" =  2.3841963\n",
      "2018-08-29 09:19:44.499805 Test Step 3975 Finished\n",
      "2018-08-29 09:19:44.499965 Test Step 3975 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:44.500981 Test Step 3975 \"loss\" =  15.453355\n",
      "2018-08-29 09:19:44.546395 Training Step 3975 Finished Timing (Training: 0.909258, Test: 0.0833338) after 0.24716 seconds\n",
      "2018-08-29 09:19:44.546534 Training Step 3975 \"min loss\" =  1.9496381\n",
      "2018-08-29 09:19:44.546597 Training Step 3975 \"loss\" =  2.8497963\n",
      "2018-08-29 09:19:44.748799 Test Step 3980 Finished\n",
      "2018-08-29 09:19:44.749375 Test Step 3980 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:44.749467 Test Step 3980 \"loss\" =  14.192195\n",
      "2018-08-29 09:19:44.794756 Training Step 3980 Finished Timing (Training: 0.90949, Test: 0.0832931) after 0.248085 seconds\n",
      "2018-08-29 09:19:44.794899 Training Step 3980 \"min loss\" =  1.9496381\n",
      "2018-08-29 09:19:44.795619 Training Step 3980 \"loss\" =  2.3892906\n",
      "2018-08-29 09:19:44.997612 Test Step 3985 Finished\n",
      "2018-08-29 09:19:44.998055 Test Step 3985 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:44.998469 Test Step 3985 \"loss\" =  15.419866\n",
      "2018-08-29 09:19:45.043908 Training Step 3985 Finished Timing (Training: 0.909518, Test: 0.0832253) after 0.24819 seconds\n",
      "2018-08-29 09:19:45.044058 Training Step 3985 \"min loss\" =  1.9496381\n",
      "2018-08-29 09:19:45.044127 Training Step 3985 \"loss\" =  2.268929\n",
      "2018-08-29 09:19:45.244939 Test Step 3990 Finished\n",
      "2018-08-29 09:19:45.245448 Test Step 3990 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:45.245705 Test Step 3990 \"loss\" =  14.911439\n",
      "2018-08-29 09:19:45.291278 Training Step 3990 Finished Timing (Training: 0.909625, Test: 0.0831926) after 0.247072 seconds\n",
      "2018-08-29 09:19:45.291411 Training Step 3990 \"min loss\" =  1.9496381\n",
      "2018-08-29 09:19:45.291476 Training Step 3990 \"loss\" =  2.1943376\n",
      "2018-08-29 09:19:45.492305 Test Step 3995 Finished\n",
      "2018-08-29 09:19:45.492860 Test Step 3995 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:45.492943 Test Step 3995 \"loss\" =  15.355559\n",
      "2018-08-29 09:19:45.538659 Training Step 3995 Finished Timing (Training: 0.909771, Test: 0.0832049) after 0.247107 seconds\n",
      "2018-08-29 09:19:45.539247 Training Step 3995 \"min loss\" =  1.9496381\n",
      "2018-08-29 09:19:45.539320 Training Step 3995 \"loss\" =  2.1288445\n",
      "2018-08-29 09:19:45.740384 Test Step 4000 Finished\n",
      "2018-08-29 09:19:45.741021 Test Step 4000 \"min loss\" =  13.799004\n",
      "2018-08-29 09:19:45.741104 Test Step 4000 \"loss\" =  14.889836\n",
      "2018-08-29 09:19:45.786924 Training Step 4000 Finished Timing (Training: 0.909812, Test: 0.0831955) after 0.247523 seconds\n",
      "2018-08-29 09:19:45.787106 Training Step 4000 \"min loss\" =  1.9496381\n",
      "2018-08-29 09:19:45.787175 Training Step 4000 \"loss\" =  2.1597772\n",
      "2018-08-29 09:19:45.988527 Test Step 4005 Finished\n",
      "2018-08-29 09:19:45.988732 Test Step 4005 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:45.988806 Test Step 4005 \"loss\" =  13.642257\n",
      "2018-08-29 09:19:46.033919 Training Step 4005 Finished Timing (Training: 0.91362, Test: 0.0847475) after 0.246649 seconds\n",
      "2018-08-29 09:19:46.034076 Training Step 4005 \"min loss\" =  1.9496381\n",
      "2018-08-29 09:19:46.034579 Training Step 4005 \"loss\" =  2.2731988\n",
      "2018-08-29 09:19:46.236522 Test Step 4010 Finished\n",
      "2018-08-29 09:19:46.237180 Test Step 4010 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:46.237253 Test Step 4010 \"loss\" =  14.762143\n",
      "2018-08-29 09:19:46.282309 Training Step 4010 Finished Timing (Training: 0.912247, Test: 0.0837179) after 0.247642 seconds\n",
      "2018-08-29 09:19:46.282464 Training Step 4010 \"min loss\" =  1.9496381\n",
      "2018-08-29 09:19:46.282562 Training Step 4010 \"loss\" =  2.2389295\n",
      "2018-08-29 09:19:46.483329 Test Step 4015 Finished\n",
      "2018-08-29 09:19:46.483451 Test Step 4015 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:46.484304 Test Step 4015 \"loss\" =  14.505128\n",
      "2018-08-29 09:19:46.529819 Training Step 4015 Finished Timing (Training: 0.911964, Test: 0.0834088) after 0.247167 seconds\n",
      "2018-08-29 09:19:46.529944 Training Step 4015 \"min loss\" =  1.9496381\n",
      "2018-08-29 09:19:46.530037 Training Step 4015 \"loss\" =  2.3393264\n",
      "2018-08-29 09:19:46.731864 Test Step 4020 Finished\n",
      "2018-08-29 09:19:46.732517 Test Step 4020 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:46.732578 Test Step 4020 \"loss\" =  14.94244\n",
      "2018-08-29 09:19:46.779176 Training Step 4020 Finished Timing (Training: 0.910296, Test: 0.0830973) after 0.248163 seconds\n",
      "2018-08-29 09:19:46.779350 Training Step 4020 \"min loss\" =  1.9496381\n",
      "2018-08-29 09:19:46.780119 Training Step 4020 \"loss\" =  2.3541112\n",
      "2018-08-29 09:19:46.982236 Test Step 4025 Finished\n",
      "2018-08-29 09:19:46.982715 Test Step 4025 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:46.982839 Test Step 4025 \"loss\" =  14.720805\n",
      "2018-08-29 09:19:47.028786 Training Step 4025 Finished Timing (Training: 0.909257, Test: 0.0831839) after 0.248127 seconds\n",
      "2018-08-29 09:19:47.029271 Training Step 4025 \"min loss\" =  1.9496381\n",
      "2018-08-29 09:19:47.029395 Training Step 4025 \"loss\" =  2.159929\n",
      "2018-08-29 09:19:47.232907 Test Step 4030 Finished\n",
      "2018-08-29 09:19:47.233403 Test Step 4030 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:47.233650 Test Step 4030 \"loss\" =  14.386525\n",
      "2018-08-29 09:19:47.279135 Training Step 4030 Finished Timing (Training: 0.909389, Test: 0.0832419) after 0.249609 seconds\n",
      "2018-08-29 09:19:47.279273 Training Step 4030 \"min loss\" =  1.9496381\n",
      "2018-08-29 09:19:47.279971 Training Step 4030 \"loss\" =  2.056635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:19:47.482271 Test Step 4035 Finished\n",
      "2018-08-29 09:19:47.482953 Test Step 4035 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:47.483320 Test Step 4035 \"loss\" =  14.971029\n",
      "2018-08-29 09:19:47.528670 Training Step 4035 Finished Timing (Training: 0.90913, Test: 0.0833277) after 0.248577 seconds\n",
      "2018-08-29 09:19:47.528843 Training Step 4035 \"min loss\" =  1.9496381\n",
      "2018-08-29 09:19:47.529735 Training Step 4035 \"loss\" =  2.380981\n",
      "2018-08-29 09:19:47.731632 Test Step 4040 Finished\n",
      "2018-08-29 09:19:47.732103 Test Step 4040 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:47.732349 Test Step 4040 \"loss\" =  15.55124\n",
      "2018-08-29 09:19:47.777893 Training Step 4040 Finished Timing (Training: 0.909005, Test: 0.0831128) after 0.247991 seconds\n",
      "2018-08-29 09:19:47.778014 Training Step 4040 \"min loss\" =  1.9496381\n",
      "2018-08-29 09:19:47.778502 Training Step 4040 \"loss\" =  2.3305464\n",
      "2018-08-29 09:19:47.980837 Test Step 4045 Finished\n",
      "2018-08-29 09:19:47.980973 Test Step 4045 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:47.981034 Test Step 4045 \"loss\" =  16.201118\n",
      "2018-08-29 09:19:48.026232 Training Step 4045 Finished Timing (Training: 0.909065, Test: 0.0833408) after 0.247345 seconds\n",
      "2018-08-29 09:19:48.026355 Training Step 4045 \"min loss\" =  1.9496381\n",
      "2018-08-29 09:19:48.027108 Training Step 4045 \"loss\" =  2.4959776\n",
      "2018-08-29 09:19:48.229424 Test Step 4050 Finished\n",
      "2018-08-29 09:19:48.230140 Test Step 4050 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:48.230279 Test Step 4050 \"loss\" =  16.450714\n",
      "2018-08-29 09:19:48.276496 Training Step 4050 Finished Timing (Training: 0.908515, Test: 0.0835177) after 0.24882 seconds\n",
      "2018-08-29 09:19:48.276674 Training Step 4050 \"min loss\" =  1.9496381\n",
      "2018-08-29 09:19:48.276743 Training Step 4050 \"loss\" =  2.312397\n",
      "2018-08-29 09:19:48.478821 Test Step 4055 Finished\n",
      "2018-08-29 09:19:48.478979 Test Step 4055 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:48.479633 Test Step 4055 \"loss\" =  15.606752\n",
      "2018-08-29 09:19:48.525266 Training Step 4055 Finished Timing (Training: 0.908439, Test: 0.0835199) after 0.247587 seconds\n",
      "2018-08-29 09:19:48.525402 Training Step 4055 \"min loss\" =  1.9496381\n",
      "2018-08-29 09:19:48.526089 Training Step 4055 \"loss\" =  2.271589\n",
      "2018-08-29 09:19:48.728065 Test Step 4060 Finished\n",
      "2018-08-29 09:19:48.728240 Test Step 4060 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:48.728313 Test Step 4060 \"loss\" =  14.746005\n",
      "2018-08-29 09:19:48.774476 Training Step 4060 Finished Timing (Training: 0.90855, Test: 0.083557) after 0.248009 seconds\n",
      "2018-08-29 09:19:48.775080 Training Step 4060 \"min loss\" =  1.9496381\n",
      "2018-08-29 09:19:48.775162 Training Step 4060 \"loss\" =  2.3815804\n",
      "2018-08-29 09:19:48.977008 Test Step 4065 Finished\n",
      "2018-08-29 09:19:48.977145 Test Step 4065 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:48.977216 Test Step 4065 \"loss\" =  15.975379\n",
      "2018-08-29 09:19:49.022053 Training Step 4065 Finished Timing (Training: 0.908844, Test: 0.083526) after 0.246809 seconds\n",
      "2018-08-29 09:19:49.022213 Training Step 4065 \"min loss\" =  1.9496381\n",
      "2018-08-29 09:19:49.023145 Training Step 4065 \"loss\" =  2.2662935\n",
      "2018-08-29 09:19:49.225202 Test Step 4070 Finished\n",
      "2018-08-29 09:19:49.225351 Test Step 4070 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:49.225931 Test Step 4070 \"loss\" =  15.395581\n",
      "2018-08-29 09:19:49.271541 Training Step 4070 Finished Timing (Training: 0.908625, Test: 0.0834945) after 0.247899 seconds\n",
      "2018-08-29 09:19:49.271695 Training Step 4070 \"min loss\" =  1.9496381\n",
      "2018-08-29 09:19:49.271797 Training Step 4070 \"loss\" =  2.0105445\n",
      "2018-08-29 09:19:49.474305 Test Step 4075 Finished\n",
      "2018-08-29 09:19:49.474926 Test Step 4075 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:49.475201 Test Step 4075 \"loss\" =  15.102151\n",
      "2018-08-29 09:19:49.520888 Training Step 4075 Finished Timing (Training: 0.908657, Test: 0.0835605) after 0.248977 seconds\n",
      "2018-08-29 09:19:49.521025 Training Step 4075 \"min loss\" =  1.9496381\n",
      "2018-08-29 09:19:49.521812 Training Step 4075 \"loss\" =  2.3424342\n",
      "2018-08-29 09:19:49.725085 Test Step 4080 Finished\n",
      "2018-08-29 09:19:49.725250 Test Step 4080 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:49.725320 Test Step 4080 \"loss\" =  15.450986\n",
      "2018-08-29 09:19:49.770823 Training Step 4080 Finished Timing (Training: 0.908606, Test: 0.0837542) after 0.248919 seconds\n",
      "2018-08-29 09:19:49.770973 Training Step 4080 \"min loss\" =  1.9496381\n",
      "2018-08-29 09:19:49.771046 Training Step 4080 \"loss\" =  2.094584\n",
      "2018-08-29 09:19:49.973162 Test Step 4085 Finished\n",
      "2018-08-29 09:19:49.973317 Test Step 4085 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:49.974034 Test Step 4085 \"loss\" =  15.988094\n",
      "2018-08-29 09:19:50.019581 Training Step 4085 Finished Timing (Training: 0.908546, Test: 0.0837246) after 0.247539 seconds\n",
      "2018-08-29 09:19:50.019726 Training Step 4085 \"min loss\" =  1.9496381\n",
      "2018-08-29 09:19:50.020469 Training Step 4085 \"loss\" =  2.2606018\n",
      "2018-08-29 09:19:50.222143 Test Step 4090 Finished\n",
      "2018-08-29 09:19:50.222337 Test Step 4090 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:50.222436 Test Step 4090 \"loss\" =  14.563354\n",
      "2018-08-29 09:19:50.268394 Training Step 4090 Finished Timing (Training: 0.908615, Test: 0.083743) after 0.247713 seconds\n",
      "2018-08-29 09:19:50.268521 Training Step 4090 \"min loss\" =  1.9496381\n",
      "2018-08-29 09:19:50.268582 Training Step 4090 \"loss\" =  2.2142482\n",
      "2018-08-29 09:19:50.470812 Test Step 4095 Finished\n",
      "2018-08-29 09:19:50.471325 Test Step 4095 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:50.471417 Test Step 4095 \"loss\" =  14.742238\n",
      "2018-08-29 09:19:50.517499 Training Step 4095 Finished Timing (Training: 0.908752, Test: 0.0837863) after 0.248791 seconds\n",
      "2018-08-29 09:19:50.517754 Training Step 4095 \"min loss\" =  1.9496381\n",
      "2018-08-29 09:19:50.518488 Training Step 4095 \"loss\" =  2.108858\n",
      "2018-08-29 09:19:50.720446 Test Step 4100 Finished\n",
      "2018-08-29 09:19:50.720877 Test Step 4100 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:50.721190 Test Step 4100 \"loss\" =  14.852334\n",
      "2018-08-29 09:19:50.766750 Training Step 4100 Finished Timing (Training: 0.908616, Test: 0.0837699) after 0.247838 seconds\n",
      "2018-08-29 09:19:50.766892 Training Step 4100 \"min loss\" =  1.9496381\n",
      "2018-08-29 09:19:50.767579 Training Step 4100 \"loss\" =  2.0635886\n",
      "2018-08-29 09:19:50.970048 Test Step 4105 Finished\n",
      "2018-08-29 09:19:50.970192 Test Step 4105 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:50.970263 Test Step 4105 \"loss\" =  14.667664\n",
      "2018-08-29 09:19:51.015315 Training Step 4105 Finished Timing (Training: 0.913879, Test: 0.0847807) after 0.24765 seconds\n",
      "2018-08-29 09:19:51.015452 Training Step 4105 \"min loss\" =  1.9496381\n",
      "2018-08-29 09:19:51.016137 Training Step 4105 \"loss\" =  2.2317026\n",
      "2018-08-29 09:19:51.217881 Test Step 4110 Finished\n",
      "2018-08-29 09:19:51.218061 Test Step 4110 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:51.218778 Test Step 4110 \"loss\" =  15.496828\n",
      "2018-08-29 09:19:51.264746 Training Step 4110 Finished Timing (Training: 0.908836, Test: 0.0851787) after 0.24834 seconds\n",
      "2018-08-29 09:19:51.265350 Training Step 4110 \"min loss\" =  1.9496381\n",
      "2018-08-29 09:19:51.265500 Training Step 4110 \"loss\" =  2.19239\n",
      "2018-08-29 09:19:51.467590 Test Step 4115 Finished\n",
      "2018-08-29 09:19:51.467741 Test Step 4115 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:51.467815 Test Step 4115 \"loss\" =  15.372382\n",
      "2018-08-29 09:19:51.513082 Training Step 4115 Finished Timing (Training: 0.909165, Test: 0.0851262) after 0.247427 seconds\n",
      "2018-08-29 09:19:51.513227 Training Step 4115 \"min loss\" =  1.9496381\n",
      "2018-08-29 09:19:51.513967 Training Step 4115 \"loss\" =  2.2037213\n",
      "2018-08-29 09:19:51.715806 Test Step 4120 Finished\n",
      "2018-08-29 09:19:51.715956 Test Step 4120 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:51.716106 Test Step 4120 \"loss\" =  14.876428\n",
      "2018-08-29 09:19:51.761412 Training Step 4120 Finished Timing (Training: 0.909687, Test: 0.0846178) after 0.247354 seconds\n",
      "2018-08-29 09:19:51.761566 Training Step 4120 \"min loss\" =  1.9496381\n",
      "2018-08-29 09:19:51.762099 Training Step 4120 \"loss\" =  2.3682334\n",
      "2018-08-29 09:19:51.963335 Test Step 4125 Finished\n",
      "2018-08-29 09:19:51.963977 Test Step 4125 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:51.964281 Test Step 4125 \"loss\" =  15.105914\n",
      "2018-08-29 09:19:52.010045 Training Step 4125 Finished Timing (Training: 0.909843, Test: 0.0841287) after 0.247861 seconds\n",
      "2018-08-29 09:19:52.010510 Training Step 4125 \"min loss\" =  1.9267887\n",
      "2018-08-29 09:19:52.010595 Training Step 4125 \"loss\" =  2.255761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:19:52.212008 Test Step 4130 Finished\n",
      "2018-08-29 09:19:52.212216 Test Step 4130 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:52.213153 Test Step 4130 \"loss\" =  15.27474\n",
      "2018-08-29 09:19:52.258586 Training Step 4130 Finished Timing (Training: 0.909364, Test: 0.0840094) after 0.247538 seconds\n",
      "2018-08-29 09:19:52.258723 Training Step 4130 \"min loss\" =  1.9267887\n",
      "2018-08-29 09:19:52.259440 Training Step 4130 \"loss\" =  2.0688071\n",
      "2018-08-29 09:19:52.461986 Test Step 4135 Finished\n",
      "2018-08-29 09:19:52.462130 Test Step 4135 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:52.462934 Test Step 4135 \"loss\" =  14.756963\n",
      "2018-08-29 09:19:52.508431 Training Step 4135 Finished Timing (Training: 0.909344, Test: 0.0838031) after 0.248897 seconds\n",
      "2018-08-29 09:19:52.508990 Training Step 4135 \"min loss\" =  1.9267887\n",
      "2018-08-29 09:19:52.509155 Training Step 4135 \"loss\" =  2.3434427\n",
      "2018-08-29 09:19:52.711548 Test Step 4140 Finished\n",
      "2018-08-29 09:19:52.712058 Test Step 4140 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:52.712481 Test Step 4140 \"loss\" =  15.668256\n",
      "2018-08-29 09:19:52.758041 Training Step 4140 Finished Timing (Training: 0.909319, Test: 0.0837016) after 0.248716 seconds\n",
      "2018-08-29 09:19:52.758233 Training Step 4140 \"min loss\" =  1.9267887\n",
      "2018-08-29 09:19:52.758378 Training Step 4140 \"loss\" =  2.4967568\n",
      "2018-08-29 09:19:52.959994 Test Step 4145 Finished\n",
      "2018-08-29 09:19:52.960223 Test Step 4145 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:52.961019 Test Step 4145 \"loss\" =  15.534059\n",
      "2018-08-29 09:19:53.006602 Training Step 4145 Finished Timing (Training: 0.909358, Test: 0.0836545) after 0.248047 seconds\n",
      "2018-08-29 09:19:53.006785 Training Step 4145 \"min loss\" =  1.9267887\n",
      "2018-08-29 09:19:53.006897 Training Step 4145 \"loss\" =  2.3130183\n",
      "2018-08-29 09:19:53.209779 Test Step 4150 Finished\n",
      "2018-08-29 09:19:53.209918 Test Step 4150 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:53.210680 Test Step 4150 \"loss\" =  14.70063\n",
      "2018-08-29 09:19:53.256317 Training Step 4150 Finished Timing (Training: 0.909386, Test: 0.0837366) after 0.249281 seconds\n",
      "2018-08-29 09:19:53.256466 Training Step 4150 \"min loss\" =  1.9267887\n",
      "2018-08-29 09:19:53.256540 Training Step 4150 \"loss\" =  2.1040113\n",
      "2018-08-29 09:19:53.458535 Test Step 4155 Finished\n",
      "2018-08-29 09:19:53.459070 Test Step 4155 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:53.459394 Test Step 4155 \"loss\" =  14.88917\n",
      "2018-08-29 09:19:53.504730 Training Step 4155 Finished Timing (Training: 0.909613, Test: 0.0836535) after 0.248074 seconds\n",
      "2018-08-29 09:19:53.504935 Training Step 4155 \"min loss\" =  1.9267887\n",
      "2018-08-29 09:19:53.505085 Training Step 4155 \"loss\" =  2.1349287\n",
      "2018-08-29 09:19:53.708092 Test Step 4160 Finished\n",
      "2018-08-29 09:19:53.708222 Test Step 4160 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:53.709279 Test Step 4160 \"loss\" =  15.367544\n",
      "2018-08-29 09:19:53.755154 Training Step 4160 Finished Timing (Training: 0.909649, Test: 0.0835643) after 0.249913 seconds\n",
      "2018-08-29 09:19:53.755603 Training Step 4160 \"min loss\" =  1.9267887\n",
      "2018-08-29 09:19:53.755847 Training Step 4160 \"loss\" =  2.5852416\n",
      "2018-08-29 09:19:53.958463 Test Step 4165 Finished\n",
      "2018-08-29 09:19:53.958662 Test Step 4165 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:53.959686 Test Step 4165 \"loss\" =  15.231957\n",
      "2018-08-29 09:19:54.005336 Training Step 4165 Finished Timing (Training: 0.909184, Test: 0.083544) after 0.248713 seconds\n",
      "2018-08-29 09:19:54.005998 Training Step 4165 \"min loss\" =  1.9267887\n",
      "2018-08-29 09:19:54.006104 Training Step 4165 \"loss\" =  2.0182323\n",
      "2018-08-29 09:19:54.207954 Test Step 4170 Finished\n",
      "2018-08-29 09:19:54.208666 Test Step 4170 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:54.209085 Test Step 4170 \"loss\" =  15.102359\n",
      "2018-08-29 09:19:54.254752 Training Step 4170 Finished Timing (Training: 0.908876, Test: 0.0835922) after 0.24856 seconds\n",
      "2018-08-29 09:19:54.254885 Training Step 4170 \"min loss\" =  1.9267887\n",
      "2018-08-29 09:19:54.255524 Training Step 4170 \"loss\" =  2.3396065\n",
      "2018-08-29 09:19:54.456990 Test Step 4175 Finished\n",
      "2018-08-29 09:19:54.457161 Test Step 4175 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:54.457231 Test Step 4175 \"loss\" =  14.360406\n",
      "2018-08-29 09:19:54.503380 Training Step 4175 Finished Timing (Training: 0.909071, Test: 0.0835735) after 0.247771 seconds\n",
      "2018-08-29 09:19:54.503510 Training Step 4175 \"min loss\" =  1.9267887\n",
      "2018-08-29 09:19:54.504391 Training Step 4175 \"loss\" =  2.2455301\n",
      "2018-08-29 09:19:54.706986 Test Step 4180 Finished\n",
      "2018-08-29 09:19:54.707151 Test Step 4180 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:54.707222 Test Step 4180 \"loss\" =  15.706179\n",
      "2018-08-29 09:19:54.752372 Training Step 4180 Finished Timing (Training: 0.909119, Test: 0.0836198) after 0.24789 seconds\n",
      "2018-08-29 09:19:54.752522 Training Step 4180 \"min loss\" =  1.9267887\n",
      "2018-08-29 09:19:54.752591 Training Step 4180 \"loss\" =  2.287049\n",
      "2018-08-29 09:19:54.954892 Test Step 4185 Finished\n",
      "2018-08-29 09:19:54.955137 Test Step 4185 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:54.955284 Test Step 4185 \"loss\" =  15.51295\n",
      "2018-08-29 09:19:55.000473 Training Step 4185 Finished Timing (Training: 0.909328, Test: 0.0836215) after 0.247777 seconds\n",
      "2018-08-29 09:19:55.000638 Training Step 4185 \"min loss\" =  1.9267887\n",
      "2018-08-29 09:19:55.000700 Training Step 4185 \"loss\" =  2.2540061\n",
      "2018-08-29 09:19:55.202757 Test Step 4190 Finished\n",
      "2018-08-29 09:19:55.202888 Test Step 4190 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:55.202954 Test Step 4190 \"loss\" =  14.848362\n",
      "2018-08-29 09:19:55.249175 Training Step 4190 Finished Timing (Training: 0.909339, Test: 0.0835484) after 0.246988 seconds\n",
      "2018-08-29 09:19:55.249301 Training Step 4190 \"min loss\" =  1.9267887\n",
      "2018-08-29 09:19:55.249364 Training Step 4190 \"loss\" =  2.2614753\n",
      "2018-08-29 09:19:55.450938 Test Step 4195 Finished\n",
      "2018-08-29 09:19:55.451075 Test Step 4195 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:55.451703 Test Step 4195 \"loss\" =  15.326297\n",
      "2018-08-29 09:19:55.497449 Training Step 4195 Finished Timing (Training: 0.90936, Test: 0.0835461) after 0.248007 seconds\n",
      "2018-08-29 09:19:55.497582 Training Step 4195 \"min loss\" =  1.9267887\n",
      "2018-08-29 09:19:55.497643 Training Step 4195 \"loss\" =  2.1650262\n",
      "2018-08-29 09:19:55.699535 Test Step 4200 Finished\n",
      "2018-08-29 09:19:55.699668 Test Step 4200 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:55.700398 Test Step 4200 \"loss\" =  14.97169\n",
      "2018-08-29 09:19:55.745436 Training Step 4200 Finished Timing (Training: 0.909475, Test: 0.0835307) after 0.247709 seconds\n",
      "2018-08-29 09:19:55.745579 Training Step 4200 \"min loss\" =  1.9267887\n",
      "2018-08-29 09:19:55.745651 Training Step 4200 \"loss\" =  2.1115146\n",
      "2018-08-29 09:19:55.948189 Test Step 4205 Finished\n",
      "2018-08-29 09:19:55.948818 Test Step 4205 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:55.948891 Test Step 4205 \"loss\" =  15.249252\n",
      "2018-08-29 09:19:55.994596 Training Step 4205 Finished Timing (Training: 0.912505, Test: 0.0841941) after 0.248858 seconds\n",
      "2018-08-29 09:19:55.994727 Training Step 4205 \"min loss\" =  1.9267887\n",
      "2018-08-29 09:19:55.994792 Training Step 4205 \"loss\" =  2.1161308\n",
      "2018-08-29 09:19:56.196346 Test Step 4210 Finished\n",
      "2018-08-29 09:19:56.196514 Test Step 4210 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:56.197285 Test Step 4210 \"loss\" =  15.077686\n",
      "2018-08-29 09:19:56.242438 Training Step 4210 Finished Timing (Training: 0.911701, Test: 0.0839335) after 0.247561 seconds\n",
      "2018-08-29 09:19:56.242589 Training Step 4210 \"min loss\" =  1.9267887\n",
      "2018-08-29 09:19:56.243146 Training Step 4210 \"loss\" =  2.1594744\n",
      "2018-08-29 09:19:56.444918 Test Step 4215 Finished\n",
      "2018-08-29 09:19:56.445535 Test Step 4215 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:56.445621 Test Step 4215 \"loss\" =  15.160469\n",
      "2018-08-29 09:19:56.491803 Training Step 4215 Finished Timing (Training: 0.91061, Test: 0.0837307) after 0.248142 seconds\n",
      "2018-08-29 09:19:56.491932 Training Step 4215 \"min loss\" =  1.9267887\n",
      "2018-08-29 09:19:56.492727 Training Step 4215 \"loss\" =  2.2941232\n",
      "2018-08-29 09:19:56.693564 Test Step 4220 Finished\n",
      "2018-08-29 09:19:56.693754 Test Step 4220 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:56.694831 Test Step 4220 \"loss\" =  15.955252\n",
      "2018-08-29 09:19:56.740070 Training Step 4220 Finished Timing (Training: 0.909783, Test: 0.0835104) after 0.247253 seconds\n",
      "2018-08-29 09:19:56.740270 Training Step 4220 \"min loss\" =  1.9267887\n",
      "2018-08-29 09:19:56.740365 Training Step 4220 \"loss\" =  2.1194086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:19:56.942299 Test Step 4225 Finished\n",
      "2018-08-29 09:19:56.942441 Test Step 4225 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:56.942534 Test Step 4225 \"loss\" =  15.287782\n",
      "2018-08-29 09:19:56.987582 Training Step 4225 Finished Timing (Training: 0.909906, Test: 0.0834037) after 0.246231 seconds\n",
      "2018-08-29 09:19:56.987716 Training Step 4225 \"min loss\" =  1.9267887\n",
      "2018-08-29 09:19:56.987786 Training Step 4225 \"loss\" =  2.116164\n",
      "2018-08-29 09:19:57.190880 Test Step 4230 Finished\n",
      "2018-08-29 09:19:57.191017 Test Step 4230 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:57.191088 Test Step 4230 \"loss\" =  14.973356\n",
      "2018-08-29 09:19:57.237732 Training Step 4230 Finished Timing (Training: 0.909727, Test: 0.0835218) after 0.249855 seconds\n",
      "2018-08-29 09:19:57.237886 Training Step 4230 \"min loss\" =  1.9267887\n",
      "2018-08-29 09:19:57.237954 Training Step 4230 \"loss\" =  2.2747998\n",
      "2018-08-29 09:19:57.440243 Test Step 4235 Finished\n",
      "2018-08-29 09:19:57.440377 Test Step 4235 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:57.441146 Test Step 4235 \"loss\" =  14.922372\n",
      "2018-08-29 09:19:57.486262 Training Step 4235 Finished Timing (Training: 0.909464, Test: 0.0833849) after 0.247195 seconds\n",
      "2018-08-29 09:19:57.486386 Training Step 4235 \"min loss\" =  1.9267887\n",
      "2018-08-29 09:19:57.487149 Training Step 4235 \"loss\" =  2.1833467\n",
      "2018-08-29 09:19:57.689583 Test Step 4240 Finished\n",
      "2018-08-29 09:19:57.689721 Test Step 4240 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:57.689792 Test Step 4240 \"loss\" =  14.99143\n",
      "2018-08-29 09:19:57.736072 Training Step 4240 Finished Timing (Training: 0.909234, Test: 0.0833142) after 0.24882 seconds\n",
      "2018-08-29 09:19:57.736757 Training Step 4240 \"min loss\" =  1.9127811\n",
      "2018-08-29 09:19:57.737042 Training Step 4240 \"loss\" =  2.160836\n",
      "2018-08-29 09:19:57.937731 Test Step 4245 Finished\n",
      "2018-08-29 09:19:57.937880 Test Step 4245 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:57.938465 Test Step 4245 \"loss\" =  15.242233\n",
      "2018-08-29 09:19:57.983873 Training Step 4245 Finished Timing (Training: 0.909188, Test: 0.0833077) after 0.246737 seconds\n",
      "2018-08-29 09:19:57.984423 Training Step 4245 \"min loss\" =  1.9127811\n",
      "2018-08-29 09:19:57.984512 Training Step 4245 \"loss\" =  2.169569\n",
      "2018-08-29 09:19:58.185848 Test Step 4250 Finished\n",
      "2018-08-29 09:19:58.185966 Test Step 4250 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:58.186751 Test Step 4250 \"loss\" =  14.776055\n",
      "2018-08-29 09:19:58.232733 Training Step 4250 Finished Timing (Training: 0.909022, Test: 0.083202) after 0.247596 seconds\n",
      "2018-08-29 09:19:58.232873 Training Step 4250 \"min loss\" =  1.9127811\n",
      "2018-08-29 09:19:58.232940 Training Step 4250 \"loss\" =  2.1352618\n",
      "2018-08-29 09:19:58.436388 Test Step 4255 Finished\n",
      "2018-08-29 09:19:58.437058 Test Step 4255 \"min loss\" =  13.642257\n",
      "2018-08-29 09:19:58.437195 Test Step 4255 \"loss\" =  13.964454\n",
      "2018-08-29 09:19:58.483077 Training Step 4255 Finished Timing (Training: 0.908678, Test: 0.0831639) after 0.249126 seconds\n",
      "2018-08-29 09:19:58.483224 Training Step 4255 \"min loss\" =  1.9127811\n",
      "2018-08-29 09:19:58.483722 Training Step 4255 \"loss\" =  2.1524508\n",
      "2018-08-29 09:19:58.686171 Test Step 4260 Finished\n",
      "2018-08-29 09:19:58.686390 Test Step 4260 \"min loss\" =  13.609721\n",
      "2018-08-29 09:19:58.687266 Test Step 4260 \"loss\" =  13.609721\n",
      "2018-08-29 09:19:58.733377 Training Step 4260 Finished Timing (Training: 0.908599, Test: 0.0831526) after 0.249263 seconds\n",
      "2018-08-29 09:19:58.733540 Training Step 4260 \"min loss\" =  1.9127811\n",
      "2018-08-29 09:19:58.733672 Training Step 4260 \"loss\" =  2.4860072\n",
      "2018-08-29 09:19:58.935893 Test Step 4265 Finished\n",
      "2018-08-29 09:19:58.936077 Test Step 4265 \"min loss\" =  13.609721\n",
      "2018-08-29 09:19:58.936205 Test Step 4265 \"loss\" =  13.968032\n",
      "2018-08-29 09:19:58.981682 Training Step 4265 Finished Timing (Training: 0.90898, Test: 0.0831368) after 0.247921 seconds\n",
      "2018-08-29 09:19:58.981873 Training Step 4265 \"min loss\" =  1.9127811\n",
      "2018-08-29 09:19:58.982689 Training Step 4265 \"loss\" =  2.491392\n",
      "2018-08-29 09:19:59.184512 Test Step 4270 Finished\n",
      "2018-08-29 09:19:59.184670 Test Step 4270 \"min loss\" =  13.609721\n",
      "2018-08-29 09:19:59.184732 Test Step 4270 \"loss\" =  14.589546\n",
      "2018-08-29 09:19:59.231378 Training Step 4270 Finished Timing (Training: 0.909039, Test: 0.083116) after 0.248201 seconds\n",
      "2018-08-29 09:19:59.231551 Training Step 4270 \"min loss\" =  1.9127811\n",
      "2018-08-29 09:19:59.232371 Training Step 4270 \"loss\" =  2.1142466\n",
      "2018-08-29 09:19:59.434361 Test Step 4275 Finished\n",
      "2018-08-29 09:19:59.435017 Test Step 4275 \"min loss\" =  13.609721\n",
      "2018-08-29 09:19:59.435090 Test Step 4275 \"loss\" =  14.619451\n",
      "2018-08-29 09:19:59.480301 Training Step 4275 Finished Timing (Training: 0.908887, Test: 0.0831658) after 0.247446 seconds\n",
      "2018-08-29 09:19:59.480426 Training Step 4275 \"min loss\" =  1.9127811\n",
      "2018-08-29 09:19:59.481168 Training Step 4275 \"loss\" =  1.9806861\n",
      "2018-08-29 09:19:59.683448 Test Step 4280 Finished\n",
      "2018-08-29 09:19:59.684242 Test Step 4280 \"min loss\" =  13.609721\n",
      "2018-08-29 09:19:59.684671 Test Step 4280 \"loss\" =  15.553147\n",
      "2018-08-29 09:19:59.730643 Training Step 4280 Finished Timing (Training: 0.908635, Test: 0.0832015) after 0.249384 seconds\n",
      "2018-08-29 09:19:59.730802 Training Step 4280 \"min loss\" =  1.9127811\n",
      "2018-08-29 09:19:59.730871 Training Step 4280 \"loss\" =  2.1655393\n",
      "2018-08-29 09:19:59.932178 Test Step 4285 Finished\n",
      "2018-08-29 09:19:59.932325 Test Step 4285 \"min loss\" =  13.609721\n",
      "2018-08-29 09:19:59.933522 Test Step 4285 \"loss\" =  14.383685\n",
      "2018-08-29 09:19:59.978676 Training Step 4285 Finished Timing (Training: 0.908648, Test: 0.0832401) after 0.247716 seconds\n",
      "2018-08-29 09:19:59.978867 Training Step 4285 \"min loss\" =  1.9127811\n",
      "2018-08-29 09:19:59.978986 Training Step 4285 \"loss\" =  2.2086442\n",
      "2018-08-29 09:20:00.181047 Test Step 4290 Finished\n",
      "2018-08-29 09:20:00.181180 Test Step 4290 \"min loss\" =  13.609721\n",
      "2018-08-29 09:20:00.181246 Test Step 4290 \"loss\" =  13.793611\n",
      "2018-08-29 09:20:00.227264 Training Step 4290 Finished Timing (Training: 0.908681, Test: 0.0833165) after 0.24817 seconds\n",
      "2018-08-29 09:20:00.227396 Training Step 4290 \"min loss\" =  1.9127811\n",
      "2018-08-29 09:20:00.227536 Training Step 4290 \"loss\" =  2.4947762\n",
      "2018-08-29 09:20:00.430504 Test Step 4295 Finished\n",
      "2018-08-29 09:20:00.431165 Test Step 4295 \"min loss\" =  13.609721\n",
      "2018-08-29 09:20:00.431699 Test Step 4295 \"loss\" =  14.569067\n",
      "2018-08-29 09:20:00.476941 Training Step 4295 Finished Timing (Training: 0.908491, Test: 0.0833731) after 0.248372 seconds\n",
      "2018-08-29 09:20:00.477090 Training Step 4295 \"min loss\" =  1.9127811\n",
      "2018-08-29 09:20:00.477160 Training Step 4295 \"loss\" =  2.1512146\n",
      "2018-08-29 09:20:00.678825 Test Step 4300 Finished\n",
      "2018-08-29 09:20:00.679560 Test Step 4300 \"min loss\" =  13.609721\n",
      "2018-08-29 09:20:00.679710 Test Step 4300 \"loss\" =  14.081575\n",
      "2018-08-29 09:20:00.725336 Training Step 4300 Finished Timing (Training: 0.908603, Test: 0.0833892) after 0.248091 seconds\n",
      "2018-08-29 09:20:00.725503 Training Step 4300 \"min loss\" =  1.9127811\n",
      "2018-08-29 09:20:00.726045 Training Step 4300 \"loss\" =  2.3098474\n",
      "2018-08-29 09:20:00.928362 Test Step 4305 Finished\n",
      "2018-08-29 09:20:00.928530 Test Step 4305 \"min loss\" =  13.609721\n",
      "2018-08-29 09:20:00.928616 Test Step 4305 \"loss\" =  13.847819\n",
      "2018-08-29 09:20:00.974523 Training Step 4305 Finished Timing (Training: 0.913159, Test: 0.0853285) after 0.247939 seconds\n",
      "2018-08-29 09:20:00.975106 Training Step 4305 \"min loss\" =  1.9127811\n",
      "2018-08-29 09:20:00.975176 Training Step 4305 \"loss\" =  2.1054013\n",
      "2018-08-29 09:20:01.176935 Test Step 4310 Finished\n",
      "2018-08-29 09:20:01.177620 Test Step 4310 \"min loss\" =  13.609721\n",
      "2018-08-29 09:20:01.178000 Test Step 4310 \"loss\" =  14.339739\n",
      "2018-08-29 09:20:01.223642 Training Step 4310 Finished Timing (Training: 0.908656, Test: 0.0842068) after 0.24768 seconds\n",
      "2018-08-29 09:20:01.223838 Training Step 4310 \"min loss\" =  1.9127811\n",
      "2018-08-29 09:20:01.223957 Training Step 4310 \"loss\" =  1.9910351\n",
      "2018-08-29 09:20:01.426383 Test Step 4315 Finished\n",
      "2018-08-29 09:20:01.426567 Test Step 4315 \"min loss\" =  13.609721\n",
      "2018-08-29 09:20:01.426640 Test Step 4315 \"loss\" =  13.931337\n",
      "2018-08-29 09:20:01.471786 Training Step 4315 Finished Timing (Training: 0.910282, Test: 0.0837869) after 0.247697 seconds\n",
      "2018-08-29 09:20:01.471931 Training Step 4315 \"min loss\" =  1.9127811\n",
      "2018-08-29 09:20:01.472003 Training Step 4315 \"loss\" =  2.2459877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:20:01.674176 Test Step 4320 Finished\n",
      "2018-08-29 09:20:01.674313 Test Step 4320 \"min loss\" =  13.609721\n",
      "2018-08-29 09:20:01.674381 Test Step 4320 \"loss\" =  14.039342\n",
      "2018-08-29 09:20:01.719625 Training Step 4320 Finished Timing (Training: 0.910891, Test: 0.0840322) after 0.247535 seconds\n",
      "2018-08-29 09:20:01.719825 Training Step 4320 \"min loss\" =  1.9127811\n",
      "2018-08-29 09:20:01.719962 Training Step 4320 \"loss\" =  2.2711444\n",
      "2018-08-29 09:20:01.923312 Test Step 4325 Finished\n",
      "2018-08-29 09:20:01.923495 Test Step 4325 \"min loss\" =  13.609721\n",
      "2018-08-29 09:20:01.923572 Test Step 4325 \"loss\" =  15.830311\n",
      "2018-08-29 09:20:01.968894 Training Step 4325 Finished Timing (Training: 0.909869, Test: 0.0846724) after 0.247925 seconds\n",
      "2018-08-29 09:20:01.969036 Training Step 4325 \"min loss\" =  1.9127811\n",
      "2018-08-29 09:20:01.969112 Training Step 4325 \"loss\" =  2.255931\n",
      "2018-08-29 09:20:02.173328 Test Step 4330 Finished\n",
      "2018-08-29 09:20:02.173947 Test Step 4330 \"min loss\" =  13.609721\n",
      "2018-08-29 09:20:02.174028 Test Step 4330 \"loss\" =  13.963747\n",
      "2018-08-29 09:20:02.219243 Training Step 4330 Finished Timing (Training: 0.910127, Test: 0.084569) after 0.250032 seconds\n",
      "2018-08-29 09:20:02.219396 Training Step 4330 \"min loss\" =  1.9127811\n",
      "2018-08-29 09:20:02.219917 Training Step 4330 \"loss\" =  2.0246863\n",
      "2018-08-29 09:20:02.422671 Test Step 4335 Finished\n",
      "2018-08-29 09:20:02.422818 Test Step 4335 \"min loss\" =  13.525784\n",
      "2018-08-29 09:20:02.423576 Test Step 4335 \"loss\" =  13.525784\n",
      "2018-08-29 09:20:02.469136 Training Step 4335 Finished Timing (Training: 0.909861, Test: 0.0843413) after 0.248742 seconds\n",
      "2018-08-29 09:20:02.469275 Training Step 4335 \"min loss\" =  1.7989203\n",
      "2018-08-29 09:20:02.470250 Training Step 4335 \"loss\" =  1.9501102\n",
      "2018-08-29 09:20:02.671848 Test Step 4340 Finished\n",
      "2018-08-29 09:20:02.672708 Test Step 4340 \"min loss\" =  13.525784\n",
      "2018-08-29 09:20:02.673168 Test Step 4340 \"loss\" =  14.696032\n",
      "2018-08-29 09:20:02.718832 Training Step 4340 Finished Timing (Training: 0.909084, Test: 0.0843498) after 0.248502 seconds\n",
      "2018-08-29 09:20:02.718966 Training Step 4340 \"min loss\" =  1.7989203\n",
      "2018-08-29 09:20:02.719050 Training Step 4340 \"loss\" =  2.3187904\n",
      "2018-08-29 09:20:02.920769 Test Step 4345 Finished\n",
      "2018-08-29 09:20:02.921403 Test Step 4345 \"min loss\" =  13.525784\n",
      "2018-08-29 09:20:02.921653 Test Step 4345 \"loss\" =  15.138477\n",
      "2018-08-29 09:20:02.967765 Training Step 4345 Finished Timing (Training: 0.908731, Test: 0.08412) after 0.24736 seconds\n",
      "2018-08-29 09:20:02.967896 Training Step 4345 \"min loss\" =  1.7989203\n",
      "2018-08-29 09:20:02.968490 Training Step 4345 \"loss\" =  2.1082385\n",
      "2018-08-29 09:20:03.169666 Test Step 4350 Finished\n",
      "2018-08-29 09:20:03.170165 Test Step 4350 \"min loss\" =  13.525784\n",
      "2018-08-29 09:20:03.170388 Test Step 4350 \"loss\" =  14.844182\n",
      "2018-08-29 09:20:03.215933 Training Step 4350 Finished Timing (Training: 0.908789, Test: 0.0839982) after 0.247359 seconds\n",
      "2018-08-29 09:20:03.216086 Training Step 4350 \"min loss\" =  1.7989203\n",
      "2018-08-29 09:20:03.217001 Training Step 4350 \"loss\" =  2.26045\n",
      "2018-08-29 09:20:03.419502 Test Step 4355 Finished\n",
      "2018-08-29 09:20:03.419636 Test Step 4355 \"min loss\" =  13.525784\n",
      "2018-08-29 09:20:03.420400 Test Step 4355 \"loss\" =  14.299034\n",
      "2018-08-29 09:20:03.465598 Training Step 4355 Finished Timing (Training: 0.908574, Test: 0.0838964) after 0.248042 seconds\n",
      "2018-08-29 09:20:03.465715 Training Step 4355 \"min loss\" =  1.7989203\n",
      "2018-08-29 09:20:03.465805 Training Step 4355 \"loss\" =  2.120704\n",
      "2018-08-29 09:20:03.667616 Test Step 4360 Finished\n",
      "2018-08-29 09:20:03.667833 Test Step 4360 \"min loss\" =  13.525784\n",
      "2018-08-29 09:20:03.667956 Test Step 4360 \"loss\" =  15.354211\n",
      "2018-08-29 09:20:03.713919 Training Step 4360 Finished Timing (Training: 0.908621, Test: 0.0839805) after 0.247358 seconds\n",
      "2018-08-29 09:20:03.714062 Training Step 4360 \"min loss\" =  1.7989203\n",
      "2018-08-29 09:20:03.714126 Training Step 4360 \"loss\" =  2.0129616\n",
      "2018-08-29 09:20:03.915402 Test Step 4365 Finished\n",
      "2018-08-29 09:20:03.915541 Test Step 4365 \"min loss\" =  13.525784\n",
      "2018-08-29 09:20:03.916354 Test Step 4365 \"loss\" =  14.396276\n",
      "2018-08-29 09:20:03.961695 Training Step 4365 Finished Timing (Training: 0.908461, Test: 0.0838399) after 0.246426 seconds\n",
      "2018-08-29 09:20:03.961827 Training Step 4365 \"min loss\" =  1.7989203\n",
      "2018-08-29 09:20:03.962658 Training Step 4365 \"loss\" =  2.164771\n",
      "2018-08-29 09:20:04.164219 Test Step 4370 Finished\n",
      "2018-08-29 09:20:04.164370 Test Step 4370 \"min loss\" =  13.525784\n",
      "2018-08-29 09:20:04.165148 Test Step 4370 \"loss\" =  14.50363\n",
      "2018-08-29 09:20:04.210737 Training Step 4370 Finished Timing (Training: 0.908312, Test: 0.0837786) after 0.247692 seconds\n",
      "2018-08-29 09:20:04.210885 Training Step 4370 \"min loss\" =  1.7989203\n",
      "2018-08-29 09:20:04.210960 Training Step 4370 \"loss\" =  2.3994012\n",
      "2018-08-29 09:20:04.413140 Test Step 4375 Finished\n",
      "2018-08-29 09:20:04.413321 Test Step 4375 \"min loss\" =  13.525784\n",
      "2018-08-29 09:20:04.413439 Test Step 4375 \"loss\" =  13.691086\n",
      "2018-08-29 09:20:04.459653 Training Step 4375 Finished Timing (Training: 0.90827, Test: 0.0837587) after 0.247925 seconds\n",
      "2018-08-29 09:20:04.459809 Training Step 4375 \"min loss\" =  1.7989203\n",
      "2018-08-29 09:20:04.460282 Training Step 4375 \"loss\" =  2.0785754\n",
      "2018-08-29 09:20:04.661894 Test Step 4380 Finished\n",
      "2018-08-29 09:20:04.662046 Test Step 4380 \"min loss\" =  13.525784\n",
      "2018-08-29 09:20:04.662121 Test Step 4380 \"loss\" =  14.298272\n",
      "2018-08-29 09:20:04.707405 Training Step 4380 Finished Timing (Training: 0.90839, Test: 0.0837782) after 0.246748 seconds\n",
      "2018-08-29 09:20:04.707587 Training Step 4380 \"min loss\" =  1.7989203\n",
      "2018-08-29 09:20:04.707666 Training Step 4380 \"loss\" =  2.1376648\n",
      "2018-08-29 09:20:04.909742 Test Step 4385 Finished\n",
      "2018-08-29 09:20:04.909928 Test Step 4385 \"min loss\" =  13.525784\n",
      "2018-08-29 09:20:04.910009 Test Step 4385 \"loss\" =  15.462772\n",
      "2018-08-29 09:20:04.955338 Training Step 4385 Finished Timing (Training: 0.908586, Test: 0.0838561) after 0.247561 seconds\n",
      "2018-08-29 09:20:04.955483 Training Step 4385 \"min loss\" =  1.7989203\n",
      "2018-08-29 09:20:04.955549 Training Step 4385 \"loss\" =  2.0463035\n",
      "2018-08-29 09:20:05.159320 Test Step 4390 Finished\n",
      "2018-08-29 09:20:05.159483 Test Step 4390 \"min loss\" =  13.525784\n",
      "2018-08-29 09:20:05.159581 Test Step 4390 \"loss\" =  14.7646475\n",
      "2018-08-29 09:20:05.204888 Training Step 4390 Finished Timing (Training: 0.908835, Test: 0.0838743) after 0.24925 seconds\n",
      "2018-08-29 09:20:05.205049 Training Step 4390 \"min loss\" =  1.7989203\n",
      "2018-08-29 09:20:05.205117 Training Step 4390 \"loss\" =  2.0888786\n",
      "2018-08-29 09:20:05.407031 Test Step 4395 Finished\n",
      "2018-08-29 09:20:05.407180 Test Step 4395 \"min loss\" =  13.525784\n",
      "2018-08-29 09:20:05.407970 Test Step 4395 \"loss\" =  14.453276\n",
      "2018-08-29 09:20:05.453674 Training Step 4395 Finished Timing (Training: 0.90888, Test: 0.0838164) after 0.248468 seconds\n",
      "2018-08-29 09:20:05.453821 Training Step 4395 \"min loss\" =  1.7989203\n",
      "2018-08-29 09:20:05.453889 Training Step 4395 \"loss\" =  2.241451\n",
      "2018-08-29 09:20:05.656221 Test Step 4400 Finished\n",
      "2018-08-29 09:20:05.656393 Test Step 4400 \"min loss\" =  13.525784\n",
      "2018-08-29 09:20:05.656478 Test Step 4400 \"loss\" =  14.213878\n",
      "2018-08-29 09:20:05.702737 Training Step 4400 Finished Timing (Training: 0.909131, Test: 0.0837907) after 0.248742 seconds\n",
      "2018-08-29 09:20:05.702946 Training Step 4400 \"min loss\" =  1.7989203\n",
      "2018-08-29 09:20:05.703073 Training Step 4400 \"loss\" =  2.02745\n",
      "2018-08-29 09:20:05.906305 Test Step 4405 Finished\n",
      "2018-08-29 09:20:05.906464 Test Step 4405 \"min loss\" =  13.525784\n",
      "2018-08-29 09:20:05.906526 Test Step 4405 \"loss\" =  14.1953335\n",
      "2018-08-29 09:20:05.952031 Training Step 4405 Finished Timing (Training: 0.915074, Test: 0.0835821) after 0.248863 seconds\n",
      "2018-08-29 09:20:05.952173 Training Step 4405 \"min loss\" =  1.7989203\n",
      "2018-08-29 09:20:05.952804 Training Step 4405 \"loss\" =  2.17004\n",
      "2018-08-29 09:20:06.155914 Test Step 4410 Finished\n",
      "2018-08-29 09:20:06.156792 Test Step 4410 \"min loss\" =  13.525784\n",
      "2018-08-29 09:20:06.156924 Test Step 4410 \"loss\" =  14.079143\n",
      "2018-08-29 09:20:06.202704 Training Step 4410 Finished Timing (Training: 0.91101, Test: 0.0834387) after 0.24981 seconds\n",
      "2018-08-29 09:20:06.202900 Training Step 4410 \"min loss\" =  1.7989203\n",
      "2018-08-29 09:20:06.202989 Training Step 4410 \"loss\" =  2.1085207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:20:06.406158 Test Step 4415 Finished\n",
      "2018-08-29 09:20:06.406757 Test Step 4415 \"min loss\" =  13.525784\n",
      "2018-08-29 09:20:06.407493 Test Step 4415 \"loss\" =  14.356298\n",
      "2018-08-29 09:20:06.452728 Training Step 4415 Finished Timing (Training: 0.908455, Test: 0.0833902) after 0.248201 seconds\n",
      "2018-08-29 09:20:06.452863 Training Step 4415 \"min loss\" =  1.7989203\n",
      "2018-08-29 09:20:06.452940 Training Step 4415 \"loss\" =  2.5861778\n",
      "2018-08-29 09:20:06.653799 Test Step 4420 Finished\n",
      "2018-08-29 09:20:06.653969 Test Step 4420 \"min loss\" =  13.525784\n",
      "2018-08-29 09:20:06.654753 Test Step 4420 \"loss\" =  14.319951\n",
      "2018-08-29 09:20:06.700136 Training Step 4420 Finished Timing (Training: 0.909097, Test: 0.08339) after 0.247115 seconds\n",
      "2018-08-29 09:20:06.700266 Training Step 4420 \"min loss\" =  1.7989203\n",
      "2018-08-29 09:20:06.700330 Training Step 4420 \"loss\" =  2.0165904\n",
      "2018-08-29 09:20:06.902292 Test Step 4425 Finished\n",
      "2018-08-29 09:20:06.902437 Test Step 4425 \"min loss\" =  13.525784\n",
      "2018-08-29 09:20:06.903451 Test Step 4425 \"loss\" =  15.385305\n",
      "2018-08-29 09:20:06.948372 Training Step 4425 Finished Timing (Training: 0.908744, Test: 0.0831325) after 0.246886 seconds\n",
      "2018-08-29 09:20:06.948507 Training Step 4425 \"min loss\" =  1.7989203\n",
      "2018-08-29 09:20:06.948571 Training Step 4425 \"loss\" =  2.2428663\n",
      "2018-08-29 09:20:07.150933 Test Step 4430 Finished\n",
      "2018-08-29 09:20:07.151089 Test Step 4430 \"min loss\" =  13.525784\n",
      "2018-08-29 09:20:07.151158 Test Step 4430 \"loss\" =  14.622792\n",
      "2018-08-29 09:20:07.196241 Training Step 4430 Finished Timing (Training: 0.908557, Test: 0.0833825) after 0.246293 seconds\n",
      "2018-08-29 09:20:07.196381 Training Step 4430 \"min loss\" =  1.7989203\n",
      "2018-08-29 09:20:07.197026 Training Step 4430 \"loss\" =  2.0909994\n",
      "2018-08-29 09:20:07.398651 Test Step 4435 Finished\n",
      "2018-08-29 09:20:07.399344 Test Step 4435 \"min loss\" =  13.525784\n",
      "2018-08-29 09:20:07.399434 Test Step 4435 \"loss\" =  14.263168\n",
      "2018-08-29 09:20:07.444576 Training Step 4435 Finished Timing (Training: 0.908774, Test: 0.0832908) after 0.247455 seconds\n",
      "2018-08-29 09:20:07.444726 Training Step 4435 \"min loss\" =  1.7989203\n",
      "2018-08-29 09:20:07.444791 Training Step 4435 \"loss\" =  2.1159458\n",
      "2018-08-29 09:20:07.646695 Test Step 4440 Finished\n",
      "2018-08-29 09:20:07.646873 Test Step 4440 \"min loss\" =  13.525784\n",
      "2018-08-29 09:20:07.646945 Test Step 4440 \"loss\" =  15.181258\n",
      "2018-08-29 09:20:07.693036 Training Step 4440 Finished Timing (Training: 0.90853, Test: 0.0833217) after 0.247239 seconds\n",
      "2018-08-29 09:20:07.693625 Training Step 4440 \"min loss\" =  1.7989203\n",
      "2018-08-29 09:20:07.693729 Training Step 4440 \"loss\" =  2.0878892\n",
      "2018-08-29 09:20:07.895287 Test Step 4445 Finished\n",
      "2018-08-29 09:20:07.895958 Test Step 4445 \"min loss\" =  13.525784\n",
      "2018-08-29 09:20:07.896219 Test Step 4445 \"loss\" =  14.146865\n",
      "2018-08-29 09:20:07.941680 Training Step 4445 Finished Timing (Training: 0.908507, Test: 0.0832689) after 0.24786 seconds\n",
      "2018-08-29 09:20:07.942282 Training Step 4445 \"min loss\" =  1.7989203\n",
      "2018-08-29 09:20:07.942560 Training Step 4445 \"loss\" =  2.1072586\n",
      "2018-08-29 09:20:08.144023 Test Step 4450 Finished\n",
      "2018-08-29 09:20:08.144575 Test Step 4450 \"min loss\" =  13.525784\n",
      "2018-08-29 09:20:08.145195 Test Step 4450 \"loss\" =  13.90235\n",
      "2018-08-29 09:20:08.190837 Training Step 4450 Finished Timing (Training: 0.908363, Test: 0.0832237) after 0.248186 seconds\n",
      "2018-08-29 09:20:08.190980 Training Step 4450 \"min loss\" =  1.7989203\n",
      "2018-08-29 09:20:08.191052 Training Step 4450 \"loss\" =  1.9177958\n",
      "2018-08-29 09:20:08.393695 Test Step 4455 Finished\n",
      "2018-08-29 09:20:08.393835 Test Step 4455 \"min loss\" =  13.525784\n",
      "2018-08-29 09:20:08.393907 Test Step 4455 \"loss\" =  14.431812\n",
      "2018-08-29 09:20:08.439728 Training Step 4455 Finished Timing (Training: 0.908513, Test: 0.0833228) after 0.24859 seconds\n",
      "2018-08-29 09:20:08.440134 Training Step 4455 \"min loss\" =  1.7989203\n",
      "2018-08-29 09:20:08.440391 Training Step 4455 \"loss\" =  2.191289\n",
      "2018-08-29 09:20:08.642713 Test Step 4460 Finished\n",
      "2018-08-29 09:20:08.643267 Test Step 4460 \"min loss\" =  13.525784\n",
      "2018-08-29 09:20:08.643344 Test Step 4460 \"loss\" =  14.040546\n",
      "2018-08-29 09:20:08.689197 Training Step 4460 Finished Timing (Training: 0.908451, Test: 0.0832969) after 0.248712 seconds\n",
      "2018-08-29 09:20:08.689363 Training Step 4460 \"min loss\" =  1.7989203\n",
      "2018-08-29 09:20:08.690079 Training Step 4460 \"loss\" =  2.1110666\n",
      "2018-08-29 09:20:08.892230 Test Step 4465 Finished\n",
      "2018-08-29 09:20:08.892405 Test Step 4465 \"min loss\" =  13.525784\n",
      "2018-08-29 09:20:08.893415 Test Step 4465 \"loss\" =  13.936935\n",
      "2018-08-29 09:20:08.939021 Training Step 4465 Finished Timing (Training: 0.908267, Test: 0.0832398) after 0.248776 seconds\n",
      "2018-08-29 09:20:08.939149 Training Step 4465 \"min loss\" =  1.7989203\n",
      "2018-08-29 09:20:08.939208 Training Step 4465 \"loss\" =  2.2400954\n",
      "2018-08-29 09:20:09.142026 Test Step 4470 Finished\n",
      "2018-08-29 09:20:09.142224 Test Step 4470 \"min loss\" =  13.525784\n",
      "2018-08-29 09:20:09.142349 Test Step 4470 \"loss\" =  13.837407\n",
      "2018-08-29 09:20:09.189319 Training Step 4470 Finished Timing (Training: 0.908344, Test: 0.0831678) after 0.248693 seconds\n",
      "2018-08-29 09:20:09.189450 Training Step 4470 \"min loss\" =  1.7989203\n",
      "2018-08-29 09:20:09.189512 Training Step 4470 \"loss\" =  2.225032\n",
      "2018-08-29 09:20:09.391963 Test Step 4475 Finished\n",
      "2018-08-29 09:20:09.392117 Test Step 4475 \"min loss\" =  13.508951\n",
      "2018-08-29 09:20:09.392188 Test Step 4475 \"loss\" =  13.508951\n",
      "2018-08-29 09:20:09.438409 Training Step 4475 Finished Timing (Training: 0.908476, Test: 0.0831716) after 0.247825 seconds\n",
      "2018-08-29 09:20:09.438844 Training Step 4475 \"min loss\" =  1.7989203\n",
      "2018-08-29 09:20:09.439226 Training Step 4475 \"loss\" =  2.2877302\n",
      "2018-08-29 09:20:09.640958 Test Step 4480 Finished\n",
      "2018-08-29 09:20:09.641777 Test Step 4480 \"min loss\" =  13.508951\n",
      "2018-08-29 09:20:09.642228 Test Step 4480 \"loss\" =  14.324304\n",
      "2018-08-29 09:20:09.687714 Training Step 4480 Finished Timing (Training: 0.908346, Test: 0.0831468) after 0.248031 seconds\n",
      "2018-08-29 09:20:09.687889 Training Step 4480 \"min loss\" =  1.7739292\n",
      "2018-08-29 09:20:09.688552 Training Step 4480 \"loss\" =  2.0692117\n",
      "2018-08-29 09:20:09.890644 Test Step 4485 Finished\n",
      "2018-08-29 09:20:09.890819 Test Step 4485 \"min loss\" =  13.508951\n",
      "2018-08-29 09:20:09.891815 Test Step 4485 \"loss\" =  14.532085\n",
      "2018-08-29 09:20:09.937500 Training Step 4485 Finished Timing (Training: 0.908264, Test: 0.0830964) after 0.248838 seconds\n",
      "2018-08-29 09:20:09.938120 Training Step 4485 \"min loss\" =  1.7739292\n",
      "2018-08-29 09:20:09.938516 Training Step 4485 \"loss\" =  1.817471\n",
      "2018-08-29 09:20:10.139961 Test Step 4490 Finished\n",
      "2018-08-29 09:20:10.140191 Test Step 4490 \"min loss\" =  13.508951\n",
      "2018-08-29 09:20:10.140335 Test Step 4490 \"loss\" =  15.065104\n",
      "2018-08-29 09:20:10.185733 Training Step 4490 Finished Timing (Training: 0.908336, Test: 0.0831279) after 0.247132 seconds\n",
      "2018-08-29 09:20:10.185875 Training Step 4490 \"min loss\" =  1.7739292\n",
      "2018-08-29 09:20:10.185939 Training Step 4490 \"loss\" =  2.1022773\n",
      "2018-08-29 09:20:10.388502 Test Step 4495 Finished\n",
      "2018-08-29 09:20:10.388693 Test Step 4495 \"min loss\" =  13.508951\n",
      "2018-08-29 09:20:10.388760 Test Step 4495 \"loss\" =  14.661968\n",
      "2018-08-29 09:20:10.434121 Training Step 4495 Finished Timing (Training: 0.908416, Test: 0.0832032) after 0.24737 seconds\n",
      "2018-08-29 09:20:10.434318 Training Step 4495 \"min loss\" =  1.7739292\n",
      "2018-08-29 09:20:10.434413 Training Step 4495 \"loss\" =  2.122802\n",
      "2018-08-29 09:20:10.636841 Test Step 4500 Finished\n",
      "2018-08-29 09:20:10.636986 Test Step 4500 \"min loss\" =  13.0416975\n",
      "2018-08-29 09:20:10.637626 Test Step 4500 \"loss\" =  13.0416975\n",
      "2018-08-29 09:20:10.683427 Training Step 4500 Finished Timing (Training: 0.908343, Test: 0.0832357) after 0.248267 seconds\n",
      "2018-08-29 09:20:10.683889 Training Step 4500 \"min loss\" =  1.7739292\n",
      "2018-08-29 09:20:10.684290 Training Step 4500 \"loss\" =  2.129047\n",
      "2018-08-29 09:20:10.885608 Test Step 4505 Finished\n",
      "2018-08-29 09:20:10.885740 Test Step 4505 \"min loss\" =  13.0416975\n",
      "2018-08-29 09:20:10.885805 Test Step 4505 \"loss\" =  13.843731\n",
      "2018-08-29 09:20:10.932535 Training Step 4505 Finished Timing (Training: 0.914207, Test: 0.0845084) after 0.247907 seconds\n",
      "2018-08-29 09:20:10.932693 Training Step 4505 \"min loss\" =  1.7739292\n",
      "2018-08-29 09:20:10.933211 Training Step 4505 \"loss\" =  2.062431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:20:11.134138 Test Step 4510 Finished\n",
      "2018-08-29 09:20:11.134755 Test Step 4510 \"min loss\" =  13.0416975\n",
      "2018-08-29 09:20:11.135348 Test Step 4510 \"loss\" =  14.229713\n",
      "2018-08-29 09:20:11.181248 Training Step 4510 Finished Timing (Training: 0.910688, Test: 0.0838222) after 0.247945 seconds\n",
      "2018-08-29 09:20:11.181418 Training Step 4510 \"min loss\" =  1.7739292\n",
      "2018-08-29 09:20:11.182199 Training Step 4510 \"loss\" =  1.8740978\n",
      "2018-08-29 09:20:11.384083 Test Step 4515 Finished\n",
      "2018-08-29 09:20:11.384206 Test Step 4515 \"min loss\" =  13.0416975\n",
      "2018-08-29 09:20:11.384283 Test Step 4515 \"loss\" =  13.574236\n",
      "2018-08-29 09:20:11.430948 Training Step 4515 Finished Timing (Training: 0.910384, Test: 0.0835022) after 0.248222 seconds\n",
      "2018-08-29 09:20:11.431073 Training Step 4515 \"min loss\" =  1.7739292\n",
      "2018-08-29 09:20:11.431799 Training Step 4515 \"loss\" =  1.8803777\n",
      "2018-08-29 09:20:11.632738 Test Step 4520 Finished\n",
      "2018-08-29 09:20:11.632873 Test Step 4520 \"min loss\" =  13.0416975\n",
      "2018-08-29 09:20:11.633641 Test Step 4520 \"loss\" =  13.856379\n",
      "2018-08-29 09:20:11.678928 Training Step 4520 Finished Timing (Training: 0.909586, Test: 0.0832661) after 0.246745 seconds\n",
      "2018-08-29 09:20:11.679058 Training Step 4520 \"min loss\" =  1.7739292\n",
      "2018-08-29 09:20:11.679114 Training Step 4520 \"loss\" =  2.0955496\n",
      "2018-08-29 09:20:11.882030 Test Step 4525 Finished\n",
      "2018-08-29 09:20:11.882173 Test Step 4525 \"min loss\" =  13.0416975\n",
      "2018-08-29 09:20:11.882241 Test Step 4525 \"loss\" =  15.467678\n",
      "2018-08-29 09:20:11.927569 Training Step 4525 Finished Timing (Training: 0.910111, Test: 0.0833087) after 0.247901 seconds\n",
      "2018-08-29 09:20:11.927707 Training Step 4525 \"min loss\" =  1.7739292\n",
      "2018-08-29 09:20:11.928383 Training Step 4525 \"loss\" =  2.1318533\n",
      "2018-08-29 09:20:12.129004 Test Step 4530 Finished\n",
      "2018-08-29 09:20:12.129132 Test Step 4530 \"min loss\" =  13.0416975\n",
      "2018-08-29 09:20:12.129205 Test Step 4530 \"loss\" =  14.50056\n",
      "2018-08-29 09:20:12.175182 Training Step 4530 Finished Timing (Training: 0.910567, Test: 0.0831309) after 0.246714 seconds\n",
      "2018-08-29 09:20:12.175310 Training Step 4530 \"min loss\" =  1.7739292\n",
      "2018-08-29 09:20:12.175418 Training Step 4530 \"loss\" =  2.1581607\n",
      "2018-08-29 09:20:12.377065 Test Step 4535 Finished\n",
      "2018-08-29 09:20:12.377209 Test Step 4535 \"min loss\" =  13.0416975\n",
      "2018-08-29 09:20:12.377883 Test Step 4535 \"loss\" =  14.538668\n",
      "2018-08-29 09:20:12.423269 Training Step 4535 Finished Timing (Training: 0.910906, Test: 0.0829674) after 0.247758 seconds\n",
      "2018-08-29 09:20:12.423447 Training Step 4535 \"min loss\" =  1.7739292\n",
      "2018-08-29 09:20:12.423547 Training Step 4535 \"loss\" =  2.1729789\n",
      "2018-08-29 09:20:12.624978 Test Step 4540 Finished\n",
      "2018-08-29 09:20:12.625105 Test Step 4540 \"min loss\" =  13.0416975\n",
      "2018-08-29 09:20:12.625186 Test Step 4540 \"loss\" =  13.835382\n",
      "2018-08-29 09:20:12.671850 Training Step 4540 Finished Timing (Training: 0.911347, Test: 0.0829263) after 0.248167 seconds\n",
      "2018-08-29 09:20:12.671991 Training Step 4540 \"min loss\" =  1.7739292\n",
      "2018-08-29 09:20:12.672474 Training Step 4540 \"loss\" =  2.1304412\n",
      "2018-08-29 09:20:12.874039 Test Step 4545 Finished\n",
      "2018-08-29 09:20:12.874169 Test Step 4545 \"min loss\" =  13.0416975\n",
      "2018-08-29 09:20:12.875037 Test Step 4545 \"loss\" =  14.302593\n",
      "2018-08-29 09:20:12.920144 Training Step 4545 Finished Timing (Training: 0.911049, Test: 0.0828929) after 0.247262 seconds\n",
      "2018-08-29 09:20:12.920274 Training Step 4545 \"min loss\" =  1.7739292\n",
      "2018-08-29 09:20:12.920358 Training Step 4545 \"loss\" =  2.1261816\n",
      "2018-08-29 09:20:13.123263 Test Step 4550 Finished\n",
      "2018-08-29 09:20:13.124049 Test Step 4550 \"min loss\" =  13.0416975\n",
      "2018-08-29 09:20:13.124430 Test Step 4550 \"loss\" =  14.238852\n",
      "2018-08-29 09:20:13.170086 Training Step 4550 Finished Timing (Training: 0.910447, Test: 0.0829633) after 0.248759 seconds\n",
      "2018-08-29 09:20:13.170232 Training Step 4550 \"min loss\" =  1.7739292\n",
      "2018-08-29 09:20:13.170299 Training Step 4550 \"loss\" =  2.0069664\n",
      "2018-08-29 09:20:13.372755 Test Step 4555 Finished\n",
      "2018-08-29 09:20:13.372916 Test Step 4555 \"min loss\" =  13.0416975\n",
      "2018-08-29 09:20:13.372987 Test Step 4555 \"loss\" =  13.5836735\n",
      "2018-08-29 09:20:13.419039 Training Step 4555 Finished Timing (Training: 0.910316, Test: 0.0830987) after 0.247678 seconds\n",
      "2018-08-29 09:20:13.419185 Training Step 4555 \"min loss\" =  1.7739292\n",
      "2018-08-29 09:20:13.419246 Training Step 4555 \"loss\" =  1.9531479\n",
      "2018-08-29 09:20:13.622704 Test Step 4560 Finished\n",
      "2018-08-29 09:20:13.622876 Test Step 4560 \"min loss\" =  13.0416975\n",
      "2018-08-29 09:20:13.622944 Test Step 4560 \"loss\" =  13.554134\n",
      "2018-08-29 09:20:13.668184 Training Step 4560 Finished Timing (Training: 0.910661, Test: 0.0830898) after 0.248864 seconds\n",
      "2018-08-29 09:20:13.668316 Training Step 4560 \"min loss\" =  1.7739292\n",
      "2018-08-29 09:20:13.668378 Training Step 4560 \"loss\" =  2.1472993\n",
      "2018-08-29 09:20:13.870503 Test Step 4565 Finished\n",
      "2018-08-29 09:20:13.870642 Test Step 4565 \"min loss\" =  13.0416975\n",
      "2018-08-29 09:20:13.871188 Test Step 4565 \"loss\" =  13.875189\n",
      "2018-08-29 09:20:13.916307 Training Step 4565 Finished Timing (Training: 0.910507, Test: 0.0830816) after 0.246852 seconds\n",
      "2018-08-29 09:20:13.916755 Training Step 4565 \"min loss\" =  1.7739292\n",
      "2018-08-29 09:20:13.917216 Training Step 4565 \"loss\" =  1.942766\n",
      "2018-08-29 09:20:14.118418 Test Step 4570 Finished\n",
      "2018-08-29 09:20:14.118610 Test Step 4570 \"min loss\" =  13.0416975\n",
      "2018-08-29 09:20:14.119183 Test Step 4570 \"loss\" =  13.213472\n",
      "2018-08-29 09:20:14.164570 Training Step 4570 Finished Timing (Training: 0.910394, Test: 0.0830128) after 0.246976 seconds\n",
      "2018-08-29 09:20:14.164723 Training Step 4570 \"min loss\" =  1.7739292\n",
      "2018-08-29 09:20:14.164787 Training Step 4570 \"loss\" =  1.989906\n",
      "2018-08-29 09:20:14.367715 Test Step 4575 Finished\n",
      "2018-08-29 09:20:14.367912 Test Step 4575 \"min loss\" =  13.0416975\n",
      "2018-08-29 09:20:14.368031 Test Step 4575 \"loss\" =  13.524987\n",
      "2018-08-29 09:20:14.413580 Training Step 4575 Finished Timing (Training: 0.910239, Test: 0.0831569) after 0.247812 seconds\n",
      "2018-08-29 09:20:14.413716 Training Step 4575 \"min loss\" =  1.7739292\n",
      "2018-08-29 09:20:14.413777 Training Step 4575 \"loss\" =  2.0621161\n",
      "2018-08-29 09:20:14.616018 Test Step 4580 Finished\n",
      "2018-08-29 09:20:14.616173 Test Step 4580 \"min loss\" =  13.0416975\n",
      "2018-08-29 09:20:14.616244 Test Step 4580 \"loss\" =  13.923161\n",
      "2018-08-29 09:20:14.661460 Training Step 4580 Finished Timing (Training: 0.91048, Test: 0.08317) after 0.247602 seconds\n",
      "2018-08-29 09:20:14.661603 Training Step 4580 \"min loss\" =  1.7739292\n",
      "2018-08-29 09:20:14.661668 Training Step 4580 \"loss\" =  1.9857799\n",
      "2018-08-29 09:20:14.864453 Test Step 4585 Finished\n",
      "2018-08-29 09:20:14.864990 Test Step 4585 \"min loss\" =  13.0416975\n",
      "2018-08-29 09:20:14.865213 Test Step 4585 \"loss\" =  14.276345\n",
      "2018-08-29 09:20:14.910846 Training Step 4585 Finished Timing (Training: 0.910349, Test: 0.0831603) after 0.248394 seconds\n",
      "2018-08-29 09:20:14.911406 Training Step 4585 \"min loss\" =  1.7739292\n",
      "2018-08-29 09:20:14.911516 Training Step 4585 \"loss\" =  2.140813\n",
      "2018-08-29 09:20:15.113587 Test Step 4590 Finished\n",
      "2018-08-29 09:20:15.113731 Test Step 4590 \"min loss\" =  13.0416975\n",
      "2018-08-29 09:20:15.114452 Test Step 4590 \"loss\" =  14.604053\n",
      "2018-08-29 09:20:15.159983 Training Step 4590 Finished Timing (Training: 0.910059, Test: 0.0831798) after 0.247516 seconds\n",
      "2018-08-29 09:20:15.160165 Training Step 4590 \"min loss\" =  1.7739292\n",
      "2018-08-29 09:20:15.160292 Training Step 4590 \"loss\" =  2.1271167\n",
      "2018-08-29 09:20:15.363791 Test Step 4595 Finished\n",
      "2018-08-29 09:20:15.363923 Test Step 4595 \"min loss\" =  13.0416975\n",
      "2018-08-29 09:20:15.364607 Test Step 4595 \"loss\" =  14.564202\n",
      "2018-08-29 09:20:15.410555 Training Step 4595 Finished Timing (Training: 0.910061, Test: 0.0831672) after 0.250125 seconds\n",
      "2018-08-29 09:20:15.410688 Training Step 4595 \"min loss\" =  1.7739292\n",
      "2018-08-29 09:20:15.410749 Training Step 4595 \"loss\" =  1.9978262\n",
      "2018-08-29 09:20:15.614955 Test Step 4600 Finished\n",
      "2018-08-29 09:20:15.615086 Test Step 4600 \"min loss\" =  13.0416975\n",
      "2018-08-29 09:20:15.615148 Test Step 4600 \"loss\" =  14.311916\n",
      "2018-08-29 09:20:15.661008 Training Step 4600 Finished Timing (Training: 0.909808, Test: 0.0831928) after 0.24874 seconds\n",
      "2018-08-29 09:20:15.661159 Training Step 4600 \"min loss\" =  1.7739292\n",
      "2018-08-29 09:20:15.661270 Training Step 4600 \"loss\" =  2.2264955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:20:15.862968 Test Step 4605 Finished\n",
      "2018-08-29 09:20:15.863512 Test Step 4605 \"min loss\" =  13.0416975\n",
      "2018-08-29 09:20:15.863598 Test Step 4605 \"loss\" =  14.04624\n",
      "2018-08-29 09:20:15.908660 Training Step 4605 Finished Timing (Training: 0.912818, Test: 0.0841641) after 0.247276 seconds\n",
      "2018-08-29 09:20:15.908800 Training Step 4605 \"min loss\" =  1.7739292\n",
      "2018-08-29 09:20:15.909471 Training Step 4605 \"loss\" =  2.06367\n",
      "2018-08-29 09:20:16.111162 Test Step 4610 Finished\n",
      "2018-08-29 09:20:16.111793 Test Step 4610 \"min loss\" =  13.0416975\n",
      "2018-08-29 09:20:16.111877 Test Step 4610 \"loss\" =  13.528733\n",
      "2018-08-29 09:20:16.157027 Training Step 4610 Finished Timing (Training: 0.911548, Test: 0.0833728) after 0.247439 seconds\n",
      "2018-08-29 09:20:16.157178 Training Step 4610 \"min loss\" =  1.7536542\n",
      "2018-08-29 09:20:16.157973 Training Step 4610 \"loss\" =  1.7536542\n",
      "2018-08-29 09:20:16.360390 Test Step 4615 Finished\n",
      "2018-08-29 09:20:16.360545 Test Step 4615 \"min loss\" =  13.0416975\n",
      "2018-08-29 09:20:16.360643 Test Step 4615 \"loss\" =  13.651685\n",
      "2018-08-29 09:20:16.407014 Training Step 4615 Finished Timing (Training: 0.910993, Test: 0.0837246) after 0.248937 seconds\n",
      "2018-08-29 09:20:16.407608 Training Step 4615 \"min loss\" =  1.7536542\n",
      "2018-08-29 09:20:16.407761 Training Step 4615 \"loss\" =  2.1005354\n",
      "2018-08-29 09:20:16.609824 Test Step 4620 Finished\n",
      "2018-08-29 09:20:16.609991 Test Step 4620 \"min loss\" =  13.0416975\n",
      "2018-08-29 09:20:16.610878 Test Step 4620 \"loss\" =  14.474869\n",
      "2018-08-29 09:20:16.656517 Training Step 4620 Finished Timing (Training: 0.910571, Test: 0.0833376) after 0.248601 seconds\n",
      "2018-08-29 09:20:16.656685 Training Step 4620 \"min loss\" =  1.7536542\n",
      "2018-08-29 09:20:16.657184 Training Step 4620 \"loss\" =  2.1677926\n",
      "2018-08-29 09:20:16.858712 Test Step 4625 Finished\n",
      "2018-08-29 09:20:16.859408 Test Step 4625 \"min loss\" =  12.964176\n",
      "2018-08-29 09:20:16.860014 Test Step 4625 \"loss\" =  12.964176\n",
      "2018-08-29 09:20:16.905340 Training Step 4625 Finished Timing (Training: 0.909754, Test: 0.0833749) after 0.247763 seconds\n",
      "2018-08-29 09:20:16.905486 Training Step 4625 \"min loss\" =  1.7536542\n",
      "2018-08-29 09:20:16.905551 Training Step 4625 \"loss\" =  2.0018501\n",
      "2018-08-29 09:20:17.108125 Test Step 4630 Finished\n",
      "2018-08-29 09:20:17.108290 Test Step 4630 \"min loss\" =  12.964176\n",
      "2018-08-29 09:20:17.109028 Test Step 4630 \"loss\" =  13.415505\n",
      "2018-08-29 09:20:17.154426 Training Step 4630 Finished Timing (Training: 0.909435, Test: 0.0832908) after 0.247849 seconds\n",
      "2018-08-29 09:20:17.154574 Training Step 4630 \"min loss\" =  1.7536542\n",
      "2018-08-29 09:20:17.155354 Training Step 4630 \"loss\" =  2.0384376\n",
      "2018-08-29 09:20:17.356193 Test Step 4635 Finished\n",
      "2018-08-29 09:20:17.356352 Test Step 4635 \"min loss\" =  12.964176\n",
      "2018-08-29 09:20:17.356422 Test Step 4635 \"loss\" =  13.426981\n",
      "2018-08-29 09:20:17.402398 Training Step 4635 Finished Timing (Training: 0.909692, Test: 0.0832787) after 0.246944 seconds\n",
      "2018-08-29 09:20:17.402546 Training Step 4635 \"min loss\" =  1.7536542\n",
      "2018-08-29 09:20:17.402608 Training Step 4635 \"loss\" =  2.3151245\n",
      "2018-08-29 09:20:17.604217 Test Step 4640 Finished\n",
      "2018-08-29 09:20:17.604741 Test Step 4640 \"min loss\" =  12.964176\n",
      "2018-08-29 09:20:17.605033 Test Step 4640 \"loss\" =  13.087658\n",
      "2018-08-29 09:20:17.650929 Training Step 4640 Finished Timing (Training: 0.909674, Test: 0.0833341) after 0.248241 seconds\n",
      "2018-08-29 09:20:17.651052 Training Step 4640 \"min loss\" =  1.7536542\n",
      "2018-08-29 09:20:17.651565 Training Step 4640 \"loss\" =  2.095696\n",
      "2018-08-29 09:20:17.853761 Test Step 4645 Finished\n",
      "2018-08-29 09:20:17.854303 Test Step 4645 \"min loss\" =  12.964176\n",
      "2018-08-29 09:20:17.855188 Test Step 4645 \"loss\" =  14.834459\n",
      "2018-08-29 09:20:17.900810 Training Step 4645 Finished Timing (Training: 0.908775, Test: 0.0834459) after 0.248449 seconds\n",
      "2018-08-29 09:20:17.900938 Training Step 4645 \"min loss\" =  1.7536542\n",
      "2018-08-29 09:20:17.901022 Training Step 4645 \"loss\" =  2.0292668\n",
      "2018-08-29 09:20:18.104253 Test Step 4650 Finished\n",
      "2018-08-29 09:20:18.104924 Test Step 4650 \"min loss\" =  12.964176\n",
      "2018-08-29 09:20:18.105347 Test Step 4650 \"loss\" =  14.108635\n",
      "2018-08-29 09:20:18.150900 Training Step 4650 Finished Timing (Training: 0.908924, Test: 0.0833642) after 0.249798 seconds\n",
      "2018-08-29 09:20:18.151042 Training Step 4650 \"min loss\" =  1.7536542\n",
      "2018-08-29 09:20:18.151539 Training Step 4650 \"loss\" =  1.8138914\n",
      "2018-08-29 09:20:18.352956 Test Step 4655 Finished\n",
      "2018-08-29 09:20:18.353091 Test Step 4655 \"min loss\" =  12.843999\n",
      "2018-08-29 09:20:18.353155 Test Step 4655 \"loss\" =  12.843999\n",
      "2018-08-29 09:20:18.399269 Training Step 4655 Finished Timing (Training: 0.908866, Test: 0.0833494) after 0.247642 seconds\n",
      "2018-08-29 09:20:18.399408 Training Step 4655 \"min loss\" =  1.7536542\n",
      "2018-08-29 09:20:18.399471 Training Step 4655 \"loss\" =  2.1013415\n",
      "2018-08-29 09:20:18.601226 Test Step 4660 Finished\n",
      "2018-08-29 09:20:18.601811 Test Step 4660 \"min loss\" =  12.843999\n",
      "2018-08-29 09:20:18.602076 Test Step 4660 \"loss\" =  13.1102295\n",
      "2018-08-29 09:20:18.647705 Training Step 4660 Finished Timing (Training: 0.908907, Test: 0.083514) after 0.248134 seconds\n",
      "2018-08-29 09:20:18.647894 Training Step 4660 \"min loss\" =  1.7536542\n",
      "2018-08-29 09:20:18.648012 Training Step 4660 \"loss\" =  1.9729439\n",
      "2018-08-29 09:20:18.851456 Test Step 4665 Finished\n",
      "2018-08-29 09:20:18.851582 Test Step 4665 \"min loss\" =  12.843999\n",
      "2018-08-29 09:20:18.851646 Test Step 4665 \"loss\" =  13.972197\n",
      "2018-08-29 09:20:18.897607 Training Step 4665 Finished Timing (Training: 0.909393, Test: 0.0833803) after 0.249454 seconds\n",
      "2018-08-29 09:20:18.897751 Training Step 4665 \"min loss\" =  1.7536542\n",
      "2018-08-29 09:20:18.898334 Training Step 4665 \"loss\" =  2.1239038\n",
      "2018-08-29 09:20:19.099856 Test Step 4670 Finished\n",
      "2018-08-29 09:20:19.100017 Test Step 4670 \"min loss\" =  12.475284\n",
      "2018-08-29 09:20:19.100083 Test Step 4670 \"loss\" =  12.475284\n",
      "2018-08-29 09:20:19.146303 Training Step 4670 Finished Timing (Training: 0.909624, Test: 0.0833324) after 0.247882 seconds\n",
      "2018-08-29 09:20:19.146830 Training Step 4670 \"min loss\" =  1.7251519\n",
      "2018-08-29 09:20:19.147105 Training Step 4670 \"loss\" =  2.2254422\n",
      "2018-08-29 09:20:19.349338 Test Step 4675 Finished\n",
      "2018-08-29 09:20:19.349929 Test Step 4675 \"min loss\" =  12.475284\n",
      "2018-08-29 09:20:19.350006 Test Step 4675 \"loss\" =  13.083294\n",
      "2018-08-29 09:20:19.395731 Training Step 4675 Finished Timing (Training: 0.909582, Test: 0.0832971) after 0.248185 seconds\n",
      "2018-08-29 09:20:19.395889 Training Step 4675 \"min loss\" =  1.7251519\n",
      "2018-08-29 09:20:19.395957 Training Step 4675 \"loss\" =  2.023049\n",
      "2018-08-29 09:20:19.598154 Test Step 4680 Finished\n",
      "2018-08-29 09:20:19.598652 Test Step 4680 \"min loss\" =  12.475284\n",
      "2018-08-29 09:20:19.598719 Test Step 4680 \"loss\" =  13.0401535\n",
      "2018-08-29 09:20:19.643870 Training Step 4680 Finished Timing (Training: 0.909748, Test: 0.0833245) after 0.247835 seconds\n",
      "2018-08-29 09:20:19.644005 Training Step 4680 \"min loss\" =  1.7251519\n",
      "2018-08-29 09:20:19.644857 Training Step 4680 \"loss\" =  1.9598756\n",
      "2018-08-29 09:20:19.846347 Test Step 4685 Finished\n",
      "2018-08-29 09:20:19.846579 Test Step 4685 \"min loss\" =  12.475284\n",
      "2018-08-29 09:20:19.846686 Test Step 4685 \"loss\" =  13.438221\n",
      "2018-08-29 09:20:19.891940 Training Step 4685 Finished Timing (Training: 0.909744, Test: 0.08336) after 0.246988 seconds\n",
      "2018-08-29 09:20:19.892440 Training Step 4685 \"min loss\" =  1.7251519\n",
      "2018-08-29 09:20:19.892670 Training Step 4685 \"loss\" =  2.054145\n",
      "2018-08-29 09:20:20.095438 Test Step 4690 Finished\n",
      "2018-08-29 09:20:20.095579 Test Step 4690 \"min loss\" =  12.475284\n",
      "2018-08-29 09:20:20.095645 Test Step 4690 \"loss\" =  13.144173\n",
      "2018-08-29 09:20:20.142244 Training Step 4690 Finished Timing (Training: 0.90925, Test: 0.0835114) after 0.248898 seconds\n",
      "2018-08-29 09:20:20.142389 Training Step 4690 \"min loss\" =  1.7251519\n",
      "2018-08-29 09:20:20.143049 Training Step 4690 \"loss\" =  1.9321712\n",
      "2018-08-29 09:20:20.344666 Test Step 4695 Finished\n",
      "2018-08-29 09:20:20.344828 Test Step 4695 \"min loss\" =  12.475284\n",
      "2018-08-29 09:20:20.345690 Test Step 4695 \"loss\" =  13.289847\n",
      "2018-08-29 09:20:20.391335 Training Step 4695 Finished Timing (Training: 0.909223, Test: 0.0834849) after 0.248203 seconds\n",
      "2018-08-29 09:20:20.391463 Training Step 4695 \"min loss\" =  1.7251519\n",
      "2018-08-29 09:20:20.392057 Training Step 4695 \"loss\" =  1.9756738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:20:20.594285 Test Step 4700 Finished\n",
      "2018-08-29 09:20:20.594438 Test Step 4700 \"min loss\" =  12.475284\n",
      "2018-08-29 09:20:20.595080 Test Step 4700 \"loss\" =  12.699254\n",
      "2018-08-29 09:20:20.640633 Training Step 4700 Finished Timing (Training: 0.909163, Test: 0.0834262) after 0.247788 seconds\n",
      "2018-08-29 09:20:20.641076 Training Step 4700 \"min loss\" =  1.7251519\n",
      "2018-08-29 09:20:20.641395 Training Step 4700 \"loss\" =  2.0649645\n",
      "2018-08-29 09:20:20.843125 Test Step 4705 Finished\n",
      "2018-08-29 09:20:20.843843 Test Step 4705 \"min loss\" =  12.475284\n",
      "2018-08-29 09:20:20.843914 Test Step 4705 \"loss\" =  12.959394\n",
      "2018-08-29 09:20:20.888985 Training Step 4705 Finished Timing (Training: 0.910788, Test: 0.0855588) after 0.247508 seconds\n",
      "2018-08-29 09:20:20.889129 Training Step 4705 \"min loss\" =  1.7251519\n",
      "2018-08-29 09:20:20.889790 Training Step 4705 \"loss\" =  1.9973332\n",
      "2018-08-29 09:20:21.090690 Test Step 4710 Finished\n",
      "2018-08-29 09:20:21.090840 Test Step 4710 \"min loss\" =  12.475284\n",
      "2018-08-29 09:20:21.090904 Test Step 4710 \"loss\" =  12.898668\n",
      "2018-08-29 09:20:21.138149 Training Step 4710 Finished Timing (Training: 0.909675, Test: 0.0840457) after 0.248273 seconds\n",
      "2018-08-29 09:20:21.138305 Training Step 4710 \"min loss\" =  1.7251519\n",
      "2018-08-29 09:20:21.138384 Training Step 4710 \"loss\" =  2.0094411\n",
      "2018-08-29 09:20:21.341043 Test Step 4715 Finished\n",
      "2018-08-29 09:20:21.341711 Test Step 4715 \"min loss\" =  12.475284\n",
      "2018-08-29 09:20:21.341837 Test Step 4715 \"loss\" =  12.822631\n",
      "2018-08-29 09:20:21.386752 Training Step 4715 Finished Timing (Training: 0.910572, Test: 0.0835567) after 0.248264 seconds\n",
      "2018-08-29 09:20:21.386884 Training Step 4715 \"min loss\" =  1.7251519\n",
      "2018-08-29 09:20:21.387925 Training Step 4715 \"loss\" =  2.1058767\n",
      "2018-08-29 09:20:21.590214 Test Step 4720 Finished\n",
      "2018-08-29 09:20:21.590373 Test Step 4720 \"min loss\" =  12.475284\n",
      "2018-08-29 09:20:21.591292 Test Step 4720 \"loss\" =  13.286977\n",
      "2018-08-29 09:20:21.636872 Training Step 4720 Finished Timing (Training: 0.909067, Test: 0.08368) after 0.248817 seconds\n",
      "2018-08-29 09:20:21.637014 Training Step 4720 \"min loss\" =  1.7251519\n",
      "2018-08-29 09:20:21.637566 Training Step 4720 \"loss\" =  2.1616132\n",
      "2018-08-29 09:20:21.838270 Test Step 4725 Finished\n",
      "2018-08-29 09:20:21.838414 Test Step 4725 \"min loss\" =  12.475284\n",
      "2018-08-29 09:20:21.838485 Test Step 4725 \"loss\" =  13.648318\n",
      "2018-08-29 09:20:21.884233 Training Step 4725 Finished Timing (Training: 0.909273, Test: 0.0833713) after 0.246572 seconds\n",
      "2018-08-29 09:20:21.884383 Training Step 4725 \"min loss\" =  1.7251519\n",
      "2018-08-29 09:20:21.884475 Training Step 4725 \"loss\" =  2.0151544\n",
      "2018-08-29 09:20:22.086769 Test Step 4730 Finished\n",
      "2018-08-29 09:20:22.086915 Test Step 4730 \"min loss\" =  12.475284\n",
      "2018-08-29 09:20:22.086983 Test Step 4730 \"loss\" =  13.877625\n",
      "2018-08-29 09:20:22.132118 Training Step 4730 Finished Timing (Training: 0.909976, Test: 0.0834487) after 0.247569 seconds\n",
      "2018-08-29 09:20:22.132254 Training Step 4730 \"min loss\" =  1.7251519\n",
      "2018-08-29 09:20:22.132865 Training Step 4730 \"loss\" =  1.9156101\n",
      "2018-08-29 09:20:22.333952 Test Step 4735 Finished\n",
      "2018-08-29 09:20:22.334092 Test Step 4735 \"min loss\" =  12.475284\n",
      "2018-08-29 09:20:22.334160 Test Step 4735 \"loss\" =  13.963461\n",
      "2018-08-29 09:20:22.380360 Training Step 4735 Finished Timing (Training: 0.909754, Test: 0.0833042) after 0.247405 seconds\n",
      "2018-08-29 09:20:22.380506 Training Step 4735 \"min loss\" =  1.7251519\n",
      "2018-08-29 09:20:22.380594 Training Step 4735 \"loss\" =  1.9359416\n",
      "2018-08-29 09:20:22.584296 Test Step 4740 Finished\n",
      "2018-08-29 09:20:22.584447 Test Step 4740 \"min loss\" =  12.475284\n",
      "2018-08-29 09:20:22.584521 Test Step 4740 \"loss\" =  13.319452\n",
      "2018-08-29 09:20:22.629699 Training Step 4740 Finished Timing (Training: 0.9096, Test: 0.0835829) after 0.248245 seconds\n",
      "2018-08-29 09:20:22.630167 Training Step 4740 \"min loss\" =  1.7251519\n",
      "2018-08-29 09:20:22.630239 Training Step 4740 \"loss\" =  1.9124521\n",
      "2018-08-29 09:20:22.832809 Test Step 4745 Finished\n",
      "2018-08-29 09:20:22.833499 Test Step 4745 \"min loss\" =  12.475284\n",
      "2018-08-29 09:20:22.833728 Test Step 4745 \"loss\" =  13.603136\n",
      "2018-08-29 09:20:22.879230 Training Step 4745 Finished Timing (Training: 0.909372, Test: 0.0835776) after 0.248384 seconds\n",
      "2018-08-29 09:20:22.879387 Training Step 4745 \"min loss\" =  1.7251519\n",
      "2018-08-29 09:20:22.879867 Training Step 4745 \"loss\" =  2.130569\n",
      "2018-08-29 09:20:23.081694 Test Step 4750 Finished\n",
      "2018-08-29 09:20:23.081852 Test Step 4750 \"min loss\" =  12.475284\n",
      "2018-08-29 09:20:23.082868 Test Step 4750 \"loss\" =  13.806392\n",
      "2018-08-29 09:20:23.128651 Training Step 4750 Finished Timing (Training: 0.909127, Test: 0.0834913) after 0.24839 seconds\n",
      "2018-08-29 09:20:23.128796 Training Step 4750 \"min loss\" =  1.7251519\n",
      "2018-08-29 09:20:23.129493 Training Step 4750 \"loss\" =  2.099472\n",
      "2018-08-29 09:20:23.331693 Test Step 4755 Finished\n",
      "2018-08-29 09:20:23.332353 Test Step 4755 \"min loss\" =  12.475284\n",
      "2018-08-29 09:20:23.332767 Test Step 4755 \"loss\" =  12.943097\n",
      "2018-08-29 09:20:23.378335 Training Step 4755 Finished Timing (Training: 0.908858, Test: 0.0834381) after 0.248741 seconds\n",
      "2018-08-29 09:20:23.378915 Training Step 4755 \"min loss\" =  1.6892508\n",
      "2018-08-29 09:20:23.379060 Training Step 4755 \"loss\" =  2.0751274\n",
      "2018-08-29 09:20:23.580810 Test Step 4760 Finished\n",
      "2018-08-29 09:20:23.581438 Test Step 4760 \"min loss\" =  12.475284\n",
      "2018-08-29 09:20:23.581520 Test Step 4760 \"loss\" =  13.083289\n",
      "2018-08-29 09:20:23.626918 Training Step 4760 Finished Timing (Training: 0.908697, Test: 0.0834001) after 0.246925 seconds\n",
      "2018-08-29 09:20:23.627048 Training Step 4760 \"min loss\" =  1.6892508\n",
      "2018-08-29 09:20:23.627728 Training Step 4760 \"loss\" =  1.8373667\n",
      "2018-08-29 09:20:23.829595 Test Step 4765 Finished\n",
      "2018-08-29 09:20:23.830183 Test Step 4765 \"min loss\" =  12.470445\n",
      "2018-08-29 09:20:23.830258 Test Step 4765 \"loss\" =  12.470445\n",
      "2018-08-29 09:20:23.876395 Training Step 4765 Finished Timing (Training: 0.908498, Test: 0.0833368) after 0.248557 seconds\n",
      "2018-08-29 09:20:23.876527 Training Step 4765 \"min loss\" =  1.6892508\n",
      "2018-08-29 09:20:23.876653 Training Step 4765 \"loss\" =  1.9162326\n",
      "2018-08-29 09:20:24.078629 Test Step 4770 Finished\n",
      "2018-08-29 09:20:24.078776 Test Step 4770 \"min loss\" =  12.470445\n",
      "2018-08-29 09:20:24.079511 Test Step 4770 \"loss\" =  12.946119\n",
      "2018-08-29 09:20:24.124690 Training Step 4770 Finished Timing (Training: 0.908673, Test: 0.0833553) after 0.247946 seconds\n",
      "2018-08-29 09:20:24.124843 Training Step 4770 \"min loss\" =  1.6892508\n",
      "2018-08-29 09:20:24.124907 Training Step 4770 \"loss\" =  2.0779161\n",
      "2018-08-29 09:20:24.327128 Test Step 4775 Finished\n",
      "2018-08-29 09:20:24.327268 Test Step 4775 \"min loss\" =  12.470445\n",
      "2018-08-29 09:20:24.327334 Test Step 4775 \"loss\" =  13.542931\n",
      "2018-08-29 09:20:24.373682 Training Step 4775 Finished Timing (Training: 0.908658, Test: 0.0834585) after 0.248686 seconds\n",
      "2018-08-29 09:20:24.373850 Training Step 4775 \"min loss\" =  1.6755185\n",
      "2018-08-29 09:20:24.373917 Training Step 4775 \"loss\" =  1.6755185\n",
      "2018-08-29 09:20:24.575082 Test Step 4780 Finished\n",
      "2018-08-29 09:20:24.575230 Test Step 4780 \"min loss\" =  12.470445\n",
      "2018-08-29 09:20:24.575986 Test Step 4780 \"loss\" =  13.238381\n",
      "2018-08-29 09:20:24.621636 Training Step 4780 Finished Timing (Training: 0.908807, Test: 0.0834559) after 0.247631 seconds\n",
      "2018-08-29 09:20:24.621820 Training Step 4780 \"min loss\" =  1.6755185\n",
      "2018-08-29 09:20:24.621896 Training Step 4780 \"loss\" =  1.8831465\n",
      "2018-08-29 09:20:24.823510 Test Step 4785 Finished\n",
      "2018-08-29 09:20:24.823704 Test Step 4785 \"min loss\" =  12.470445\n",
      "2018-08-29 09:20:24.823813 Test Step 4785 \"loss\" =  13.351935\n",
      "2018-08-29 09:20:24.870187 Training Step 4785 Finished Timing (Training: 0.909042, Test: 0.0834827) after 0.248199 seconds\n",
      "2018-08-29 09:20:24.870336 Training Step 4785 \"min loss\" =  1.6124171\n",
      "2018-08-29 09:20:24.870938 Training Step 4785 \"loss\" =  1.9139901\n",
      "2018-08-29 09:20:25.072489 Test Step 4790 Finished\n",
      "2018-08-29 09:20:25.072731 Test Step 4790 \"min loss\" =  12.470445\n",
      "2018-08-29 09:20:25.072872 Test Step 4790 \"loss\" =  12.870319\n",
      "2018-08-29 09:20:25.119080 Training Step 4790 Finished Timing (Training: 0.909047, Test: 0.0835323) after 0.247856 seconds\n",
      "2018-08-29 09:20:25.119211 Training Step 4790 \"min loss\" =  1.6124171\n",
      "2018-08-29 09:20:25.119757 Training Step 4790 \"loss\" =  1.943935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:20:25.320782 Test Step 4795 Finished\n",
      "2018-08-29 09:20:25.320917 Test Step 4795 \"min loss\" =  12.470445\n",
      "2018-08-29 09:20:25.320986 Test Step 4795 \"loss\" =  13.603021\n",
      "2018-08-29 09:20:25.366113 Training Step 4795 Finished Timing (Training: 0.909176, Test: 0.0835627) after 0.246275 seconds\n",
      "2018-08-29 09:20:25.366245 Training Step 4795 \"min loss\" =  1.6124171\n",
      "2018-08-29 09:20:25.366854 Training Step 4795 \"loss\" =  2.0070643\n",
      "2018-08-29 09:20:25.568654 Test Step 4800 Finished\n",
      "2018-08-29 09:20:25.568811 Test Step 4800 \"min loss\" =  12.470445\n",
      "2018-08-29 09:20:25.569833 Test Step 4800 \"loss\" =  14.182566\n",
      "2018-08-29 09:20:25.615330 Training Step 4800 Finished Timing (Training: 0.909133, Test: 0.0835343) after 0.248393 seconds\n",
      "2018-08-29 09:20:25.615477 Training Step 4800 \"min loss\" =  1.6124171\n",
      "2018-08-29 09:20:25.616336 Training Step 4800 \"loss\" =  1.8947392\n",
      "2018-08-29 09:20:25.817592 Test Step 4805 Finished\n",
      "2018-08-29 09:20:25.817752 Test Step 4805 \"min loss\" =  12.470445\n",
      "2018-08-29 09:20:25.817827 Test Step 4805 \"loss\" =  13.134249\n",
      "2018-08-29 09:20:25.863789 Training Step 4805 Finished Timing (Training: 0.911748, Test: 0.0831674) after 0.246902 seconds\n",
      "2018-08-29 09:20:25.863930 Training Step 4805 \"min loss\" =  1.6124171\n",
      "2018-08-29 09:20:25.863997 Training Step 4805 \"loss\" =  1.9446758\n",
      "2018-08-29 09:20:26.065757 Test Step 4810 Finished\n",
      "2018-08-29 09:20:26.065942 Test Step 4810 \"min loss\" =  12.470445\n",
      "2018-08-29 09:20:26.066017 Test Step 4810 \"loss\" =  13.066793\n",
      "2018-08-29 09:20:26.111172 Training Step 4810 Finished Timing (Training: 0.912478, Test: 0.0836002) after 0.247091 seconds\n",
      "2018-08-29 09:20:26.111321 Training Step 4810 \"min loss\" =  1.6124171\n",
      "2018-08-29 09:20:26.111387 Training Step 4810 \"loss\" =  1.9974846\n",
      "2018-08-29 09:20:26.313591 Test Step 4815 Finished\n",
      "2018-08-29 09:20:26.314201 Test Step 4815 \"min loss\" =  12.470445\n",
      "2018-08-29 09:20:26.314314 Test Step 4815 \"loss\" =  13.066547\n",
      "2018-08-29 09:20:26.360403 Training Step 4815 Finished Timing (Training: 0.910185, Test: 0.0834347) after 0.248243 seconds\n",
      "2018-08-29 09:20:26.360538 Training Step 4815 \"min loss\" =  1.6124171\n",
      "2018-08-29 09:20:26.360655 Training Step 4815 \"loss\" =  1.9298003\n",
      "2018-08-29 09:20:26.563986 Test Step 4820 Finished\n",
      "2018-08-29 09:20:26.564130 Test Step 4820 \"min loss\" =  12.470445\n",
      "2018-08-29 09:20:26.564194 Test Step 4820 \"loss\" =  13.801294\n",
      "2018-08-29 09:20:26.610493 Training Step 4820 Finished Timing (Training: 0.910839, Test: 0.083723) after 0.249745 seconds\n",
      "2018-08-29 09:20:26.610638 Training Step 4820 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:26.611328 Training Step 4820 \"loss\" =  1.8905666\n",
      "2018-08-29 09:20:26.815020 Test Step 4825 Finished\n",
      "2018-08-29 09:20:26.815186 Test Step 4825 \"min loss\" =  12.470445\n",
      "2018-08-29 09:20:26.815280 Test Step 4825 \"loss\" =  13.4317465\n",
      "2018-08-29 09:20:26.861550 Training Step 4825 Finished Timing (Training: 0.909244, Test: 0.084538) after 0.249933 seconds\n",
      "2018-08-29 09:20:26.861698 Training Step 4825 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:26.862365 Training Step 4825 \"loss\" =  1.977483\n",
      "2018-08-29 09:20:27.064938 Test Step 4830 Finished\n",
      "2018-08-29 09:20:27.065157 Test Step 4830 \"min loss\" =  12.470445\n",
      "2018-08-29 09:20:27.065281 Test Step 4830 \"loss\" =  12.84092\n",
      "2018-08-29 09:20:27.110660 Training Step 4830 Finished Timing (Training: 0.909208, Test: 0.0844238) after 0.247887 seconds\n",
      "2018-08-29 09:20:27.110808 Training Step 4830 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:27.111327 Training Step 4830 \"loss\" =  1.9777112\n",
      "2018-08-29 09:20:27.313645 Test Step 4835 Finished\n",
      "2018-08-29 09:20:27.313805 Test Step 4835 \"min loss\" =  12.470445\n",
      "2018-08-29 09:20:27.313879 Test Step 4835 \"loss\" =  14.01821\n",
      "2018-08-29 09:20:27.359059 Training Step 4835 Finished Timing (Training: 0.909304, Test: 0.0843311) after 0.247178 seconds\n",
      "2018-08-29 09:20:27.359206 Training Step 4835 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:27.359958 Training Step 4835 \"loss\" =  2.1298113\n",
      "2018-08-29 09:20:27.562004 Test Step 4840 Finished\n",
      "2018-08-29 09:20:27.562159 Test Step 4840 \"min loss\" =  12.470445\n",
      "2018-08-29 09:20:27.562232 Test Step 4840 \"loss\" =  13.070671\n",
      "2018-08-29 09:20:27.609920 Training Step 4840 Finished Timing (Training: 0.909541, Test: 0.0840806) after 0.249583 seconds\n",
      "2018-08-29 09:20:27.610113 Training Step 4840 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:27.610907 Training Step 4840 \"loss\" =  2.0957117\n",
      "2018-08-29 09:20:27.812713 Test Step 4845 Finished\n",
      "2018-08-29 09:20:27.812867 Test Step 4845 \"min loss\" =  12.470445\n",
      "2018-08-29 09:20:27.812930 Test Step 4845 \"loss\" =  13.234975\n",
      "2018-08-29 09:20:27.859377 Training Step 4845 Finished Timing (Training: 0.908915, Test: 0.0840525) after 0.248035 seconds\n",
      "2018-08-29 09:20:27.859527 Training Step 4845 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:27.859651 Training Step 4845 \"loss\" =  1.90037\n",
      "2018-08-29 09:20:28.061937 Test Step 4850 Finished\n",
      "2018-08-29 09:20:28.062141 Test Step 4850 \"min loss\" =  12.470445\n",
      "2018-08-29 09:20:28.062217 Test Step 4850 \"loss\" =  13.168032\n",
      "2018-08-29 09:20:28.108251 Training Step 4850 Finished Timing (Training: 0.909155, Test: 0.0839037) after 0.248501 seconds\n",
      "2018-08-29 09:20:28.108378 Training Step 4850 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:28.108463 Training Step 4850 \"loss\" =  1.8579757\n",
      "2018-08-29 09:20:28.310991 Test Step 4855 Finished\n",
      "2018-08-29 09:20:28.311145 Test Step 4855 \"min loss\" =  12.470445\n",
      "2018-08-29 09:20:28.312130 Test Step 4855 \"loss\" =  13.201804\n",
      "2018-08-29 09:20:28.358050 Training Step 4855 Finished Timing (Training: 0.909283, Test: 0.0837959) after 0.249511 seconds\n",
      "2018-08-29 09:20:28.358180 Training Step 4855 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:28.358269 Training Step 4855 \"loss\" =  1.9888419\n",
      "2018-08-29 09:20:28.560139 Test Step 4860 Finished\n",
      "2018-08-29 09:20:28.560360 Test Step 4860 \"min loss\" =  12.470445\n",
      "2018-08-29 09:20:28.560486 Test Step 4860 \"loss\" =  12.939189\n",
      "2018-08-29 09:20:28.605803 Training Step 4860 Finished Timing (Training: 0.909287, Test: 0.0837578) after 0.246496 seconds\n",
      "2018-08-29 09:20:28.605928 Training Step 4860 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:28.605988 Training Step 4860 \"loss\" =  1.7441839\n",
      "2018-08-29 09:20:28.807165 Test Step 4865 Finished\n",
      "2018-08-29 09:20:28.807326 Test Step 4865 \"min loss\" =  12.470445\n",
      "2018-08-29 09:20:28.807404 Test Step 4865 \"loss\" =  13.46904\n",
      "2018-08-29 09:20:28.853660 Training Step 4865 Finished Timing (Training: 0.909377, Test: 0.0837254) after 0.247597 seconds\n",
      "2018-08-29 09:20:28.853796 Training Step 4865 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:28.854546 Training Step 4865 \"loss\" =  1.7253094\n",
      "2018-08-29 09:20:29.056124 Test Step 4870 Finished\n",
      "2018-08-29 09:20:29.056272 Test Step 4870 \"min loss\" =  12.470445\n",
      "2018-08-29 09:20:29.056964 Test Step 4870 \"loss\" =  13.354181\n",
      "2018-08-29 09:20:29.102772 Training Step 4870 Finished Timing (Training: 0.909327, Test: 0.0836943) after 0.248129 seconds\n",
      "2018-08-29 09:20:29.102910 Training Step 4870 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:29.103613 Training Step 4870 \"loss\" =  1.7377282\n",
      "2018-08-29 09:20:29.304268 Test Step 4875 Finished\n",
      "2018-08-29 09:20:29.304453 Test Step 4875 \"min loss\" =  12.470445\n",
      "2018-08-29 09:20:29.304578 Test Step 4875 \"loss\" =  12.837775\n",
      "2018-08-29 09:20:29.350159 Training Step 4875 Finished Timing (Training: 0.909453, Test: 0.0836481) after 0.246459 seconds\n",
      "2018-08-29 09:20:29.350289 Training Step 4875 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:29.350359 Training Step 4875 \"loss\" =  2.2133245\n",
      "2018-08-29 09:20:29.551792 Test Step 4880 Finished\n",
      "2018-08-29 09:20:29.551945 Test Step 4880 \"min loss\" =  12.470445\n",
      "2018-08-29 09:20:29.552018 Test Step 4880 \"loss\" =  12.873861\n",
      "2018-08-29 09:20:29.597993 Training Step 4880 Finished Timing (Training: 0.909613, Test: 0.0837607) after 0.247552 seconds\n",
      "2018-08-29 09:20:29.598134 Training Step 4880 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:29.598800 Training Step 4880 \"loss\" =  1.8499286\n",
      "2018-08-29 09:20:29.800580 Test Step 4885 Finished\n",
      "2018-08-29 09:20:29.801188 Test Step 4885 \"min loss\" =  12.470445\n",
      "2018-08-29 09:20:29.801345 Test Step 4885 \"loss\" =  13.179801\n",
      "2018-08-29 09:20:29.847525 Training Step 4885 Finished Timing (Training: 0.909572, Test: 0.0837524) after 0.248642 seconds\n",
      "2018-08-29 09:20:29.847666 Training Step 4885 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:29.847788 Training Step 4885 \"loss\" =  1.9922943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:20:30.051512 Test Step 4890 Finished\n",
      "2018-08-29 09:20:30.051676 Test Step 4890 \"min loss\" =  12.470445\n",
      "2018-08-29 09:20:30.051788 Test Step 4890 \"loss\" =  12.617145\n",
      "2018-08-29 09:20:30.097219 Training Step 4890 Finished Timing (Training: 0.909647, Test: 0.0838715) after 0.249344 seconds\n",
      "2018-08-29 09:20:30.097370 Training Step 4890 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:30.097462 Training Step 4890 \"loss\" =  1.9578857\n",
      "2018-08-29 09:20:30.300080 Test Step 4895 Finished\n",
      "2018-08-29 09:20:30.300294 Test Step 4895 \"min loss\" =  12.470445\n",
      "2018-08-29 09:20:30.301274 Test Step 4895 \"loss\" =  12.899651\n",
      "2018-08-29 09:20:30.346900 Training Step 4895 Finished Timing (Training: 0.909508, Test: 0.0839033) after 0.249363 seconds\n",
      "2018-08-29 09:20:30.347049 Training Step 4895 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:30.347124 Training Step 4895 \"loss\" =  2.0157647\n",
      "2018-08-29 09:20:30.549586 Test Step 4900 Finished\n",
      "2018-08-29 09:20:30.550257 Test Step 4900 \"min loss\" =  12.470445\n",
      "2018-08-29 09:20:30.550669 Test Step 4900 \"loss\" =  12.956878\n",
      "2018-08-29 09:20:30.596081 Training Step 4900 Finished Timing (Training: 0.909403, Test: 0.083946) after 0.248439 seconds\n",
      "2018-08-29 09:20:30.596229 Training Step 4900 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:30.596989 Training Step 4900 \"loss\" =  1.9897449\n",
      "2018-08-29 09:20:30.798523 Test Step 4905 Finished\n",
      "2018-08-29 09:20:30.798674 Test Step 4905 \"min loss\" =  12.470445\n",
      "2018-08-29 09:20:30.799576 Test Step 4905 \"loss\" =  13.564465\n",
      "2018-08-29 09:20:30.845073 Training Step 4905 Finished Timing (Training: 0.910511, Test: 0.0832911) after 0.247646 seconds\n",
      "2018-08-29 09:20:30.845216 Training Step 4905 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:30.846095 Training Step 4905 \"loss\" =  2.128427\n",
      "2018-08-29 09:20:31.048709 Test Step 4910 Finished\n",
      "2018-08-29 09:20:31.048880 Test Step 4910 \"min loss\" =  12.470445\n",
      "2018-08-29 09:20:31.048954 Test Step 4910 \"loss\" =  12.894359\n",
      "2018-08-29 09:20:31.095316 Training Step 4910 Finished Timing (Training: 0.90943, Test: 0.084528) after 0.249124 seconds\n",
      "2018-08-29 09:20:31.095459 Training Step 4910 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:31.096079 Training Step 4910 \"loss\" =  2.1759713\n",
      "2018-08-29 09:20:31.297422 Test Step 4915 Finished\n",
      "2018-08-29 09:20:31.297598 Test Step 4915 \"min loss\" =  12.470445\n",
      "2018-08-29 09:20:31.298479 Test Step 4915 \"loss\" =  12.887448\n",
      "2018-08-29 09:20:31.343626 Training Step 4915 Finished Timing (Training: 0.909036, Test: 0.0841859) after 0.247452 seconds\n",
      "2018-08-29 09:20:31.343773 Training Step 4915 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:31.343837 Training Step 4915 \"loss\" =  1.9581913\n",
      "2018-08-29 09:20:31.546109 Test Step 4920 Finished\n",
      "2018-08-29 09:20:31.546783 Test Step 4920 \"min loss\" =  12.470445\n",
      "2018-08-29 09:20:31.546864 Test Step 4920 \"loss\" =  13.0848875\n",
      "2018-08-29 09:20:31.592710 Training Step 4920 Finished Timing (Training: 0.909919, Test: 0.0838424) after 0.2488 seconds\n",
      "2018-08-29 09:20:31.592855 Training Step 4920 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:31.592916 Training Step 4920 \"loss\" =  1.7644577\n",
      "2018-08-29 09:20:31.796191 Test Step 4925 Finished\n",
      "2018-08-29 09:20:31.796708 Test Step 4925 \"min loss\" =  12.437172\n",
      "2018-08-29 09:20:31.797315 Test Step 4925 \"loss\" =  12.437172\n",
      "2018-08-29 09:20:31.842998 Training Step 4925 Finished Timing (Training: 0.90946, Test: 0.0839464) after 0.249974 seconds\n",
      "2018-08-29 09:20:31.843144 Training Step 4925 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:31.843249 Training Step 4925 \"loss\" =  2.0480583\n",
      "2018-08-29 09:20:32.045074 Test Step 4930 Finished\n",
      "2018-08-29 09:20:32.045707 Test Step 4930 \"min loss\" =  12.437172\n",
      "2018-08-29 09:20:32.045784 Test Step 4930 \"loss\" =  12.983702\n",
      "2018-08-29 09:20:32.091906 Training Step 4930 Finished Timing (Training: 0.909556, Test: 0.0837509) after 0.248521 seconds\n",
      "2018-08-29 09:20:32.092051 Training Step 4930 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:32.092120 Training Step 4930 \"loss\" =  1.9009968\n",
      "2018-08-29 09:20:32.294217 Test Step 4935 Finished\n",
      "2018-08-29 09:20:32.294377 Test Step 4935 \"min loss\" =  12.437172\n",
      "2018-08-29 09:20:32.295214 Test Step 4935 \"loss\" =  12.726719\n",
      "2018-08-29 09:20:32.340559 Training Step 4935 Finished Timing (Training: 0.909749, Test: 0.0837055) after 0.248358 seconds\n",
      "2018-08-29 09:20:32.340725 Training Step 4935 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:32.341476 Training Step 4935 \"loss\" =  1.7623738\n",
      "2018-08-29 09:20:32.542427 Test Step 4940 Finished\n",
      "2018-08-29 09:20:32.542567 Test Step 4940 \"min loss\" =  12.437172\n",
      "2018-08-29 09:20:32.543135 Test Step 4940 \"loss\" =  12.805864\n",
      "2018-08-29 09:20:32.588874 Training Step 4940 Finished Timing (Training: 0.909487, Test: 0.0835393) after 0.247089 seconds\n",
      "2018-08-29 09:20:32.589333 Training Step 4940 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:32.589678 Training Step 4940 \"loss\" =  1.726634\n",
      "2018-08-29 09:20:32.790719 Test Step 4945 Finished\n",
      "2018-08-29 09:20:32.790862 Test Step 4945 \"min loss\" =  12.437172\n",
      "2018-08-29 09:20:32.790935 Test Step 4945 \"loss\" =  13.24293\n",
      "2018-08-29 09:20:32.837376 Training Step 4945 Finished Timing (Training: 0.909659, Test: 0.0835059) after 0.247473 seconds\n",
      "2018-08-29 09:20:32.837522 Training Step 4945 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:32.837602 Training Step 4945 \"loss\" =  1.8753825\n",
      "2018-08-29 09:20:33.038953 Test Step 4950 Finished\n",
      "2018-08-29 09:20:33.039136 Test Step 4950 \"min loss\" =  12.437172\n",
      "2018-08-29 09:20:33.039854 Test Step 4950 \"loss\" =  12.787363\n",
      "2018-08-29 09:20:33.084858 Training Step 4950 Finished Timing (Training: 0.909883, Test: 0.0834228) after 0.247168 seconds\n",
      "2018-08-29 09:20:33.085003 Training Step 4950 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:33.085646 Training Step 4950 \"loss\" =  1.9961808\n",
      "2018-08-29 09:20:33.286486 Test Step 4955 Finished\n",
      "2018-08-29 09:20:33.287088 Test Step 4955 \"min loss\" =  12.437172\n",
      "2018-08-29 09:20:33.287421 Test Step 4955 \"loss\" =  12.976875\n",
      "2018-08-29 09:20:33.332865 Training Step 4955 Finished Timing (Training: 0.909752, Test: 0.0834501) after 0.247113 seconds\n",
      "2018-08-29 09:20:33.333008 Training Step 4955 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:33.333521 Training Step 4955 \"loss\" =  1.9324087\n",
      "2018-08-29 09:20:33.534990 Test Step 4960 Finished\n",
      "2018-08-29 09:20:33.535652 Test Step 4960 \"min loss\" =  12.437172\n",
      "2018-08-29 09:20:33.535730 Test Step 4960 \"loss\" =  12.556425\n",
      "2018-08-29 09:20:33.581616 Training Step 4960 Finished Timing (Training: 0.909563, Test: 0.0834518) after 0.247923 seconds\n",
      "2018-08-29 09:20:33.581766 Training Step 4960 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:33.582421 Training Step 4960 \"loss\" =  2.0492425\n",
      "2018-08-29 09:20:33.783862 Test Step 4965 Finished\n",
      "2018-08-29 09:20:33.784471 Test Step 4965 \"min loss\" =  12.437172\n",
      "2018-08-29 09:20:33.784545 Test Step 4965 \"loss\" =  12.819899\n",
      "2018-08-29 09:20:33.830371 Training Step 4965 Finished Timing (Training: 0.909384, Test: 0.0834226) after 0.247838 seconds\n",
      "2018-08-29 09:20:33.830518 Training Step 4965 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:33.831243 Training Step 4965 \"loss\" =  1.9081188\n",
      "2018-08-29 09:20:34.033184 Test Step 4970 Finished\n",
      "2018-08-29 09:20:34.033342 Test Step 4970 \"min loss\" =  12.437172\n",
      "2018-08-29 09:20:34.033413 Test Step 4970 \"loss\" =  13.581618\n",
      "2018-08-29 09:20:34.079441 Training Step 4970 Finished Timing (Training: 0.909346, Test: 0.0835555) after 0.24796 seconds\n",
      "2018-08-29 09:20:34.079597 Training Step 4970 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:34.079675 Training Step 4970 \"loss\" =  2.0714586\n",
      "2018-08-29 09:20:34.282052 Test Step 4975 Finished\n",
      "2018-08-29 09:20:34.282205 Test Step 4975 \"min loss\" =  12.437172\n",
      "2018-08-29 09:20:34.282989 Test Step 4975 \"loss\" =  13.036976\n",
      "2018-08-29 09:20:34.328975 Training Step 4975 Finished Timing (Training: 0.909081, Test: 0.0834716) after 0.247989 seconds\n",
      "2018-08-29 09:20:34.329142 Training Step 4975 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:34.330062 Training Step 4975 \"loss\" =  1.9121172\n",
      "2018-08-29 09:20:34.531313 Test Step 4980 Finished\n",
      "2018-08-29 09:20:34.531874 Test Step 4980 \"min loss\" =  12.437172\n",
      "2018-08-29 09:20:34.531957 Test Step 4980 \"loss\" =  12.689394\n",
      "2018-08-29 09:20:34.577655 Training Step 4980 Finished Timing (Training: 0.909044, Test: 0.0833844) after 0.247462 seconds\n",
      "2018-08-29 09:20:34.578232 Training Step 4980 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:34.578362 Training Step 4980 \"loss\" =  1.7736568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-29 09:20:34.780987 Test Step 4985 Finished\n",
      "2018-08-29 09:20:34.781600 Test Step 4985 \"min loss\" =  12.387922\n",
      "2018-08-29 09:20:34.781719 Test Step 4985 \"loss\" =  12.387922\n",
      "2018-08-29 09:20:34.827167 Training Step 4985 Finished Timing (Training: 0.909064, Test: 0.0833934) after 0.248658 seconds\n",
      "2018-08-29 09:20:34.827384 Training Step 4985 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:34.827516 Training Step 4985 \"loss\" =  2.0880363\n",
      "2018-08-29 09:20:35.030010 Test Step 4990 Finished\n",
      "2018-08-29 09:20:35.030148 Test Step 4990 \"min loss\" =  12.387922\n",
      "2018-08-29 09:20:35.030930 Test Step 4990 \"loss\" =  13.151239\n",
      "2018-08-29 09:20:35.076067 Training Step 4990 Finished Timing (Training: 0.909147, Test: 0.0833805) after 0.248396 seconds\n",
      "2018-08-29 09:20:35.076193 Training Step 4990 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:35.076885 Training Step 4990 \"loss\" =  1.9412118\n",
      "2018-08-29 09:20:35.278838 Test Step 4995 Finished\n",
      "2018-08-29 09:20:35.279498 Test Step 4995 \"min loss\" =  12.387922\n",
      "2018-08-29 09:20:35.279888 Test Step 4995 \"loss\" =  12.65126\n",
      "2018-08-29 09:20:35.325336 Training Step 4995 Finished Timing (Training: 0.908889, Test: 0.0835195) after 0.248351 seconds\n",
      "2018-08-29 09:20:35.325487 Training Step 4995 \"min loss\" =  1.5589557\n",
      "2018-08-29 09:20:35.325554 Training Step 4995 \"loss\" =  2.1257308\n",
      "2018-08-29 09:20:36.095141 Test Step 5000 Finished\n",
      "2018-08-29 09:20:36.095349 Training completed, starting cleanup!\n",
      "2018-08-29 09:20:36.096093 Cleanup completed!\n"
     ]
    }
   ],
   "source": [
    "class SA1Experiment():\n",
    "    def __init__(self, neurons, blocks):\n",
    "        self.blocks = blocks\n",
    "        self.neurons = neurons\n",
    "    \n",
    "    def create_network(self, net, input):\n",
    "        net.create_network(input)\n",
    "        net.make_embedding_layer(self.neurons)\n",
    "        net.make_dropout_layer()\n",
    "        \n",
    "        for _ in range(self.blocks):\n",
    "            net.make_graphcnn_layer(self.neurons)\n",
    "            net.make_dropout_layer()\n",
    "            net.make_embedding_layer(self.neurons)\n",
    "            net.make_dropout_layer()\n",
    "        \n",
    "        net.make_auxilary_embedding_layer(self.neurons)\n",
    "        net.make_auxilary_dropout_layer()\n",
    "#         net.make_reverse_auxilary_linkage_layer(self.neurons)\n",
    "# #         net.make_auxilary_embedding_layer(self.neurons)\n",
    "# #         net.make_auxilary_dropout_layer()\n",
    "#         net.make_auxilary_graphcnn_layer(self.neurons)\n",
    "#         net.make_auxilary_dropout_layer()\n",
    "        net.make_auxilary_linkage_layer(0)\n",
    "        \n",
    "        net.make_embedding_layer(self.neurons)\n",
    "        net.make_embedding_layer(1, name='final', with_bn=False, with_act_func = False)\n",
    "\n",
    "\n",
    "no_folds = 10\n",
    "inst = KFold(n_splits = no_folds, shuffle=True, random_state=125)\n",
    "\n",
    "l = 2\n",
    "n = 128\n",
    "i = 4\n",
    "\n",
    "    \n",
    "exp = experiment.GGCNNExperiment('2018-08-28-SA1SA2', '2018-08-28-SA1SA2', SA1Experiment(neurons = n, blocks = l))\n",
    "\n",
    "\n",
    "exp.num_iterations = 5000\n",
    "exp.optimizer = 'adam'\n",
    "exp.loss_type = 'linear'\n",
    "\n",
    "exp.debug = True  # Was True\n",
    "\n",
    "exp.preprocess_data(dataset)\n",
    "\n",
    "# train_idx, test_idx = list(inst.split(np.arange(len(dataset[0]))))[i]\n",
    "test_idx, train_idx = list(inst.split(np.arange(len(dataset[0]))))[i]  # Reversed to get more samples in the test set than the training set\n",
    "\n",
    "\n",
    "exp.create_data(train_idx, test_idx)\n",
    "exp.build_network()\n",
    "results = exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(results[0])\n",
    "test_df = pd.DataFrame(results[1])\n",
    "test_df.set_index(test_df.index * exp.iterations_per_test, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_df['accuracy'].plot()\n",
    "test_df['accuracy'].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['cross_entropy'].loc[10:].plot()\n",
    "test_df['cross_entropy'].loc[10:].plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.887605667114258\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_df['loss'].loc[500:].plot()\n",
    "test_df['loss'].loc[500:].plot()\n",
    "train_df['min loss'].loc[500:].plot()\n",
    "test_df['min loss'].loc[500:].plot()\n",
    "print(test_df['min loss'].iloc[-1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = results[-1].ravel()[test_idx]\n",
    "actual = dataset[2].ravel()[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max error:  31.96836334612675\n"
     ]
    }
   ],
   "source": [
    "plt.scatter(actual, predictions); plt.xlabel('Actual'); plt.ylabel('Predicted'); plt.show()\n",
    "print('Max error: ', np.max(np.abs(actual - predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(actual - predictions, bins = 80); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "sklearn.metrics.r2_score(predictions, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(predictions, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
